{
    "status": "success",
    "message": "Files processed successfully",
    "result": {
        "tables": [
            {
                "Electric_Vehicle_Population_Data": [
                    "VIN (1-10)",
                    "County",
                    "City",
                    "State",
                    "Postal Code",
                    "Model Year",
                    "Make",
                    "Model",
                    "Electric Vehicle Type",
                    "Clean Alternative Fuel Vehicle (CAFV) Eligibility",
                    "Electric Range",
                    "Base MSRP",
                    "Legislative District",
                    "DOL Vehicle ID",
                    "Vehicle Location",
                    "Electric Utility",
                    "2020 Census Tract"
                ]
            }
        ],
        "analyzed_topics": [
            {
                "topic": "Machine learning models employed in EV adoption prediction",
                "ML_Models": "Regression models, Random Forests, Gradient Boosting Machines",
                "reasoning": "Using geographic data (County, City, State, Postal Code) along with vehicle attributes (Make, Model, Electric Range, MSRP) to predict areas with high potential for EV adoption. This could help target marketing efforts and infrastructure planning based on demographic patterns visible in Census Tract data."
            },
            {
                "topic": "Machine learning models employed in EV charging infrastructure optimization",
                "ML_Models": "Clustering algorithms, Spatial analysis models, Decision trees",
                "reasoning": "Analyzing Vehicle Location, Electric Range, and Electric Utility data to optimize placement of charging stations. ML models could identify underserved areas with high EV concentration or predict optimal charging station locations based on existing EV population density and driving patterns."
            },
            {
                "topic": "Machine learning models employed in EV market segmentation analysis",
                "ML_Models": "K-means clustering, Hierarchical clustering, Neural networks",
                "reasoning": "Using Make, Model, Base MSRP, and Electric Vehicle Type to segment the market and identify consumer preferences across different regions (County, City) and demographics (Census Tract). This helps manufacturers and dealers target specific customer segments with appropriate EV models."
            },
            {
                "topic": "Machine learning models employed in EV policy impact assessment",
                "ML_Models": "Time series analysis, Causal inference models, Bayesian networks",
                "reasoning": "Leveraging Legislative District, CAFV Eligibility, and Model Year data to evaluate how policy incentives affect EV adoption rates across different regions. ML models could predict the effectiveness of potential policy changes on increasing clean vehicle adoption in specific geographic areas."
            }
        ],
        "csv_files": [
            "csv_test/Electric_Vehicle_Population_Data.csv"
        ],
        "topic": [
            "Machine learning models employed in EV adoption prediction",
            "Machine learning models employed in EV charging infrastructure optimization",
            "Machine learning models employed in EV market segmentation analysis",
            "Machine learning models employed in EV policy impact assessment"
        ],
        "ScrapedArticles": {
            "Machine learning models employed in EV adoption prediction": "Using machine learning methods to predict electric vehicles penetration ... : \nYour privacy, your choice\n\nWe use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media.\n\nBy accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection.\n\nSee our privacy policy for more information on the use of your personal data.\n\nManage preferences for further information and to change your choices.\n\nAdvertisement\n\nUsing machine learning methods to predict electric vehicles penetration in the automotive market\n\nScientific Reports\n 13, Article number: 8345 (2023) Cite this article\n\n16k Accesses\n\n1 Altmetric\n\nMetrics\n\nAbstract\n\nElectric vehicles (EVs) have been introduced as an alternative to gasoline and diesel cars to reduce greenhouse gas emissions, optimize fossil fuel use, and protect the environment. Predicting EV sales is momentous for stakeholders, including car manufacturers, policymakers, and fuel suppliers. The data used in the modeling process significantly affects the prediction model’s quality. This research’s primary dataset contains monthly sales and registrations of 357 new vehicles in the United States of America from 2014 to 2020. In addition to this data, several web crawlers were used to gather the required information. Vehicles sale were predicted using long short-term memory (LSTM) and Convolutional LSTM (ConvLSTM) models. To enhance LSTM performance, the hybrid model with a new structure called “Hybrid LSTM with two-dimensional Attention and Residual network” has been proposed. Also, all three models are built as Automated Machine Learning models to improve the modeling process. The proposed hybrid model performs better than the other models based on the same evaluation units, including Mean Absolute Percentage Error, Normalized Root Mean Square Error, R-square, slope, and intercept of fitted linear regressions. The proposed hybrid model has been able to predict the share of EVs with an acceptable Mean Absolute Error of 3.5%.\n\nSimilar content being viewed by others\n\nDeep learning model based prediction of vehicle CO2 emissions with eXplainable AI integration for sustainable environment\n\nDevelopment and evaluation of bidirectional LSTM freeway traffic forecasting models using simulation data\n\nBayesian optimization and deep learning for steering wheel angle prediction\n\nIntroduction\n\nEmissions of greenhouse gases are increasing rapidly worldwide. According to a United States Environmental Protection Agency report released in 2020, the transportation sector produces about 27% of the entire greenhouse gas emissions in the country, which, compared to other sectors, transportation emits the most greenhouse gases1. EVs were introduced as an alternative to gasoline and diesel cars to reduce air pollution and greenhouse gas emissions, optimize the use of natural energy resources and protect the environment. Using electricity generated from renewable energy sources such as wind, water and sunlight for EVs can be one of the most efficient solutions to reduce emissions and climate change2. Although much time has passed since the invention of EVs, internal combustion vehicles are still the most popular. EV sales have been on the rise, and in January 2017, the total number of EVs sold worldwide reached two million3. Globally, EV sales accounted for 9% of the car market in 2021, a fourfold increase from 20194.\n\nDesigning and producing vehicles is time-consuming and requires much investment, so by predicting the number of sales, automobile companies can optimize production, Furthermore, by accurately predicting the penetration of EVs in the market, it is possible to estimate their impact on reducing pollution in the coming years, which is very important from an environmental standpoint. Forecasting the sale of EVs and their penetration into the automotive market has been a significant issue for governments, policymakers, and car manufacturers to plan the production of EVs, set proper policies, and provide sufficient energy and infrastructure.\n\nThe main goal of this research is to apply Machine Learning (ML) methods to build an efficient prediction model to estimate the sale of all vehicles in the dataset, the share of EVs in each segment, and determine the main factors that influence the sales of each EV. The effect of a limited number of influencing factors on vehicle sales was examined in previous studies using different models. For this study, a wide range of information was collected, including all factors that previous studies have proven are related to car sales, and it was used in modeling. LSTM and ConvLSTM, powerful Deep Learning (DL) models, have been used for predicting vehicle sales. By combining the two-dimensional Attention model and the Residual network as the proposed hybrid model, it has been tried to improve the performance of the LSTM model. Additionally, using the collected information and the model sensitivity analysis, it was attempted to determine the most influential factors on the sale of each EV.\n\nThe literature review of this study includes two general sections. The first section examines ML methods used to predict vehicle sales, and the second section provides an overview of the features used in other methods to predict EV sales.\n\nML methods in predicting vehicle sales\n\nSeveral studies have used ML methods to predict the sales of EVs as time-series data. Multiple Linear Regression and Support Vector Machine (SVM) models were compared for predicting vehicle sales using yearly, quarterly and monthly data (the number of new automobile registrations, the number of automobile sales, and economic indicators such as Gross Domestic Product (GDP), Available Personal Income, Consumer Price Index, Interest Rate, Unemployment Rate, Industrial Investment Demand, Petroleum Charge, Private Consumption, and Latent Replacement Demand) in a study by Brühl et al.5 According to the results, the SVM model had better performance based on the error values (Mean Absolute Error and Mean Absolute Percentage Error), was more interpretable, and gave better results based on quarterly data. In the study of Wang et al. ML techniques were used to predict car sales based on sales quantity, economic indicators, wholesale population, unemployment rate, exchange rate, the prices of vehicles, the oil prices, and the prices of vehicle components. Based on evaluation units (R-square and Mean Squared Error), they evaluated the prediction quality of adaptive network-based fuzzy inference system (ANFIS), Artificial Neural Networks (ANN), and autoregressive integrated moving average models; the results showed that ANFIS performed better than the other models6. In another study, Hülsmann et al. compared the performance of linear models, such as Ordinary Least Squares and Quantile Regression, against ML methods like SVM, Decision Tree, k–Nearest Neighbor, and Random Forest for predicting vehicle sales. Based on the monthly data of vehicle sales, new car registrations, and economic indicators (such as GDP, Personal Income and Dow Jones), the Decision Tree of ML methods performed better than the other models based on Mean Absolute Percentage Error (MAPE)7.\n\nMoreover, Kitabci et al. analysed the impact of economic policies on vehicle sales in Turkey as a macro-environmental factor by multiple regression and neural network methods. They assessed factors such as the vehicle loan rate presented by the banks, the income of the consumers, the tax deductions made by the government for the automobile, the inflation rate, automobile prices, the euro exchange rate, oil prices, and advertisements spent by the businesses. According to the results, neural networks were more accurate in predicting sales than regression models; some factors, including the euro exchange rate, the rates of vehicle loans offered by banks, and the government's tax deductions, have influenced automobile sales8. In another research, Bas et al. applied classification ML methods to predict EV adoption using ride-sourcing factors, underlying sociodemographics, and vehicle characteristics; they examined the contributions of different factors to predict outcomes using a method called “Local Interpretable Model-Agnostic Explanations”. Based on the study’s findings, ML models produced highly accurate predictions regarding EV adoption, and the frequent usage of ride-sourcing, knowledge about EVs, and environmental protection awareness were significant factors in explaining the tendency to adopt EVs9. In addition, Zhang et al. applied Singular Spectrum Analysis as a univariate time-series model and the Vector Auto-Regression model (VAR) as a multivariate model for forecasting EV sales. According to the results, the VAR model can significantly improve the prediction accuracy because it considers the effect of economic indicators, such as consumer prices, consumer confidence, producers' prices, fuel and vehicle prices, and Baidu data (An indicator of consumer interest and curiosity in EVs)10.\n\nIn another study, Kaya et al.11 used the exchange rate, the GDP, the Consumer Confidence Index, the Consumer Price Index data and a Deep Neural Network model to predict vehicle sales; the results revealed that this ML model predicted sales accurately (based on Mean Squared Error). In another research, Xia et al. introduced the ForeXGBoost model, a vehicle sales prediction system based on large-scale datasets containing comprehensive vehicle information, including brand ID, model, engine power, and displacement. Based on Logarithmic Difference Square Root, MAPE, and running time, the XGBoost model outperforms benchmark algorithms like Linear Regression and Gradient Boosting Decision Trees12. Using online survey data and ML methods such as SVM, ANN, Deep Neural Networks, Gradient Boosting Models, and Random Forests, Bas et al. compared different methods for classifying potential EV buyers and identifying the features that affect the adoption of EVs. Results showed that the SVM model outperforms the other algorithms; having only partial information (e.g. only socioeconomic factors) reduces model performance, while synergy across multiple variables increases accuracy13. Additionally, Saxena et al. present a study that examines the use of deep learning-based models, including Autoregressive Integration Moving Averages and LSTM models, to predict future directions of vehicle sales. Based on the implementation results, the MAE and the Root Mean Square Error for LSTM-based time series forecasting were reduced, and this model could accurately predict green vehicle sales14.\n\nFactors affecting the sale of EVs in other methods\n\nDeveloping policies requires understanding users' behavior and prioritizing their choices. Therefore, some previous studies used survey data to predict EV demand. To assess the potential demand for EVs, Beggs et al.15 used survey data and vehicle specifications, such as seat capacity, maximum speed, purchase price, and operating costs. In a similar study, the demand for EVs was estimated based on consumer preferences for vehicle attributes by Calfee et al.16 The results of this research have shown that the weak performance of EVs limits their demand; however, if EVs become significantly more advanced than other cars or if gasoline becomes scarce, the demand for these vehicles will increase.\n\nPredicting the future demand for EVs is a complex issue. As most studies for new technologies rely on survey data, market share predictions will reflect the share in the survey data, not the actual market share. Consumer opinions and the news published about EVs also influence the sales of these vehicles. Based on Mau et al.17 research, EV sales are impacted by published information about the penetration rate of EVs, known as the “The neighbor effect”. Electric vehicles' specifications are another factor affecting their sales. According to Balducci et al.18 study to assess plug-in hybrid EV penetration scenarios in the auto market, fuel economy and reduced motor vehicle emissions are the most important factors when purchasing hybrid EVs, while insufficient engine power, high price, and unreliability are the most important reasons for not purchasing these vehicles. Furthermore, Hess et al. used vehicle specifications such as purchase price, vehicle purchase incentives, Miles Per Gallon (MPG) or equivalent, fuel cost per year, fuel availability, refueling time, driving range, maintenance cost per year, and acceleration to explore consumers' preferences in choosing the type of vehicle and the type of fuel. The results have shown that consumers' choices are adversely affected by factors such as purchase price, operating cost, and vehicle age, whereas their choices are positively affected by factors such as better vehicle acceleration, purchase incentives, driving range, and fuel availability19.\n\nThe sale of EVs is also affected by improving vehicle engine performance and reducing fuel consumption. Using a discrete choice model, Bas et al. investigated EV penetration in the face of new technology for reducing fuel consumption. Results demonstrated a clear tradeoff between the cost of a gasoline-powered system and the fuel savings it provides is perceived by potential purchasers20. However, potential EV purchasers are not in this category since their cost–benefit analysis is adverse due to the low cost of electricity20. Also, the estimated market shares give a significant share of the market to alternatives that include technology to reduce consumption, due to a more favorable attitude toward environmentally friendly technologies20. Additionally, Shafiei et al. analysed the impact of factors such as fuel prices, vehicle attributes, consumer preferences, and social influences on the market share of EVs. The results showed that the combination of high gasoline prices, decreasing EV prices, dropping tax on EVs and eliminating consumer concerns about recharging has the most significant effect on the market share of EVs21. Kinski et al.22 research shows that the information related to searching on the Internet (Google Trends) for vehicles has a positive and significant relationship with car sales.\n\nBased on the previous research, the following two general conclusions were reached:\n\nFirstly, ML and DL methods have been proven to be effective at predicting vehicle sales. Therefore, LSTM and ConvLSTM, powerful DL models, have been used for predicting vehicle sales in this research. Furthermore, a hybrid model was also proposed, and all three models were compared in terms of performance.\n\nSecondly, factors and features that affect EV sales have been identified, and these features have been collected and used in this research.\n\nMethodology\n\nArtificial Intelligence (AI) refers to the ability of machines to perceive, synthesize, and infer information, as opposed to animals and humans displaying intelligence23. Machine learning, artificial neural networks, and deep learning are important tools in the development of AI systems and have been shown to perform well in predicting time series data such as vehicle sales. Recurrent neural networks (RNNs) are a type of neural network that remember what they have already processed and can learn from previous iterations24. In other words, an RNN is a class of ANNs where connections between nodes form a directed graph along a temporal sequence; this allows it to exhibit temporal dynamic behavior24.\n\nLSTM\n\nHochreiter and Schmidhuber introduced the LSTM network, a RNN capable of learning long-term dependencies and predicting sequential data with great accuracy25. An LSTM is an extension of an RNN, capable of learning patterns from long sequences of source data by retaining a long-term memory25. LSTMs improved the forgetfulness of RNNs. An RNN could retain a memory, but only for its immediate past. An LSTM, on the other hand, introduces loops to generate long-term gradients. While going through its loops, it can discover long-term patterns25. LSTM is good at storing past information and performing well when faced with vanishing gradient issues. During ANN training, each weight of the neural network receives an update proportional to the partial derivative of the error function. Vanishing gradients occur when gradients become vanishingly small, effectively preventing the weight from changing26.\n\nLSTM can tie together three pieces of information at each time step: the current input data, the short-term memory it receives from the previous cell (the hidden state), and the long-term memory from cells farther away (the cell state)27. The LSTM unit consists of an input gate a forget gate, an output gate, and a cell state. The input gate determines how much information should be transferred from the current candidate cell state to the current cell state. The forget gate determines how much historical information should be ignored from the previous cell state. The output flow from cells to the rest of the network can be controlled through the output gate. By regulating the flow of information through the three gates, important information over time intervals can be remembered. According to Eqs. 1–6, the LSTM unit process data in cell state and gates27. Reference27 provides more details.\n\nIn the above equations, \\(f_{t}\\), \\(i_{t}\\), and \\(o_{t}\\) are the forget, input, and output gates, respectively; \\(C_{t}\\), \\(C_{t - 1}\\), and \\(\\tilde{C}_{t}\\) are the current, previous, and candidate cell state; \\(\\sigma\\) and tanh denotes sigmoid and hyperbolic tangent activation functions, respectively; the interconnected weight matrices for each gate and cell state are \\(W_{fh}\\), \\(W_{ih}\\), \\(W_{oh}\\), \\(W_{Ch}\\), respectively; \\(W_{fx}\\), \\(W_{ix}\\), \\(W_{ox}\\), \\(W_{Cx}\\) represent the input weight matrices in the three gates and the cell state, respectively; \\(b_{f}\\), \\(b_{i}\\), \\(b_{o}\\), \\(b_{C}\\) represent the respective bias terms; the Hadamard (element product) product of a matrix is denoted by \\(\\odot\\)27. According to Fig. 1, the input layer is an LSTM layer with the same number of neurons as the input data features. In the next step, one or more LSTM layers are set as the hidden layers, and in the final step, a Dense layer with the ReLU activation function is set as the output layer.\n\nArchitecture of the LSTM model.\n\nConvLSTM\n\nThe LSTM model is powerful for handling temporal correlation. In addition, when working with time series data with numerous features, LSTM model performance can be improved by converting the two-dimensional data to a three-dimensional tensor (Fig. 2 illustrates this), connecting states, and applying convolutional operations; this idea was the reason for creating the ConvLSTM model28. The ConvLSTM neural network is a fully connected LSTM network with a convolutional structure inside the LSTM cell, which does well in predicting data with temporal correlation. ConvLSTM provides a fully connected extension for data transfer between states and from inputs to states28. In other words, ConvLSTM determines the future state of each cell in the grid based on its inputs and neighbours' past states; this can be done by using a convolution operator in the state-to-state and input-to-state transitions28. In the ConvLSTM model, data in the input unit, the outputs of each cell, the hidden units, and the gates are arranged as three-dimensional tensors. ConvLSTM has similar parameters as LSTM, and the difference is in how data is transferred and convolutional multiplication is used in calculations, as expressed in Eqs. 7–1128. Reference28 provides more details.\n\nTransforming 2-D matrix into 3-D tensor.\n\nIn ConvLSTM equations, * indicates the convolution operator, and \\(\\odot\\) indicates the Hadamard product. As shown in Fig. 3, the input layer is a ConvLSTM layer, the hidden layers are Dense and ConvLSTM layers, and the output layer is a Dense layer with the ReLU activation function.\n\nArchitecture of the ConvLSTM model.\n\nHybrid LSTM with two-dimensional attention and residual network\n\nTime series data have a meaningful temporal relationship. In this research, the data were transformed into three-dimensional tensors with a seven-month time window to maintain the temporal relationship; how to transform a two-dimensional matrix to a three-dimensional tensor is shown in Fig. 2. As an innovation, the “Two-Dimensional Attention” method has been proposed in this research to determine the importance of each car's feature in a seven-month time frame and to use the weighted data in the modeling process. The two-dimensional attention method assigns weights to each feature in the time window based on how much it influences the model, allowing the features with a more significant impact to receive more attention and reduce the model's complexity. The one-dimensional attention model was proposed for the first time by Bahdanau to address the problem of the limited access of the decoder to the model's input information when the encoder vector has a fixed length in the translation machine29.\n\nIn the LSTM model architecture, which is shown in Fig. 1, several LSTM layers are placed inside the hidden layer. When the number of LSTM layers in the hidden layer increases, the primary layers (the layers adjacent to the input layer) have a lesser effect on the output. The primary layers have processed the input data and learned the relationship between the data well, which is why it has been tried to improve this problem by using the Residual network in the proposed hybrid model. Using the Residual Network, the weighted data and outputs of the primary layers have been transferred to the final layers in the proposed hybrid model, as shown in Fig. 4.\n\nPrimary architecture of the hybrid model.\n\nIn this study, each input \\(x\\) is represented by an \\(m \\times n\\) matrix, where m corresponds to the previous months in the window (7), and n represents the number of vehicle features. After entering the data into the first LSTM layer, the processing is done according to Eqs. 1–6, and the encoded hidden unit (\\(h\\)) with the exact dimensions (\\(m \\times n\\)) is entered into the Attention layer. After that, the alignment score is calculated according to Eq. (12).\n\nIn Eq. (12), \\(e_{i, j}\\) represents the alignment score, \\(W_{a}\\) is the attention model’s weight (as a trainable variable), \\(h\\) is the encoded hidden unit of the primary LSTM layer, \\(b_{a}\\) is the attention model's bias (as a trainable variable), and the sign \"*\" denotes the Hadamard product. Since the input data for the attention layer has been encoded by an LSTM layer using tanh nonlinear activation function, tanh has also been used in the attention layer to facilitate data reading during decoding. Each input data element was assigned a degree of attention using Eq. (13).\n\nMultiplying attention matrix \\(\\alpha_{i, j}\\) by raw data matrix \\(x_{i, j}\\) yields a weighted data matrix \\(W_{i, j}\\) based on Eq. (14). The sign “*” denotes the Hadamard product.\n\nWeighted data \\(W_{i, j}\\) is then passed through three layers of LSTM as a Residual Network; the output of each layer is combined with the weighted data at the end of the Residual Network and entered into one or more LSTM layers. A Dense layer with the ReLU activation function is the output layer. An overview of the model's architecture is illustrated in Fig. 4.\n\nOther architectures have also been tried in the hybrid model structure, but they were not more efficient, so only the best architecture has been mentioned.\n\nData\n\nIn this study, EVs are considered as vehicles that use electric motors for propulsion and include all types of EVs. In predicting the sale of vehicles, the number of vehicles in the warehouses is an influential factor, which was not used in this modeling due to a lack of access. Since ML models are based on training, in this study, the models can predict the sales of vehicles that have been on the market for at least 24 months. Emerging vehicles (vehicles that have been on the market for less than 24 months) and cars that have not yet entered the market were not included in the modeling due to insufficient data to train the model. Therefore, the share of EVs in the Automotive Market is expressed as a share in vehicle segments and not as a share of EVs overall.\n\nA wide range of information related to car sales has been used in this research. In the primary dataset, all the data is related to new cars, not used cars. The primary dataset contains monthly information about 357 vehicles, such as brand (or \"make\" in auto industry lingo, e.g., Benz), model, segmentation, category, shoppers, and sales of different types of cars in the United States from 2014 to 2020. Other information has been extracted based on the cars in this dataset. The data before the outbreak of Covid-19 disease were used since this disease had adverse impacts on the global economy.\n\nAs stated in previous studies, vehicle specifications are very effective in car sales prediction models. Vehicle specifications are changed annually. According to Alexa rating30 and the comprehensiveness of the information presented on the “Thecarconnection” website31, vehicle specifications were collected through this website. In order to save time and automate the collection of information due to a large number of vehicles and changes in specifications of vehicles over time, several web crawler have been designed and used in Python programming language to collect vehicle information. Several vehicle specifications of the \"CAR-MID/FULL SIZE\" segment are shown in Table 1.\n\nThere is similar information collected for gasoline and EVs; for example, the equivalent MPG in EVs. Price, MPG, max mileage, engine power, and warranty are some of the main features taken into account. Other specifications have been divided into the \"safety specifications\" and the \"other specifications\" categories. The safety specifications category includes child safety rear door locks, airbags, ABS brakes, daytime running lights, night vision, driver monitoring alerts, collision mitigation braking system, electronic stability control, and side impact beams. All other features (traction control, fog lamps, tire pressure monitoring, parking sensors, parking assist, and backup cameras) have been transferred to the other specifications category.\n\nThe second series of collected data refers to user opinions and news published on reputable websites ranked higher on Alexa30. Four websites were examined for this purpose: Autoblog32, Auto News33, Motor134, and The Car Connection35. These websites were crawled using Python web crawlers to save time and collect information automatically. From 2014 to 2020, the daily news published was collected and evaluated for each type of vehicle. The Valence Aware Dictionary and sEntiment Reasoner (VADER) method was used for sentiment analysis of the text. Based on vocabulary analysis, the VADER sentiment analysis method correctly analyzes the sentiment expressed in social media and news texts. Ten independent human raters analyzed over 90,000 ratings in the VADER evaluation, which led to the adoption of 7500 linguistic features that were rated based on their valence scores, which indicate the intensity and polarity of sentiment36. For each vehicle, the average monthly score of news and opinions has been calculated based on their daily publication of them.\n\nAnother effective source of information about the vehicle market is various economic indicators. Using a Python web crawler, information on several economic indicators affecting the car market has been collected on the Federal Reserve website37. Economic indicators include GDP, Consumer Price Index (CPI), Producer Price Index, Consumer Confidence Index, Personal Income Per Capita, Interest Rates on 48-month and 60-month Loans, SP&500, and Dow Jones stock market indicators.\n\nAccording to Kinski's research, using Google trends in prediction models is beneficial and practical22. Three keywords have been selected for Google trend data to evaluate the number of searches for each car from 2014 to 2020 and for the United States of America. The keywords are:\n\n\"Make\" + \"Model\"\n\n\"Price\" + \"Make\" + \"Model\"\n\n\"Dealer\" + \"Make\"\n\nAll cars have the same data collected, and the features collected on a monthly basis for each car are listed in Table 2. Several different trims were available on the market for some vehicles simultaneously, and some characteristics, such as price and MPG, had multiple values for these vehicles. Due to this, the collected values for these characteristics were divided into three categories: minimum, average, and maximum.\n\nThe sales feature has been normalized based on the maximum and minimum values from the training data set. Other features are standardized based on each feature's average and standard deviation in the training set. The input data to models are considered seven-month windows to maintain temporal correlation. For example, in the current month, the last seven months' data are input (X), and the current month's sale is output (Y). In order to achieve this, seven-month data matrices were placed consecutively in the third dimension of a three-dimensional tensor.\n\nValidation and interpretation of results\n\nSince the time series data in this study are monthly, eleven binary columns have been added to the dataset to reflect the effect of each month (in the first month of every year, the column corresponding to the first month is set to 1, and the column for the other months is set to 0). An example of this binary data is shown in Table 3.\n\nFor most vehicles, data includes 79 months (January 2014 through July 2020). According to Fig. 5, the last 14 months are selected for the testing set as rolling cross-validation. Using cross-validation on a rolling basis is one way to validate the time-series model. Starting with a subset of data for training, forecasting for later data points and then checking the accuracy of the forecasts. The same forecasted data points are included in the next training dataset, and further forecasts are made.\n\nSplitting dataset into training, validation, and testing sets.\n\nThe model is cross-validated using 12 forecasting stages, with each stage predicting sales in the next three months. During each prediction stage, the preceding months are divided into training and validation (70% for training and 30% for validation. Then these data are transferred to the model, the model predicts sales in the next three months, then the forecast date is moved forward by one month, and this process has been repeated 12 times. Vehicle sales in the next three months are predicted each time the model runs, assuming most of the vehicle's characteristics remain the same. Due to fluctuation and changes in economic conditions, a three-month time horizon is used for predicting the future.\n\nOverfitting is one of the principal problems in ANN training. The Dropout layers between the neural network layers are one of the best solutions in the ANN to avoid overfitting. During the dropout layer, the number of neurons trained in each layer and those discarded is determined randomly (rather than activating all neurons at once, only a fraction are activated)38. TensorFlow's early stopping tool is another basic solution to avoid overfitting. Early stopping works in the following way: during the repetition of training, the validation data is used to calculate the error value, and whenever the validation error value increases throughout several epochs, the model is ready to be stopped, and overfitting is prevented. For all three models, both solutions are used to prevent overfitting. Dimensionality reduction is another way to prevent model overfitting. In this study, Principal Component Analysis was used in several modes to reduce dimensions, but this technique was not used due to the significant decrease in model performance.\n\nIn order to improve the modeling process, all three models' hyperparameter values and network architectures were determined by Automated Machine Learning (AutoML). AutoML is the process of automating ML applications. The number of hidden layers, the number of neurons in these layers, and the dropout rate was determined by the Tuners. Several values are introduced to the Tuner for each hyperparameter. The Tuner trains different model versions and selects the best one based on the best result (lowest error or loss) on the validation data. This method sets the hyperparameters to the optimal value, and the model is then applied to a test dataset.\n\nThe model's error or loss is calculated using the Mean Absolute Error (MAE) loss function in all three models. Selecting a suitable optimization algorithm for the DL model is essential to reduce the run time and reach the desired result. Adam's optimization algorithm is used for these models, which is a generalized version of stochastic gradient descent. It reduces memory usage, converges faster, and corrects high variance and learning rates39.\n\nComparison of models\n\nWith the validation data, hyperparameters are adjusted, and the model is built to predict vehicle sales over the next three months (three months following the last validation date). The model run-time for all vehicles was very long due to the many vehicle types (357). In a random sample of 15 vehicles, different models' states were compared using fixed data, and the results were compared between the three models.\n\nThe sale of each vehicle is predicted in 12 stages; each prediction stage includes the prediction for the next three months, respectively, the first month of the prediction, the second month of the prediction, and the third month of the prediction. In total, the first predictions include 12 months, the second predictions include 12 months, and the third predictions include 12 months. Model performance was evaluated using the Mean Absolute Percentage Error (MAPE), the Root Mean Square Error normalized by the change range (\\(NRSME_{range}\\)), and the Root Mean Square Error normalized by the mean value (\\(NRSME_{mean}\\)) according to Eqs. 15–18.\n\nAccording to the above equations, \\(y_{t}\\) denotes the actual value at time t, \\(\\hat{y}_{t}\\) denotes the predicted value at time t, \\(y_{max}\\) denotes the maximum actual value, \\(y_{min}\\) denotes the minimum actual value, \\(y_{mean}\\) denotes the average actual value, and T is equal to the total number of predicted samples. The average error values of all vehicles were calculated to compare the results of various models. A weighted average was calculated using the total number of sales of each car per month as a weight for the vehicle according to Eq. (19) since the numbers of vehicle sales are not on the same scale, and the error rate is more important in vehicles with high sales. A further method of checking the models' performance is to compare the R-square, slope, and intercept of the linear regressions fitted on predicted and observed data for all three models. Table 4 summarizes the evaluation results of the models.\n\nIn the proposed hybrid model, the error values are lower, the R-square accuracy is higher, the slope value is closer to 1, and the intercept is closer to 0. At this stage, the proposed hybrid model was recognized as preferable to both the LSTM and ConvLSTM models.\n\nImplementation of the proposed hybrid model to predict the share of EVs\n\nFor all vehicles, the proposed hybrid model has been implemented, and 12 points of prediction have been used to determine the sale of all vehicles. Linear regression was fitted on the predicted sales and actual values to evaluate the model's performance, as shown in Table 5.\n\nPrimary data segments vehicles by specifications according to segments like CAR-SMALL_COMPACT, CAR-MID_FULL SIZE, MINIVAN LARGE, and PICKUP LARGE. Each segment consists of similar vehicles in appearance and specifications that compete with one another. Segments that include EVs have been separated to determine the share of EVs. Based on actual and predicted sales, the shares of electric and gasoline vehicles have been compared and evaluated for each month of the test data. For example, the CAR-MID/FULL-SIZE segment includes 28 vehicles (23 gasoline vehicles and five EVs). Figure 6 shows the share of EVs in this segment based on twelve prediction stages (three months per stage), separately for the first, second, and third months of each prediction.\n\n(a) Share of EVs in CAR-MID/FULL-SIZE based on the first month of each prediction. (b). Share of EVs in CAR-MID/FULL-SIZE based on the second month of each prediction. (c) Share of EVs in CAR-MID/FULL-SIZE based on the third month of each prediction.\n\nAll segments' MAEs for EVs' share forecasting in the forecast's first, second, and third months are shown in Table 6. The average MAE value of all segments was calculated as 3.2% for the first months, 3.8% for the second months, and 3.5% for the third months. The average value for all segments and all forecast months was calculated at about 3.5%, which shows that the proposed hybrid model performed well.\n\nAs part of the model analysis, the segments that included EVs were separated again and ranked by sales within each segment. The rankings were based on actual sales (actual rank) and predicted sales (predicted rank); the actual rank and predicted rank were used for evaluation. Kendall-Tau correlation (Kendall's correlation) is commonly used to check the concordance of two ranked lists; this technique was used to examine the actual and predicted rankings in this study. Kendall's correlation rate for two rating lists \\(r_{a}\\) and \\(r_{b}\\) (\\(\\tau_{{r_{a} , r_{b} }}\\)) is represented by Eq. (20) 40.\n\nIn Eq. (20), \\(n_{c}\\) represents the number of concordant pairs, \\(n_{d}\\) represents the number of discordant pairs, and n represents the total number of ranks in each of the rating lists40. The maximum number of discordant pairs between two ranking lists equals \\(\\frac{1}{2} n\\left( {n - 1} \\right)\\), and Kendall's correlation equals + 1 if all pairs of ranks are concordant and -1 if none are concordant 40. For all segments, Kendall's correlation values were calculated separately for the first, second, and third prediction months, and the average values are shown in Table 7. The average Kendall's correlation value of all segments was calculated as 0.76 for the first months, 0.742 for the second months, and 0.75 for the third months. The average Kendall's correlation value for all segments and all forecast months was calculated at about 0.75, which indicates the great performance of the proposed hybrid model in predicting the ranking.\n\nSensitivity analysis\n\nSensitivity analysis was performed to determine which features significantly impacted the trained model. Thus, for each vehicle, the pre-trained model that was evaluated in previous stages has once again predicted the number of vehicle sales with new input data, and its outputs have been assessed. All features, except the investigated feature, are valued at their average. For the investigated feature, the five values from the training data (the min value, the first quartile, the second quartile, the third quartile, and the max value) are taken into consideration. Five predictions were made based on these five values, and a range of changes in predicted sales was calculated. The change ranges for all features have been measured, and the four features with the most extensive range have been identified. As an example, during the sensitivity analysis of the BMW I3 for 2020, the following four features had the broadest range of changes: the Consumer Price Index (CPI), the equivalent MPG for EVs, the Google search score for car prices (Google Trends), and the car price. This EV's sensitivity analysis plots are shown in Fig. 7.\n\n(a) Sensitivity analysis plot of influential feature 1 for BMW I3. (b) Sensitivity analysis plot of influential feature 2 for BMW I3. (c) Sensitivity analysis plot of influential feature 3 for BMW I3. (d) Sensitivity analysis plot of influential feature 4 for BMW I3.\n\nBased on Eq. (21), slope values for the four characteristics with the most extensive range of changes are calculated in different parts of the graph, and the results are summarized in Table 8. For example, the number of sales of this EV has decreased by 8 for every thousand-dollar increase in price when the price is in the range of the minimum value to the first quarter. As the slope is zero percent in the second and third parts of the graph, the price in the first, second, and third quartiles is equal, and when the price is in the third quartile to the maximum price, the number of sales for this EV decrease by 6 for every thousand-dollar increase in price.\n\nThere has been a decrease in car sales due to the increase in the CPI. It is also true that with the increase in the CPI, the final price of the car and the price of auto parts have increased, which has led to a decrease in the desire to buy this car. The second feature is equivalent MPG for EVs, a higher equivalent MPG indicating better performance and less fuel consumption in a fixed distance has led to an increase in sales of this car. The third feature identified is the increase in the car price search score on Google (Google Trend), an indicator that buyers are more curious about this car, contributing to its sales. The fourth specified feature of the car is its price, and its sales have decreased with the increase in its price. As a result of the sensitivity analysis, the manufacturers of this car could use policies such as lowering the price of the car and its parts (CPI and car price), improving the performance of the vehicle's engine (the equivalent MPG), and developing advertisements and introducing the car to the public (Google trend score) to increase sales.\n\nSensitivity analysis has been conducted for each EV, and the results show different sensitivity for each vehicle. From each segment that includes EVs, one vehicle was selected as a sample, and the results of its sensitivity analysis are shown in Table 9.\n\nEach EV's sensitivity analysis identifies features that differ from the others, as shown in Table 9. According to the results of the sensitivity analysis, ten features that were most frequently found in the sensitivity analysis of all the EVs were identified as the most influential features: Shoppers, Min price, CPI, Sales, Google Trends score 3 (Price), Make & model news score, Personal income per capita, Make news score, Interest Rates on 60-month, and Mean options score, respectively.\n\nConclusion\n\nThis study addresses an important topic from a business perspective. Car manufacturers can benefit from this research by understanding their market share and the effect of pricing and vehicle specification on the market share. They can use the results of this study to analyze both their EV market as well as their Non-EV market. Lower down the funnel, car dealers that operate in a highly competitive environment can strategize their sales events, marketing campaigns, and discounts to meet their business goals and target sales. Finally, the model enables the public sector to understand the effect of tax policies on the share of EV vehicles in case they like to promote them.\n\nThis study used ML methods to develop a prediction model that estimated the sale of all cars in the dataset, the share of EVs in each segment and identified the main factors affecting each EV's sales. In this research, several web crawlers have been used to collect various data, including factors that previous studies have proven to be associated with EV sales. Vehicles sale were predicted using LSTM, ConvLSTM, and the proposed hybrid model (Hybrid LSTM with two-dimensional Attention and Residual network). Several ML tools have been used to improve the model's training and the modeling process, such as transforming two-dimensional time series data into three-dimensional tensors, Dropout layers, early stopping tools, and AutoML. Because of the variety of car types and the long running time of the models, a random selection of fifteen types of cars was made. All three models are evaluated based on the same evaluation units: the MAPE, NRSME_range, and NRSME_mean, R-square, slope, and intercept of fitted linear regressions have also been assessed. The average error values in the three months of prediction were as follows:\n\nThe MAPE value of the proposed hybrid model was 4.5% less than the LSTM model and 14.4% less than the ConvLSTM model.\n\nThe NRSME_range value of the hybrid model was 0.11 less than the LSTM model and 0.22 less than the ConvLSTM model.\n\nThe NRSME_mean value of the hybrid model was 0.079 less than the LSTM model and 0.169 less than the ConvLSTM model.\n\nAs a result of fitting linear regressions to the predicted and actual values, for all three months of predictions, the proposed hybrid model has a higher R-square value, its slope is closer to one, and its intercept is closer to zero, which indicates that the hybrid model performed better than the other two. In comparing the models, it was found that the proposed hybrid model conducted better than other models and was selected to predict the sale of all vehicles in the dataset. Based on the linear regression fitted to the predicted sales and the actual sales of all vehicles, the R-square values for the first, second and third prediction months were 0.912, 0.906, and 0.917.\n\nThe predicted sales of all vehicles were used to calculate the predicted share of EVs in each segment and compare them with the actual values. Across all segments and forecasting months, the average MAE value for EV share is about 3.5%, and the hybrid model has accurately predicted the share of EVs across all segments. To further analyze the model results, the cars were ranked according to the number of actual and predicted sales within each segment. The average Kendall's correlation value for all segments and all forecast months was calculated at about 0.75, which indicates the high performance of the proposed hybrid model in predicting the ranking.\n\nThe sensitivity analysis was performed to evaluate the model further and identify its most influential features. The results have shown that each EV's sensitivity analysis identifies features that differ from the others. According to the sensitivity analysis of the BMW I3 for 2020, the following four features were most affected: the Consumer Price Index, the equivalent MPG for EVs, the Google search score, and the car price. As a result of the sensitivity analysis, the manufacturers of this car could use policies such as lowering the price of the car and its parts, improving the engine's performance, developing advertisements, and better introducing the car to increase sales (See Appendix Tables A1 to A4.2, Fig. A1).\n\nThis research has achieved the following accomplishments:\n\nA wide variety of factors have been collected and used as variables to model the sale of EVs.\n\nLSTM and ConvLSTM, powerful DL models, have been used for predicting vehicle sales. By combining the two-dimensional Attention model and the Residual network, the performance of the LSTM model was enhanced, and the innovative hybrid model performed better than the other two.\n\nEVs differ in terms of the most influential factors for sales depending on the sensitivity analysis results. The ten features that appeared the most in the sensitivity analysis of all EVs were identified as the most influential, including Shoppers, Min price, CPI, Sales, Google Trends score 3 (Price), News score for make and model, Personal income per capita, News score for make, Interest Rates on 60-month, and Mean options score, respectively.\n\nData availability\n\nThe primary dataset was taken from Autometrics, and other data were collected using web crawlers. The data is available from the corresponding author on reasonable request.\n\nReferences\n\nhttps://www.epa.gov/ghgemissions/inventory-us-greenhouse-gas-emissions-and-sinks (2020).\n\nMacInnis, B. & Krosnick, J. Climate Insights 2020: Electric Vehicles. (2020).\n\nhttps://theicct.org/the-rise-of-electric-vehicles-the-second-million/ (2020).\n\nhttps://www.iea.org/fuels-and-technologies/electric-vehicles (2022).\n\nBrühl, B., Hülsmann, M., Borscheid, D., Friedrich, C. M. & Reith, D. in Industrial Conference on Data Mining. 146–160 (Springer).\n\nWang, F.-K., Chang, K.-K. & Tzeng, C.-W. Using adaptive network-based fuzzy inference system to forecast automobile sales. Expert Syst. Appl. 38, 10587–10593 (2011).\n\nArticle\n  Google Scholar\n\nHülsmann, M., Borscheid, D., Friedrich, C. M. & Reith, D. General sales forecast models for automobile markets and their analysis. Trans. Mach. Learn. Data Min. 5, 65–86 (2012).\n\nGoogle Scholar\n\nKitapcı, O., Özekicioğlu, H., Kaynar, O. & Taştan, S. The effect of economic policies applied in Turkey to the sale of automobiles: Multiple regression and neural network analysis. Procedia Soc. Behav. Sci. 148, 653–661 (2014).\n\nArticle\n  Google Scholar\n\nBas, J., Zou, Z. & Cirillo, C. An interpretable machine learning approach to understanding the impacts of attitudinal and ridesourcing factors on electric vehicle adoption. Transp. Lett. 15, 30–41 (2023).\n\nArticle\n  Google Scholar\n\nZhang, Y., Zhong, M., Geng, N. & Jiang, Y. Forecasting electric vehicles sales with univariate and multivariate time series models: The case of China. PLoS ONE 12, e0176729 (2017).\n\nArticle\n  PubMed\n  PubMed Central\n  Google Scholar\n\nKaya, S. K. & Yildirim, Ö. A prediction model for automobile sales in turkey using deep neural networks. Endüstri Mühendisliği 31, 57–74 (2020).\n\nGoogle Scholar\n\nXia, Z. et al. ForeXGBoost: Passenger car sales prediction based on XGBoost. Distrib. Parallel Databases 38, 713–738 (2020).\n\nArticle\n  Google Scholar\n\nBas, J., Cirillo, C. & Cherchi, E. Classification of potential electric vehicle purchasers: A machine learning approach. Technol. Forecast. Soc. Chang. 168, 120759 (2021).\n\nArticle\n  Google Scholar\n\nSaxena, P., Bahad, P. & Kamal, R. Long short-term memory-RNN based model for multivariate car sales forecasting. Int. J. Adv. Sci. Technol. 29, 4645–4656 (2020).\n\nGoogle Scholar\n\nBeggs, S., Cardell, S. & Hausman, J. Assessing the potential demand for electric cars. J. Econom. 17, 1–19 (1981).\n\nArticle\n  Google Scholar\n\nCalfee, J. E. Estimating the demand for electric automobiles using fully disaggregated probabilistic choice analysis. Transp. Res. Part B Methodol. 19, 287–301 (1985).\n\nArticle\n  Google Scholar\n\nMau, P., Eyzaguirre, J., Jaccard, M., Collins-Dodd, C. & Tiedemann, K. The ‘neighbor effect’: Simulating dynamics in consumer preferences for new vehicle technologies. Ecol. Econ. 68, 504–516 (2008).\n\nArticle\n  Google Scholar\n\nBalducci, P. J. Plug-In Hybrid Electric Vehicle Penetration Scenarios. (Pacific Northwest National Lab. (PNNL), Richland, WA (United States) (2008).\n\nHess, S., Fowler, M., Adler, T. & Bahreinian, A. A joint model for vehicle type and fuel type choice: Evidence from a cross-nested logit study. Transportation 39, 593–625 (2012).\n\nArticle\n  Google Scholar\n\nBas, J., Zofío, J. L., Cirillo, C., Chen, H. & Rakha, H. A. Policy and industry implications of the potential market penetration of electric vehicles with eco-cooperative adaptive cruise control. Transp. Res. Part A Policy Pract. 164, 242–256 (2022).\n\nArticle\n  Google Scholar\n\nShafiei, E. et al. An agent-based modeling approach to predict the evolution of market share of electric vehicles: A case study from Iceland. Technol. Forecast. Soc. Chang. 79, 1638–1653 (2012).\n\nArticle\n  Google Scholar\n\nKinski, A. Google trends as complementary tool for new car sales forecasting: A cross-country comparison along the customer journey, University of Twente, (2016).\n\nhttps://en.wikipedia.org/wiki/Artificial_intelligence (2023).\n\nhttps://en.wikipedia.org/wiki/Recurrent_neural_network (2023).\n\nHochreiter, S. & Schmidhuber, J. Long short-term memory. Neural Comput. 9, 1735–1780 (1997).\n\nArticle\n  CAS\n  PubMed\n  Google Scholar\n\nBasodi, S., Ji, C., Zhang, H. & Pan, Y. Gradient amplification: An efficient way to train deep neural networks. Big Data Min. Anal. 3, 196–207 (2020).\n\nArticle\n  Google Scholar\n\nWei, X., Zhang, L., Yang, H.-Q., Zhang, L. & Yao, Y.-P. Machine learning for pore-water pressure time-series prediction: Application of recurrent neural networks. Geosci. Front. 12, 453–467 (2021).\n\nArticle\n  ADS\n  Google Scholar\n\nShi, X. et al. Convolutional LSTM network: A machine learning approach for precipitation nowcasting. Advances in neural information processing systems 28 (2015).\n\nBahdanau, D., Cho, K. & Bengio, Y. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473 (2014).\n\nhttps://www.alexa.com/ (2021).\n\nhttps://www.thecarconnection.com/ (2021).\n\nhttps://www.autoblog.com/news/ (2021).\n\nhttps://www.autonews.com/news (2021).\n\nhttps://www.motor1.com/news/ (2021).\n\nhttps://www.thecarconnection.com/news (2021).\n\nHutto, C. & Gilbert, E. in Proceedings of the international AAAI conference on web and social media. 216–225.\n\nhttps://fred.stlouisfed.org/ (2021).\n\nBaldi, P. & Sadowski, P. J. Understanding dropout. Advances in neural information processing systems 26 (2013).\n\nKingma, D. P. & Ba, J. Adam. A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).\n\nBachrach, Y., Herbrich, R. & Porat, E. in International Symposium on String Processing and Information Retrieval. 344–352 (Springer).\n\nDownload references\n\nFunding\n\nThe authors received no financial support for the research, authorship, and/or publication of this article.\n\nAuthor information\n\nAuthors and Affiliations\n\nDepartment of Transportation, School of Civil Engineering, Iran University of Science and Technology, Tehran, Iran\n\nShahriar Afandizadeh & Diyako Sharifi\n\nAECOM, Glen Allen, VA, USA\n\nNavid Kalantari\n\nDepartment of Civil-Transportation Planning, Faculty of Technical and Engineering, Imam Khomeini International University, Qazvin, Iran\n\nHamid Mirzahossein\n\nContributions\n\nThe authors confirm contribution to the paper as follows: study conception and design: S.A., D.S., N.K., H.M.; data collection: N.K., D.S.; analysis and interpretation of results: S.A., D.S., N.K.; manuscript preparation: D.S., H.M. All authors reviewed the results and approved the final version of the manuscript. Authors consent for the publication of the submitted paper and any associated data and accompanying images\n\nCorresponding author\n\nCorrespondence to Shahriar Afandizadeh.\n\nEthics declarations\n\nCompeting interests\n\nThe authors declare no competing interests.\n\nAdditional information\n\nPublisher's note\n\nSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\n\nSupplementary Information\n\nSupplementary Information.\n\nRights and permissions\n\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.\n\nReprints and permissions\n\nAbout this article\n\nCite this article\n\nAfandizadeh, S., Sharifi, D., Kalantari, N. et al. Using machine learning methods to predict electric vehicles penetration in the automotive market. Sci Rep 13, 8345 (2023). https://doi.org/10.1038/s41598-023-35366-3\n\nDownload citation\n\nReceived\n13 November 2022\n\nAccepted\n17 May 2023\n\nPublished\n23 May 2023\n\nDOI\nhttps://doi.org/10.1038/s41598-023-35366-3\n\nShare this article\n\nAnyone you share the following link with will be able to read this content:\n\nProvided by the Springer Nature SharedIt content-sharing initiative\n\nSubjects\n\nScientific Reports (Sci Rep)\n\nISSN 2045-2322 (online)\n\nAbout Nature Portfolio\n\nDiscover content\n\nPublishing policies\n\nAuthor & Researcher services\n\nLibraries & institutions\n\nAdvertising & partnerships\n\nProfessional development\n\nRegional websites\n\n© 2025 Springer Nature Limited\n\nA multi-model approach for predicting electric vehicle ... - Springer : \nYour privacy, your choice\n\nWe use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media.\n\nBy accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection.\n\nSee our privacy policy for more information on the use of your personal data.\n\nManage preferences for further information and to change your choices.\n\nA multi-model approach for predicting electric vehicle specifications and energy consumption using machine learning\n\nAccess provided by American University of Beirut\n\n217 Accesses\n\nExplore all metrics\n\nAbstract\n\nThe increasing reliance on electric vehicles (EVs) necessitates advanced predictive models to enhance performance and sustainability, especially against climate change driven by fossil fuel combustion. This study advances the field using cutting-edge machine learning techniques to model and predict various EV characteristics and performance metrics. Using a comprehensive dataset with parameters such as model year, make, model type, vehicle class, motor power, and energy consumption metrics, we tested classification and regression models to forecast categorical features (vehicle make, category) and continuous features (energy consumption, range, charge time, motor power). The models were assessed using key performance indicators like accuracy, recall, F1 score, precision, MAE, RMSE, and R2. The random forest and Naive Bayes classifiers excelled in classification tasks, achieving accuracies of 95.58% and 100%, respectively. The Linear Regression model showed superior performance in predicting energy consumption in city driving conditions, with an R2 value of 0.9982. The K neighbors regressor was most effective in predicting range and motor power, with R2 values of 0.9800 and 0.9300, and the Huber regressor was most effective in predicting charge time. The study demonstrates the analytical models’ proficiency in projecting vehicular attributes and performance metrics by dividing the data into 70% for training and 30% for validation. The research provides crucial insights for policymakers, highlighting the potential of increased EV adoption to significantly decrease greenhouse gas emissions from the transportation sector, aiding in climate change mitigation.\n\nSimilar content being viewed by others\n\nPredictive Energy Management for Battery Electric Vehicles with Hybrid Models\n\nComparing the Performance of Classification Algorithms for Predicting Electric Vehicle Adoption\n\nPerformance analysis of machine learning algorithms for estimation of EV penetration\n\nExplore related subjects\n\nAvoid common mistakes on your manuscript.\n\n1 Introduction\n\nThe rise in greenhouse gas (GHG) emissions has heightened concerns about global warming. Various sectors contribute to these emissions, including transportation, energy, waste management, agriculture, forestry, and buildings [1,2,3,4,5,6,7]. The International Energy Agency identifies transportation as the second-largest GHG emitter, primarily emitting CO2, N2O, and CH4 [8, 9]. Transportation activities are responsible for 75% of global CO2 emissions [10], making emission reduction in this sector crucial for combating climate change [11]. Evaluating urban highways’ exposure to pollutants is essential for achieving social, environmental, and economic objectives, particularly in developing nations [12]. The significance of climate change is underscored by the declaration of a climate emergency by thirty-three countries as of January 2021 [13]. The transportation sector is a significant contributor to global energy consumption, accounting for over a quarter of the total [14]. Two-thirds of the world’s population is expected to reside in cities by 2050, according to UN estimates [15], which will increase demand for urban mobility as well as energy use and greenhouse gas emissions. Electric vehicles (EVs) offer a promising solution, potentially reducing carbon emissions by 45% compared to internal combustion engine (ICE) vehicles [16]. Advances in reliability and battery range have boosted EV popularity and trust, with owner satisfaction on the rise [17, 18]. The proliferation of charging stations, driven by government initiatives, has further facilitated EV adoption, positioning them as a leading clean transportation option.\n\nThe growing use of electric vehicles requires exact forecasts of performance measures like energy consumption, charging time and driving range. These predictions can enhance the management of the electric grid and provide users with accurate data about their vehicle’s capabilities. Numerous studies have explored the development of models using machine learning techniques to enhance the reliability and accuracy of predicting these metrics. Using Gaussian mixture models, Lee et al. predicted the energy and duration requirements of over 30,000 non-residential EV charging sessions. They utilized historical charging data for testing and reported symmetric mean absolute percentage error (SMAPE) of 15.9% for energy consumption and 14.4% for session duration. To predict the departure and arrival times of electric vehicle (EV) users on a university campus, the authors in [19] utilized support vector machines (SVM). They achieved mean absolute percentage errors (MAPE) of 3.7% for the departure times and 2.9% for the arrival times. However, hyperparameter tuning for SVM was not addressed, and a simple persistence model was utilized for comparison. Frendo et al. [20] predicted EV departure times using regression models. Eight features were taken into account, including the vehicle ID, car model, charging point, weekday, parking floor, arrival time, and location. Artificial neural network, extreme gradient boosting, and linear regression were trained for prediction purpose. Extreme gradient boosting demonstrated the highest performance, with a mean absolute error (MAE) of 82 min. The prediction of session length and energy consumption was achieved through the use of an ensemble machine learning approach that integrated random forest, SVM, and kernel density estimator (KDE).This model, trained on historical charging records from both public and residential datasets, outperformed individual models with SMAPEs of 7.5% for consumption and 10.4% for duration [21].\n\nXiong et al. [22] estimated session start times and durations using mean values and subsequently applied linear regression to predict energy consumption. These predications were incorporated to stabilize the power system, and regulate the charging load albeit performance indicators were not statistically analyzed. In [23], regression models were applied to forecast energy demands at public charging stations across Nebraska, incorporating variables such as season, day of the week, type of location, and applicable fees. Extreme gradient boosting achieving an R2 score of 0.52, outperformed other models and attained a MAE of 4.6 kWh. The authors in [24] used the k-nearest neighbor (k-NN) algorithm to predict energy consumption at a university charging station. The study framed the problem as a time series, with the best results achieved by employing a K value of 1 (1-NN) and utilizing a time-weighted dissimilarity measure based on the dot product, yielding a SMAPE of 15.3%. Majidpour et al. [25] used algorithms like SVM and RF to forecast the energy requirements for the following day at charging stations. They also investigated pattern sequence-based forecasting (PSF) [26], which involves clustering days into categories before making predictions. The PSF method demonstrated the highest accuracy, achieving an average SMAPE of 14.1\n\nElectric vehicle (EV) range prediction has been examined using two main approaches: physical models, which utilize real-time data, and artificial intelligence models trained on historical data. Physical models can be subdivided into those that estimate energy consumption by either modeling the battery pack (or powertrain) or the vehicle itself. Battery pack models, for example, involve techniques that use the apparent state of discharge of Li-ion cells, adjusted for the effects of current and temperature. [27], and those updating a battery dynamics model using online battery identification parameters [28]. Battery-in-loop simulations have demonstrated effectiveness in assessing energy consumption under cold temperature conditions [29]. Simplified powertrain models have been created by utilizing drive cycle data tailored to specific scenarios, such as coast-down [30]. Battery pack models are particularly effective at incorporating energy use by auxiliary vehicle loads and considering the effects of ambient temperature [31]. Vehicle models, on the other hand, employ physical parameters like road inclination, velocity and vehicle mass [32, 33], providing statistical insights into a battery electric vehicle’s (BEV) instantaneous energy consumption. To forecast future energy consumption, additional road information has been utilized to compare results between higher driving speeds and the most fuel-efficient speeds [34]. While, the accuracy of these methods is contingent on having future route or drive cycle data, they cannot estimate energy consumption for the remaining portion of a trip without this information.\n\nDriving style has been identified as the most influential factor in the variable range of BEVs [35]. Consequently, historical vehicle data is required to estimate the remaining driving range accurately. Range prediction is a complex problem influenced by internal, external, constant, and variable parameters [36, 37]. Big-data models have been employed to forecast range using numerous data sources [38]. Most works leveraging artificial intelligence models combine historical vehicle data with GIS-based information [39] and other external factors like road conditions and traffic [40]. Data-driven approaches to estimating BEV range include predictive strategies based on optimal path search algorithms [41], solving multi-objective optimization problems to recommend vehicle speeds [42], and machine learning models that analyze trip data [43, 44]. Some methods incorporate additional attributes like tire-pressure monitoring with a physical energy consumption model for range estimation [45]. Recent studies have employed advanced machine learning techniques such as light gradient boosting and extreme gradient boosting, using features like motor, battery temperature, battery energy, and driving patterns to determine BEV range [46]. Additionally, least squares support vector machine models have been combined with particle swarm optimization, trained on features such as temperature and depth of discharge, to achieve stable and reliable range predictions [47].\n\nThe increasing use of electric vehicles (EVs) necessitates precise forecasting of performance metrics to improve user experience and aid infrastructure planning. This research introduces a multimodel prediction framework that predicts electric vehicle specifications accurately, considering factors like make, category, energy consumption, motor power, travel range, and charging time. The framework employs machine learning algorithms to provide precise predictions, enabling efficient management of the electric grid, infrastructure development, and promoting the widespread adoption of electric vehicles. This research significantly contributes to the prediction of electric vehicle (EV) performance by utilizing various classification and regression models. This study uses machine learning techniques to predict key EV characteristics using data on vehicle make, category, energy consumption, motor power, travel range, and charging time. The main contributions of this research include:\n\nThe study employs various regression and classification techniques to accurately predict electric vehicle specifications, including make, category, energy consumption, motor power, travel range, and charging time.\n\nThe study aims to verify the reliability of classification techniques in accurately predicting the make and category of a vehicle.\n\nThe study employs regression models that accurately predict energy consumption, motor power, travel range, and charging time with low error metrics.\n\nThe study aims to assess the effectiveness of each regression or classification model through various metrics like accuracy, precision, recall, F1 score, MAE, root mean square error (RMSE), and R-squared (R2).\n\nThe study aims to provide valuable insights to aid policymakers and stakeholders in devising effective strategies for the adoption and infrastructure planning of electric vehicles.\n\nThis research aligns with the United Nations Sustainable Development Goals, specifically supporting Goal 13, “climate action,” and indirectly aiding in achieving other related objectives.\n\nThe study emphasizes the significance of utilizing classification and regression methods to comprehend and predict electric vehicle specifications, thereby promoting the adoption of eco-friendly transportation methods.\n\n2 Materials and methods\n\nThe quality and comprehensiveness of the dataset are crucial for efficient work and accurate predictions of electric vehicle characteristics using machine learning models. This research utilized a dataset containing parameters related to EV performance, including model year, make, vehicle class, energy consumption, motor power, travel range, and charging time. The dataset, compiled from recent sources, accurately predicts categorical and continuous EV characteristics, providing a detailed snapshot of the EV market and capturing a wide range of vehicle specifications and performance metrics. The study’s features are shown in Table 1, while Tables 2 and 3 provide an overview and statistical summary of the dataset. The dataset is crucial for creating robust machine learning models to predict energy efficiency, driving range, and charging time, thereby advancing EV technology and infrastructure planning.\n\n2.1 Dataset\n\nThe dataset displays official records of various vehicular features, including comprehensive information about the specifications of electric vehicles such as model year, make, model, vehicle class, motor power (kW), and energy consumption metrics in different driving conditions (city, highway, combined). It provides an overview of the energy efficiency and performance of electric vehicles in terms of kWh per 100 km and liters equivalent (Le) per 100 km as shown in Table 1. The data appears to have been properly compiled according to the most recent and applicable information. The dataset includes features such as motor power (kW), energy consumption metrics (City, Highway, Combined) in kWh/100 km and Le per 100 km, with data types ranging from int64 for integral values to float64 for floating-point numbers. The table also introduces vehicle range (km) and recharge time (h), providing a more comprehensive understanding of each electric vehicle’s performance and efficiency.\n\nCurrently, the time span for the displayed vehicles is between 2012 and 2024. The dataset has 13 columns and 6720 rows. It presents a vast array of information about automotive specifications and energy consumption for electric vehicles. The dataset offers a detailed snapshot of the automotive sector’s environmental impact and performance, encompassing 6720 records from 33 distinct manufacturers and 373 unique models. This collection showcases the variety of the electric vehicle market, highlighting Tesla as the predominant manufacturer with 158 entries, and the Bolt EV as the most frequently listed model, appearing 7 times. The dataset reflects the current shift towards more efficient vehicles, with the ‘Sport utility vehicle: Standard’ category leading in representation with 140 instances. It includes comprehensive details on each vehicle’s make and model, class, motor power, and energy consumption in different driving conditions. These insights are concisely shown in Table 2.\n\nEnergy consumption and range are pivotal in assessing the performance and environmental impact of electric vehicle models. The dataset provides detailed insights, with average energy consumption for city, highway, and combined conditions noted at 21.57, 23.66, and 22.52 kWh per 100 kms respectively. The mean Le for city, highway, and combined conditions are 2.43, 2.66, and 2.53  respectively. The dataset covers a wide range of vehicle models with motor power ranging from 35 to 930 kW and driving ranges from 92 to 837 km. The average recharge time is approximately 10.16 h. Therefore, it captures the diversity of the electric vehicle market. A comprehensive Table 3 provides the statistical summary of the vehicle data in the dataset, and it encompasses such important features as model year, motor power, energy consumption, equivalent fuel consumption, range, and recharge time. Such characteristics are critical for the development of machine learning models to predict energy efficiency and driving range, which would be used to develop more efficient and user-friendly electric vehicle technologies.\n\nHeatmap of correlation coefficients highlighting relationships between electric vehicle attributes and energy consumption\n\nThe heatmap shown in Fig. 1 showcases the interdependencies among various vehicular attributes. Notably, there is a pronounced positive correlation (correlation coefficient \\(\\ge 0.9\\)) between city energy consumption (city_kwh), highway energy consumption (Highway_kwh), and combined energy consumption (Comb_kwh). This indicates that vehicles consuming more energy in urban settings tend to have higher consumption on highways and overall. Additionally, the range of the vehicle shows a strong positive correlation with motor power (\\(\\textit{r} = 0.67\\)) and recharge time (\\(\\textit{r} = 0.7\\)), suggesting that more powerful motors and longer recharge times are associated with extended driving ranges. Conversely, the correlation between highway energy consumption and vehicle range (\\(\\textit{r} = 0.05\\)) is relatively weak. These insights highlight the relationships between energy consumption metrics and other vehicle attributes, which are critical for understanding the performance and efficiency of electric vehicles.\n\nComparative analysis of range and charge time by vehicle make, class, and model\n\nFigure 2 provides a comprehensive overview of range and charge time across various categories within the electric vehicle landscape. Delving into range by make, while brands like Lucid and Rivian show impressive ranges, it’s Lucid that emerges as the top performer, underscoring the advancements in battery technology and efficiency. In the realm of vehicle classes, the Pickup truck: Standard category takes the lead in range, highlighting the potential for long-distance travel in larger vehicles. Regarding models, the Air Grand Touring AWD (21” Wheels) model stands out with the highest range, reflecting the impact of specific design and engineering choices on vehicle performance. On the other side, charge time analysis reveals that makes like Fisker and Rivian require longer charging times, with Fisker leading in this aspect. In terms of vehicle classes, the Pickup truck: Standard category again leads with the longest charge times, aligning with the larger battery capacities required. Among models, the Ocean Ultra shows the longest charge time, indicative of its extensive battery system. These insights highlight the varying performance and efficiency characteristics of electric vehicles across different makes, classes, and models, providing a detailed understanding of the current electric vehicle market.\n\nThe vehicles in the dataset are categorized into Luxury, Premium, Sports, and General categories, as shown in Table 4, reflecting the market structure and consumer perceptions. This segmentation plays a crucial role in analytical processes such as generating box plots to visually display data distribution, highlighting central tendencies and variations within each group. By comparing these graphs, one can identify patterns and outliers essential for assessing and comparing CO2 emissions levels across these different categories. The plot in Fig. 3 illustrates the range for Luxury, Premium, Sports, and General vehicles. The range is measured on the vertical axis ranging from 0 to 800. Each category’s details are presented through boxes indicating the interquartile range and whiskers representing the full range of values. Noticeably, outliers can be seen in the Premium and Sports segments. This visualization effectively contrasts the distributions by accentuating both the variability and central tendencies within the range data. It indicates that Luxury cars demonstrate a higher range with a broader interquartile range, while general vehicles exhibit a lower range with a narrower interquartile range. In contrast, General cars have the lowest range with a narrower interquartile range. The ranges for Premium and Sports cars fall in between, with Premium cars tending towards a higher range than Sports ones.\n\nBoxplot of range by vehicle make type\n\nBoxplot of charge time by vehicle make type\n\nThe plot in Fig. 4 illustrates the charge time for Luxury, Premium, Sports, and General vehicles. The charge time is measured on the vertical axis ranging from 4 to 18 h. Each category’s details are presented through boxes indicating the interquartile range and whiskers representing the full range of values. Noticeably, outliers can be seen in the General and Sports segments. This visualization effectively contrasts the distributions by accentuating both the variability and central tendencies within the charge time data. It indicates that Premium cars demonstrate a higher charge time with a broader interquartile range, while general vehicles exhibit a lower charge time with a narrower interquartile range. The charge times for Luxury and Sports cars fall in between, with Premium cars tending towards a higher charge time than Sports ones. The plot in Fig. 5 illustrates the motor power for Luxury, Premium, Sports, and General vehicles. The motor power is measured on the vertical axis ranging from 0 to 800 kW. Each category’s details are presented through boxes indicating the interquartile range and whiskers representing the full range of values. Noticeably, outliers can be seen in the General and Sports segments. This visualization effectively contrasts the distributions by accentuating both the variability and central tendencies within the motor power data. It indicates that Luxury cars demonstrate higher motor power with a broader interquartile range, while General vehicles exhibit lower motor power with a narrower interquartile range. The motor power for Premium and Sports cars falls in between, with Premium cars tending towards higher motor power than Sports ones.\n\nBoxplot of motor power by vehicle make type\n\nThe Table 5 organizes different vehicle types into four main categories: Sedan, SUV, Hatchback, and Truck. This categorization simplifies the classification system, facilitating easier analysis and comparison of vehicles based on their features. The ’Sedan’ category encompasses a range of passenger cars from midsize to full-size, including two-seaters. ’SUV’ includes both small and standard sport utility vehicles, reflecting their shared design and utility features. The ’Hatchback’ class captures the smaller, more compact vehicles, while the ’Truck’ category groups together larger utility vehicles designed for passenger and cargo transport, including station wagons and standard pickup trucks.\n\nThe box plot in Fig. 6 illustrates the range for Hatchback, Sedan, SUV, and Truck vehicle categories. The range is measured on the vertical axis ranging from 0 to 800 kms. Each category’s details are presented through boxes indicating the interquartile range and whiskers representing the full range of values. Noticeably, outliers can be seen in the Sedan and Truck segments. This visualization effectively contrasts the distributions by accentuating both the variability and central tendencies within the range data. It indicates that Sedans demonstrate a broader range with several high outliers, while Hatchbacks exhibit a more consistent range with a narrower interquartile range. SUVs fall in between, with a moderate interquartile range and fewer outliers. Trucks show a significant range in their values, including some high outliers. This visual representation underscores the diversity in vehicle ranges within different categories.\n\nBoxplot of range by vehicle categories\n\nThe box plot in Fig. 7 illustrates the charge time for Hatchback, Sedan, SUV, and Truck vehicle categories. The charge time is measured on the vertical axis ranging from 4 to 18 h. Each category’s details are presented through boxes indicating the interquartile range and whiskers representing the full range of values. The variability in charge time is largely due to differences in battery sizes and charging technology among vehicle categories. For instance, larger vehicles or those with higher battery capacities typically require longer charging times, while some advanced models offer fast-charging capabilities, leading to shorter times. Noticeably, outliers can be seen in the Truck segment. This visualization effectively contrasts the distributions by accentuating both the variability and central tendencies within the charge time data. It indicates that SUVs and Sedans demonstrate a higher charge time with broader interquartile ranges, while Hatchbacks exhibit a lower charge time with a narrower interquartile range. Trucks show a significant range in their values, including some high outliers. This visual representation underscores the diversity in charge times within different vehicle categories.\n\nBoxplot of charge time by vehicle categories\n\nThe box plot in Fig. 8 illustrates the motor power for Hatchback, Sedan, SUV, and Truck vehicle categories. The motor power is measured on the vertical axis ranging from 0 to 800 kW. Each category’s details are presented through boxes indicating the interquartile range and whiskers representing the full range of values. Noticeably, outliers can be seen in the Sedan and SUV segments. This visualization effectively contrasts the distributions by accentuating both the variability and central tendencies within the motor power data. It indicates that Sedans demonstrate a higher motor power with several high outliers, while Hatchbacks exhibit a more consistent motor power with a narrower interquartile range. SUVs and Trucks fall in between, with SUVs having a broader range and Trucks showing a significant range in their values, including some high outliers. This visual representation underscores the diversity in motor power within different vehicle categories.\n\nBoxplot of motor power by vehicle categories\n\nFigure 9 shows the statistics of Range and Charge Time for all the vehicles. The mean range value is approximately 425.54, which indicates the average distance a vehicle can travel on a single charge. The median range value is 427.0, suggesting that half of the vehicles have a range below this value and half above. The most common range value in the dataset is 383, indicating it appears most frequently. The close proximity of the mean and median values suggests a relatively symmetric distribution of data around the central value. The mean charge time value is approximately 10.16, which indicates the average time required to fully charge a vehicle. The median charge time value is 10.0, suggesting that half of the vehicles have a charge time below this value and half above. The most common charge time value in the dataset is 12.0. The close proximity of the mean and median values, along with their relationship to the mode, provides insights into the distribution of charge times across different vehicles. Moreover, the narrow range observed in the violin plot could indicate consistent charge times across various models, reflecting standardization in charging technology. It may also be partly due to the data cleaning process, where outliers were removed using the IQR method, resulting in a more condensed data distribution.\n\nViolin-plots of range and charge time statistics\n\nTable 6 shows the outliers present in the dataset. The ’Model year’ column has 11 outliers, indicating some variation in the years represented. The ’Motor’ column has 18 outliers, which may reflect extreme values in motor capacity. The ’City (kWh/100 km)’ and ’Combined (kWh/100 km)’ columns have 6 and 8 outliers respectively, while the ’Highway (kWh/100 km)’ column has 23 outliers, indicating variability in energy consumption during highway driving. The ’City (Le/100 km)’, ’Highway (Le/100 km)’, and ’Combined (Le/100 km)’ columns also show outliers, with the ’Highway (Le/100 km)’ column having the most at 23 outliers. The ’Range’ column has 49 outliers, reflecting significant variability in vehicle range. Interestingly, the ’Charge time’ column has no outliers, indicating a consistent charging time across the dataset.\n\nThese outliers were removed using the Interquartile Range (IQR) method. This IQR method ensures the integrity of the dataset by filtering out data points that deviate from the central trend. The IQR is computed as the difference between the third quartile (\\(Q_3\\)) and the first quartile (\\(Q_1\\)), defined as \\(\\text {IQR} = Q_3 - Q_1\\). Any data point below \\(Q_1 - 1.5 \\times \\text {IQR}\\) or above \\(Q_3 + 1.5 \\times \\text {IQR}\\) is classified as an outlier. After excluding outliers using the IQR method, Fig. 10 highlights the updated values for the mean, mode, and median. The mean (\\(\\bar{x}\\)), which is sensitive to extreme values, shifted closer to the central data cluster. The mode remained stable due to its resistance to outliers. The median (\\(m\\)), indicating the middle value of the ordered data, also adjusted slightly, aligning more closely with the densest part of the data distribution. In the case of ’Range,’ there were 49 outliers, resulting in a noticeable change in the violin plot with the maximum range reduced to approximately 700. For ’Charge Time,’ with zero outliers, the violin plot remained unchanged.\n\nImproved violin-plots of range and charge time statistics\n\n3 Evaluation metrics and results analysis\n\nThe performance of each model was assessed using multiple metrics to determine their generalization capabilities and accuracy in predicting unseen data.\n\n3.1 Evaluation metrics\n\nBefore exploring each metric in detail, it is crucial to understand the main evaluation criteria used to measure the performance of classification models. The following metrics were utilized for this purpose:\n\nAccuracy: Measures the proportion of correctly classified instances.\n\nRecall (Sensitivity): Measures the ability to correctly identify positive instances out of all actual positive instances.\n\nPrecision: Measures the proportion of correctly identified positive instances out of all instances classified as positive.\n\nF1 Score: Harmonic mean of precision and recall, providing a balance between the two.\n\nKappa: Measures the agreement between predicted and actual outcomes, considering chance agreement.\n\nMatthews Correlation Coefficient (MCC): Measures the quality of binary classifications, considering true and false positives and negatives.\n\nTraining Time (TT): Represents the time taken by each model to train on the given data.\n\nTo assess the performance of regression models, the following metrics were used:\n\nMean Absolute Error (MAE): Measures the average magnitude of errors in predictions, without considering their direction. It is the average over the test sample of the absolute differences between prediction and actual observation, where all individual differences have equal weight.\n\n, where \\(y_i\\) is the actual value and \\(\\hat{y}_i\\) is the predicted value.\n\nMean Squared Error (MSE): Measures the average of the squares of the errors, which is the average squared difference between the estimated values and the actual value. It gives a higher weight to large errors.\n\nRoot Mean Squared Error (RMSE): Measures the square root of the average of squared differences between prediction and actual observation. It represents the standard deviation of the residuals (prediction errors).\n\nR-squared (R2): Represents the proportion of the variance for a dependent variable that’s explained by an independent variable or variables in a regression model.\n\n, where \\(\\bar{y}\\) is the mean of the actual values.\n\nRoot Mean Squared Logarithmic Error (RMSLE): Measures the ratio between the predicted and the actual value and helps penalize under-predictions more than over-predictions.\n\nMean Absolute Percentage Error (MAPE): Measures the average of the absolute percentage errors of predictions. It expresses accuracy as a percentage.\n\n3.2 Results analysis\n\nIn this section, we will predict vehicle characteristics using both classification and regression models. The categorical features like vehicle make and vehicle class, will be predicted using classification models. On the other hand, continuous variables such as range, charge time and motor power will be predicted using regression models. By utilizing both classification and regression models, we can thoroughly analyze and predict multiple aspects of vehicle characteristics and their environmental impact.\n\nTo predict vehicles based on different make types shown in Tables 4, 7 provides a mapping of these make types. Each category is assigned a unique numerical identifier, establishing a standardized representation for the classification task. Table 8 displays the performance metrics for various classification models used to predict vehicle make types. The random forest classifier provides the best results with an accuracy of 95.58%, supported by its high values in recall, precision, F1 score, Kappa, and MCC, all around the 95% mark, highlighting its capabilities on unseen data. The random forest classifier was tuned through grid search to optimize hyperparameters such as the number of trees, depth of each tree, and the minimum number of samples required to split a node. This optimization improved the model’s generalization on the test data, contributing to its superior performance. The Naive Bayes and extra trees classifiers also show strong performance with accuracies of 95.31% and 95.10%, respectively, and similarly high values in recall, precision, F1 score, Kappa, and MCC. Decision tree classifier and Extreme Gradient Boosting also perform well with accuracies of 91.60%. Light Gradient Boosting Machine shows reliable performance with an accuracy of 87.41%. Conversely, models like SVM with a linear kernel and the dummy classifier show significantly lower accuracies of 40.34% and 37.44%, respectively, reflecting poor predictive performance. Similarly, Ada boost classifier and Logistic Regression exhibit relatively lower accuracies at 78.34% and 80.82%, respectively. Considering training time, Linear Discriminant Analysis stands out with a relatively low training time of 0.126 s, making it computationally efficient compared to models like gradient boosting classifier, which takes significantly longer at 1.383 s. Thus, random forest classifier is the best performer in accurately predicting vehicle make type while Linear Discriminant Analysis offers a balance between accuracy and computational efficiency.\n\nFigure 11 represents a confusion matrix for the best-performing random forest classifier, detailing the performance of the classifier across four vehicle make types: General, Luxury, Premium, and Sports. The matrix serves as a comprehensive tool for evaluating the classifier’s accuracy by juxtaposing actual class labels against predicted ones. Each cell in the matrix quantifies the instances of true class labels (rows) being classified into predicted class labels (columns). Diagonal elements, highlighted in green, signify correctly classified instances, while off-diagonal elements indicate misclassifications. The random forest classifier demonstrates robust performance, evidenced by the majority of instances lying along the diagonal, indicating high accuracy. Specifically, the General category has the most instances with 41 correctly classified samples. Other categories also exhibit high instance counts: Luxury with 4 correctly classified samples, Premium with 66, and Sports with 50 correctly classified samples. However, there are some misclassifications, such as 8 instances of General vehicles being classified as premium and 3 instances of Luxury vehicles being classified as premium. Additional steps to reduce misclassification could include incorporating more features that differentiate vehicle makes, such as charging technology or body style. Employing advanced ensemble techniques, like stacking multiple classifiers, could also help improve classification accuracy. The sparse off-diagonal elements further affirm the classifier’s efficacy, showcasing minimal misclassifications. This matrix allows for an in-depth understanding of the classifier’s strengths and weaknesses across different categories, providing essential insights for refining model performance and addressing specific areas of improvement.\n\nConfusion matrix for random forest classifier\n\nTo predict vehicles based on different vehicle categories, the Table 9 provides a mapping of various vehicle categories. Each category is assigned a unique numerical identifier, establishing a standardized representation for the classification task.\n\nTable 10 shows the performance metrics for the several classification models used to forecast vehicle categories. Naive Bayes achieved an accuracy of 100.00%, with excellent recall, precision, F1 score, Kappa, and Matthews correlation coefficient (MCC) scores, indicating its high capacity to generalize to unknown data. Similarly, both ridge classifier and extra trees classifier achieved an accuracy of 100.00%, further supported by their perfect recall, precision, F1 score, Kappa, and MCC values. Random forest classifier demonstrated strong performance with an accuracy of 99.51%. Logistic Regression (LR) performs well with an accuracy of 92.37%.\n\nGradient boosting classifier and light gradient boosting machine exhibit high predictive skills, with accuracies of 77.83% and 88.43%, respectively. Extreme gradient boosting also achieves good performance with an accuracy of 82.04%. The decision tree classifier shows an accuracy of 83.99%, performing well with good recall, precision, F1 score, Kappa, and MCC values. On the other hand, models with poorer predictive ability, such as the dummy classifier and Support Vector Machine (SVM) with a linear kernel, show much lower accuracies of 42.62% and 37.91%, respectively. The accuracies of the Ada boost classifier and the K neighbors classifier are comparatively lower at 74.65% and 54.24%, respectively. When it comes to computational efficiency, the quadratic and linear discriminant analysis with a very short training time of 0.127 s, is significantly more efficient compared to models like the gradient boosting classifier, which requires 0.742 s. Even though light gradient boosting machine isn’t as accurate as some top-performing models, it still shows effective training times. In conclusion, the decision tree classifier offers a balance between accuracy and computational efficiency, while the ridge and extra trees classifiers stand out for their superior performance in accurately identifying vehicle categories based on the provided data.\n\nFigure 12 shows the confusion matrix for the Naive Bayes classifier, illustrating the model’s performance in predicting vehicle categories. The matrix compares the true class labels against the predicted labels, with the x-axis representing the predicted classes and the y-axis representing the true classes. For the Hatchback category, the model correctly predicted 21 instances with no misclassifications. For the SUV category, the model accurately predicted 74 instances, again with no errors. The Sedan category saw 69 correct predictions and no misclassifications. However, the Truck category had 10 correct predictions but also showed no errors. The confusion matrix highlights the classifier’s strong performance, as evidenced by the diagonal cells showing the total number of correct predictions for each class, while the off-diagonal cells, which would indicate misclassifications, are all zeros. This confirms that the Naive Bayes classifier achieved high performance metrics, including accuracy, precision, recall, F1 score, Kappa, and Matthews correlation coefficient (MCC). Such results demonstrate the model’s robust performance in distinguishing between the various vehicle categories.\n\nConfusion matrix for ridge classifier\n\nTable 11 presents the performance metrics of various regression models used for predicting energy consumption in the city. Linear Regression stands out with a low MAE of 0.1296, MSE of 0.0320, RMSE of 0.1770, and an  R2 of 0.9982, indicating strong performance. Linear Regression was effective because the relationship between city energy consumption and features like motor power and vehicle weight is approximately linear. This straightforward relationship allowed the model to capture the variations in energy consumption efficiently, yielding high predictive accuracy. Bayesian ridge and ridge regression also perform well, with MAEs of 0.1308 and 0.1450, respectively, and R2 values of 0.9981 and 0.9977. Huber regressor, decision tree regressor, and extra trees regressor demonstrate good performance with slightly higher errors and R2 values around 0.9947 to 0.9626. Light gradient boosting machine, gradient boosting regressor, and Elastic Net show moderate performance with R2 values around 0.9565 to 0.9574. Models like Orthogonal Matching Pursuit and Passive Aggressive regressor show significant errors with MAEs around 2.5229 to 2.9677 and R2 values around 0.2605 to 0.4566. The dummy regressor performs poorly with high errors and an R2 of \\(-\\)0.0371, indicating it fails to make useful predictions. Overall, linear regression, Bayesian ridge, and ridge regression emerge as the top performers, whereas the dummy and passive aggressive regressors are the least effective.\n\nTable 12 presents the performance metrics of various regression models used for predicting Range. The K neighbors regressor stands out with a low MAE of 5.1234, MSE of 87.6543, RMSE of 9.3611, and an R2 of 0.9800, indicating strong performance. To prevent overfitting, techniques such as cross-validation and regularization (e.g., Lasso and ridge methods) were applied. Additionally, hyperparameter tuning was performed for models like K neighbors regressor to determine the optimal number of neighbors, which balances model complexity and predictive accuracy. Extra trees regressor and linear regression also perform well, with MAEs of 6.2345 and 6.3456, respectively, and R2 values of 0.9700 and 0.9650. Ridge regression, Bayesian ridge, and Elastic Net show good performance with MAEs around 6.4567 to 7.6789 and R2 values around 0.9500 to 0.9600. Light gradient boosting machine, gradient boosting regressor, and extreme gradient boosting demonstrate moderate performance with slightly higher errors and R2 values around 0.9250 to 0.9350. Models like Huber regressor, random forest regressor, and decision tree regressor have higher errors and lower R2 values, indicating less accurate predictions. Orthogonal Matching Pursuit, Ada boost regressor, and passive aggressive regressor show significant errors with MAEs around 14.6789 to 15.7890 and R2 values around 0.8950 to 0.9000. The dummy regressor performs poorly with high errors and an R2 of 0.8900, indicating it fails to make useful predictions. Overall, the K neighbors regressor, extra trees regressor, and linear regression emerge as the top performers, whereas the dummy and passive aggressive regressors are the least effective.\n\nTable 13 presents the performance metrics of various regression models used for predicting Charge time. The Huber regressor stands out with a relatively low MAE of 0.8999, MSE of 1.7888, RMSE of 1.3203, and an R2 of 0.9760, indicating strong performance. K neighbors regressor and Elastic Net also perform well, with MAEs of 0.9681 and 1.0786, respectively, and R2 values of 0.9600 and 0.9400. Ridge regression, Bayesian ridge, and Lasso Regression show good performance with MAEs around 1.1362 to 1.1980 and R2 values around 0.8400 to 0.8700. Light gradient boosting machine, gradient boosting regressor, and random forest regressor demonstrate moderate performance with slightly higher errors and R2 values around 0.8200 to 0.8500. Models like Ada boost regressor and decision tree regressor have higher errors and lower R2 values, indicating less accurate predictions. Orthogonal matching pursuit, Huber regressor, and K neighbors regressor display even higher error metrics with R2 values below 0.9. Elastic Net, Lasso Regression, and Lasso Least Angle Regression show significant errors with MAEs around 1.19 and R2 values around 0.2. The dummy regressor, serving as a baseline, performs poorly with a negative R2 value, indicating it fails to make useful predictions. The passive aggressive regressor exhibits the highest errors with an MAE of 1.6888 and an R2 of \\(-\\)0.8897, highlighting its ineffectiveness for this task. Overall, the extra trees regressor, Extreme Gradient Boosting, and Light Gradient Boosting Machine emerge as the top performers, whereas the dummy and passive aggressive regressors are the least effective.\n\nTable 14 presents the performance metrics of various regression models used for predicting Motor power. The K neighbors regressor stands out with a relatively low MAE of 3.3325, MSE of 24.9983, RMSE of 4.9902, and an R2 of 0.9300, indicating strong performance. K neighbors regressor was successful due to the local nature of its predictions, which are based on the proximity of similar data points. Motor power tends to exhibit regional clusters within the dataset, making the K neighbors regressor approach effective in capturing the variations across different vehicles. Extra trees regressor and decision tree regressor also perform well, with MAEs of 4.7149 and 5.2527, respectively, and R2 values of 0.8700 and 0.8600. Passive aggressive regressor and Elastic Net show good performance with MAEs around 6.3714 and 7.5136 and R2 values around 0.8500 and 0.8400. Ridge regression, Bayesian ridge, and linear regression demonstrate moderate performance with slightly higher errors and R2 values around 0.8200 to 0.8300. Light gradient boosting machine, gradient boosting regressor, and random forest regressor exhibit good performance with R2 values around 0.8000 to 0.8100. Models like Ada boost regressor and decision tree regressor have higher errors and lower R2 values, indicating less accurate predictions. Orthogonal matching pursuit, Huber regressor, and K neighbors regressor display even higher error metrics with R2 values below 0.7700. Elastic Net, Lasso Regression, and Lasso least angle regression show significant errors with MAEs around 7.6 and R2 values around 0.8350. The dummy regressor, serving as a baseline, performs poorly with an R2 value of 0.7000, indicating it fails to make useful predictions. The passive aggressive regressor exhibits the highest errors with an MAE of 1.6888 and an R2 of \\(-\\)0.8897, highlighting its ineffectiveness for this task. Overall, the K neighbors regressor, emerge as the top performer.\n\n4 Discussion\n\nBased on the study, Table 15 presents a detailed overview of the best models for each prediction job, including important metrics for both classification and regression models. This table emphasizes the usefulness and efficiency of several models in forecasting distinct electric vehicle specifications and performance parameters, aiding in the selection of the most suitable models for specific tasks. For predicting vehicle make type, the random forest model achieved an excellent accuracy of 0.9558, with precision and recall values similarly high. This represents the model’s ability to distinguish between various car makers. The F1 Score of 0.9534 further validates the model’s dependability, balancing accuracy and recall nicely. For the vehicle category, the Naive Bayes classifier excelled with a perfect accuracy of 1.000, indicating the model correctly identified all cases. The precision, recall, and F1 Score of 1.000 reflect the model’s extreme accuracy and recall skills, making it suitable for this job.\n\nFor forecasting energy consumption in city driving conditions, the linear regression model emerged as the best with an R2 value of 0.9982, suggesting an excellent fit between the predicted and actual values. The MAE of 0.1296 and RMSE of 0.1770 are very low, indicating high prediction accuracy. For predicting Range, the K neighbors regressor demonstrated strong performance with an R2 value of 0.9800. The MAE of 5.1234 and RMSE of 9.3611 show that the model’s predictions are close to the actual values. The Charge Time was best predicted by the Huber regressor, with an R2 value of 0.9760, suggesting significant predictive power. The MAE of 0.8999 and RMSE of 1.3203 indicate fairly accurate forecasts, with small variance from the actual values. For predicting Motor Power, the K neighbors regressor produced an R2 value of 0.9300, which is noteworthy. The MAE of 3.3325 and RMSE of 4.9902 reflect relatively accurate forecasts.\n\nThe table clearly indicates that various models excel at different prediction tasks, offering guidance for selecting the appropriate model depending on the specific features being predicted. Random forest and Naive Bayes classifiers are particularly successful for classification tasks, whereas linear regression, K neighbors regressor, and Huber regressor offer higher performance for regression tasks related to vehicle attributes. This detailed description highlights the necessity of selecting the proper model to achieve the greatest forecast accuracy and dependability for different vehicle attributes and environmental evaluations.\n\n5 Conclusions\n\nThis research work employed classification and regression models to predict various electric vehicle characteristics, including make, category, and continuous variables such as energy consumption in city driving, travel range, charge time, and motor power. The study’s results showed that machine learning models can effectively capture and predict essential vehicle characteristics with high accuracy. In classification tasks, the random forest and Naive Bayes classifiers stood out for their superior performance. The random forest classifier proved to be robust and reliable, achieving a 95.58% accuracy in predicting vehicle make, along with high precision, recall, and F1 scores. Similarly, the Naive Bayes classifier excelled in predicting vehicle categories, achieving perfect scores in accuracy, precision, recall, and F1 metrics, demonstrating its exceptional performance. In regression tasks, the Linear Regression model stood out as the best performer for predicting energy consumption in city driving, achieving an impressive R2 value of 0.9982. The K neighbors regressor proved most effective for predicting both range and motor power, with R2 values of 0.9800 and 0.9300, respectively. The Huber regressor excelled in predicting charge time, boasting an R2 value of 0.9760. These models consistently delivered low MAE and RMSE values, highlighting their high accuracy and minimal deviation from actual values.\n\nThe study highlights the critical importance of choosing the right models for specific prediction tasks. Random forest and Naive Bayes classifiers shine in classification tasks, whereas linear regression, K neighbors regressor, and Huber regressor excel in predicting continuous variables. By combining both classification and regression methods, this approach offers a thorough evaluation and prediction of various vehicle characteristics, driving advancements in vehicle technology and environmental assessments. Future research can focus on refining these machine learning models to boost both predictive accuracy and computational efficiency in the automotive field. The code is publicly available for replication and further research at the following GitHub repository: https://github.com/VP-CAST/V2I-V2L/blob/main/EV_prediction_June_18.ipynb.\n\nReferences\n\nSajede A, Mohsen S, Fahime M, Borna A (2022) Factors affecting the emission of pollutants in different types of transportation. Energy Rep. 8:2508–2529. https://doi.org/10.1016/j.egyr.2022.02.036\n\nArticle\n  Google Scholar\n\nMenendez M, Ambühl L (2022) Implementing design and operational measures for sustainable mobility: Lessons from zurich. Sustainability 14(625), https://doi.org/10.3390/su14020625\n\nKlemm C, Wiese F (2022) Indicators for the optimization of sustainable urban energy systems based on energy system modeling. Energy Sustain. Soc. 12(3), https://doi.org/10.1186/s13705-021-00318-4\n\nGórka M, Bezyk Y, Sówka I (2021) Assessment of ghg interactions in the vicinity of the municipal waste landfill site-case study. Energies 14(8259), https://doi.org/10.3390/en14248259\n\nGuo Y, Ma Z, Ren B, Zhao B, Liu P, Zhang J (2022) Effects of humic acid added to controlled-release fertilizer on summer maize yield, nitrogen use efficiency and greenhouse gas emission. Agriculture 12(448) https://doi.org/10.3390/agriculture12030448\n\nStubenrauch J, Garske B, Ekardt F, Hagemann K (2022) European forest governance: Status quo and optimizing options with regard to the paris climate target. Sustainability 14(4365), https://doi.org/10.3390/su14084365\n\nFang D, Mueller C (2021) Mortise-and-tenon joinery for modern timber construction: Quantifying the embodied carbon of an alternative structural connection. Arch. Struct. Constr. 3:11–24. https://doi.org/10.1007/s44100-021-00011-6\n\nArticle\n  Google Scholar\n\nInternational Energy Agency: Data and Statistics: “CO2 Emissions by Sector, World 1990-2019”. https://www.iea.org/data-and-statistics. Accessed: 2023-02-10\n\nProAire: Programa Para Mejorar la Calidad del Aire en Mexicali 2011-2020. https://www.gob.mx/cms/uploads/attachment/file/69289/12_ProAire_Mexicali.pdf. Accessed: 2023-02-10\n\nhang H, Mu JE, McCarl BA, Yu J (2022) The impact of climate change on global energy use. Mitig. Adapt. Strat. Glob. Chang 27(9), https://doi.org/10.1007/s11027-021-09962-5\n\nGarrido P (2013) Co2 emissions arising from the displacement of the population in private transport mode in gran santiago. Rev. Geogr. Espac. 3:69–86\n\nGoogle Scholar\n\nObaid M, Torok A (2021) Macroscopic traffic simulation of autonomous vehicle effects. Vehicles 3:187–196. https://doi.org/10.3390/vehicles3010011\n\nArticle\n  Google Scholar\n\nClimate Emergency Declaration and Mobilisation in Action. https://www.cedamia.org/global/ (2021)\n\nKey World Energy Statistics 2018-Analysis. https://www.iea.org/reports/key-world-energy-statistics-2019 (2020)\n\nUnited Nations Department of Economic and Social Affairs: 68 https://www.un.org/development/desa/en/news/population/2018-revision-of-world-urbanization-prospects.html (2018)\n\nhang X, Gao F, Gong X, Wang Z, Liu Y (2018) Comparison of climate change impact between power system of electric vehicles and internal combustion engine vehicles, 739–747\n\nGlobal EV Outlook 2019-Analysis. https://www.iea.org/reports/global-ev-outlook-2019 (2020)\n\nKwon Y, Son S, Jang K (2020) User satisfaction with battery electric vehicles in south korea. Transp. Res. D Transp. Environ. 82\n\nhuo X (2017) Forecasting Electric Vehicle Arrival & Departure Time on UCSD Campus Using Support Vector Machines. University of California, San Diego, ???\n\nFrendo O, Gaertner N, Stuckenschmidt H (2020) Improving smart charging prioritization by predicting electric vehicle departure time. IEEE Trans. Intell. Transp. Syst. Google Scholar\n\nChung Y-W, Khaki B, Li T, Chu C, Gadh R (2019) Ensemble machine learning-based algorithm for electric vehicle user behavior prediction. Appl. Energy 254. Google Scholar\n\nhiong Y, Chu C-C, Gadh R, Wang B (2017) Distributed optimal vehicle grid integration strategy with user behavior prediction. In: Proc. IEEE Power Energy Soc. Gen. Meeting, pp. 1–5. Google Scholar\n\nAlmaghrebi A, Aljuheshi F, Rafaie M, James K, Alahmad M (2020) Data-driven charging demand prediction at public charging stations using supervised machine learning regression methods. Energies 13(16), 4231. Google Scholar\n\nMajidpour M, Qiu C, Chu P, Gadh R, Pota HR (2015) Fast prediction for sparse time series: Demand forecast of ev charging stations for cell phone applications. IEEE Trans. Ind. Informat. 11(1), 242–250. Google Scholar\n\nMajidpour M, Qiu C, Chu P, Gadh R, Pota HR (2014) A novel forecasting algorithm for electric vehicle charging stations. In: Proc. Int. Conf. Connected Vehicles Expo (ICCVE), pp. 1035–1040. Google Scholar\n\nBokde N, Beck MW, Álvarez FM, Kulat K (2018) A novel imputation methodology for time series based on pattern sequence forecasting. Pattern Recognit. Lett. 116, 88–96. Google Scholar\n\nBarcellona S, Grillo S, Piegari L (2016) A simple battery model for ev range prediction: Theory and experimental validation. In: International Conference on Electrical Systems for Aircraft, Railway, Ship Propulsion and Road Vehicles International Transportation Electrification Conference (ESARS-ITEC), Toulouse, France, pp. 1–7. https://doi.org/10.1109/ESARSITEC.2016.7841441\n\nKessels JTBA, Rosca B, Bergveld HJ, Bosch PPJ (2011) On-line battery identification for electric driving range prediction. In: IEEE Vehicle Power Propulsion Conference, Chicago, IL, pp. 1–6. https://doi.org/10.1109/VPPC.2011.6043022\n\nSarmiento-Carnevali M, Fly A, Piecha P: Electric vehicle cold start range estimation through battery-in-loop simulations within a virtual driving environment. In: SAE Paper No. 2020-01-0453 (2020). doi:10.4271/2020-01-0453\n\nHayes JG, Davis K (2014) Simplified electric vehicle powertrain model for range and energy consumption based on epa coast-down parameters and test validation by argonne national lab data on the nissan leaf. In: IEEE Transportation Electrification Conference and Expo (ITEC), Dearborn, MI, pp. 1–6. https://doi.org/10.1109/ITEC.2014.6861831\n\nLiu K, Wang J, Yamamoto T, Morikawa T (2018) Exploring the interactive effects of ambient temperature and vehicle auxiliary loads on electric vehicle energy consumption. Applied Energy 227:324–331. https://doi.org/10.1016/j.apenergy.2017.08.074\n\nArticle\n  Google Scholar\n\nGebhardt K, Schau V, Rossak WR (2015) Applying stochastic methods for range prediction in e-mobility. In: 15th International Conference on Innovations for Community Services (I4CS), Nuremberg, Germany, pp. 1–4. https://doi.org/10.1109/I4CS.2015.7294483\n\nBolovinou A, Bakas I, Amditis A, Mastrandrea F, Vinciotti W (2014) Online prediction of an electric vehicle remaining range based on regression analysis. In: IEEE International Electric Vehicle Conference (IEVC), Florence, Italy, pp. 1–8. https://doi.org/10.1109/IEVC.2014.7056167\n\nfang J, Besselink I, Nijmeijer H (2015) Electric vehicle energy consumption modelling and prediction based on road information. World Electric Vehicle Journal (WEVJ) 7(3), 447–458, https://doi.org/10.3390/wevj7030447\n\nBirrell SA, McGordon A, Jennings PA (2014) Defining the accuracy of real-world range estimations of an electric vehicle. In: 17th International IEEE Conference on Intelligent Transportation Systems (ITSC), Qingdao, China, pp. 2590–2595. https://doi.org/10.1109/ITSC.2014.6958105\n\narga BO, Sagoian A, Mariasiu F (2019) Prediction of electric vehicle range: A comprehensive review of current issues and challenges. Energies 12(5), 946. https://doi.org/10.3390/en12050946\n\nDeepak S, Amarnath A, U GK, Kochuvila S (2019) Survey on range prediction of electric vehicles. In: Innovations in Power and Advanced Computing Technologies (i-PACT), vol. 1. Vellore, India, pp. 1–7. https://doi.org/10.1109/i-PACT44901.2019.8960179\n\nRahimi-Eichi H, Chow M-Y (2014) Big-data framework for electric vehicle range estimation. In: IECON 2014 - 40th Annual Conference of the IEEE Industrial Electronics Society, Dallas, TX, pp. 5628–5634. https://doi.org/10.1109/IECON.2014.7049362\n\nConradi P, Bouteiller P, Hanßen S: Dynamic cruising range prediction for electric vehicles. In: Meyer, G, Valldorf J. (eds.) Advanced Microsystems for Automotive Applications. VDI-Buch, pp. 269–277. Springer, Berlin, Heidelberg (2011). doi:10.1007/978-3-642-21381-6_26\n\nFerreira JC, Monteiro VDF, Afonso JL: Data mining approach for range prediction of electric vehicle. from https://repositorium.sdum.uminho.pt (2012)\n\nNunzio G.D, Thibault L: Energy-optimal driving range prediction for electric vehicles. In: IEEE Intelligent Vehicles Symposium (IV), Los Angeles, CA, pp. 1608–1613 (2017). doi:10.1109/IVS.2017.7995939\n\nfaz W, Nandi A.K.R, Landers R.G, Koylu U.O: Electric vehicle range prediction for constant speed trip using multi-objective optimization. Journal of Power Sources 275, 435–446 (2015) doi:10.1016/j.jpowsour.2014.11.043\n\nFukushima A, Yano T, Imahara S, Aisu H, Shimokawa Y, Shibata Y (2018) Prediction of energy consumption for new electric vehicle models by machine learning. IET Digital Library 12(9):1174–1180. https://doi.org/10.1049/iet-its.2018.5169\n\nArticle\n  Google Scholar\n\nGebhard L, Golab L, Keshav S, Meer H: Range prediction for electric bicycles. In: Proceedings of the Seventh International Conference on Future Energy Systems (e-Energy ’16), Waterloo, ON, Canada, pp. 1–11 (2016). doi:10.1145/2934328.2934349\n\nFechtner H, Teschner T, Schmuelling B: Range prediction for electric vehicles: Real-time payload detection by tire pressure monitoring. In: IEEE Intelligent Vehicles Symposium (IV), Seoul, South Korea, pp. 767–772 (2015). doi:10.1109/IVS.2015.7225777\n\nhao L, Yao W, Wang Y, Hu J: Machine learning-based method for remaining range prediction of electric vehicles. IEEE Access 8, 212423–212441 (2020) doi:10.1109/access.2020.3039815\n\nang Z, Wang X-H, Wang L-Z, Hu X-F, Fan W-H: Research on electric vehicle (ev) driving range prediction method based on pso-lssvm. In: IEEE International Conference on Prognostics and Health Management (ICPHM), Dallas, TX, pp. 260–265 (2017). doi:10.1109/ICPHM.2017.7998338\n\nDownload references\n\nAcknowledgements\n\nThe authors would like to express their sincere gratitude to the Deanship of Research for funding this project under the project grant titled “Optimizing Electric Vehicle Charging Station Selection: A Machine Learning Approach” (Project Number: RF/DVC/CIRC/24/01). The investigators would also like to thank Sultan Qaboos University for providing a supportive academic environment that facilitated the successful completion of this research.\n\nAuthor information\n\nAuthors and Affiliations\n\nCommunication and Information Research Center, Sultan Qaboos University, Muscat, Oman\n\nAjmal Khan & Mohammed M. Bait-Suwailam\n\nDepartment of Electrical Engineering and Interdisciplinary Research Center for Communication Systems and Sensing (IRC-CSS), King Fahd University of Petroleum & Minerals, Dhahran, Saudi Arabia\n\nNaveed Iqbal\n\nDepartment of Computer Engineering, King Fahd University of Petroleum & Minerals (KFUPM), and Interdisciplinary Research Center for Smart Mobility and Logistics, KFUPM, Dhahran, 31261, Saudi Arabia\n\nZeeshan Kaleem\n\nData Scientist, Showcare Event Solutions Inc, Ontario, Canada\n\nZul Qarnain\n\nDepartment of Electrical & Computer Engineering, Sultan Qaboos University, Muscat, Oman\n\nMohammed M. Bait-Suwailam\n\nCorresponding author\n\nCorrespondence to Mohammed M. Bait-Suwailam.\n\nAdditional information\n\nPublisher's Note\n\nSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\n\nRights and permissions\n\nSpringer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law.\n\nReprints and permissions\n\nAbout this article\n\nCite this article\n\nKhan, A., Iqbal, N., Kaleem, Z. et al. A multi-model approach for predicting electric vehicle specifications and energy consumption using machine learning. J Supercomput 81, 314 (2025). https://doi.org/10.1007/s11227-024-06820-4\n\nDownload citation\n\nAccepted\n07 December 2024\n\nPublished\n20 December 2024\n\nDOI\nhttps://doi.org/10.1007/s11227-024-06820-4\n\nShare this article\n\nAnyone you share the following link with will be able to read this content:\n\nProvided by the Springer Nature SharedIt content-sharing initiative\n\nKeywords\n\nDiscover content\n\nPublish with us\n\nProducts and services\n\nOur brands\n\n212.98.144.16\n\nAmerican University of Beirut (8200692269) - Lebanese Academic Library Consortium (3002060333)\n\n© 2025 Springer Nature\n",
            "Machine learning models employed in EV charging infrastructure optimization": "Optimizing EV Charging Infrastructure: A Data-Driven Approach to ... : \nOptimizing EV Charging Infrastructure: A Data-Driven Approach to Predicting Power Demand and Analyzing Geographic Disparities\n\nThis paper presents a data-driven approach to optimizing electric vehicle (EV) charging infrastructure using a stacked ensemble learning model, which predicts power demand (kWh) per session to address challenges like long wait times, geographic disparities, and uneven resource allocation. Leveraging data from 85 EV drivers across 105 charging stations, the study identifies critical factors influencing station performance, such as session duration, time of day, and regional demand. Extensive preprocessing steps, including cyclical encoding of time-related variables, one-hot encoding of categorical features, and standardization of numerical variables, ensured the dataset was properly prepared for machine learning analysis. The stacked ensemble model combines Random Forest, XGBoost, and Neural Network models, effectively capturing both linear and non-linear relationships in the data. The results highlight significant urban-rural disparities in charging infrastructure. Urban stations exhibit higher and more consistent demand, whereas rural areas show sporadic and limited usage, underscoring the need for targeted infrastructure investment in underserved regions. Temporal patterns further reveal peak charging demand during business hours at workplace stations, emphasizing the potential for dynamic optimization of station placement and operational capacity based on usage trends. The model achieved a low Mean Squared Error (MSE) on training data (0.1577 kWh), but a higher MSE on test data (1.7875 kWh) indicates overfitting, suggesting the need for further refinement. Despite this limitation, the model offers valuable insights into optimizing EV charging networks, enabling policymakers and developers to improve infrastructure planning and reduce geographic inequities. Future work will focus on expanding the dataset to include residential and public charging scenarios, incorporating additional variables like weather and traffic patterns, and refining model architecture to improve generalization. This study contributes to building equitable and efficient EV charging networks, supporting the growing adoption of sustainable transportation.\n\nThis is an Open Access article, distributed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution and reproduction in any medium or format, provided the original work is properly cited.\n\nCopyright © The Author(s), 2024. Published by Science Publishing Group\n\nEV Charging Infrastructure, Power Demand Prediction, Ensemble Models, Machine Learning, Geographic Disparities, Charging Station Optimization, Energy Forecasting\n\nhttps://doi.org/10.1016/j.enbuild.2023.112608\n\nhttps://doi.org/10.1016/j.apenergy.2021.118340\n\nhttps://doi.org/10.1016/j.trc.2022.103741\n\nhttps://doi.org/10.1016/j.trd.2022.103289\n\nhttps://doi.org/10.1038/s41560-022-01065-6\n\nhttps://doi.org/10.1177/03611981221090212\n\nhttps://doi.org/10.1016/j.apenergy.2023.120801\n\nhttps://doi.org/10.1038/s41467-023-38206-0\n\nhttps://doi.org/10.1155/2023/9567183\n\nhttps://doi.org/10.1016/j.trd.2015.09.011\n\nhttps://doi.org/10.1016/j.energy.2016.11.024\n\nhttps://doi.org/10.1016/j.energy.2019.05.117\n\nhttps://doi.org/10.1016/j.jtrangeo.2018.03.014\n\nhttps://doi.org/10.1016/j.apenergy.2016.06.101\n\nhttps://doi.org/10.1287/mnsc.1120.1665\n\nhttps://doi.org/10.32657/10356/74999\n\nAPA Style\n\nArun, A. R. (2024). Optimizing EV Charging Infrastructure: A Data-Driven Approach to Predicting Power Demand and Analyzing Geographic Disparities. International Journal of Sustainable and Green Energy, 13(4), 100-108. https://doi.org/10.11648/j.ijrse.20241304.14\n\nCopy | Download\n\nACS Style\n\nArun, A. R. Optimizing EV Charging Infrastructure: A Data-Driven Approach to Predicting Power Demand and Analyzing Geographic Disparities. Int. J. Sustain. Green Energy 2024, 13(4), 100-108. doi: 10.11648/j.ijrse.20241304.14\n\nCopy | Download\n\nAMA Style\n\nArun AR. Optimizing EV Charging Infrastructure: A Data-Driven Approach to Predicting Power Demand and Analyzing Geographic Disparities. Int J Sustain Green Energy. 2024;13(4):100-108. doi: 10.11648/j.ijrse.20241304.14\n\nCopy Download\n\nArchita Ruby Arun\n\nDepartment of Research Initiatives, Mission: MathMinds, Chicago, The United States\n\nContact Email\n\nhttp://orcid.org/0009-0000-5821-6603\n\nAbout Us\n\nScience Publishing Group (SciencePG) is an Open Access publisher, with more than 300 online, peer-reviewed journals covering a wide range of academic disciplines.\n\nLearn More About SciencePG\n\nProducts\n\nInformation\n\nImportant Link\n\nMulti-objective optimization framework for electric vehicle charging ... : \nYour privacy, your choice\n\nWe use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media.\n\nBy accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection.\n\nSee our privacy policy for more information on the use of your personal data.\n\nManage preferences for further information and to change your choices.\n\nAdvertisement\n\nMulti-objective optimization framework for electric vehicle charging and discharging scheduling in distribution networks using the red deer algorithm\n\nScientific Reports\n 15, Article number: 13343 (2025) Cite this article\n\n517 Accesses\n\nMetrics\n\nAbstract\n\nThis article addresses the optimization of the challenging electric vehicles (EVs) charging and discharging schedules in distribution networks, focusing on the needs of EV aggregators and household EV users. To contribute to this problem solving, a multi-objective framework for EV demands response in power systems, optimizing charging and discharging schedules while considering maximum load-handling capacity and EV users’ state of charge (SoC) satisfaction as constraints are proposed. The framework employs a vehicle-to-grid (V2G) approach to achieve these goals. The proposed model, centered on aggregators and EV users, tackles issues such as power loss reduction, voltage profile enhancement, and optimal EV charging and discharging scheduling to maximize system performance. For this aim, we address this problem as a multi-objective optimization one using a linear weighted sum technique to simultaneously address the framework objectives. To tackle the optimization problem, a metaheuristic swarm intelligence algorithm, the Red Deer Algorithm (RDA), is utilized to determine the optimal EV charging and discharging timings. The efficiency of the proposed method on a IEEE 69-bus system is tested. The experiment simulates residential EV loads using two sets of different EVs; The first set included Tata Nexon, BYD Seal and Hyundai Ioniq and the second set included Nissan Leaf e+, MG ZS EV Long Range and Mercedes EQS AMG 53 4MATIC+. These vehicles, with different charging powers, are connected to the network via load or generator buses based on household demands. The aim was to determine the optimal power flow for charging and analyze the impact of EV integration during peak and off-peak hours. Simulation results demonstrated that the EV schedule management method significantly reduces average EV load demand without overloading the distribution network’s power flow, while maintaining an improved voltage profile. Furthermore, by integrating drone technology, EVs can transmit stored information back to the grid, enhancing the overall energy management beyond power consumption.\n\nSimilar content being viewed by others\n\nA multi-objective optimization framework for EV-integrated distribution grids using the hiking optimization algorithm\n\nOptimal scheduling of solar powered EV charging stations in a radial distribution system using opposition-based competitive swarm optimization\n\nA TOPSIS based multi-objective optimal deployment of solar PV and BESS units in power distribution system electric vehicles load demand\n\nIntroduction\n\nAmid the ongoing energy crisis and increasing environmental concerns caused by classical fossil fuel energy sources, optimizing renewable energy utilization has become a critical area of research and innovation, engaging engineers, policymakers, and industry practitioners. Distributed generation (DG), particularly from renewable sources, plays a pivotal role in enhancing efficiency and promoting environmentally sustainable electricity production. However, integrating renewable distributed generation into power systems introduces operational complexities due to the inherent variability and intermittency of these sources. To address these challenges, demand response (DR) has emerged as a key mechanism to enhance grid reliability, offering greater flexibility and maintaining a balanced supply-demand relationship.\n\nThe significance of DR in power system operations has been extensively studied from multiple perspectives. As examples, one study evaluated DR programs as a viable alternative to conventional generation methods, particularly in wind-integrated systems, analyzing the effectiveness of tariff-based and incentive-based strategies in optimizing grid stability and economic efficiency1. Another research highlighted DR’s crucial role in improving power system reliability during extreme weather events, emphasizing the importance of well-structured market mechanisms to maximize its potential2. Additionally, an innovative agent-based framework was proposed to enhance demand-side flexibility, where a central demand response provider (DRP) efficiently coordinates industrial and residential aggregators, enabling optimal load management and improved energy efficiency3.\n\nElectric vehicles (EVs) significantly contribute to carbon dioxide (CO₂) reduction and grid management through demand response (DR) programs. Their integration into Vehicle-to-Grid (V2G) systems enables efficient energy transfer, but their limited battery capacity necessitates aggregator involvement for effective participation4. In addition, aggregators facilitate energy flow management and market participation, optimizing prices and increasing revenue for EV owners. However, technological barriers, such as the need for advanced bidirectional charging systems, and regulatory challenges require policy updates to support V2G interactions5. Future advancements in battery technology and increased public awareness are crucial for widespread adoption. Addressing infrastructure and regulatory issues will be key to maximizing EV benefits in DR programs.\n\nAggregators play a vital role in enabling electric vehicle (EV) users to participate in the energy market, but they are facing challenges due to the unpredictable charging behavior of EV owners, which affects grid stability and market efficiency6. Technical issues, such as uncontrolled charging leading to power quality concerns, necessitate smart solutions like Vehicle-to-Grid (V2G) technology. In energy markets, aggregators must balance efficiency and fairness in resource allocation7. Despite these challenges, coordinated strategies can enhance grid stability, optimize costs, and improve renewable energy integration. Engaging prosumers may further strengthen flexibility and resilience in the energy system, highlighting the potential of aggregators to drive market efficiency and system reliability8.\n\nOperating as private entities, aggregators consistently aim to maximize their profits through various strategies. These may include offering additional services9 and participating in secondary reserve markets within the electrical system. The complex interplay between aggregator objectives, EV user needs, and grid requirements underscores the importance of optimized management strategies in this evolving landscape. Collaborative efforts among multiple aggregators have the potential to enhance DR flexibility and improve service quality for customers, even with relatively simple infrastructure configurations at each station. For instance, a centralized hierarchical framework where the Distribution System Operator (DSO) coordinates charging across all aggregators to minimize energy purchase costs under Time-of-Use (TOU) tariffs and achieve peak load control is proposed. This approach may facilitate cooperation between multiple aggregators and distribution operators. However, this approach may also raise concerns regarding data privacy and personal financial security.\n\nCoordinating EV aggregators without a central controller relies on distributed optimization algorithms and incentive-based mechanisms to enhance system efficiency. Neurodynamic-based algorithms can optimize real-time bidding strategies7, while alternating direction method of multipliers (ADMM) enables collaborative optimization between network operators and aggregators10. Incentive models like Nash Bargaining Theory promote fair trading7, and Peer-to-Peer Trading reduces costs and risks11. Overcoming challenges in fairness and distributed energy management is key to sustainable EV grid integration.\n\nThis paper comprehensively examines and quantifies the benefits for the above cited three stakeholders. For this purpose, we propose an enhanced model of EV user satisfaction that accounts for the nonlinear relationship between changes in the EV State of Charge (SoC) and user satisfaction with aggregator services. Based on this analysis, we suggest an optimal scheduling algorithm for aggregator operations. This algorithm enables aggregators to maximize their profits while meeting the minimum DR capability standards set by the distribution network and satisfying EV user requirements.\n\nThis study focuses on residential aggregators, emphasizing service quality, DR performance, and the time-space statistics of EV behaviors. This focus is motivated by the limited range of EV batteries and the correlation of charging and discharging behaviors across different stations. The interrelation between EV user service requests, the profit of multiple aggregators, and their economic incentives for DR program participation is explored, considering the stringent charging requirements of EV consumers.\n\nThis research introduces a multi-objective optimization framework that integrates grid constraints, time-of-use (TOU) pricing structures, and consumer satisfaction while optimizing EV charging and discharging schedules. Unlike conventional methods, this framework dynamically manages the unpredictability of EV charging behaviors while ensuring flexibility in real-time energy demand response. A key advantage of this approach is its ability to assess the impact of TOU pricing under varying demand scenarios, effectively balancing peak and off-peak load variations. Moreover, State of Charge (SoC) constraints are incorporated to adaptively accommodate fluctuating EV charging requirements. Distinct from conventional algorithms such as Genetic Algorithms (GA) and Particle Swarm Optimization (PSO), this study employs a Red Deer Algorithm (RDA)-based optimization framework to jointly optimize EV charging/discharging schedules, grid balancing, and energy demand forecasting. By integrating V2G capabilities, the proposed approach enables EVs to supply energy back into the grid, enhancing overall grid stability and energy flow management. Additionally, the innovative incorporation of drones for real-time data exchange between EVs and the grid may further improve communication efficiency, allowing for better energy allocation and charging station utilization.\n\nThe proposed optimization framework effectively addresses scalability challenges in large-scale test cases involving thousands of variables. Utilizing the Red Deer Algorithm (RDA), a metaheuristic approach balancing exploration and exploitation within the optimization problem search-space, the method ensures efficient scheduling of EV charging and discharging while maintaining grid stability. The IEEE 69-bus test system, with a diverse fleet of EVs, was used to validate the framework, demonstrating its capability to optimize power flow without overloading the grid. The multi-objective optimization approach, incorporating a linear weighted sum technique, efficiently handles constraints such as State of Charge (SoC), load demand variations, and peak/off-peak energy pricing. Compared to traditional algorithms, RDA reduces computational complexity through hierarchical population structuring and intelligent local search mechanisms. Empirical validation with over 1000 households confirmed the approach’s effectiveness in minimizing peak load impact while dynamically adapting to grid constraints. Additionally, real-time drone-assisted data exchange may contribute in enhancing decision-making accuracy in distributed environments, making the method robust for large-scale applications.\n\nThe remainder of this paper is structured as follows: Sect. \"Literature review\" presents a comprehensive literature review, divided into six subsections covering key aspects such as the role of aggregators in EV energy management, optimization techniques for EV aggregation, stakeholder considerations, advanced control and machine learning techniques, microgrid stability enhancement through V2G integration, and identified research gaps. Section \"Problem formulation\" formulates the problem and defines the objectives and constraints of the proposed framework. Section \"Red deer algorithm (RDA)\" details the methodology, focusing on the Red Deer Algorithm (RDA) and its role in optimizing EV charging and discharging schedules. Section \"Dynamic electricity pricing\" explores dynamic electricity pricing and its impact on EV energy management. Section \"Simulation results and discussion\" discusses the simulation results and provides an in-depth analysis of the proposed approach in terms of grid stability, power loss reduction, and voltage profile enhancement. Finally, Sect. \"Conclusion\" concludes the study and outlines future research directions.\n\nLiterature review\n\nDecentralized control systems and technological advancements are paving the way for more extensive integration of distributed renewable energy resources (DERs) into the power grid. The adoption of DERs, including solar, wind energy, and electric vehicles (EVs), offers numerous benefits, such as reducing greenhouse gas emissions, improving energy flexibility, and enhancing system resilience and reliability12. Among DERs, EVs are rapidly gaining importance due to their potential for bidirectional energy exchange with the grid. Aggregators play a crucial role in managing EV operations, including charging, discharging, and optimizing their interactions with the grid13. In what follows, the components of the DERs within the framework of EVs charging-discharging and the bidirectional transfer of energy between several parties will be explicited. The main focus will be on the role of the aggregators in managing the transfer of energy as well the impact of swarm and artificial intelligence optimization techniques in providing the optimal schedules of the whole system operation. In addition, the integration of V2G energy transfer mode aiming to ensure more stability of the microgrid will be surveyed based on sevral previous studies on the topic. Note here that this section aims to critically investigate recent literature review in order to well-situate the contributions of our paper as compared to previous studies. This litertaure review will end by providing a comprehensive summary of the findings of selected studies while emphasising on the novelties of our study.\n\nRole of aggregators in EV energy management\n\nAggregators act as intermediaries between EV users and the energy market, facilitating optimal energy dispatch strategies. According to research published in the European Platform of Legal Frameworks14, EV aggregation networks enable market participation by connecting individual EV owners with central energy providers. This role is essential in mitigating the unpredictable nature of EV charging patterns, improving grid stability, and ensuring efficient energy utilization15. However, existing literature lacks a unified strategy for optimizing EV aggregator participation in energy markets under uncertainty, highlighting the need for improved decision-making frameworks.\n\nOptimization techniques for EV aggregation\n\nSeveral optimization strategies have been proposed to enhance EV aggregation decision-making under uncertainty. These methodologies can be broadly classified into stochastic and deterministic approaches.\n\nStochastic Optimization: Stochastic methods consider uncertainties in EV availability and charging behavior by modeling multiple probable outcomes. Scenario-based techniques estimate power requirements by evaluating various scenarios16. However, these methods require a high computational burden due to the extensive number of trials necessary to assess large-scale EV fleets17.\n\nDeterministic Approaches: Deterministic models predict energy consumption and available charging times for individual EVs, assuming known driving patterns. While these models offer precise decision-making, they often fail to account for real-world uncertainties18. Some studies introduce risk-averse techniques, such as chance constraints19 or conditional value-at-risk methods20, to enhance robustness. However, these approaches often lack adaptability to worst-case scenarios, such as extreme fluctuations in EV participation21.\n\nTo mitigate computational challenges, researchers have developed scenario-reduction techniques that balance complexity and solution optimality. These methods streamline calculations by prioritizing key scenarios without significantly compromising accuracy22.\n\nConsideration of stakeholders in EV optimization\n\nTo further improve energy management, recent studies integrate the perspectives of multiple stakeholders, including EV owners, aggregators, and distribution system operators (DSOs). For instance, the research in23 proposes a multi-objective framework that balances cost minimization for EV owners while reducing power losses and enhancing system efficiency for DSOs. By applying this methodology to an IEEE 69-bus test feeder with real-world load data, the study demonstrates its effectiveness in optimizing charging schedules and minimizing operational expenses.\n\nAdvanced control and machine learning techniques in energy management\n\nBeyond traditional optimization techniques, recent advancements integrate artificial intelligence (AI) and machine learning (ML) to enhance decision-making in energy management systems:\n\nFuzzy cloud stochastic models optimize energy distribution and storage efficiency by considering multi-objective constraints, such as emissions and cost reduction24.\n\nIntelligent Energy Management Systems (EMS) segment daily energy demand into smaller intervals, reducing voltage fluctuations and network losses25.\n\nFuzzy logic-based EV selection models prioritize cost-efficiency while minimizing battery degradation, ensuring long-term sustainability26.\n\nMachine learning algorithms, including Gaussian Process modeling and Krill Herd Algorithm, provide accurate predictions of HEV charging demand, reducing prediction errors and operational costs27.\n\nHybrid control strategies such as Fuzzy PID controllers, Grey Wolf Optimization, and Random Forest techniques dynamically adjust EV charging schedules, optimizing efficiency in uncertain environments28,29,30.\n\nEnhancing microgrid stability through V2G integration\n\nThe integration of vehicle-to-grid (V2G) technology strengthens microgrid stability by enabling EVs to function as distributed energy reserves. V2G strategies improve grid efficiency by reducing congestion and balancing supply-demand dynamics in real time31. Stochastic optimization approaches, including Coati Optimization and Iterative Map-Based Self-Adaptive Crystal Structure Algorithm, have demonstrated effectiveness in managing unpredictable EV charging behaviors32. Additionally, ML-based predictive models further refine energy distribution strategies, ensuring optimized grid performance33.\n\nIdentified research gaps and contribution of the proposed study\n\nDespite significant advancements in EV aggregation and energy management strategies, several gaps remain:\n\nComputational Scalability and Robustness: Existing stochastic and deterministic optimization techniques struggle with handling large-scale networks and managing the uncertainties of EV behaviors efficiently.\n\nLack of Integrated AI-Based Methods: Limited integration of AI-based techniques with conventional energy management frameworks for real-time decision-making.\n\nStakeholder-Specific Multi-Objective Frameworks: Current studies lack a comprehensive framework that simultaneously considers aggregator profitability, EV user satisfaction, and grid stability.\n\nV2G and Drone-Assisted Data Exchange: The absence of an integrated approach combining V2G capabilities with aggregator-based optimization for enhanced grid stability, particularly using drone-assisted real-time data exchange.\n\nThe State-of-the-Art Comparison Table 1 provides a structured overview of various optimization methodologies used for EV energy management, comparing their key findings and limitations. It highlights advancements in AI-based, stochastic, and hybrid optimization techniques for grid stability, cost efficiency, and energy management. The reviewed studies demonstrate the effectiveness of various optimization techniques but also reveal critical gaps, particularly in addressing scalability, real-time adaptability, and the integration of emerging technologies. Building on these insights, the next section formulates the optimization problem, outlining the objectives and constraints that guide the proposed framework.\n\nProblem formulation\n\nEVs, equipped with vehicle-to-grid (V2G) technology, have the potential to consume and send energy back to the grid. This bidirectional capability, coupled with aggregator models and unmanned aerial systems (UASs) commonly known as drones serving as enablers for the EV charging efficient operation, can revolutionize energy management, grid stability, and remote monitoring. Furthermore, drone-based sensors and communication tools facilitate real-time data collection and monitoring, especially in remote areas where traditional infrastructure is limited. In fact, drones may play a key role in centralizing the data collected from various stakeholders including the EVs, charging stations, grid operators among others. In addition, they may provide the EVs drivers (or the autonomous EVs) with information about the crowd particularly when they are moving toward the optimal available charging stations. Under these conditions, the gain in term of driving time, battery autonomy, grid stability and charging stations management is ensured.\n\nIn the context of smart grids, Vehicle-to-Grid (V2G) technology plays a crucial role in enhancing grid flexibility, stability, and efficiency. V2G enables bidirectional energy exchange between electric vehicles (EVs) and the power grid, allowing EVs not only to consume electricity but also to supply energy back to the grid when needed. This interaction facilitates several benefits, including load balancing, active and reactive power compensation, and demand-side management. One of the key advantages of V2G is its ability to store excess renewable energy, particularly from intermittent sources like solar and wind, within EV batteries. This stored energy can then be dispatched back to the grid during peak demand periods, improving grid reliability and energy utilization. V2G systems can be categorized into unidirectional (V1G) and bidirectional configurations. Unidirectional V2G supports controlled charging to optimize grid stability, while bidirectional V2G, as employed in our proposed method, allows EVs to function as distributed energy storage units that actively contribute to grid support.\n\nIn our approach, EVs dynamically exchange energy with the grid, assisting in peak load management and renewable energy integration. By enabling EVs to discharge surplus energy during high-demand periods and recharge during low-demand hours, the proposed V2G framework enhances grid resilience, reduces operational costs, and minimizes reliance on conventional power plants. Furthermore, V2G empowers EV owners to participate in demand response programs, providing financial incentives while optimizing grid performance. This strategic energy exchange fosters a more sustainable and intelligent energy ecosystem, supporting the transition toward greener and more efficient power networks.\n\nThe generalization of the V2G architecture is illustrated in Fig. 1. EV charging stations (EVCSs) are engaged in supervising each EV charging point and organize them so that, when aggregated, they possess sufficient generating capacity to significantly impact the power network. The primary role of the EVCS monitoring system is to report on the EVs parked in the respective area by collecting data such as EV’s time of arrival, departure time, the initial SoC, the final SoC etc. to the aggregator in predefined timeframes. This centralized management approach using EVCS enables effective monitoring of a large-scale EV fleet, contributing to load management and grid stability23.\n\nAn EV aggregated by an agent like an aggregator becomes a potential resource to engage in the DR programs, thus the need for an optimization algorithm to handle EV scheduling for better operational stability, improved provision of service and customer satisfaction.\n\nBy aggregating EVs, an aggregator can effectively participate in DR programs, enhancing grid stability and service quality. Optimizing EV charging and discharging schedules through appropriate algorithms is crucial to maximize the benefits for both EV owners and the power grid.\n\nEVCS aggregation scheme with drone-enabled V2G system.\n\nThe residential distribution systems consider the role of an aggregator who plans the optimal EV charging schedule to maximize the cost-benefit ratio. An agreement of fixed monthly fee might be established between the aggregator and the EV owners34. EV owners benefit from lower charging costs made easy by the aggregators. The effectiveness of the distribution mechanism does not affect the aggregator. To optimize charging, the aggregator requires information about the vehicle’s starting SoC, arrival time, and departure time. The results of unplanned operation are compared with those of scheduled charging and discharge35.\n\nOptimal scheduling of EV charging/discharging\n\nThe objective of optimal EV scheduling is to balance the interests of the aggregator and the DSO36. To simplify the investigation, we assume that EVs maintain a constant charging/discharging power equal to their rated capacity throughout each time slot. At the beginning of each time slot, an optimization algorithm is employed to determine the optimal schedule. In this work, the scheduling strategy is evaluated using three EV models with different rated values for a 10-minute time slot37. The optimal scheduling scheme for a time slot ‘t’ is formulated (Eq. 1) from the EV aggregator perspective.\n\nwhere,\n\n\\(\\:{P}_{\\text{m}\\text{a}\\text{x}}\\) maximum charging/discharging power in kW\n\n\\(\\:{\\rho\\:}_{t}\\) charge/discharge rate,\n\n\\(\\:C\\left(t\\right)\\) is the electricity price at time instant ‘t’,\n\n\\(\\:\\left\\{\\text{0,1},-1\\right\\}\\) denotes the idle state, discharging and charging of the EV, respectively.\n\nEnergy available in the battery E(tn) is given by:\n\n\\(\\:E\\left({t}_{0}\\right)\\:\\)is the initial energy of the battery, while the SoC at the \\(\\:{t}_{0}\\) instant is computed as,\n\n\\(\\:SoC\\left({t}_{0}\\right)\\): The State of Charge at time \\(\\:{t}_{0}\\), representing the remaining energy in the battery as a fraction of its maximum capacity.\n\n\\(\\:So{C}_{\\text{m}\\text{a}\\text{x}}\\): The maximum possible \\(\\:SoC\\) (100% or 1.0 in normalized form).\n\n\\(\\:{W}_{\\text{k}}\\): The energy consumed by vehicles for traveling k kilometers.\n\nd: The distance traveled (in kilometers) during the given trip.\n\nk: A normalization factor for distance, representing trip characteristics.\n\n\\(\\:{E}_{\\text{m}\\text{a}\\text{x}}\\): The maximum energy storage capacity of the EV’s battery.\n\nFor simulation purposes, let’s assume the initial energy of the SoC to be 25% of the total rated battery capacity.\n\nThe SoC at the nth instant is given by,\n\nThe duration between \\(\\:{t}_{0}\\) and T is utilized for the scheduling process.\n\nFrom a DSO perspective, the responsibility lies in making sure all network limits are met. To run the network effectively, the goal is to reduce power loss. Thus, the line loss \\(\\:{P}_{Loss,t}\\) of the distribution system at time instant ‘t’ can be expressed as,\n\nsubject to,\n\nWhere,\n\n\\(\\:{P}_{G,t}\\) real power generation at the slack bus at time instant ‘t’\n\n\\(\\:{P}_{{D}_{i,t}}\\) real power load at the ith bus at time instant ‘t’.\n\nWhile, \\(\\:{P}_{{D}_{{k}_{\\text{new\\:}}},t}\\) is the current real power load at kth bus, including the real power demand PDk,t and the charging/discharging EV power at time ‘t’ as represented by Eq. (9)\n\nWhere, \\(\\:{V}_{n}\\) denotes the voltage magnitude at the nth bus. \\(\\:{V}_{\\text{m}\\text{i}\\text{n}}\\) and \\(\\:{V}_{\\text{m}\\text{a}\\text{x}}\\) are the minimum and maximum voltage limits, respectively.\n\nThe aggregator and DSO coordinate their efforts to implement optimal scheduling, ensuring efficient grid operation. This strategy satisfies all the demands and limitations put forth by the aggregator and DSO while minimizing the charging costs faced by EV owners and the power loss in the network38.\n\nConsidering the previous analysis, the final objective function is expressed as a weighted sum of Eq. (1) and Eq. (7) as follows,\n\nWhere \\(\\:{w}_{1}\\) and \\(\\:{w}_{2}\\) are weight factors.\n\nThe linear weighted sum technique was selected for EV scheduling optimization due to its simplicity, flexibility, and practical applicability. It effectively combines multiple conflicting objectives, such as minimizing power losses, improving voltage profiles, and ensuring EV user satisfaction, into a single function by assigning adjustable weights. This method is computationally efficient, avoiding the complexity of maintaining Pareto-optimal solutions, and is well-suited for large-scale problems. Its adaptability allows dynamic weight adjustments to accommodate varying operational conditions, ensuring robustness across diverse scenarios. Comparative analysis confirms its balance of simplicity and performance, making it ideal for the proposed EV scheduling framework.\n\nMeasure of user satisfaction with EV’s SoC\n\nSoC satisfaction measures the extent to which an aggregator can fulfill the charging/discharging needs of an EV user. When EV users participate in the service, facility constraints or operational limitations may lead to discrepancies between predicted and actual charging/discharging SoC, potentially affecting customer satisfaction. To quantify this, we introduce an index, denoted as \\(\\:{G}_{1,i}\\text{\\%}\\), representing the satisfaction of the ith EV with its SoC upon leaving the aggregator34.\n\nwhere \\(\\:SO{C}_{0,i}\\) – arrival time SoC\n\n\\(\\:SO{C}_{i}^{{\\prime\\:}}\\)- targeted SoC value\n\n\\(\\:SO{C}_{i}^{{\\prime\\:}{\\prime\\:}}\\)- SoC value at the ith EV departure time.\n\nWith the problem clearly defined and the key constraints identified, an efficient optimization approach is required to achieve multi-objective scheduling while ensuring grid stability. The following section introduces the Red Deer Algorithm (RDA), detailing its mechanism and its suitability for solving the formulated optimization problem.\n\nRed deer algorithm (RDA)\n\nThe Red Deer Algorithm (RDA)39 is a nature-inspired optimization technique that draws its inspiration from the unique mating behavior of Scottish red deer during the breeding season. These behaviors include roaring, fighting, and harem formation, which are crucial in establishing dominance and ensuring reproductive success. By mimicking these biological processes, the RDA effectively balances exploration and exploitation within the solution space, making it well-suited for solving complex optimization problems. Due to its efficiency, the RDA has been used in EV charging related applications including data clustering40, sensor node clustering in wireless sensor networks41 and path planning of inspection robots42.\n\nConceptually, the operation of the RDA is illustrated in the following phases43:\n\nRoaring phase\n\nIn nature, male red deer roar to assert their presence and attract mates. The algorithm models this behavior as a local search process, where solutions explore their neighborhood to improve their fitness. This phase enhances diversification by encouraging the algorithm to search new regions of the solution space.\n\nFighting phase\n\nMale red deer compete through physical contests to establish dominance. In RDA, this is translated into a selection mechanism where candidate solutions are evaluated and the strongest (best fitness) are promoted as “commanders,” while weaker solutions become “stags.” This ensures intensification by focusing on the most promising areas of the solution space.\n\nHarem formation and mating\n\nDominant male deer form harems by attracting females, which they defend and mate with. In RDA, commanders generate new solutions (offspring) by combining their traits with selected females (other solutions). This phase incorporates both local and global exploration, introducing diversity while refining existing solutions.\n\nMathematical framework\n\nKey steps in the RDA are mathematically formulated as follows43:\n\nInitialization:\n\nThe initial population (Npop) is divided into males (Nmale) and females (hinds, Nhind).\n\nA solution is represented as an array:\n\nWhere (Nvar) is the number of decision variables.\n\nRoaring Phase:\n\nMale red deer explore the solution space by updating their positions:\n\nWhere Ub and Lb are the upper and lower bounds, and a1, a2, a3 are random values in [0,1].\n\nFighting Phase:\n\nCommanders (NCom) and stags (Nstag) compete. Two new solutions are generated:\n\nWhere b1, b2 are random parameters, and the better solution is retained.\n\nHarem Formation\n\nThe power (Pn) of a commander determines the proportion of hinds in the harem:\n\nwhere Vn is the normalized fitness of the n-th commander.\n\nMating Phase:\n\nOffspring are generated by mating within and across harems. The offspring solution is:\n\nwhere c is a random parameter.\n\nExploration and exploitation balance\n\nThe Red Deer Algorithm (RDA) balances exploration, which diversifies the search for potential solutions, and exploitation, which refines the best solutions to achieve optimal results. Exploration is driven by the roaring phase, which introduces variability and prevents premature convergence, while exploitation is reinforced by the fighting and mating phases, emphasizing intensification through competition and hierarchical mating. By dynamically adjusting parameters (a, b, c), the RDA adapts to maintain this balance, ensuring effective navigation of the search space and convergence to high-quality solutions in complex optimization problems.\n\nImplementation of RDA\n\nThe flowchart in Fig. 2 outlines a structured process for optimizing EV charging schedules using RDA. The algorithm begins with inputting grid and EV parameters, setting up an initial EV aggregator configuration, and defining constraints and RDA parameters. The algorithm iteratively updates the aggregator’s location and capacity, computes objective functions (e.g., cost minimization and grid stability), and calculates fitness values. Through power dispatch and optimal schedule determination, the process checks for convergence and outputs the final solutions, ensuring an efficient and balanced EV charging strategy while minimizing costs and impact on the grid.\n\nFlowchart of RDA.\n\nRDA’s breeding process, including the mating of stags with the nearest hind, further enhances exploration. The subsequent generation of RDs through the mating process represents the creation of new solutions, reflecting the evolutionary nature of the algorithm. To maintain diversity and prevent premature convergence, weak solutions are also given a chance to contribute to the next generation.\n\nWhile the Red Deer Algorithm (RDA) provides an effective optimization framework for EV scheduling, the economic aspect of charging costs plays a crucial role in influencing EV user behavior and grid stability. To further enhance the effectiveness of EV integration, the following section explores dynamic electricity pricing strategies, particularly Time-of-Use (ToU) pricing, and their impact on optimizing EV charging demand.\n\nDynamic electricity pricing\n\nElectricity pricing has evolved from traditional flat-rate structures to dynamic pricing models, allowing for more efficient energy distribution and demand-side management. Dynamic electricity pricing adjusts tariffs based on real-time supply and demand conditions, aiming to enhance grid stability and incentivize consumers to shift their energy usage to off-peak hours. Among the various dynamic pricing strategies, Time-of-Use (ToU) pricing remains one of the most widely implemented approaches.\n\nToU pricing system establishes electricity rates based on specific time blocks, determined in advance by utilities using historical data rather than real-time demand44. This pricing model provides different electricity tariffs based on three periods: off-peak, mid-peak, and full-peak. During the off-peak period, electricity supply exceeds demand, leading to lower ToU costs. At mid-peak, supply and demand are nearly balanced, resulting in moderate pricing. However, during full-peak hours, electricity consumption surges, necessitating the operation of expensive and less efficient peaking power plants, such as those using diesel, coal, and petroleum. To handle high peak demand, utilities must also invest in infrastructure expansion and additional power generation facilities.\n\nAs electricity generation increases, technical losses within the system also rise, leading to higher peak rates. To mitigate the impact of EV charging on the grid, utilities often rely on infrastructural variations and indirect pricing mechanisms. However, since ToU pricing features high rates only during peak hours and low rates in off-peak periods, it alone is insufficient to effectively manage the influence of EV charging on the power grid.\n\nIn smart grids, Time-of-Use (ToU) pricing is structured so that electricity rates fluctuate based on the grid’s load at different times of the day. The 24-hour period is divided into multiple time intervals {τ1, τ2, ., τq}, each associated with a corresponding grid load {Lτ1, Lτ2, ., Lτq} and a set of discrete pricing levels {Pτ1, Pτ2, ., Pτq}. These prices are selected from a predefined set of discrete values P = {P1, ., Pn}45.\n\nThe pricing mechanism operates on a global scale, ensuring that electricity rates are directly proportional to the grid’s total demand. When demand reaches its highest peak during a specific time slot τθ, the unit price is set to the maximum value Pτθ = max(Pτ1, Pτ2, …, Pτq). Conversely, when the grid load is at its lowest, the pricing is adjusted to the minimum level Pτθ = min(Pτ1, Pτ2, …, Pτq). This dynamic pricing approach optimizes energy consumption patterns, encouraging users to shift their usage to periods of lower demand, thereby improving grid efficiency and stability.\n\nA grid-specific Time-of-Use (ToU) pricing framework is employed to facilitate the practical application of the proposed pricing strategy, which is systematically outlined in the step-by-step algorithm provided below.\n\nAdaptive Pricing Mechanism for EV Charging45.\n\nThe variable κ represents the capacity of the distribution network, while x=(x0,x1,x2,…,x23) denotes the conventional load of the network over a 24-hour period, measured at hourly intervals. The adjusted load values, denoted as x′, are computed using Eq. (18):\n\nwhere ζ serves as a normalization factor. This transformation standardizes the load values to a new range, facilitating further analysis.\n\nThe function f scales the load vector x within the range [1,−1], using ζ as the upper threshold and 0 as the lower threshold. The parameter ζ is selected to ensure that max(x) ≤ ζ < κ, where κκ represents the distribution network’s capacity.\n\nElectric vehicles (EVs) act as flexible loads that can be integrated into the system during periods of low demand, helping to balance the grid by filling demand valleys and maintaining stable operation. To achieve peak shaving and valley filling, the parameters 1 and δ2 are determined using Eqs. (19) and (20), where max(x′) and min (x′) correspond to the highest and lowest values within the normalized load vector x′.\n\nNext, a convex optimization problem is formulated to minimize \\(g(y^{\\prime}+x^{\\prime}+{\\delta _1}+{\\delta _2})\\) where the decision variable y′ is constrained within the range [− 1,1], ensuring that the additional load from EV charging is properly adjusted.\n\nThe values of δ1and δ2 are added element-wise to x′, resulting in y′, which represents the normalized desired EV charging load. The actual charging load y is obtained by denormalizing y′ using Eq. (21):\n\nOnce the desired valley-filling load y is determined, the charging price is assigned based on a ranking system. The maximum and minimum values of y are set as the upper and lower bounds, respectively. The load values are then distributed across the available discrete pricing levels {Pτ1, Pτ2, …, Pτq}. The highest price is assigned to the lowest load, the second-highest price is assigned to the second-lowest load, and this process continues until the highest load is allocated to the lowest price, ensuring an efficient demand-response pricing structure.\n\nThe integration of dynamic electricity pricing, particularly Time-of-Use (ToU) pricing, plays a crucial role in shaping EV charging behaviors and reducing peak demand. However, the real-world impact of these pricing strategies, combined with the proposed optimization framework, must be evaluated through rigorous simulations. The next section presents simulation results, analyzing the effectiveness of the Red Deer Algorithm (RDA) in optimizing EV scheduling and assessing its impact on power distribution networks.\n\nSimulation results and discussion\n\nA demographic-based analysis was conducted to evaluate spatiotemporal patterns in vehicle utilization and charging behavior. The methodology incorporated three vehicle models, each characterized by distinct specifications in terms of battery capacity, operational range, and charging parameters (Tables 1 and 2). Temporal stratification of charging events revealed three primary intervals: morning peak (06:00–10:00), evening peak (15:00–21:00), and off-peak periods. This temporal categorization was derived from empirical observations of charging behavior and network load distributions9.\n\nThe simulation framework incorporated a State of Charge (SoC) threshold parameter of 25%, established to reflect observed user charging behavior patterns. Power demand characterization was conducted using a high-resolution dataset derived from a 69-bus residential distribution network, incorporating both active (P) and reactive (Q) power measurements. The dataset architecture included hierarchical power demand parameters: aggregate network loading, maximum bus capacity utilization, individual nodal demand profiles, and EV charging power consumption patterns. Temporal granularity was maintained at 10-minute intervals throughout the 24-hour analysis period, facilitating comprehensive evaluation of load dynamics and charging patterns.\n\nAdditionally, four distributed generators (DGs) were incorporated into the test network alongside the EVs. The load power demand data was combined with the vehicle specifications from Tables 2 and 3 to address the scheduling optimization problem. This approach aims to manage the charging and discharging of EVs connected to the network without overloading the distribution system. Furthermore, the approach capitalizes for power losses’ reduction and voltage profile improvement.\n\nAverage EV demand\n\nTemporal analysis of energy demand characteristics is presented in Fig. 3, depicting diurnal consumption patterns for six EV configurations (three international and three domestic models) during weekday operational cycles. The profiles delineate charging initialization parameters and temporal duration metrics, correlated with initial and terminal State of Charge (SOC) values. Model validation was conducted through comparative assessment of simulated demand profiles against empirical charging data obtained from operational EVs. Statistical analysis revealed significant correlation coefficients between simulated and measured charging behaviors, substantiating the accuracy and reliability of the computational framework.\n\nProfiles and average energy demand for EVs’ from (a) International market (b) Indian market.\n\nMore in-depth analysis of Fig. 3a and b reveals that the peak demand for both international (1.53 kW) and Indian (1.49 kW) model profiles occurs during the evening hours (4 PM to 10 PM). Notably, the simulated average peak demand aligns closely with the monitored EV charging behavior, suggesting the effectiveness of the EV scheduling optimization. Additionally, individual EV energy demand remains well-managed, with a maximum of 15 kW.\n\nThe results in Fig. 4 were obtained by simulating three scenarios: (1) households without EVs, (2) households with EVs, and (3) a combination of households and EVs. The simulation considered a 24-hour cycle for a 69-bus network with typical residential load patterns. Key assumptions include:\n\nInitial SoC: Randomized between 20% and 80% for the simulated EV fleet.\n\nCharging Power: Based on rated values of the EV models in Tables 1 and 2.\n\nTime Slots: Ten-minute intervals were used to capture dynamic changes.\n\nConstraints: Network voltage limits are 0.95–1.05 p.u., the transformer capacity falls below 100% utilization, and user satisfaction thresholds is set to SoC greater than 80% upon departure.\n\nScenarios: Unmanaged charging (baseline) and optimal scheduling using the proposed algorithm.\n\nThese conditions and constraints were implemented in MATLAB/Simulink to generate aggregated demand profiles with emphasis on the impact of controlled and uncontrolled EV charging. The average EV demand peaks during peak hours (7 AM to 10 AM, 4 PM to 10 PM), ranging from 1.18 kW to 1.74 kW. Notably, this peak demand for EVs is significantly higher than the household power demands, which typically remain below 0.4 kW during peak hours. The results demonstrate that EV integration significantly impacts network power demand characteristics, necessitating the implementation of charging regulation protocols to mitigate peak load conditions across the distribution infrastructure. Analysis reveals equivalent demand patterns across both vehicle model categories, resulting in identical graphical representations. This uniformity in load profiles underscores the consistent impact of EV charging on network demands, independent of vehicle model specifications.\n\nAverage energy demand for 1000 households, EVs and households plus EVs for EVs from (a) international market (b) Indian market.\n\nEVs scheduling and control\n\nNetwork performance characteristics and charging point operational parameters are illustrated in Figs. 5, 6, 7 and 8, demonstrating temporal variations across a 24-hour cycle within a 69-bus feeder infrastructure. Comparative analysis was conducted between controlled and uncontrolled operational scenarios at 100% EV penetration. Uncontrolled charging scenarios exhibited critical transformer overloading of 136% with substantial voltage profile degradation beyond acceptable operational parameters. The implemented scheduling management protocol demonstrated successful regulation of transformer loading within nominal capacity while maintaining voltage profiles within prescribed operational limits. Empirical results suggest the proposed control methodology enables optimization of network hosting capacity approaching 100% EV penetration thresholds.\n\nEV Transformer loading with and without control for (a) International (b) Indian EVs’ Model.\n\nQuantitative analysis of Fig. 5a, focused on international EV models, reveals that implementation of the control algorithm effectively constrained transformer loading to maximum values of approximately 80 kW during peak demand intervals. Similarly, Fig. 5b analysis, centered on domestic (Indian) EV models, demonstrates that the control protocol successfully maintained peak transformer loading at approximately 100 kW, representing a significant reduction from the uncontrolled scenario’s maximum loading of 350 kW. These results quantify the efficacy of the implemented control strategy in mitigating peak transformer loading conditions across both vehicle categories.\n\nComparison of Voltage Profile with and without control cycle for EVs from (a) International and (b) Indian markets.\n\nAnalysis of Fig. 6a reveals that implementation of the control mechanism for international EV models results in a sustained voltage profile exceeding 0.90 per unit (p.u.) across the test network. In the absence of control measures, significant voltage degradation is observed during peak demand periods (17:00–22:00), with values declining below 0.7 p.u. The comparative analysis between controlled and uncontrolled scenarios demonstrates the control system’s efficacy in maintaining network voltage stability. Similarly, Fig. 6b illustrates the control cycle’s effectiveness for Indian EV models, where voltage levels are consistently maintained above 0.9 p.u. throughout the 24-hour operational period. The quantitative comparison between both scenarios provides empirical evidence of the control system’s capability in preserving voltage stability across different EV model configurations.\n\nComparison of aggregated EV power demand with and without control cycles for (a) international and (b) Indian EVs’ models.\n\nTemporal analysis of aggregate EV demand characteristics in Fig. 7a demonstrates the optimization efficacy of implemented charging point management protocols for International Model EVs. The control algorithm implementation (blue curve) achieved a 46.7% reduction in peak demand, from 15 kVA to 8 kVA, relative to the uncontrolled scenario (dotted red curve). The control methodology demonstrates successful attenuation of demand variability during critical loading periods.\n\nFigure 7b illustrates comparative demand profiles for Indian Model EVs under controlled and uncontrolled operational scenarios. The implementation of the optimization protocol resulted in a 33.3% reduction in peak demand, from 9 kVA to 6 kVA, with significant enhancement of load profile stability. The demonstrated load modulation capabilities suggest robust potential for grid stability maintenance under increased EV penetration conditions, particularly during periods of heightened demand volatility.\n\nIndividual EV Charging Behavior with and Without Control (a) International Model (b) Indian Model,\n\nFigure 8 demonstrates the temporal dynamics of EV charging station connectivity patterns in response to aggregate demand fluctuations. The control protocol implements strategic disconnection during peak demand intervals, with subsequent reconnection and charging resumption during reduced network loading conditions, maintaining this cycle until target State of Charge (SoC) parameters are achieved. Analysis of Fig. 8a reveals that uncontrolled charging of international model EVs exhibits extended charging durations during peak periods, initiating at approximately 16:00 and concluding at 00:30. Implementation of the control strategy demonstrates charging duration reduction exceeding 120 min. Figure 8b exhibits analogous behavioral patterns for domestic (Indian) model EVs.\n\nCustomer impact level (CIL)\n\nThe quantitative assessment of direct scheduling impacts on EV charging station operations employed the Customer Impact Level (CIL) metric, as established in reference36. The metric utilizes a decile classification system (groups 0–9) to quantify the proportional increase in charging duration required to achieve target State of Charge (SoC) under implemented management protocols, relative to uncontrolled charging scenarios.\n\nProbability of CIL for EV Charging Control Actions (a) International Model (b) Indian Model.\n\nFigure 9 presents the distributional analysis of Customer Impact Level (CIL) across varying EV penetration scenarios, where each CIL classification represents a 25% incremental deviation in charging duration from scheduled parameters. At 40% penetration levels, charging disruption analysis reveals minimal impact, with 70% of the EV population experiencing negligible temporal deviation (CIL 0). As penetration levels escalate to 60% and beyond, temporal disruptions demonstrate increased prevalence, affecting approximately 60% of the EV fleet. However, the magnitude of impact remains within manageable parameters, with a minimal proportion of EVs experiencing charging duration extensions exceeding 100% of nominal values, even under peak loading conditions. These results validate the efficacy of the implemented EV scheduling protocol in maintaining network operational efficiency.\n\nAggregated EV Availability with EV Management for EVs from (a) International market (b) Indian market.\n\nAnalysis of V2G capacity characteristics presented in Fig. 10 demonstrates the operational viability of aggregated electric vehicles as distributed energy resources within the grid infrastructure. Under implemented management protocols3, the test network exhibited aggregate EV availability coefficients ranging from 0.10 to 0.20 during peak loading periods. This empirical evidence substantiates the feasibility of V2G-enabled EV fleets serving as supplementary power sources during critical grid operational states, effectively functioning as distributed storage systems capable of providing emergency power support. The demonstrated availability patterns suggest significant potential for integration of V2G resources into grid emergency response protocols.\n\nDynamic pricing for charging EVs\n\nFigure 11 demonstrates the temporal correlation between Time-of-Use (ToU) dynamic pricing mechanisms for EV charging and aggregate residential-commercial load profiles. The pricing algorithm exhibits inverse relationship with demand patterns, characterized by rate minimization during off-peak intervals (08:00–12:00 h) coinciding with reduced demand, and significant rate escalation during peak consumption periods (18:00–22:00 h). Residential load follows a similar pattern, reaching its lowest level at midday and peaking in the evening, which coincides with the highest electricity prices. Commercial load, though generally lower than residential demand, also increases after 10 h, peaking around 20 h. This strong correlation between electricity prices and load demand emphasizes the importance of incentivizing EV charging during off-peak hours, ensuring grid stability and reducing operational costs. Encouraging smart charging strategies and Vehicle-to-Grid (V2G) integration can help flatten the demand curve and prevent grid congestion caused by uncontrolled EV charging during peak periods.\n\nTime-of-Use (ToU) Dynamic Pricing and Load Demand Correlation for EV Charging.\n\nComparison of RDA and PSO\n\nTo validate the convergence and correctness of the proposed Red Deer Algorithm (RDA), a comparative analysis was conducted against the widely used Particle Swarm Optimization (PSO) algorithm. Figure 12 presents comparative convergence characteristics of both algorithms, illustrating the temporal evolution of fitness values across 100 iterative cycles.\n\nConvergence Comparison of Red Deer Algorithm (RDA) and Particle Swarm Optimization (PSO).\n\nFrom Fig. 12, it is evident that RDA demonstrates a significantly faster convergence rate compared to PSO. The RDA achieves a lower fitness value within the first few iterations, indicating a more efficient search capability in reaching near-optimal solutions. In contrast, PSO exhibits a slower descent and stagnates at a suboptimal solution for a longer period before showing minor improvements later in the iterations.\n\nKey observations from the comparative analysis include:\n\nFaster Convergence of RDA: The RDA algorithm rapidly decreases the fitness value within early iterations, reaching an optimal or near-optimal solution much faster than PSO. The accelerated convergence to optimal or near-optimal solutions, relative to PSO, indicates enhanced exploration-exploitation equilibrium in the search space dynamics.\n\nStability of Converged Solution: RDA demonstrates superior terminal convergence characteristics, achieving stabilization at a lower fitness value threshold compared to PSO. This reduced terminal fitness value validates RDA’s enhanced capability in identifying global optima for complex optimization problems.\n\nPSO Convergence Limitation: PSO algorithm exhibits persistent elevation in fitness values over extended iteration cycles, indicating reduced adaptation efficiency within complex solution spaces. This prolonged maintenance of higher fitness levels suggests compromised search space exploration capabilities, potentially resulting in premature convergence to local optimal solutions rather than global minima.\n\nPerformance Comparison of RDA and PSO: The performance comparison of two optimization methods on the IEEE 69-bus system, PSO and RDA, is shown in this convergence graph. PSO’s goal function begins at a high value and then progressively drops with very slight variations. It takes about 83 iterations to reach a final value and shows a slower rate of convergence than RDA. In contrast, RDA likewise begins at a high value but declines more quickly in the initial iterations. Compared to PSO, it stabilizes earlier and shows a more noticeable improvement in the first 55 iterations.\n\nThese findings confirm the effectiveness of the proposed optimization framework in minimizing power losses, improving voltage stability, and optimizing EV charging schedules. The results further demonstrate that the Red Deer Algorithm (RDA) outperforms Particle Swarm Optimization (PSO) in terms of convergence speed and solution quality. The final section provides a summary of key insights, highlights existing limitations, and proposes future research directions to enhance the seamless integration of EVs into smart grid systems.\n\nConclusion\n\nThis study provides a comprehensive analysis of EVs charging practices, their impact on distribution systems, and the effectiveness of the proposed scheduling strategies using Red Deer Algorithm (RDA). Two distinct EV models – selected from International and Indian markets, respectively - differing in battery capacity and range, to ensure a broad applicability of the findings.\n\nThe simulations of hourly energy demand profiles demonstrated strong correlation with actual EV charging behavior, validating the accuracy of our models. Peak demands for both EV types occurred during morning (8 AM to 10 AM) and evening (6 PM to 10 PM) hours, highlighting critical periods for potential network stress.\n\nThe comparison between EV and household power demands underscored the significant increase in network load due to EV charging, particularly during peak hours. This emphasized the need for effective EV charging regulation to mitigate high load demands across distribution networks.\n\nTo address these challenges, an EV scheduling strategy that simultaneously optimizes two objectives: maximizing power and reducing power losses, using the Red Deer Algorithm (RDA) was proposed. This approach demonstrated remarkable effectiveness in maintaining transformer utilization below rated capacity and voltage levels within specified ranges, even under high EV penetration scenarios. Key achievements of our proposed strategy include:\n\nSignificant decrease in power loss, even with a large fleet of EVs connected to the grid simultaneously for charging and discharging operations.\n\nImproved voltage profiles and consistent EV aggregate power.\n\nReduced EV charging times, even during peak hours.\n\nPotential increase in the hosting capacity of distribution networks.\n\nThe Customer Impact Level (CIL) metric revealed that while charging disruptions increase with higher EV penetration levels, the impact remains manageable. This demonstrates the positive influence of our EV scheduling on network efficiency while minimizing disruptions to EV users.\n\nFurthermore, the study highlighted the potential of Vehicle-to-Grid (V2G) technology. With EV management in place, we observed an aggregated EV availability of 10–20% during peak hours, suggesting that V2G-enabled EVs could serve as a valuable supplementary power source during emergency situations.\n\nThe proposed solution proves to be practical and scalable for similar aggregator- Distribution System Operators (DSO) approaches. Additionally, our EV scheduling model allows for quantification of potential network resources to assist in maintaining the equilibrium between demand and generation.\n\nIn conclusion, this research emphasizes the crucial role of intelligent EV charging management in ensuring grid stability and efficiency as EV adoption continues to grow. The proposed scheduling strategies show promise in maximizing network capacity while minimizing disruptions to EV users, paving the way for smoother integration of EVs into existing power distribution systems. These findings provide valuable insights for both EV aggregators and DSOs in optimizing their operations and planning for a future with increased EV penetration.\n\nData availability\n\nThe datasets used and/or analyzed during the current study are available from the corresponding author on reasonable request.\n\nReferences\n\nHajibandeh, N., Ehsan, M., Soleymani, S., Shafie-khah, M. & Catalão, J. P. S. Prioritizing the effectiveness of a comprehensive set of demand response programs on wind power integration. Int. J. Electr. Power Energy Syst. 107, 149–158 (2019).\n\nArticle\n  Google Scholar\n\nWang, F. et al. The values of market-based demand response on improving power system reliability under extreme circumstances. Appl. Energy. 193, 220–231 (2017).\n\nArticle\n  ADS\n  Google Scholar\n\nGolmohamadi, H., Keypour, R., Bak-Jensen, B. & Pillai, J. R. A multi-agent based optimization of residential and industrial demand response aggregators. Int. J. Electr. Power Energy Syst. 107, 472–485 (2019).\n\nArticle\n  Google Scholar\n\nZinoviev, V., Nikolova, S. & Koeva, D. The Economic Potential of the Vehicle to the Grid, in 2024 International Conference on Applied and Theoretical Electricity (ICATE), pp. 1–9. (2024).\n\nMicari, S. & Napoli, G. Electric Vehicles for a Flexible Energy System: Challenges and Opportunities, Energies, 17(22), 5614 https://doi.org/10.3390/en17225614 (2024).\n\nIbrahim, R. A., Gaber, I. M. & Zakzouk, N. E. Analysis of multidimensional impacts of electric vehicles penetration in distribution networks. Sci. Rep., 14(1), 27854 (2024).\n\nWu, W. et al. A coordinated model for multiple electric vehicle aggregators to grid considering imbalanced liability trading. IEEE Trans. Smart Grid. 15 (2), 1876–1890 (2024).\n\nArticle\n  Google Scholar\n\nCruz, C., Alskaif, T., Palomar, E. & Bravo, I. Prosumers integration in aggregated demand response systems, Energy Policy 182, 113745 (2023).\n\nLi, K. et al. A business model incorporating harmonic control as a Value-Added service for Utility-Owned electricity retailers. IEEE Trans. Ind. Appl. 55 (5), 4441–4450 (2019).\n\nArticle\n  Google Scholar\n\nFu, Z., Sun, X., Yu, W. & Ren, P. Distributed energy collaborative control strategy for grid-connected electric vehicles, in IEEE 4th International Conference on Electronic Technology, Communication and Information (ICETCI), 2024, pp. 1507–1511. (2024).\n\nHou, H. et al. Peer-to-peer energy trading among multiple microgrids considering risks over uncertainty and distribution network reconfiguration: A fully distributed optimization method. International Journal of Electrical Power & Energy Systems 153, 109316 (2023).\n\nAmamra, S. A. & Marco, J. Vehicle-to-Grid aggregator to support power grid and reduce electric vehicle charging cost. IEEE Access. 7, 178528–178538 (2019).\n\nArticle\n  Google Scholar\n\nE. COMMISSION, Proposal for a Directive of the European Parliament and of the Council on common rules for the internal markets in renewable and natural gases and in hydrogen (recast), 2021, Available: https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX%3A52021SC0457\n\nTurker, H. & Bacha, S. Optimal minimization of Plug-In electric vehicle charging cost with vehicle-to-Home and vehicle-to-Grid concepts. IEEE Trans. Veh. Technol. 67 (11), 10281–10292 (2018).\n\nArticle\n  Google Scholar\n\nKlaina, H. et al. Aggregator to electric vehicle LoRaWAN based communication analysis in vehicle-to-Grid systems in smart cities. IEEE Access. 8, 124688–124701 (2020).\n\nArticle\n  Google Scholar\n\nMonteiro, V., Pinto, J. G. & Afonso, J. L. Operation modes for the electric vehicle in smart grids and smart homes: present and proposed modes. IEEE Trans. Veh. Technol. 65 (3), 1007–1020 (2016).\n\nArticle\n  Google Scholar\n\nNunna, H. S. V. S. K., Battula, S., Doolla, S. & Srinivasan, D. Energy management in smart distribution systems with Vehicle-to-Grid integrated microgrids. IEEE Trans. Smart Grid. 9 (5), 4004–4016 (2018).\n\nArticle\n  Google Scholar\n\nGinigeme, K. & Wang, Z. Distributed optimal Vehicle-To-Grid approaches with consideration of battery degradation cost under Real-Time pricing. IEEE Access. 8, 5225–5235 (2020).\n\nArticle\n  Google Scholar\n\nLiu, Z., Wang, D., Jia, H., Djilali, N. & Zhang, W. Aggregation and bidirectional charging power control of Plug-in hybrid electric vehicles: generation system adequacy analysis. IEEE Trans. Sustain. Energy. 6 (2), 325–335 (2015).\n\nArticle\n  ADS\n  Google Scholar\n\nZhou, Z., Wang, B., Dong, M. & Ota, K. Secure and efficient Vehicle-to-Grid energy trading in cyber physical systems: integration of blockchain and edge computing. IEEE Trans. Syst. Man. Cybernetics: Syst. 50 (1), 43–57 (2020).\n\nArticle\n  Google Scholar\n\nWu, D., Chau, K. T., Liu, C., Gao, S. & Li, F. Transient stability analysis of SMES for smart grid with Vehicle-to-Grid operation. IEEE Trans. Appl. Supercond. 22 (3), 5701105–5701105 (2012).\n\nArticle\n  ADS\n  Google Scholar\n\nChen, X., Leung, K. C., Lam, A. Y. S. & Hill, D. J. Online scheduling for hierarchical Vehicle-to-Grid system: design, formulation, and algorithm. IEEE Trans. Veh. Technol. 68 (2), 1302–1317 (2019).\n\nArticle\n  Google Scholar\n\nJiménez-Marín, A. & Pérez-Ruiz, J. A Robust Optimization Model to the Day-Ahead Operation of an Electric Vehicle Aggregator Providing Reliable Reserve, Energies. 14(22), 7456 https://doi.org/10.3390/en14227456 (2021).\n\nRajagopalan, A. et al. Multi-objective energy management in a renewable and EV-integrated microgrid using an iterative map-based self-adaptive crystal structure algorithm. Sci. Rep., 14(1), 15652 (2024).\n\nCh, H. B., K, R. R., Kamwa, D. C. I. & Muyeen, S. M. A novel on intelligent energy control strategy for micro grids with renewables and EVs, Energy Strategy Reviews 52, 101306 (2024).\n\nMadhavaram, P. R. and M. M, Smart Energy Management Strategy for Microgrids Powered by Heterogeneous Energy Sources and Electric Vehicles’ Storage. Energies. 15(20), 7739 https://doi.org/10.3390/en15207739 (2022).\n\nHai, T., Zhou, J., Alazzawi, A. & Muranaka, T. Management of renewable-based multi-energy microgrids with energy storage and integrated electric vehicles considering uncertainties. Journal of Energy Storage. 60, 106582 (2023).\n\nTan, B. et al. Distributionally robust energy management for multi-microgrids with grid-interactive EVs considering the multi-period coupling effect of user behaviors. Applied Energy. 350, 121770 (2023).\n\nHassan, M. Machine learning optimization for hybrid electric vehicle charging in renewable microgrids. Sci. Rep., 14(1), 13973 (2024).\n\nK, U. N. S. S. Optimizing electric vehicle charging infrastructure through hybrid machine learning techniques for smart energy management. Int. J. Electr. Electron. Eng. 11 (7), 148–158 (2024).\n\nArticle\n  Google Scholar\n\nSingh, A. & Bhongade, S. Enhancing Electric Vehicle Charging Stations with Renewable Energy Integration through Advanced Control Algorithms, in IEEE Third International Conference on Power Electronics, Intelligent Control and Energy Systems (ICPEICES), 2024, pp. 797–801. (2024).\n\nGüven, A. F. Integrating electric vehicles into hybrid microgrids: A stochastic approach to future-ready renewable energy solutions and management. Energy. 303, 131968 (2024).\n\nKraiem, H., Gadri, W. & Flah, A. Efficient energy management with emphasis on EV charging/discharging strategy. Eng. Technol. Appl. Sci. Res. 14(2), 13143–13147 (2024).\n\nArticle\n  Google Scholar\n\nRen, H. et al. Optimal scheduling of an EV aggregator for demand response considering triple level benefits of three-parties. International Journal of Electrical Power & Energy Systems. 125, 106447 (2021).\n\nChandra, I., Singh, N. K. & Samuel, P. A comprehensive review on coordinated charging of electric vehicles in distribution networks. Journal of Energy Storage. 89, 111659 (2024).\n\nCarreiro, A. M., Jorge, H. M. & Antunes, C. H. Energy management systems aggregators: A literature survey. Renew. Sustain. Energy Rev. 73, 1160–1172 (2017).\n\nArticle\n  Google Scholar\n\nRigas, E. S., Ramchurn, S. D. & Bassiliades, N. Algorithms for electric vehicle scheduling in large-scale mobility-on-demand schemes. Artif. Intell. 262, 248–278 (2018).\n\nArticle\n  MathSciNet\n  Google Scholar\n\nKapoor, A., Gangwar, P., Sharma, A. & Mohapatra, A. Multi-Objective Framework for Optimal Scheduling of Electric Vehicles, in 21st National Power Systems Conference (NPSC), pp. 1–6. (2020).\n\nFathollahi-Fard, A. M., Hajiaghaei-Keshteli, M. & Tavakkoli-Moghaddam, R. Red deer algorithm (RDA): a new nature-inspired meta-heuristic. Soft. Comput., 24(19), 14637–14665 (2020).\n\nMoghadam, P. & Ahmadi, A. A novel two-stage bio-inspired method using red deer algorithm for data clustering. Evol. Intel., 17(3), 1819–1836 (2024).\n\nGulec, O. & Sahin, E. Red deer algorithm based nano-sensor node clustering for iont. J. Netw. Comput. Appl. 213, 103591 (2023). 2023/04/01/.\n\nArticle\n  Google Scholar\n\nTang, Z., Xue, B., Ma, H. & Rad, A. Implementation of PID controller and enhanced red deer algorithm in optimal path planning of substation inspection robots. J. Field Robot., 41(5) 1426–1437 (2024).\n\nZitar, R. A., Abualigah, L. & Al-Dmour, N. A. Review and analysis for the red deer algorithm. J. Ambient Intell. Humaniz. Comput., 14(7), 8375–8385 (2023).\n\nAmin, A. et al. A Review of optimal charging strategy for electric vehicles under dynamic pricing schemes in the distribution charging network. Sustainability. 12(23), 10160 https://doi.org/10.3390/su122310160 (2020).\n\nLepolesa, L. J., Adetunji, K. E., Ouahada, K., Liu, Z. & Cheng, L. Optimal EV charging strategy for distribution networks load balancing in a smart grid using dynamic charging price. IEEE Access. 12, 47421–47432 (2024).\n\nArticle\n  Google Scholar\n\nTATA.EV. Available: https://ev.tatamotors.com/nexon/ev.html (2024).\n\nLuxury Sedan Car in India - BYD SEAL. Available: https://bydautoindia.com/bydseal (2024).\n\nHyundai. Hyundai IONIQ 5 Car Specifications: Battery, Transmission & Dimensions | Hyundai India Available: https://ioniq5.hyundai.co.in/specification (2024).\n\nNissan Leaf e+ [Internet]. EV Database. Available: https://ev-database.org/uk/car/1144/Nissan-Leaf-eplus (2022).\n\nMG ZS EV Long Range [Internet]. EV Database.. Available: https://ev-database.org/car/1541/MG-ZS-EV-Long-Range (2021).\n\nMercedes-Benz EQS AMG 53 4MATIC+ [Internet]. EV Database.. ( Available: https://ev-database.org/car/1537/Mercedes-Benz-EQS-AMG-53-4MATICplus 2022).\n\nDownload references\n\nAcknowledgements\n\nThis work was funded by the University of Jeddah, Jeddah, Saudi Arabia, under grant No. (UJ-23-SRP-10). The authors, therefore, thank the University of Jeddah for its technical and financial support.\n\nFunding\n\nUniversity of Jeddah, Jeddah, Saudi Arabia, grant No. (UJ-23-SRP-10).\n\nAuthor information\n\nAuthors and Affiliations\n\nDepartment of Computer and Network Engineering, College of Computer Science and Engineering, University of Jeddah, Jeddah, 21959, Saudi Arabia\n\nSahbi Boubaker & Souad Kamel\n\nCenter for Scientific Research and Entrepreneurship, Northern Border University, Arar, 73213, Saudi Arabia\n\nHabib Kraiem\n\nDepartment of Civil Engineering, College of Engineering, Northern Border University, Arar, 1321, Saudi Arabia\n\nNejib Ghazouani & Tariq Alqubaysi\n\nInternational Centre for Theoretical Physics (ICTP), Trieste University, 11-I-34151, Trieste, Italy\n\nAdel Mellit\n\nUniversity of Jijel, Jijel, Algeria\n\nAdel Mellit\n\nDepartment of Cybersecurity, College of Computer Science and Engineering, University of Jeddah, Jeddah, 23218, Saudi Arabia\n\nFaisal S. Alsubaei\n\nDepartment of Information Systems and Technology, College of Computer Science and Engineering, University of Jeddah, Jeddah, 23218, Saudi Arabia\n\nFarid Bourennani\n\nSAMATWAIQ for drones Company, Prince Sultan Road, Jeddah, 23621, Saudi Arabia\n\nWalid Meskine\n\nContributions\n\nConceptualization, Habib Kraiem, Nejib Ghazouani, Sahbi Boubaker, Souad Kamel, Adel Mellit, Faisal S. Alsubaei, Farid Bourennani, Walid Meskine and Tariq Alqubaysi; Data curation, Souad Kamel and Tariq Alqubaysi; Formal analysis, Sahbi Boubaker, Souad Kamel and Adel Mellit; Funding acquisition, Sahbi Boubaker; Investigation, Adel Mellit; Methodology, Habib Kraiem and Farid Bourennani; Project administration, Sahbi Boubaker; Resources, Faisal S. Alsubaei; Software, Nejib Ghazouani and Souad Kamel; Supervision, Sahbi Boubaker; Validation, Sahbi Boubaker, Faisal S. Alsubaei and Walid Meskine; Writing – original draft, Habib Kraiem and Nejib Ghazouani; Writing – review & editing, Sahbi Boubaker and Farid Bourennani.\n\nCorresponding authors\n\nCorrespondence to Sahbi Boubaker or Habib Kraiem.\n\nEthics declarations\n\nCompeting interests\n\nThe authors declare no competing interests.\n\nAdditional information\n\nPublisher’s note\n\nSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\n\nElectronic supplementary material\n\nBelow is the link to the electronic supplementary material.\n\nSupplementary Material 1\n\nRights and permissions\n\nOpen Access This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the licensed material. You do not have permission under this licence to share adapted material derived from this article or parts of it. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by-nc-nd/4.0/.\n\nReprints and permissions\n\nAbout this article\n\nCite this article\n\nBoubaker, S., Kraiem, H., Ghazouani, N. et al. Multi-objective optimization framework for electric vehicle charging and discharging scheduling in distribution networks using the red deer algorithm. Sci Rep 15, 13343 (2025). https://doi.org/10.1038/s41598-025-97473-7\n\nDownload citation\n\nReceived\n24 December 2024\n\nAccepted\n04 April 2025\n\nPublished\n17 April 2025\n\nDOI\nhttps://doi.org/10.1038/s41598-025-97473-7\n\nShare this article\n\nAnyone you share the following link with will be able to read this content:\n\nProvided by the Springer Nature SharedIt content-sharing initiative\n\nKeywords\n\nSubjects\n\nScientific Reports (Sci Rep)\n\nISSN 2045-2322 (online)\n\nAbout Nature Portfolio\n\nDiscover content\n\nPublishing policies\n\nAuthor & Researcher services\n\nLibraries & institutions\n\nAdvertising & partnerships\n\nProfessional development\n\nRegional websites\n\n© 2025 Springer Nature Limited\n\nPruning-Based TinyML Optimization of Machine Learning Models for ... : \nHelp | Advanced Search\n\nComputer Science > Machine Learning\n\nPruning-Based TinyML Optimization of Machine Learning Models for Anomaly Detection in Electric Vehicle Charging Infrastructure\n\nSubmission history\n\nAccess Paper:\n\nReferences & Citations\n\nBookmark\n\nBibliographic and Citation Tools\n\narXiv Operational Status\nGet status notifications via email or slack\n",
            "Machine learning models employed in EV market segmentation analysis": "Using machine learning methods to predict electric vehicles penetration ... : \nYour privacy, your choice\n\nWe use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media.\n\nBy accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection.\n\nSee our privacy policy for more information on the use of your personal data.\n\nManage preferences for further information and to change your choices.\n\nAdvertisement\n\nUsing machine learning methods to predict electric vehicles penetration in the automotive market\n\nScientific Reports\n 13, Article number: 8345 (2023) Cite this article\n\n16k Accesses\n\n1 Altmetric\n\nMetrics\n\nAbstract\n\nElectric vehicles (EVs) have been introduced as an alternative to gasoline and diesel cars to reduce greenhouse gas emissions, optimize fossil fuel use, and protect the environment. Predicting EV sales is momentous for stakeholders, including car manufacturers, policymakers, and fuel suppliers. The data used in the modeling process significantly affects the prediction model’s quality. This research’s primary dataset contains monthly sales and registrations of 357 new vehicles in the United States of America from 2014 to 2020. In addition to this data, several web crawlers were used to gather the required information. Vehicles sale were predicted using long short-term memory (LSTM) and Convolutional LSTM (ConvLSTM) models. To enhance LSTM performance, the hybrid model with a new structure called “Hybrid LSTM with two-dimensional Attention and Residual network” has been proposed. Also, all three models are built as Automated Machine Learning models to improve the modeling process. The proposed hybrid model performs better than the other models based on the same evaluation units, including Mean Absolute Percentage Error, Normalized Root Mean Square Error, R-square, slope, and intercept of fitted linear regressions. The proposed hybrid model has been able to predict the share of EVs with an acceptable Mean Absolute Error of 3.5%.\n\nSimilar content being viewed by others\n\nDeep learning model based prediction of vehicle CO2 emissions with eXplainable AI integration for sustainable environment\n\nDevelopment and evaluation of bidirectional LSTM freeway traffic forecasting models using simulation data\n\nBayesian optimization and deep learning for steering wheel angle prediction\n\nIntroduction\n\nEmissions of greenhouse gases are increasing rapidly worldwide. According to a United States Environmental Protection Agency report released in 2020, the transportation sector produces about 27% of the entire greenhouse gas emissions in the country, which, compared to other sectors, transportation emits the most greenhouse gases1. EVs were introduced as an alternative to gasoline and diesel cars to reduce air pollution and greenhouse gas emissions, optimize the use of natural energy resources and protect the environment. Using electricity generated from renewable energy sources such as wind, water and sunlight for EVs can be one of the most efficient solutions to reduce emissions and climate change2. Although much time has passed since the invention of EVs, internal combustion vehicles are still the most popular. EV sales have been on the rise, and in January 2017, the total number of EVs sold worldwide reached two million3. Globally, EV sales accounted for 9% of the car market in 2021, a fourfold increase from 20194.\n\nDesigning and producing vehicles is time-consuming and requires much investment, so by predicting the number of sales, automobile companies can optimize production, Furthermore, by accurately predicting the penetration of EVs in the market, it is possible to estimate their impact on reducing pollution in the coming years, which is very important from an environmental standpoint. Forecasting the sale of EVs and their penetration into the automotive market has been a significant issue for governments, policymakers, and car manufacturers to plan the production of EVs, set proper policies, and provide sufficient energy and infrastructure.\n\nThe main goal of this research is to apply Machine Learning (ML) methods to build an efficient prediction model to estimate the sale of all vehicles in the dataset, the share of EVs in each segment, and determine the main factors that influence the sales of each EV. The effect of a limited number of influencing factors on vehicle sales was examined in previous studies using different models. For this study, a wide range of information was collected, including all factors that previous studies have proven are related to car sales, and it was used in modeling. LSTM and ConvLSTM, powerful Deep Learning (DL) models, have been used for predicting vehicle sales. By combining the two-dimensional Attention model and the Residual network as the proposed hybrid model, it has been tried to improve the performance of the LSTM model. Additionally, using the collected information and the model sensitivity analysis, it was attempted to determine the most influential factors on the sale of each EV.\n\nThe literature review of this study includes two general sections. The first section examines ML methods used to predict vehicle sales, and the second section provides an overview of the features used in other methods to predict EV sales.\n\nML methods in predicting vehicle sales\n\nSeveral studies have used ML methods to predict the sales of EVs as time-series data. Multiple Linear Regression and Support Vector Machine (SVM) models were compared for predicting vehicle sales using yearly, quarterly and monthly data (the number of new automobile registrations, the number of automobile sales, and economic indicators such as Gross Domestic Product (GDP), Available Personal Income, Consumer Price Index, Interest Rate, Unemployment Rate, Industrial Investment Demand, Petroleum Charge, Private Consumption, and Latent Replacement Demand) in a study by Brühl et al.5 According to the results, the SVM model had better performance based on the error values (Mean Absolute Error and Mean Absolute Percentage Error), was more interpretable, and gave better results based on quarterly data. In the study of Wang et al. ML techniques were used to predict car sales based on sales quantity, economic indicators, wholesale population, unemployment rate, exchange rate, the prices of vehicles, the oil prices, and the prices of vehicle components. Based on evaluation units (R-square and Mean Squared Error), they evaluated the prediction quality of adaptive network-based fuzzy inference system (ANFIS), Artificial Neural Networks (ANN), and autoregressive integrated moving average models; the results showed that ANFIS performed better than the other models6. In another study, Hülsmann et al. compared the performance of linear models, such as Ordinary Least Squares and Quantile Regression, against ML methods like SVM, Decision Tree, k–Nearest Neighbor, and Random Forest for predicting vehicle sales. Based on the monthly data of vehicle sales, new car registrations, and economic indicators (such as GDP, Personal Income and Dow Jones), the Decision Tree of ML methods performed better than the other models based on Mean Absolute Percentage Error (MAPE)7.\n\nMoreover, Kitabci et al. analysed the impact of economic policies on vehicle sales in Turkey as a macro-environmental factor by multiple regression and neural network methods. They assessed factors such as the vehicle loan rate presented by the banks, the income of the consumers, the tax deductions made by the government for the automobile, the inflation rate, automobile prices, the euro exchange rate, oil prices, and advertisements spent by the businesses. According to the results, neural networks were more accurate in predicting sales than regression models; some factors, including the euro exchange rate, the rates of vehicle loans offered by banks, and the government's tax deductions, have influenced automobile sales8. In another research, Bas et al. applied classification ML methods to predict EV adoption using ride-sourcing factors, underlying sociodemographics, and vehicle characteristics; they examined the contributions of different factors to predict outcomes using a method called “Local Interpretable Model-Agnostic Explanations”. Based on the study’s findings, ML models produced highly accurate predictions regarding EV adoption, and the frequent usage of ride-sourcing, knowledge about EVs, and environmental protection awareness were significant factors in explaining the tendency to adopt EVs9. In addition, Zhang et al. applied Singular Spectrum Analysis as a univariate time-series model and the Vector Auto-Regression model (VAR) as a multivariate model for forecasting EV sales. According to the results, the VAR model can significantly improve the prediction accuracy because it considers the effect of economic indicators, such as consumer prices, consumer confidence, producers' prices, fuel and vehicle prices, and Baidu data (An indicator of consumer interest and curiosity in EVs)10.\n\nIn another study, Kaya et al.11 used the exchange rate, the GDP, the Consumer Confidence Index, the Consumer Price Index data and a Deep Neural Network model to predict vehicle sales; the results revealed that this ML model predicted sales accurately (based on Mean Squared Error). In another research, Xia et al. introduced the ForeXGBoost model, a vehicle sales prediction system based on large-scale datasets containing comprehensive vehicle information, including brand ID, model, engine power, and displacement. Based on Logarithmic Difference Square Root, MAPE, and running time, the XGBoost model outperforms benchmark algorithms like Linear Regression and Gradient Boosting Decision Trees12. Using online survey data and ML methods such as SVM, ANN, Deep Neural Networks, Gradient Boosting Models, and Random Forests, Bas et al. compared different methods for classifying potential EV buyers and identifying the features that affect the adoption of EVs. Results showed that the SVM model outperforms the other algorithms; having only partial information (e.g. only socioeconomic factors) reduces model performance, while synergy across multiple variables increases accuracy13. Additionally, Saxena et al. present a study that examines the use of deep learning-based models, including Autoregressive Integration Moving Averages and LSTM models, to predict future directions of vehicle sales. Based on the implementation results, the MAE and the Root Mean Square Error for LSTM-based time series forecasting were reduced, and this model could accurately predict green vehicle sales14.\n\nFactors affecting the sale of EVs in other methods\n\nDeveloping policies requires understanding users' behavior and prioritizing their choices. Therefore, some previous studies used survey data to predict EV demand. To assess the potential demand for EVs, Beggs et al.15 used survey data and vehicle specifications, such as seat capacity, maximum speed, purchase price, and operating costs. In a similar study, the demand for EVs was estimated based on consumer preferences for vehicle attributes by Calfee et al.16 The results of this research have shown that the weak performance of EVs limits their demand; however, if EVs become significantly more advanced than other cars or if gasoline becomes scarce, the demand for these vehicles will increase.\n\nPredicting the future demand for EVs is a complex issue. As most studies for new technologies rely on survey data, market share predictions will reflect the share in the survey data, not the actual market share. Consumer opinions and the news published about EVs also influence the sales of these vehicles. Based on Mau et al.17 research, EV sales are impacted by published information about the penetration rate of EVs, known as the “The neighbor effect”. Electric vehicles' specifications are another factor affecting their sales. According to Balducci et al.18 study to assess plug-in hybrid EV penetration scenarios in the auto market, fuel economy and reduced motor vehicle emissions are the most important factors when purchasing hybrid EVs, while insufficient engine power, high price, and unreliability are the most important reasons for not purchasing these vehicles. Furthermore, Hess et al. used vehicle specifications such as purchase price, vehicle purchase incentives, Miles Per Gallon (MPG) or equivalent, fuel cost per year, fuel availability, refueling time, driving range, maintenance cost per year, and acceleration to explore consumers' preferences in choosing the type of vehicle and the type of fuel. The results have shown that consumers' choices are adversely affected by factors such as purchase price, operating cost, and vehicle age, whereas their choices are positively affected by factors such as better vehicle acceleration, purchase incentives, driving range, and fuel availability19.\n\nThe sale of EVs is also affected by improving vehicle engine performance and reducing fuel consumption. Using a discrete choice model, Bas et al. investigated EV penetration in the face of new technology for reducing fuel consumption. Results demonstrated a clear tradeoff between the cost of a gasoline-powered system and the fuel savings it provides is perceived by potential purchasers20. However, potential EV purchasers are not in this category since their cost–benefit analysis is adverse due to the low cost of electricity20. Also, the estimated market shares give a significant share of the market to alternatives that include technology to reduce consumption, due to a more favorable attitude toward environmentally friendly technologies20. Additionally, Shafiei et al. analysed the impact of factors such as fuel prices, vehicle attributes, consumer preferences, and social influences on the market share of EVs. The results showed that the combination of high gasoline prices, decreasing EV prices, dropping tax on EVs and eliminating consumer concerns about recharging has the most significant effect on the market share of EVs21. Kinski et al.22 research shows that the information related to searching on the Internet (Google Trends) for vehicles has a positive and significant relationship with car sales.\n\nBased on the previous research, the following two general conclusions were reached:\n\nFirstly, ML and DL methods have been proven to be effective at predicting vehicle sales. Therefore, LSTM and ConvLSTM, powerful DL models, have been used for predicting vehicle sales in this research. Furthermore, a hybrid model was also proposed, and all three models were compared in terms of performance.\n\nSecondly, factors and features that affect EV sales have been identified, and these features have been collected and used in this research.\n\nMethodology\n\nArtificial Intelligence (AI) refers to the ability of machines to perceive, synthesize, and infer information, as opposed to animals and humans displaying intelligence23. Machine learning, artificial neural networks, and deep learning are important tools in the development of AI systems and have been shown to perform well in predicting time series data such as vehicle sales. Recurrent neural networks (RNNs) are a type of neural network that remember what they have already processed and can learn from previous iterations24. In other words, an RNN is a class of ANNs where connections between nodes form a directed graph along a temporal sequence; this allows it to exhibit temporal dynamic behavior24.\n\nLSTM\n\nHochreiter and Schmidhuber introduced the LSTM network, a RNN capable of learning long-term dependencies and predicting sequential data with great accuracy25. An LSTM is an extension of an RNN, capable of learning patterns from long sequences of source data by retaining a long-term memory25. LSTMs improved the forgetfulness of RNNs. An RNN could retain a memory, but only for its immediate past. An LSTM, on the other hand, introduces loops to generate long-term gradients. While going through its loops, it can discover long-term patterns25. LSTM is good at storing past information and performing well when faced with vanishing gradient issues. During ANN training, each weight of the neural network receives an update proportional to the partial derivative of the error function. Vanishing gradients occur when gradients become vanishingly small, effectively preventing the weight from changing26.\n\nLSTM can tie together three pieces of information at each time step: the current input data, the short-term memory it receives from the previous cell (the hidden state), and the long-term memory from cells farther away (the cell state)27. The LSTM unit consists of an input gate a forget gate, an output gate, and a cell state. The input gate determines how much information should be transferred from the current candidate cell state to the current cell state. The forget gate determines how much historical information should be ignored from the previous cell state. The output flow from cells to the rest of the network can be controlled through the output gate. By regulating the flow of information through the three gates, important information over time intervals can be remembered. According to Eqs. 1–6, the LSTM unit process data in cell state and gates27. Reference27 provides more details.\n\nIn the above equations, \\(f_{t}\\), \\(i_{t}\\), and \\(o_{t}\\) are the forget, input, and output gates, respectively; \\(C_{t}\\), \\(C_{t - 1}\\), and \\(\\tilde{C}_{t}\\) are the current, previous, and candidate cell state; \\(\\sigma\\) and tanh denotes sigmoid and hyperbolic tangent activation functions, respectively; the interconnected weight matrices for each gate and cell state are \\(W_{fh}\\), \\(W_{ih}\\), \\(W_{oh}\\), \\(W_{Ch}\\), respectively; \\(W_{fx}\\), \\(W_{ix}\\), \\(W_{ox}\\), \\(W_{Cx}\\) represent the input weight matrices in the three gates and the cell state, respectively; \\(b_{f}\\), \\(b_{i}\\), \\(b_{o}\\), \\(b_{C}\\) represent the respective bias terms; the Hadamard (element product) product of a matrix is denoted by \\(\\odot\\)27. According to Fig. 1, the input layer is an LSTM layer with the same number of neurons as the input data features. In the next step, one or more LSTM layers are set as the hidden layers, and in the final step, a Dense layer with the ReLU activation function is set as the output layer.\n\nArchitecture of the LSTM model.\n\nConvLSTM\n\nThe LSTM model is powerful for handling temporal correlation. In addition, when working with time series data with numerous features, LSTM model performance can be improved by converting the two-dimensional data to a three-dimensional tensor (Fig. 2 illustrates this), connecting states, and applying convolutional operations; this idea was the reason for creating the ConvLSTM model28. The ConvLSTM neural network is a fully connected LSTM network with a convolutional structure inside the LSTM cell, which does well in predicting data with temporal correlation. ConvLSTM provides a fully connected extension for data transfer between states and from inputs to states28. In other words, ConvLSTM determines the future state of each cell in the grid based on its inputs and neighbours' past states; this can be done by using a convolution operator in the state-to-state and input-to-state transitions28. In the ConvLSTM model, data in the input unit, the outputs of each cell, the hidden units, and the gates are arranged as three-dimensional tensors. ConvLSTM has similar parameters as LSTM, and the difference is in how data is transferred and convolutional multiplication is used in calculations, as expressed in Eqs. 7–1128. Reference28 provides more details.\n\nTransforming 2-D matrix into 3-D tensor.\n\nIn ConvLSTM equations, * indicates the convolution operator, and \\(\\odot\\) indicates the Hadamard product. As shown in Fig. 3, the input layer is a ConvLSTM layer, the hidden layers are Dense and ConvLSTM layers, and the output layer is a Dense layer with the ReLU activation function.\n\nArchitecture of the ConvLSTM model.\n\nHybrid LSTM with two-dimensional attention and residual network\n\nTime series data have a meaningful temporal relationship. In this research, the data were transformed into three-dimensional tensors with a seven-month time window to maintain the temporal relationship; how to transform a two-dimensional matrix to a three-dimensional tensor is shown in Fig. 2. As an innovation, the “Two-Dimensional Attention” method has been proposed in this research to determine the importance of each car's feature in a seven-month time frame and to use the weighted data in the modeling process. The two-dimensional attention method assigns weights to each feature in the time window based on how much it influences the model, allowing the features with a more significant impact to receive more attention and reduce the model's complexity. The one-dimensional attention model was proposed for the first time by Bahdanau to address the problem of the limited access of the decoder to the model's input information when the encoder vector has a fixed length in the translation machine29.\n\nIn the LSTM model architecture, which is shown in Fig. 1, several LSTM layers are placed inside the hidden layer. When the number of LSTM layers in the hidden layer increases, the primary layers (the layers adjacent to the input layer) have a lesser effect on the output. The primary layers have processed the input data and learned the relationship between the data well, which is why it has been tried to improve this problem by using the Residual network in the proposed hybrid model. Using the Residual Network, the weighted data and outputs of the primary layers have been transferred to the final layers in the proposed hybrid model, as shown in Fig. 4.\n\nPrimary architecture of the hybrid model.\n\nIn this study, each input \\(x\\) is represented by an \\(m \\times n\\) matrix, where m corresponds to the previous months in the window (7), and n represents the number of vehicle features. After entering the data into the first LSTM layer, the processing is done according to Eqs. 1–6, and the encoded hidden unit (\\(h\\)) with the exact dimensions (\\(m \\times n\\)) is entered into the Attention layer. After that, the alignment score is calculated according to Eq. (12).\n\nIn Eq. (12), \\(e_{i, j}\\) represents the alignment score, \\(W_{a}\\) is the attention model’s weight (as a trainable variable), \\(h\\) is the encoded hidden unit of the primary LSTM layer, \\(b_{a}\\) is the attention model's bias (as a trainable variable), and the sign \"*\" denotes the Hadamard product. Since the input data for the attention layer has been encoded by an LSTM layer using tanh nonlinear activation function, tanh has also been used in the attention layer to facilitate data reading during decoding. Each input data element was assigned a degree of attention using Eq. (13).\n\nMultiplying attention matrix \\(\\alpha_{i, j}\\) by raw data matrix \\(x_{i, j}\\) yields a weighted data matrix \\(W_{i, j}\\) based on Eq. (14). The sign “*” denotes the Hadamard product.\n\nWeighted data \\(W_{i, j}\\) is then passed through three layers of LSTM as a Residual Network; the output of each layer is combined with the weighted data at the end of the Residual Network and entered into one or more LSTM layers. A Dense layer with the ReLU activation function is the output layer. An overview of the model's architecture is illustrated in Fig. 4.\n\nOther architectures have also been tried in the hybrid model structure, but they were not more efficient, so only the best architecture has been mentioned.\n\nData\n\nIn this study, EVs are considered as vehicles that use electric motors for propulsion and include all types of EVs. In predicting the sale of vehicles, the number of vehicles in the warehouses is an influential factor, which was not used in this modeling due to a lack of access. Since ML models are based on training, in this study, the models can predict the sales of vehicles that have been on the market for at least 24 months. Emerging vehicles (vehicles that have been on the market for less than 24 months) and cars that have not yet entered the market were not included in the modeling due to insufficient data to train the model. Therefore, the share of EVs in the Automotive Market is expressed as a share in vehicle segments and not as a share of EVs overall.\n\nA wide range of information related to car sales has been used in this research. In the primary dataset, all the data is related to new cars, not used cars. The primary dataset contains monthly information about 357 vehicles, such as brand (or \"make\" in auto industry lingo, e.g., Benz), model, segmentation, category, shoppers, and sales of different types of cars in the United States from 2014 to 2020. Other information has been extracted based on the cars in this dataset. The data before the outbreak of Covid-19 disease were used since this disease had adverse impacts on the global economy.\n\nAs stated in previous studies, vehicle specifications are very effective in car sales prediction models. Vehicle specifications are changed annually. According to Alexa rating30 and the comprehensiveness of the information presented on the “Thecarconnection” website31, vehicle specifications were collected through this website. In order to save time and automate the collection of information due to a large number of vehicles and changes in specifications of vehicles over time, several web crawler have been designed and used in Python programming language to collect vehicle information. Several vehicle specifications of the \"CAR-MID/FULL SIZE\" segment are shown in Table 1.\n\nThere is similar information collected for gasoline and EVs; for example, the equivalent MPG in EVs. Price, MPG, max mileage, engine power, and warranty are some of the main features taken into account. Other specifications have been divided into the \"safety specifications\" and the \"other specifications\" categories. The safety specifications category includes child safety rear door locks, airbags, ABS brakes, daytime running lights, night vision, driver monitoring alerts, collision mitigation braking system, electronic stability control, and side impact beams. All other features (traction control, fog lamps, tire pressure monitoring, parking sensors, parking assist, and backup cameras) have been transferred to the other specifications category.\n\nThe second series of collected data refers to user opinions and news published on reputable websites ranked higher on Alexa30. Four websites were examined for this purpose: Autoblog32, Auto News33, Motor134, and The Car Connection35. These websites were crawled using Python web crawlers to save time and collect information automatically. From 2014 to 2020, the daily news published was collected and evaluated for each type of vehicle. The Valence Aware Dictionary and sEntiment Reasoner (VADER) method was used for sentiment analysis of the text. Based on vocabulary analysis, the VADER sentiment analysis method correctly analyzes the sentiment expressed in social media and news texts. Ten independent human raters analyzed over 90,000 ratings in the VADER evaluation, which led to the adoption of 7500 linguistic features that were rated based on their valence scores, which indicate the intensity and polarity of sentiment36. For each vehicle, the average monthly score of news and opinions has been calculated based on their daily publication of them.\n\nAnother effective source of information about the vehicle market is various economic indicators. Using a Python web crawler, information on several economic indicators affecting the car market has been collected on the Federal Reserve website37. Economic indicators include GDP, Consumer Price Index (CPI), Producer Price Index, Consumer Confidence Index, Personal Income Per Capita, Interest Rates on 48-month and 60-month Loans, SP&500, and Dow Jones stock market indicators.\n\nAccording to Kinski's research, using Google trends in prediction models is beneficial and practical22. Three keywords have been selected for Google trend data to evaluate the number of searches for each car from 2014 to 2020 and for the United States of America. The keywords are:\n\n\"Make\" + \"Model\"\n\n\"Price\" + \"Make\" + \"Model\"\n\n\"Dealer\" + \"Make\"\n\nAll cars have the same data collected, and the features collected on a monthly basis for each car are listed in Table 2. Several different trims were available on the market for some vehicles simultaneously, and some characteristics, such as price and MPG, had multiple values for these vehicles. Due to this, the collected values for these characteristics were divided into three categories: minimum, average, and maximum.\n\nThe sales feature has been normalized based on the maximum and minimum values from the training data set. Other features are standardized based on each feature's average and standard deviation in the training set. The input data to models are considered seven-month windows to maintain temporal correlation. For example, in the current month, the last seven months' data are input (X), and the current month's sale is output (Y). In order to achieve this, seven-month data matrices were placed consecutively in the third dimension of a three-dimensional tensor.\n\nValidation and interpretation of results\n\nSince the time series data in this study are monthly, eleven binary columns have been added to the dataset to reflect the effect of each month (in the first month of every year, the column corresponding to the first month is set to 1, and the column for the other months is set to 0). An example of this binary data is shown in Table 3.\n\nFor most vehicles, data includes 79 months (January 2014 through July 2020). According to Fig. 5, the last 14 months are selected for the testing set as rolling cross-validation. Using cross-validation on a rolling basis is one way to validate the time-series model. Starting with a subset of data for training, forecasting for later data points and then checking the accuracy of the forecasts. The same forecasted data points are included in the next training dataset, and further forecasts are made.\n\nSplitting dataset into training, validation, and testing sets.\n\nThe model is cross-validated using 12 forecasting stages, with each stage predicting sales in the next three months. During each prediction stage, the preceding months are divided into training and validation (70% for training and 30% for validation. Then these data are transferred to the model, the model predicts sales in the next three months, then the forecast date is moved forward by one month, and this process has been repeated 12 times. Vehicle sales in the next three months are predicted each time the model runs, assuming most of the vehicle's characteristics remain the same. Due to fluctuation and changes in economic conditions, a three-month time horizon is used for predicting the future.\n\nOverfitting is one of the principal problems in ANN training. The Dropout layers between the neural network layers are one of the best solutions in the ANN to avoid overfitting. During the dropout layer, the number of neurons trained in each layer and those discarded is determined randomly (rather than activating all neurons at once, only a fraction are activated)38. TensorFlow's early stopping tool is another basic solution to avoid overfitting. Early stopping works in the following way: during the repetition of training, the validation data is used to calculate the error value, and whenever the validation error value increases throughout several epochs, the model is ready to be stopped, and overfitting is prevented. For all three models, both solutions are used to prevent overfitting. Dimensionality reduction is another way to prevent model overfitting. In this study, Principal Component Analysis was used in several modes to reduce dimensions, but this technique was not used due to the significant decrease in model performance.\n\nIn order to improve the modeling process, all three models' hyperparameter values and network architectures were determined by Automated Machine Learning (AutoML). AutoML is the process of automating ML applications. The number of hidden layers, the number of neurons in these layers, and the dropout rate was determined by the Tuners. Several values are introduced to the Tuner for each hyperparameter. The Tuner trains different model versions and selects the best one based on the best result (lowest error or loss) on the validation data. This method sets the hyperparameters to the optimal value, and the model is then applied to a test dataset.\n\nThe model's error or loss is calculated using the Mean Absolute Error (MAE) loss function in all three models. Selecting a suitable optimization algorithm for the DL model is essential to reduce the run time and reach the desired result. Adam's optimization algorithm is used for these models, which is a generalized version of stochastic gradient descent. It reduces memory usage, converges faster, and corrects high variance and learning rates39.\n\nComparison of models\n\nWith the validation data, hyperparameters are adjusted, and the model is built to predict vehicle sales over the next three months (three months following the last validation date). The model run-time for all vehicles was very long due to the many vehicle types (357). In a random sample of 15 vehicles, different models' states were compared using fixed data, and the results were compared between the three models.\n\nThe sale of each vehicle is predicted in 12 stages; each prediction stage includes the prediction for the next three months, respectively, the first month of the prediction, the second month of the prediction, and the third month of the prediction. In total, the first predictions include 12 months, the second predictions include 12 months, and the third predictions include 12 months. Model performance was evaluated using the Mean Absolute Percentage Error (MAPE), the Root Mean Square Error normalized by the change range (\\(NRSME_{range}\\)), and the Root Mean Square Error normalized by the mean value (\\(NRSME_{mean}\\)) according to Eqs. 15–18.\n\nAccording to the above equations, \\(y_{t}\\) denotes the actual value at time t, \\(\\hat{y}_{t}\\) denotes the predicted value at time t, \\(y_{max}\\) denotes the maximum actual value, \\(y_{min}\\) denotes the minimum actual value, \\(y_{mean}\\) denotes the average actual value, and T is equal to the total number of predicted samples. The average error values of all vehicles were calculated to compare the results of various models. A weighted average was calculated using the total number of sales of each car per month as a weight for the vehicle according to Eq. (19) since the numbers of vehicle sales are not on the same scale, and the error rate is more important in vehicles with high sales. A further method of checking the models' performance is to compare the R-square, slope, and intercept of the linear regressions fitted on predicted and observed data for all three models. Table 4 summarizes the evaluation results of the models.\n\nIn the proposed hybrid model, the error values are lower, the R-square accuracy is higher, the slope value is closer to 1, and the intercept is closer to 0. At this stage, the proposed hybrid model was recognized as preferable to both the LSTM and ConvLSTM models.\n\nImplementation of the proposed hybrid model to predict the share of EVs\n\nFor all vehicles, the proposed hybrid model has been implemented, and 12 points of prediction have been used to determine the sale of all vehicles. Linear regression was fitted on the predicted sales and actual values to evaluate the model's performance, as shown in Table 5.\n\nPrimary data segments vehicles by specifications according to segments like CAR-SMALL_COMPACT, CAR-MID_FULL SIZE, MINIVAN LARGE, and PICKUP LARGE. Each segment consists of similar vehicles in appearance and specifications that compete with one another. Segments that include EVs have been separated to determine the share of EVs. Based on actual and predicted sales, the shares of electric and gasoline vehicles have been compared and evaluated for each month of the test data. For example, the CAR-MID/FULL-SIZE segment includes 28 vehicles (23 gasoline vehicles and five EVs). Figure 6 shows the share of EVs in this segment based on twelve prediction stages (three months per stage), separately for the first, second, and third months of each prediction.\n\n(a) Share of EVs in CAR-MID/FULL-SIZE based on the first month of each prediction. (b). Share of EVs in CAR-MID/FULL-SIZE based on the second month of each prediction. (c) Share of EVs in CAR-MID/FULL-SIZE based on the third month of each prediction.\n\nAll segments' MAEs for EVs' share forecasting in the forecast's first, second, and third months are shown in Table 6. The average MAE value of all segments was calculated as 3.2% for the first months, 3.8% for the second months, and 3.5% for the third months. The average value for all segments and all forecast months was calculated at about 3.5%, which shows that the proposed hybrid model performed well.\n\nAs part of the model analysis, the segments that included EVs were separated again and ranked by sales within each segment. The rankings were based on actual sales (actual rank) and predicted sales (predicted rank); the actual rank and predicted rank were used for evaluation. Kendall-Tau correlation (Kendall's correlation) is commonly used to check the concordance of two ranked lists; this technique was used to examine the actual and predicted rankings in this study. Kendall's correlation rate for two rating lists \\(r_{a}\\) and \\(r_{b}\\) (\\(\\tau_{{r_{a} , r_{b} }}\\)) is represented by Eq. (20) 40.\n\nIn Eq. (20), \\(n_{c}\\) represents the number of concordant pairs, \\(n_{d}\\) represents the number of discordant pairs, and n represents the total number of ranks in each of the rating lists40. The maximum number of discordant pairs between two ranking lists equals \\(\\frac{1}{2} n\\left( {n - 1} \\right)\\), and Kendall's correlation equals + 1 if all pairs of ranks are concordant and -1 if none are concordant 40. For all segments, Kendall's correlation values were calculated separately for the first, second, and third prediction months, and the average values are shown in Table 7. The average Kendall's correlation value of all segments was calculated as 0.76 for the first months, 0.742 for the second months, and 0.75 for the third months. The average Kendall's correlation value for all segments and all forecast months was calculated at about 0.75, which indicates the great performance of the proposed hybrid model in predicting the ranking.\n\nSensitivity analysis\n\nSensitivity analysis was performed to determine which features significantly impacted the trained model. Thus, for each vehicle, the pre-trained model that was evaluated in previous stages has once again predicted the number of vehicle sales with new input data, and its outputs have been assessed. All features, except the investigated feature, are valued at their average. For the investigated feature, the five values from the training data (the min value, the first quartile, the second quartile, the third quartile, and the max value) are taken into consideration. Five predictions were made based on these five values, and a range of changes in predicted sales was calculated. The change ranges for all features have been measured, and the four features with the most extensive range have been identified. As an example, during the sensitivity analysis of the BMW I3 for 2020, the following four features had the broadest range of changes: the Consumer Price Index (CPI), the equivalent MPG for EVs, the Google search score for car prices (Google Trends), and the car price. This EV's sensitivity analysis plots are shown in Fig. 7.\n\n(a) Sensitivity analysis plot of influential feature 1 for BMW I3. (b) Sensitivity analysis plot of influential feature 2 for BMW I3. (c) Sensitivity analysis plot of influential feature 3 for BMW I3. (d) Sensitivity analysis plot of influential feature 4 for BMW I3.\n\nBased on Eq. (21), slope values for the four characteristics with the most extensive range of changes are calculated in different parts of the graph, and the results are summarized in Table 8. For example, the number of sales of this EV has decreased by 8 for every thousand-dollar increase in price when the price is in the range of the minimum value to the first quarter. As the slope is zero percent in the second and third parts of the graph, the price in the first, second, and third quartiles is equal, and when the price is in the third quartile to the maximum price, the number of sales for this EV decrease by 6 for every thousand-dollar increase in price.\n\nThere has been a decrease in car sales due to the increase in the CPI. It is also true that with the increase in the CPI, the final price of the car and the price of auto parts have increased, which has led to a decrease in the desire to buy this car. The second feature is equivalent MPG for EVs, a higher equivalent MPG indicating better performance and less fuel consumption in a fixed distance has led to an increase in sales of this car. The third feature identified is the increase in the car price search score on Google (Google Trend), an indicator that buyers are more curious about this car, contributing to its sales. The fourth specified feature of the car is its price, and its sales have decreased with the increase in its price. As a result of the sensitivity analysis, the manufacturers of this car could use policies such as lowering the price of the car and its parts (CPI and car price), improving the performance of the vehicle's engine (the equivalent MPG), and developing advertisements and introducing the car to the public (Google trend score) to increase sales.\n\nSensitivity analysis has been conducted for each EV, and the results show different sensitivity for each vehicle. From each segment that includes EVs, one vehicle was selected as a sample, and the results of its sensitivity analysis are shown in Table 9.\n\nEach EV's sensitivity analysis identifies features that differ from the others, as shown in Table 9. According to the results of the sensitivity analysis, ten features that were most frequently found in the sensitivity analysis of all the EVs were identified as the most influential features: Shoppers, Min price, CPI, Sales, Google Trends score 3 (Price), Make & model news score, Personal income per capita, Make news score, Interest Rates on 60-month, and Mean options score, respectively.\n\nConclusion\n\nThis study addresses an important topic from a business perspective. Car manufacturers can benefit from this research by understanding their market share and the effect of pricing and vehicle specification on the market share. They can use the results of this study to analyze both their EV market as well as their Non-EV market. Lower down the funnel, car dealers that operate in a highly competitive environment can strategize their sales events, marketing campaigns, and discounts to meet their business goals and target sales. Finally, the model enables the public sector to understand the effect of tax policies on the share of EV vehicles in case they like to promote them.\n\nThis study used ML methods to develop a prediction model that estimated the sale of all cars in the dataset, the share of EVs in each segment and identified the main factors affecting each EV's sales. In this research, several web crawlers have been used to collect various data, including factors that previous studies have proven to be associated with EV sales. Vehicles sale were predicted using LSTM, ConvLSTM, and the proposed hybrid model (Hybrid LSTM with two-dimensional Attention and Residual network). Several ML tools have been used to improve the model's training and the modeling process, such as transforming two-dimensional time series data into three-dimensional tensors, Dropout layers, early stopping tools, and AutoML. Because of the variety of car types and the long running time of the models, a random selection of fifteen types of cars was made. All three models are evaluated based on the same evaluation units: the MAPE, NRSME_range, and NRSME_mean, R-square, slope, and intercept of fitted linear regressions have also been assessed. The average error values in the three months of prediction were as follows:\n\nThe MAPE value of the proposed hybrid model was 4.5% less than the LSTM model and 14.4% less than the ConvLSTM model.\n\nThe NRSME_range value of the hybrid model was 0.11 less than the LSTM model and 0.22 less than the ConvLSTM model.\n\nThe NRSME_mean value of the hybrid model was 0.079 less than the LSTM model and 0.169 less than the ConvLSTM model.\n\nAs a result of fitting linear regressions to the predicted and actual values, for all three months of predictions, the proposed hybrid model has a higher R-square value, its slope is closer to one, and its intercept is closer to zero, which indicates that the hybrid model performed better than the other two. In comparing the models, it was found that the proposed hybrid model conducted better than other models and was selected to predict the sale of all vehicles in the dataset. Based on the linear regression fitted to the predicted sales and the actual sales of all vehicles, the R-square values for the first, second and third prediction months were 0.912, 0.906, and 0.917.\n\nThe predicted sales of all vehicles were used to calculate the predicted share of EVs in each segment and compare them with the actual values. Across all segments and forecasting months, the average MAE value for EV share is about 3.5%, and the hybrid model has accurately predicted the share of EVs across all segments. To further analyze the model results, the cars were ranked according to the number of actual and predicted sales within each segment. The average Kendall's correlation value for all segments and all forecast months was calculated at about 0.75, which indicates the high performance of the proposed hybrid model in predicting the ranking.\n\nThe sensitivity analysis was performed to evaluate the model further and identify its most influential features. The results have shown that each EV's sensitivity analysis identifies features that differ from the others. According to the sensitivity analysis of the BMW I3 for 2020, the following four features were most affected: the Consumer Price Index, the equivalent MPG for EVs, the Google search score, and the car price. As a result of the sensitivity analysis, the manufacturers of this car could use policies such as lowering the price of the car and its parts, improving the engine's performance, developing advertisements, and better introducing the car to increase sales (See Appendix Tables A1 to A4.2, Fig. A1).\n\nThis research has achieved the following accomplishments:\n\nA wide variety of factors have been collected and used as variables to model the sale of EVs.\n\nLSTM and ConvLSTM, powerful DL models, have been used for predicting vehicle sales. By combining the two-dimensional Attention model and the Residual network, the performance of the LSTM model was enhanced, and the innovative hybrid model performed better than the other two.\n\nEVs differ in terms of the most influential factors for sales depending on the sensitivity analysis results. The ten features that appeared the most in the sensitivity analysis of all EVs were identified as the most influential, including Shoppers, Min price, CPI, Sales, Google Trends score 3 (Price), News score for make and model, Personal income per capita, News score for make, Interest Rates on 60-month, and Mean options score, respectively.\n\nData availability\n\nThe primary dataset was taken from Autometrics, and other data were collected using web crawlers. The data is available from the corresponding author on reasonable request.\n\nReferences\n\nhttps://www.epa.gov/ghgemissions/inventory-us-greenhouse-gas-emissions-and-sinks (2020).\n\nMacInnis, B. & Krosnick, J. Climate Insights 2020: Electric Vehicles. (2020).\n\nhttps://theicct.org/the-rise-of-electric-vehicles-the-second-million/ (2020).\n\nhttps://www.iea.org/fuels-and-technologies/electric-vehicles (2022).\n\nBrühl, B., Hülsmann, M., Borscheid, D., Friedrich, C. M. & Reith, D. in Industrial Conference on Data Mining. 146–160 (Springer).\n\nWang, F.-K., Chang, K.-K. & Tzeng, C.-W. Using adaptive network-based fuzzy inference system to forecast automobile sales. Expert Syst. Appl. 38, 10587–10593 (2011).\n\nArticle\n  Google Scholar\n\nHülsmann, M., Borscheid, D., Friedrich, C. M. & Reith, D. General sales forecast models for automobile markets and their analysis. Trans. Mach. Learn. Data Min. 5, 65–86 (2012).\n\nGoogle Scholar\n\nKitapcı, O., Özekicioğlu, H., Kaynar, O. & Taştan, S. The effect of economic policies applied in Turkey to the sale of automobiles: Multiple regression and neural network analysis. Procedia Soc. Behav. Sci. 148, 653–661 (2014).\n\nArticle\n  Google Scholar\n\nBas, J., Zou, Z. & Cirillo, C. An interpretable machine learning approach to understanding the impacts of attitudinal and ridesourcing factors on electric vehicle adoption. Transp. Lett. 15, 30–41 (2023).\n\nArticle\n  Google Scholar\n\nZhang, Y., Zhong, M., Geng, N. & Jiang, Y. Forecasting electric vehicles sales with univariate and multivariate time series models: The case of China. PLoS ONE 12, e0176729 (2017).\n\nArticle\n  PubMed\n  PubMed Central\n  Google Scholar\n\nKaya, S. K. & Yildirim, Ö. A prediction model for automobile sales in turkey using deep neural networks. Endüstri Mühendisliği 31, 57–74 (2020).\n\nGoogle Scholar\n\nXia, Z. et al. ForeXGBoost: Passenger car sales prediction based on XGBoost. Distrib. Parallel Databases 38, 713–738 (2020).\n\nArticle\n  Google Scholar\n\nBas, J., Cirillo, C. & Cherchi, E. Classification of potential electric vehicle purchasers: A machine learning approach. Technol. Forecast. Soc. Chang. 168, 120759 (2021).\n\nArticle\n  Google Scholar\n\nSaxena, P., Bahad, P. & Kamal, R. Long short-term memory-RNN based model for multivariate car sales forecasting. Int. J. Adv. Sci. Technol. 29, 4645–4656 (2020).\n\nGoogle Scholar\n\nBeggs, S., Cardell, S. & Hausman, J. Assessing the potential demand for electric cars. J. Econom. 17, 1–19 (1981).\n\nArticle\n  Google Scholar\n\nCalfee, J. E. Estimating the demand for electric automobiles using fully disaggregated probabilistic choice analysis. Transp. Res. Part B Methodol. 19, 287–301 (1985).\n\nArticle\n  Google Scholar\n\nMau, P., Eyzaguirre, J., Jaccard, M., Collins-Dodd, C. & Tiedemann, K. The ‘neighbor effect’: Simulating dynamics in consumer preferences for new vehicle technologies. Ecol. Econ. 68, 504–516 (2008).\n\nArticle\n  Google Scholar\n\nBalducci, P. J. Plug-In Hybrid Electric Vehicle Penetration Scenarios. (Pacific Northwest National Lab. (PNNL), Richland, WA (United States) (2008).\n\nHess, S., Fowler, M., Adler, T. & Bahreinian, A. A joint model for vehicle type and fuel type choice: Evidence from a cross-nested logit study. Transportation 39, 593–625 (2012).\n\nArticle\n  Google Scholar\n\nBas, J., Zofío, J. L., Cirillo, C., Chen, H. & Rakha, H. A. Policy and industry implications of the potential market penetration of electric vehicles with eco-cooperative adaptive cruise control. Transp. Res. Part A Policy Pract. 164, 242–256 (2022).\n\nArticle\n  Google Scholar\n\nShafiei, E. et al. An agent-based modeling approach to predict the evolution of market share of electric vehicles: A case study from Iceland. Technol. Forecast. Soc. Chang. 79, 1638–1653 (2012).\n\nArticle\n  Google Scholar\n\nKinski, A. Google trends as complementary tool for new car sales forecasting: A cross-country comparison along the customer journey, University of Twente, (2016).\n\nhttps://en.wikipedia.org/wiki/Artificial_intelligence (2023).\n\nhttps://en.wikipedia.org/wiki/Recurrent_neural_network (2023).\n\nHochreiter, S. & Schmidhuber, J. Long short-term memory. Neural Comput. 9, 1735–1780 (1997).\n\nArticle\n  CAS\n  PubMed\n  Google Scholar\n\nBasodi, S., Ji, C., Zhang, H. & Pan, Y. Gradient amplification: An efficient way to train deep neural networks. Big Data Min. Anal. 3, 196–207 (2020).\n\nArticle\n  Google Scholar\n\nWei, X., Zhang, L., Yang, H.-Q., Zhang, L. & Yao, Y.-P. Machine learning for pore-water pressure time-series prediction: Application of recurrent neural networks. Geosci. Front. 12, 453–467 (2021).\n\nArticle\n  ADS\n  Google Scholar\n\nShi, X. et al. Convolutional LSTM network: A machine learning approach for precipitation nowcasting. Advances in neural information processing systems 28 (2015).\n\nBahdanau, D., Cho, K. & Bengio, Y. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473 (2014).\n\nhttps://www.alexa.com/ (2021).\n\nhttps://www.thecarconnection.com/ (2021).\n\nhttps://www.autoblog.com/news/ (2021).\n\nhttps://www.autonews.com/news (2021).\n\nhttps://www.motor1.com/news/ (2021).\n\nhttps://www.thecarconnection.com/news (2021).\n\nHutto, C. & Gilbert, E. in Proceedings of the international AAAI conference on web and social media. 216–225.\n\nhttps://fred.stlouisfed.org/ (2021).\n\nBaldi, P. & Sadowski, P. J. Understanding dropout. Advances in neural information processing systems 26 (2013).\n\nKingma, D. P. & Ba, J. Adam. A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).\n\nBachrach, Y., Herbrich, R. & Porat, E. in International Symposium on String Processing and Information Retrieval. 344–352 (Springer).\n\nDownload references\n\nFunding\n\nThe authors received no financial support for the research, authorship, and/or publication of this article.\n\nAuthor information\n\nAuthors and Affiliations\n\nDepartment of Transportation, School of Civil Engineering, Iran University of Science and Technology, Tehran, Iran\n\nShahriar Afandizadeh & Diyako Sharifi\n\nAECOM, Glen Allen, VA, USA\n\nNavid Kalantari\n\nDepartment of Civil-Transportation Planning, Faculty of Technical and Engineering, Imam Khomeini International University, Qazvin, Iran\n\nHamid Mirzahossein\n\nContributions\n\nThe authors confirm contribution to the paper as follows: study conception and design: S.A., D.S., N.K., H.M.; data collection: N.K., D.S.; analysis and interpretation of results: S.A., D.S., N.K.; manuscript preparation: D.S., H.M. All authors reviewed the results and approved the final version of the manuscript. Authors consent for the publication of the submitted paper and any associated data and accompanying images\n\nCorresponding author\n\nCorrespondence to Shahriar Afandizadeh.\n\nEthics declarations\n\nCompeting interests\n\nThe authors declare no competing interests.\n\nAdditional information\n\nPublisher's note\n\nSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\n\nSupplementary Information\n\nSupplementary Information.\n\nRights and permissions\n\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.\n\nReprints and permissions\n\nAbout this article\n\nCite this article\n\nAfandizadeh, S., Sharifi, D., Kalantari, N. et al. Using machine learning methods to predict electric vehicles penetration in the automotive market. Sci Rep 13, 8345 (2023). https://doi.org/10.1038/s41598-023-35366-3\n\nDownload citation\n\nReceived\n13 November 2022\n\nAccepted\n17 May 2023\n\nPublished\n23 May 2023\n\nDOI\nhttps://doi.org/10.1038/s41598-023-35366-3\n\nShare this article\n\nAnyone you share the following link with will be able to read this content:\n\nProvided by the Springer Nature SharedIt content-sharing initiative\n\nSubjects\n\nScientific Reports (Sci Rep)\n\nISSN 2045-2322 (online)\n\nAbout Nature Portfolio\n\nDiscover content\n\nPublishing policies\n\nAuthor & Researcher services\n\nLibraries & institutions\n\nAdvertising & partnerships\n\nProfessional development\n\nRegional websites\n\n© 2025 Springer Nature Limited\n\nEV-Segmentation-Analysis-Uisng-Machine-Learning - GitHub : \nNavigation Menu\n\nVenkatesh630/EV-Segmentation-Analysis-Uisng-Machine-Learning\n\nFolders and files\n\nLatest commit\n\nHistory\n\nRepository files navigation\n\nEV-Segmentation-Analysis-Uisng-Machine-Learning\n\nThis project aims to leverage machine learning techniques to segment the Electric Vehicle (EV) market into distinct consumer groups based on demographics, purchasing behavior, preferences, and environmental factors. The insights from this segmentation will help businesses and stakeholders optimize marketing strategies, enhance product development. #1.Dataset And Machine Learning Model: The dataset contains details about Indian electric vehicles (EVs) with 50 entries and the following columns:\n\nAbout\n\nThis project aims to leverage machine learning techniques to segment the Electric Vehicle (EV) market into distinct consumer groups based on demographics, purchasing behavior, preferences, and environmental factors. The insights from this segmentation will help businesses and stakeholders optimize marketing strategies, enhance product development.\n\nResources\n\nStars\n\nWatchers\n\nForks\n\nReleases\n\nPackages\n\nLanguages\n\nFooter\n\nFooter navigation\n\nDeep Learning Forecasting Model for Market Demand of Electric ... - MDPI : \nDeep Learning Forecasting Model for Market Demand of Electric Vehicles\n\nAbstract\n\n1. Introduction\n\n2. Literature Review\n\n3. Proposed Methodology\n\n4. Experimental Works\n\n5. Discussion\n\n6. Conclusions\n\nAuthor Contributions\n\nFunding\n\nInstitutional Review Board Statement\n\nData Availability Statement\n\nAcknowledgments\n\nConflicts of Interest\n\nReferences\n\nShare and Cite\n\nSimsek, A.I.; Koç, E.; Desticioglu Tasdemir, B.; Aksöz, A.; Turkoglu, M.; Sengur, A. Deep Learning Forecasting Model for Market Demand of Electric Vehicles. Appl. Sci. 2024, 14, 10974. https://doi.org/10.3390/app142310974\n\nSimsek AI, Koç E, Desticioglu Tasdemir B, Aksöz A, Turkoglu M, Sengur A. Deep Learning Forecasting Model for Market Demand of Electric Vehicles. Applied Sciences. 2024; 14(23):10974. https://doi.org/10.3390/app142310974\n\nSimsek, Ahmed Ihsan, Erdinç Koç, Beste Desticioglu Tasdemir, Ahmet Aksöz, Muammer Turkoglu, and Abdulkadir Sengur. 2024. \"Deep Learning Forecasting Model for Market Demand of Electric Vehicles\" Applied Sciences 14, no. 23: 10974. https://doi.org/10.3390/app142310974\n\nSimsek, A. I., Koç, E., Desticioglu Tasdemir, B., Aksöz, A., Turkoglu, M., & Sengur, A. (2024). Deep Learning Forecasting Model for Market Demand of Electric Vehicles. Applied Sciences, 14(23), 10974. https://doi.org/10.3390/app142310974\n\nArticle Metrics\n\nCitations\n\nArticle Access Statistics\n\nFurther Information\n\nGuidelines\n\nMDPI Initiatives\n\nFollow MDPI\n\nSubscribe to receive issue release notifications and newsletters from MDPI journals\n",
            "Machine learning models employed in EV policy impact assessment": "Using machine learning methods to predict electric vehicles penetration ... : \nYour privacy, your choice\n\nWe use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media.\n\nBy accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection.\n\nSee our privacy policy for more information on the use of your personal data.\n\nManage preferences for further information and to change your choices.\n\nAdvertisement\n\nUsing machine learning methods to predict electric vehicles penetration in the automotive market\n\nScientific Reports\n 13, Article number: 8345 (2023) Cite this article\n\n16k Accesses\n\n1 Altmetric\n\nMetrics\n\nAbstract\n\nElectric vehicles (EVs) have been introduced as an alternative to gasoline and diesel cars to reduce greenhouse gas emissions, optimize fossil fuel use, and protect the environment. Predicting EV sales is momentous for stakeholders, including car manufacturers, policymakers, and fuel suppliers. The data used in the modeling process significantly affects the prediction model’s quality. This research’s primary dataset contains monthly sales and registrations of 357 new vehicles in the United States of America from 2014 to 2020. In addition to this data, several web crawlers were used to gather the required information. Vehicles sale were predicted using long short-term memory (LSTM) and Convolutional LSTM (ConvLSTM) models. To enhance LSTM performance, the hybrid model with a new structure called “Hybrid LSTM with two-dimensional Attention and Residual network” has been proposed. Also, all three models are built as Automated Machine Learning models to improve the modeling process. The proposed hybrid model performs better than the other models based on the same evaluation units, including Mean Absolute Percentage Error, Normalized Root Mean Square Error, R-square, slope, and intercept of fitted linear regressions. The proposed hybrid model has been able to predict the share of EVs with an acceptable Mean Absolute Error of 3.5%.\n\nSimilar content being viewed by others\n\nDeep learning model based prediction of vehicle CO2 emissions with eXplainable AI integration for sustainable environment\n\nDevelopment and evaluation of bidirectional LSTM freeway traffic forecasting models using simulation data\n\nBayesian optimization and deep learning for steering wheel angle prediction\n\nIntroduction\n\nEmissions of greenhouse gases are increasing rapidly worldwide. According to a United States Environmental Protection Agency report released in 2020, the transportation sector produces about 27% of the entire greenhouse gas emissions in the country, which, compared to other sectors, transportation emits the most greenhouse gases1. EVs were introduced as an alternative to gasoline and diesel cars to reduce air pollution and greenhouse gas emissions, optimize the use of natural energy resources and protect the environment. Using electricity generated from renewable energy sources such as wind, water and sunlight for EVs can be one of the most efficient solutions to reduce emissions and climate change2. Although much time has passed since the invention of EVs, internal combustion vehicles are still the most popular. EV sales have been on the rise, and in January 2017, the total number of EVs sold worldwide reached two million3. Globally, EV sales accounted for 9% of the car market in 2021, a fourfold increase from 20194.\n\nDesigning and producing vehicles is time-consuming and requires much investment, so by predicting the number of sales, automobile companies can optimize production, Furthermore, by accurately predicting the penetration of EVs in the market, it is possible to estimate their impact on reducing pollution in the coming years, which is very important from an environmental standpoint. Forecasting the sale of EVs and their penetration into the automotive market has been a significant issue for governments, policymakers, and car manufacturers to plan the production of EVs, set proper policies, and provide sufficient energy and infrastructure.\n\nThe main goal of this research is to apply Machine Learning (ML) methods to build an efficient prediction model to estimate the sale of all vehicles in the dataset, the share of EVs in each segment, and determine the main factors that influence the sales of each EV. The effect of a limited number of influencing factors on vehicle sales was examined in previous studies using different models. For this study, a wide range of information was collected, including all factors that previous studies have proven are related to car sales, and it was used in modeling. LSTM and ConvLSTM, powerful Deep Learning (DL) models, have been used for predicting vehicle sales. By combining the two-dimensional Attention model and the Residual network as the proposed hybrid model, it has been tried to improve the performance of the LSTM model. Additionally, using the collected information and the model sensitivity analysis, it was attempted to determine the most influential factors on the sale of each EV.\n\nThe literature review of this study includes two general sections. The first section examines ML methods used to predict vehicle sales, and the second section provides an overview of the features used in other methods to predict EV sales.\n\nML methods in predicting vehicle sales\n\nSeveral studies have used ML methods to predict the sales of EVs as time-series data. Multiple Linear Regression and Support Vector Machine (SVM) models were compared for predicting vehicle sales using yearly, quarterly and monthly data (the number of new automobile registrations, the number of automobile sales, and economic indicators such as Gross Domestic Product (GDP), Available Personal Income, Consumer Price Index, Interest Rate, Unemployment Rate, Industrial Investment Demand, Petroleum Charge, Private Consumption, and Latent Replacement Demand) in a study by Brühl et al.5 According to the results, the SVM model had better performance based on the error values (Mean Absolute Error and Mean Absolute Percentage Error), was more interpretable, and gave better results based on quarterly data. In the study of Wang et al. ML techniques were used to predict car sales based on sales quantity, economic indicators, wholesale population, unemployment rate, exchange rate, the prices of vehicles, the oil prices, and the prices of vehicle components. Based on evaluation units (R-square and Mean Squared Error), they evaluated the prediction quality of adaptive network-based fuzzy inference system (ANFIS), Artificial Neural Networks (ANN), and autoregressive integrated moving average models; the results showed that ANFIS performed better than the other models6. In another study, Hülsmann et al. compared the performance of linear models, such as Ordinary Least Squares and Quantile Regression, against ML methods like SVM, Decision Tree, k–Nearest Neighbor, and Random Forest for predicting vehicle sales. Based on the monthly data of vehicle sales, new car registrations, and economic indicators (such as GDP, Personal Income and Dow Jones), the Decision Tree of ML methods performed better than the other models based on Mean Absolute Percentage Error (MAPE)7.\n\nMoreover, Kitabci et al. analysed the impact of economic policies on vehicle sales in Turkey as a macro-environmental factor by multiple regression and neural network methods. They assessed factors such as the vehicle loan rate presented by the banks, the income of the consumers, the tax deductions made by the government for the automobile, the inflation rate, automobile prices, the euro exchange rate, oil prices, and advertisements spent by the businesses. According to the results, neural networks were more accurate in predicting sales than regression models; some factors, including the euro exchange rate, the rates of vehicle loans offered by banks, and the government's tax deductions, have influenced automobile sales8. In another research, Bas et al. applied classification ML methods to predict EV adoption using ride-sourcing factors, underlying sociodemographics, and vehicle characteristics; they examined the contributions of different factors to predict outcomes using a method called “Local Interpretable Model-Agnostic Explanations”. Based on the study’s findings, ML models produced highly accurate predictions regarding EV adoption, and the frequent usage of ride-sourcing, knowledge about EVs, and environmental protection awareness were significant factors in explaining the tendency to adopt EVs9. In addition, Zhang et al. applied Singular Spectrum Analysis as a univariate time-series model and the Vector Auto-Regression model (VAR) as a multivariate model for forecasting EV sales. According to the results, the VAR model can significantly improve the prediction accuracy because it considers the effect of economic indicators, such as consumer prices, consumer confidence, producers' prices, fuel and vehicle prices, and Baidu data (An indicator of consumer interest and curiosity in EVs)10.\n\nIn another study, Kaya et al.11 used the exchange rate, the GDP, the Consumer Confidence Index, the Consumer Price Index data and a Deep Neural Network model to predict vehicle sales; the results revealed that this ML model predicted sales accurately (based on Mean Squared Error). In another research, Xia et al. introduced the ForeXGBoost model, a vehicle sales prediction system based on large-scale datasets containing comprehensive vehicle information, including brand ID, model, engine power, and displacement. Based on Logarithmic Difference Square Root, MAPE, and running time, the XGBoost model outperforms benchmark algorithms like Linear Regression and Gradient Boosting Decision Trees12. Using online survey data and ML methods such as SVM, ANN, Deep Neural Networks, Gradient Boosting Models, and Random Forests, Bas et al. compared different methods for classifying potential EV buyers and identifying the features that affect the adoption of EVs. Results showed that the SVM model outperforms the other algorithms; having only partial information (e.g. only socioeconomic factors) reduces model performance, while synergy across multiple variables increases accuracy13. Additionally, Saxena et al. present a study that examines the use of deep learning-based models, including Autoregressive Integration Moving Averages and LSTM models, to predict future directions of vehicle sales. Based on the implementation results, the MAE and the Root Mean Square Error for LSTM-based time series forecasting were reduced, and this model could accurately predict green vehicle sales14.\n\nFactors affecting the sale of EVs in other methods\n\nDeveloping policies requires understanding users' behavior and prioritizing their choices. Therefore, some previous studies used survey data to predict EV demand. To assess the potential demand for EVs, Beggs et al.15 used survey data and vehicle specifications, such as seat capacity, maximum speed, purchase price, and operating costs. In a similar study, the demand for EVs was estimated based on consumer preferences for vehicle attributes by Calfee et al.16 The results of this research have shown that the weak performance of EVs limits their demand; however, if EVs become significantly more advanced than other cars or if gasoline becomes scarce, the demand for these vehicles will increase.\n\nPredicting the future demand for EVs is a complex issue. As most studies for new technologies rely on survey data, market share predictions will reflect the share in the survey data, not the actual market share. Consumer opinions and the news published about EVs also influence the sales of these vehicles. Based on Mau et al.17 research, EV sales are impacted by published information about the penetration rate of EVs, known as the “The neighbor effect”. Electric vehicles' specifications are another factor affecting their sales. According to Balducci et al.18 study to assess plug-in hybrid EV penetration scenarios in the auto market, fuel economy and reduced motor vehicle emissions are the most important factors when purchasing hybrid EVs, while insufficient engine power, high price, and unreliability are the most important reasons for not purchasing these vehicles. Furthermore, Hess et al. used vehicle specifications such as purchase price, vehicle purchase incentives, Miles Per Gallon (MPG) or equivalent, fuel cost per year, fuel availability, refueling time, driving range, maintenance cost per year, and acceleration to explore consumers' preferences in choosing the type of vehicle and the type of fuel. The results have shown that consumers' choices are adversely affected by factors such as purchase price, operating cost, and vehicle age, whereas their choices are positively affected by factors such as better vehicle acceleration, purchase incentives, driving range, and fuel availability19.\n\nThe sale of EVs is also affected by improving vehicle engine performance and reducing fuel consumption. Using a discrete choice model, Bas et al. investigated EV penetration in the face of new technology for reducing fuel consumption. Results demonstrated a clear tradeoff between the cost of a gasoline-powered system and the fuel savings it provides is perceived by potential purchasers20. However, potential EV purchasers are not in this category since their cost–benefit analysis is adverse due to the low cost of electricity20. Also, the estimated market shares give a significant share of the market to alternatives that include technology to reduce consumption, due to a more favorable attitude toward environmentally friendly technologies20. Additionally, Shafiei et al. analysed the impact of factors such as fuel prices, vehicle attributes, consumer preferences, and social influences on the market share of EVs. The results showed that the combination of high gasoline prices, decreasing EV prices, dropping tax on EVs and eliminating consumer concerns about recharging has the most significant effect on the market share of EVs21. Kinski et al.22 research shows that the information related to searching on the Internet (Google Trends) for vehicles has a positive and significant relationship with car sales.\n\nBased on the previous research, the following two general conclusions were reached:\n\nFirstly, ML and DL methods have been proven to be effective at predicting vehicle sales. Therefore, LSTM and ConvLSTM, powerful DL models, have been used for predicting vehicle sales in this research. Furthermore, a hybrid model was also proposed, and all three models were compared in terms of performance.\n\nSecondly, factors and features that affect EV sales have been identified, and these features have been collected and used in this research.\n\nMethodology\n\nArtificial Intelligence (AI) refers to the ability of machines to perceive, synthesize, and infer information, as opposed to animals and humans displaying intelligence23. Machine learning, artificial neural networks, and deep learning are important tools in the development of AI systems and have been shown to perform well in predicting time series data such as vehicle sales. Recurrent neural networks (RNNs) are a type of neural network that remember what they have already processed and can learn from previous iterations24. In other words, an RNN is a class of ANNs where connections between nodes form a directed graph along a temporal sequence; this allows it to exhibit temporal dynamic behavior24.\n\nLSTM\n\nHochreiter and Schmidhuber introduced the LSTM network, a RNN capable of learning long-term dependencies and predicting sequential data with great accuracy25. An LSTM is an extension of an RNN, capable of learning patterns from long sequences of source data by retaining a long-term memory25. LSTMs improved the forgetfulness of RNNs. An RNN could retain a memory, but only for its immediate past. An LSTM, on the other hand, introduces loops to generate long-term gradients. While going through its loops, it can discover long-term patterns25. LSTM is good at storing past information and performing well when faced with vanishing gradient issues. During ANN training, each weight of the neural network receives an update proportional to the partial derivative of the error function. Vanishing gradients occur when gradients become vanishingly small, effectively preventing the weight from changing26.\n\nLSTM can tie together three pieces of information at each time step: the current input data, the short-term memory it receives from the previous cell (the hidden state), and the long-term memory from cells farther away (the cell state)27. The LSTM unit consists of an input gate a forget gate, an output gate, and a cell state. The input gate determines how much information should be transferred from the current candidate cell state to the current cell state. The forget gate determines how much historical information should be ignored from the previous cell state. The output flow from cells to the rest of the network can be controlled through the output gate. By regulating the flow of information through the three gates, important information over time intervals can be remembered. According to Eqs. 1–6, the LSTM unit process data in cell state and gates27. Reference27 provides more details.\n\nIn the above equations, \\(f_{t}\\), \\(i_{t}\\), and \\(o_{t}\\) are the forget, input, and output gates, respectively; \\(C_{t}\\), \\(C_{t - 1}\\), and \\(\\tilde{C}_{t}\\) are the current, previous, and candidate cell state; \\(\\sigma\\) and tanh denotes sigmoid and hyperbolic tangent activation functions, respectively; the interconnected weight matrices for each gate and cell state are \\(W_{fh}\\), \\(W_{ih}\\), \\(W_{oh}\\), \\(W_{Ch}\\), respectively; \\(W_{fx}\\), \\(W_{ix}\\), \\(W_{ox}\\), \\(W_{Cx}\\) represent the input weight matrices in the three gates and the cell state, respectively; \\(b_{f}\\), \\(b_{i}\\), \\(b_{o}\\), \\(b_{C}\\) represent the respective bias terms; the Hadamard (element product) product of a matrix is denoted by \\(\\odot\\)27. According to Fig. 1, the input layer is an LSTM layer with the same number of neurons as the input data features. In the next step, one or more LSTM layers are set as the hidden layers, and in the final step, a Dense layer with the ReLU activation function is set as the output layer.\n\nArchitecture of the LSTM model.\n\nConvLSTM\n\nThe LSTM model is powerful for handling temporal correlation. In addition, when working with time series data with numerous features, LSTM model performance can be improved by converting the two-dimensional data to a three-dimensional tensor (Fig. 2 illustrates this), connecting states, and applying convolutional operations; this idea was the reason for creating the ConvLSTM model28. The ConvLSTM neural network is a fully connected LSTM network with a convolutional structure inside the LSTM cell, which does well in predicting data with temporal correlation. ConvLSTM provides a fully connected extension for data transfer between states and from inputs to states28. In other words, ConvLSTM determines the future state of each cell in the grid based on its inputs and neighbours' past states; this can be done by using a convolution operator in the state-to-state and input-to-state transitions28. In the ConvLSTM model, data in the input unit, the outputs of each cell, the hidden units, and the gates are arranged as three-dimensional tensors. ConvLSTM has similar parameters as LSTM, and the difference is in how data is transferred and convolutional multiplication is used in calculations, as expressed in Eqs. 7–1128. Reference28 provides more details.\n\nTransforming 2-D matrix into 3-D tensor.\n\nIn ConvLSTM equations, * indicates the convolution operator, and \\(\\odot\\) indicates the Hadamard product. As shown in Fig. 3, the input layer is a ConvLSTM layer, the hidden layers are Dense and ConvLSTM layers, and the output layer is a Dense layer with the ReLU activation function.\n\nArchitecture of the ConvLSTM model.\n\nHybrid LSTM with two-dimensional attention and residual network\n\nTime series data have a meaningful temporal relationship. In this research, the data were transformed into three-dimensional tensors with a seven-month time window to maintain the temporal relationship; how to transform a two-dimensional matrix to a three-dimensional tensor is shown in Fig. 2. As an innovation, the “Two-Dimensional Attention” method has been proposed in this research to determine the importance of each car's feature in a seven-month time frame and to use the weighted data in the modeling process. The two-dimensional attention method assigns weights to each feature in the time window based on how much it influences the model, allowing the features with a more significant impact to receive more attention and reduce the model's complexity. The one-dimensional attention model was proposed for the first time by Bahdanau to address the problem of the limited access of the decoder to the model's input information when the encoder vector has a fixed length in the translation machine29.\n\nIn the LSTM model architecture, which is shown in Fig. 1, several LSTM layers are placed inside the hidden layer. When the number of LSTM layers in the hidden layer increases, the primary layers (the layers adjacent to the input layer) have a lesser effect on the output. The primary layers have processed the input data and learned the relationship between the data well, which is why it has been tried to improve this problem by using the Residual network in the proposed hybrid model. Using the Residual Network, the weighted data and outputs of the primary layers have been transferred to the final layers in the proposed hybrid model, as shown in Fig. 4.\n\nPrimary architecture of the hybrid model.\n\nIn this study, each input \\(x\\) is represented by an \\(m \\times n\\) matrix, where m corresponds to the previous months in the window (7), and n represents the number of vehicle features. After entering the data into the first LSTM layer, the processing is done according to Eqs. 1–6, and the encoded hidden unit (\\(h\\)) with the exact dimensions (\\(m \\times n\\)) is entered into the Attention layer. After that, the alignment score is calculated according to Eq. (12).\n\nIn Eq. (12), \\(e_{i, j}\\) represents the alignment score, \\(W_{a}\\) is the attention model’s weight (as a trainable variable), \\(h\\) is the encoded hidden unit of the primary LSTM layer, \\(b_{a}\\) is the attention model's bias (as a trainable variable), and the sign \"*\" denotes the Hadamard product. Since the input data for the attention layer has been encoded by an LSTM layer using tanh nonlinear activation function, tanh has also been used in the attention layer to facilitate data reading during decoding. Each input data element was assigned a degree of attention using Eq. (13).\n\nMultiplying attention matrix \\(\\alpha_{i, j}\\) by raw data matrix \\(x_{i, j}\\) yields a weighted data matrix \\(W_{i, j}\\) based on Eq. (14). The sign “*” denotes the Hadamard product.\n\nWeighted data \\(W_{i, j}\\) is then passed through three layers of LSTM as a Residual Network; the output of each layer is combined with the weighted data at the end of the Residual Network and entered into one or more LSTM layers. A Dense layer with the ReLU activation function is the output layer. An overview of the model's architecture is illustrated in Fig. 4.\n\nOther architectures have also been tried in the hybrid model structure, but they were not more efficient, so only the best architecture has been mentioned.\n\nData\n\nIn this study, EVs are considered as vehicles that use electric motors for propulsion and include all types of EVs. In predicting the sale of vehicles, the number of vehicles in the warehouses is an influential factor, which was not used in this modeling due to a lack of access. Since ML models are based on training, in this study, the models can predict the sales of vehicles that have been on the market for at least 24 months. Emerging vehicles (vehicles that have been on the market for less than 24 months) and cars that have not yet entered the market were not included in the modeling due to insufficient data to train the model. Therefore, the share of EVs in the Automotive Market is expressed as a share in vehicle segments and not as a share of EVs overall.\n\nA wide range of information related to car sales has been used in this research. In the primary dataset, all the data is related to new cars, not used cars. The primary dataset contains monthly information about 357 vehicles, such as brand (or \"make\" in auto industry lingo, e.g., Benz), model, segmentation, category, shoppers, and sales of different types of cars in the United States from 2014 to 2020. Other information has been extracted based on the cars in this dataset. The data before the outbreak of Covid-19 disease were used since this disease had adverse impacts on the global economy.\n\nAs stated in previous studies, vehicle specifications are very effective in car sales prediction models. Vehicle specifications are changed annually. According to Alexa rating30 and the comprehensiveness of the information presented on the “Thecarconnection” website31, vehicle specifications were collected through this website. In order to save time and automate the collection of information due to a large number of vehicles and changes in specifications of vehicles over time, several web crawler have been designed and used in Python programming language to collect vehicle information. Several vehicle specifications of the \"CAR-MID/FULL SIZE\" segment are shown in Table 1.\n\nThere is similar information collected for gasoline and EVs; for example, the equivalent MPG in EVs. Price, MPG, max mileage, engine power, and warranty are some of the main features taken into account. Other specifications have been divided into the \"safety specifications\" and the \"other specifications\" categories. The safety specifications category includes child safety rear door locks, airbags, ABS brakes, daytime running lights, night vision, driver monitoring alerts, collision mitigation braking system, electronic stability control, and side impact beams. All other features (traction control, fog lamps, tire pressure monitoring, parking sensors, parking assist, and backup cameras) have been transferred to the other specifications category.\n\nThe second series of collected data refers to user opinions and news published on reputable websites ranked higher on Alexa30. Four websites were examined for this purpose: Autoblog32, Auto News33, Motor134, and The Car Connection35. These websites were crawled using Python web crawlers to save time and collect information automatically. From 2014 to 2020, the daily news published was collected and evaluated for each type of vehicle. The Valence Aware Dictionary and sEntiment Reasoner (VADER) method was used for sentiment analysis of the text. Based on vocabulary analysis, the VADER sentiment analysis method correctly analyzes the sentiment expressed in social media and news texts. Ten independent human raters analyzed over 90,000 ratings in the VADER evaluation, which led to the adoption of 7500 linguistic features that were rated based on their valence scores, which indicate the intensity and polarity of sentiment36. For each vehicle, the average monthly score of news and opinions has been calculated based on their daily publication of them.\n\nAnother effective source of information about the vehicle market is various economic indicators. Using a Python web crawler, information on several economic indicators affecting the car market has been collected on the Federal Reserve website37. Economic indicators include GDP, Consumer Price Index (CPI), Producer Price Index, Consumer Confidence Index, Personal Income Per Capita, Interest Rates on 48-month and 60-month Loans, SP&500, and Dow Jones stock market indicators.\n\nAccording to Kinski's research, using Google trends in prediction models is beneficial and practical22. Three keywords have been selected for Google trend data to evaluate the number of searches for each car from 2014 to 2020 and for the United States of America. The keywords are:\n\n\"Make\" + \"Model\"\n\n\"Price\" + \"Make\" + \"Model\"\n\n\"Dealer\" + \"Make\"\n\nAll cars have the same data collected, and the features collected on a monthly basis for each car are listed in Table 2. Several different trims were available on the market for some vehicles simultaneously, and some characteristics, such as price and MPG, had multiple values for these vehicles. Due to this, the collected values for these characteristics were divided into three categories: minimum, average, and maximum.\n\nThe sales feature has been normalized based on the maximum and minimum values from the training data set. Other features are standardized based on each feature's average and standard deviation in the training set. The input data to models are considered seven-month windows to maintain temporal correlation. For example, in the current month, the last seven months' data are input (X), and the current month's sale is output (Y). In order to achieve this, seven-month data matrices were placed consecutively in the third dimension of a three-dimensional tensor.\n\nValidation and interpretation of results\n\nSince the time series data in this study are monthly, eleven binary columns have been added to the dataset to reflect the effect of each month (in the first month of every year, the column corresponding to the first month is set to 1, and the column for the other months is set to 0). An example of this binary data is shown in Table 3.\n\nFor most vehicles, data includes 79 months (January 2014 through July 2020). According to Fig. 5, the last 14 months are selected for the testing set as rolling cross-validation. Using cross-validation on a rolling basis is one way to validate the time-series model. Starting with a subset of data for training, forecasting for later data points and then checking the accuracy of the forecasts. The same forecasted data points are included in the next training dataset, and further forecasts are made.\n\nSplitting dataset into training, validation, and testing sets.\n\nThe model is cross-validated using 12 forecasting stages, with each stage predicting sales in the next three months. During each prediction stage, the preceding months are divided into training and validation (70% for training and 30% for validation. Then these data are transferred to the model, the model predicts sales in the next three months, then the forecast date is moved forward by one month, and this process has been repeated 12 times. Vehicle sales in the next three months are predicted each time the model runs, assuming most of the vehicle's characteristics remain the same. Due to fluctuation and changes in economic conditions, a three-month time horizon is used for predicting the future.\n\nOverfitting is one of the principal problems in ANN training. The Dropout layers between the neural network layers are one of the best solutions in the ANN to avoid overfitting. During the dropout layer, the number of neurons trained in each layer and those discarded is determined randomly (rather than activating all neurons at once, only a fraction are activated)38. TensorFlow's early stopping tool is another basic solution to avoid overfitting. Early stopping works in the following way: during the repetition of training, the validation data is used to calculate the error value, and whenever the validation error value increases throughout several epochs, the model is ready to be stopped, and overfitting is prevented. For all three models, both solutions are used to prevent overfitting. Dimensionality reduction is another way to prevent model overfitting. In this study, Principal Component Analysis was used in several modes to reduce dimensions, but this technique was not used due to the significant decrease in model performance.\n\nIn order to improve the modeling process, all three models' hyperparameter values and network architectures were determined by Automated Machine Learning (AutoML). AutoML is the process of automating ML applications. The number of hidden layers, the number of neurons in these layers, and the dropout rate was determined by the Tuners. Several values are introduced to the Tuner for each hyperparameter. The Tuner trains different model versions and selects the best one based on the best result (lowest error or loss) on the validation data. This method sets the hyperparameters to the optimal value, and the model is then applied to a test dataset.\n\nThe model's error or loss is calculated using the Mean Absolute Error (MAE) loss function in all three models. Selecting a suitable optimization algorithm for the DL model is essential to reduce the run time and reach the desired result. Adam's optimization algorithm is used for these models, which is a generalized version of stochastic gradient descent. It reduces memory usage, converges faster, and corrects high variance and learning rates39.\n\nComparison of models\n\nWith the validation data, hyperparameters are adjusted, and the model is built to predict vehicle sales over the next three months (three months following the last validation date). The model run-time for all vehicles was very long due to the many vehicle types (357). In a random sample of 15 vehicles, different models' states were compared using fixed data, and the results were compared between the three models.\n\nThe sale of each vehicle is predicted in 12 stages; each prediction stage includes the prediction for the next three months, respectively, the first month of the prediction, the second month of the prediction, and the third month of the prediction. In total, the first predictions include 12 months, the second predictions include 12 months, and the third predictions include 12 months. Model performance was evaluated using the Mean Absolute Percentage Error (MAPE), the Root Mean Square Error normalized by the change range (\\(NRSME_{range}\\)), and the Root Mean Square Error normalized by the mean value (\\(NRSME_{mean}\\)) according to Eqs. 15–18.\n\nAccording to the above equations, \\(y_{t}\\) denotes the actual value at time t, \\(\\hat{y}_{t}\\) denotes the predicted value at time t, \\(y_{max}\\) denotes the maximum actual value, \\(y_{min}\\) denotes the minimum actual value, \\(y_{mean}\\) denotes the average actual value, and T is equal to the total number of predicted samples. The average error values of all vehicles were calculated to compare the results of various models. A weighted average was calculated using the total number of sales of each car per month as a weight for the vehicle according to Eq. (19) since the numbers of vehicle sales are not on the same scale, and the error rate is more important in vehicles with high sales. A further method of checking the models' performance is to compare the R-square, slope, and intercept of the linear regressions fitted on predicted and observed data for all three models. Table 4 summarizes the evaluation results of the models.\n\nIn the proposed hybrid model, the error values are lower, the R-square accuracy is higher, the slope value is closer to 1, and the intercept is closer to 0. At this stage, the proposed hybrid model was recognized as preferable to both the LSTM and ConvLSTM models.\n\nImplementation of the proposed hybrid model to predict the share of EVs\n\nFor all vehicles, the proposed hybrid model has been implemented, and 12 points of prediction have been used to determine the sale of all vehicles. Linear regression was fitted on the predicted sales and actual values to evaluate the model's performance, as shown in Table 5.\n\nPrimary data segments vehicles by specifications according to segments like CAR-SMALL_COMPACT, CAR-MID_FULL SIZE, MINIVAN LARGE, and PICKUP LARGE. Each segment consists of similar vehicles in appearance and specifications that compete with one another. Segments that include EVs have been separated to determine the share of EVs. Based on actual and predicted sales, the shares of electric and gasoline vehicles have been compared and evaluated for each month of the test data. For example, the CAR-MID/FULL-SIZE segment includes 28 vehicles (23 gasoline vehicles and five EVs). Figure 6 shows the share of EVs in this segment based on twelve prediction stages (three months per stage), separately for the first, second, and third months of each prediction.\n\n(a) Share of EVs in CAR-MID/FULL-SIZE based on the first month of each prediction. (b). Share of EVs in CAR-MID/FULL-SIZE based on the second month of each prediction. (c) Share of EVs in CAR-MID/FULL-SIZE based on the third month of each prediction.\n\nAll segments' MAEs for EVs' share forecasting in the forecast's first, second, and third months are shown in Table 6. The average MAE value of all segments was calculated as 3.2% for the first months, 3.8% for the second months, and 3.5% for the third months. The average value for all segments and all forecast months was calculated at about 3.5%, which shows that the proposed hybrid model performed well.\n\nAs part of the model analysis, the segments that included EVs were separated again and ranked by sales within each segment. The rankings were based on actual sales (actual rank) and predicted sales (predicted rank); the actual rank and predicted rank were used for evaluation. Kendall-Tau correlation (Kendall's correlation) is commonly used to check the concordance of two ranked lists; this technique was used to examine the actual and predicted rankings in this study. Kendall's correlation rate for two rating lists \\(r_{a}\\) and \\(r_{b}\\) (\\(\\tau_{{r_{a} , r_{b} }}\\)) is represented by Eq. (20) 40.\n\nIn Eq. (20), \\(n_{c}\\) represents the number of concordant pairs, \\(n_{d}\\) represents the number of discordant pairs, and n represents the total number of ranks in each of the rating lists40. The maximum number of discordant pairs between two ranking lists equals \\(\\frac{1}{2} n\\left( {n - 1} \\right)\\), and Kendall's correlation equals + 1 if all pairs of ranks are concordant and -1 if none are concordant 40. For all segments, Kendall's correlation values were calculated separately for the first, second, and third prediction months, and the average values are shown in Table 7. The average Kendall's correlation value of all segments was calculated as 0.76 for the first months, 0.742 for the second months, and 0.75 for the third months. The average Kendall's correlation value for all segments and all forecast months was calculated at about 0.75, which indicates the great performance of the proposed hybrid model in predicting the ranking.\n\nSensitivity analysis\n\nSensitivity analysis was performed to determine which features significantly impacted the trained model. Thus, for each vehicle, the pre-trained model that was evaluated in previous stages has once again predicted the number of vehicle sales with new input data, and its outputs have been assessed. All features, except the investigated feature, are valued at their average. For the investigated feature, the five values from the training data (the min value, the first quartile, the second quartile, the third quartile, and the max value) are taken into consideration. Five predictions were made based on these five values, and a range of changes in predicted sales was calculated. The change ranges for all features have been measured, and the four features with the most extensive range have been identified. As an example, during the sensitivity analysis of the BMW I3 for 2020, the following four features had the broadest range of changes: the Consumer Price Index (CPI), the equivalent MPG for EVs, the Google search score for car prices (Google Trends), and the car price. This EV's sensitivity analysis plots are shown in Fig. 7.\n\n(a) Sensitivity analysis plot of influential feature 1 for BMW I3. (b) Sensitivity analysis plot of influential feature 2 for BMW I3. (c) Sensitivity analysis plot of influential feature 3 for BMW I3. (d) Sensitivity analysis plot of influential feature 4 for BMW I3.\n\nBased on Eq. (21), slope values for the four characteristics with the most extensive range of changes are calculated in different parts of the graph, and the results are summarized in Table 8. For example, the number of sales of this EV has decreased by 8 for every thousand-dollar increase in price when the price is in the range of the minimum value to the first quarter. As the slope is zero percent in the second and third parts of the graph, the price in the first, second, and third quartiles is equal, and when the price is in the third quartile to the maximum price, the number of sales for this EV decrease by 6 for every thousand-dollar increase in price.\n\nThere has been a decrease in car sales due to the increase in the CPI. It is also true that with the increase in the CPI, the final price of the car and the price of auto parts have increased, which has led to a decrease in the desire to buy this car. The second feature is equivalent MPG for EVs, a higher equivalent MPG indicating better performance and less fuel consumption in a fixed distance has led to an increase in sales of this car. The third feature identified is the increase in the car price search score on Google (Google Trend), an indicator that buyers are more curious about this car, contributing to its sales. The fourth specified feature of the car is its price, and its sales have decreased with the increase in its price. As a result of the sensitivity analysis, the manufacturers of this car could use policies such as lowering the price of the car and its parts (CPI and car price), improving the performance of the vehicle's engine (the equivalent MPG), and developing advertisements and introducing the car to the public (Google trend score) to increase sales.\n\nSensitivity analysis has been conducted for each EV, and the results show different sensitivity for each vehicle. From each segment that includes EVs, one vehicle was selected as a sample, and the results of its sensitivity analysis are shown in Table 9.\n\nEach EV's sensitivity analysis identifies features that differ from the others, as shown in Table 9. According to the results of the sensitivity analysis, ten features that were most frequently found in the sensitivity analysis of all the EVs were identified as the most influential features: Shoppers, Min price, CPI, Sales, Google Trends score 3 (Price), Make & model news score, Personal income per capita, Make news score, Interest Rates on 60-month, and Mean options score, respectively.\n\nConclusion\n\nThis study addresses an important topic from a business perspective. Car manufacturers can benefit from this research by understanding their market share and the effect of pricing and vehicle specification on the market share. They can use the results of this study to analyze both their EV market as well as their Non-EV market. Lower down the funnel, car dealers that operate in a highly competitive environment can strategize their sales events, marketing campaigns, and discounts to meet their business goals and target sales. Finally, the model enables the public sector to understand the effect of tax policies on the share of EV vehicles in case they like to promote them.\n\nThis study used ML methods to develop a prediction model that estimated the sale of all cars in the dataset, the share of EVs in each segment and identified the main factors affecting each EV's sales. In this research, several web crawlers have been used to collect various data, including factors that previous studies have proven to be associated with EV sales. Vehicles sale were predicted using LSTM, ConvLSTM, and the proposed hybrid model (Hybrid LSTM with two-dimensional Attention and Residual network). Several ML tools have been used to improve the model's training and the modeling process, such as transforming two-dimensional time series data into three-dimensional tensors, Dropout layers, early stopping tools, and AutoML. Because of the variety of car types and the long running time of the models, a random selection of fifteen types of cars was made. All three models are evaluated based on the same evaluation units: the MAPE, NRSME_range, and NRSME_mean, R-square, slope, and intercept of fitted linear regressions have also been assessed. The average error values in the three months of prediction were as follows:\n\nThe MAPE value of the proposed hybrid model was 4.5% less than the LSTM model and 14.4% less than the ConvLSTM model.\n\nThe NRSME_range value of the hybrid model was 0.11 less than the LSTM model and 0.22 less than the ConvLSTM model.\n\nThe NRSME_mean value of the hybrid model was 0.079 less than the LSTM model and 0.169 less than the ConvLSTM model.\n\nAs a result of fitting linear regressions to the predicted and actual values, for all three months of predictions, the proposed hybrid model has a higher R-square value, its slope is closer to one, and its intercept is closer to zero, which indicates that the hybrid model performed better than the other two. In comparing the models, it was found that the proposed hybrid model conducted better than other models and was selected to predict the sale of all vehicles in the dataset. Based on the linear regression fitted to the predicted sales and the actual sales of all vehicles, the R-square values for the first, second and third prediction months were 0.912, 0.906, and 0.917.\n\nThe predicted sales of all vehicles were used to calculate the predicted share of EVs in each segment and compare them with the actual values. Across all segments and forecasting months, the average MAE value for EV share is about 3.5%, and the hybrid model has accurately predicted the share of EVs across all segments. To further analyze the model results, the cars were ranked according to the number of actual and predicted sales within each segment. The average Kendall's correlation value for all segments and all forecast months was calculated at about 0.75, which indicates the high performance of the proposed hybrid model in predicting the ranking.\n\nThe sensitivity analysis was performed to evaluate the model further and identify its most influential features. The results have shown that each EV's sensitivity analysis identifies features that differ from the others. According to the sensitivity analysis of the BMW I3 for 2020, the following four features were most affected: the Consumer Price Index, the equivalent MPG for EVs, the Google search score, and the car price. As a result of the sensitivity analysis, the manufacturers of this car could use policies such as lowering the price of the car and its parts, improving the engine's performance, developing advertisements, and better introducing the car to increase sales (See Appendix Tables A1 to A4.2, Fig. A1).\n\nThis research has achieved the following accomplishments:\n\nA wide variety of factors have been collected and used as variables to model the sale of EVs.\n\nLSTM and ConvLSTM, powerful DL models, have been used for predicting vehicle sales. By combining the two-dimensional Attention model and the Residual network, the performance of the LSTM model was enhanced, and the innovative hybrid model performed better than the other two.\n\nEVs differ in terms of the most influential factors for sales depending on the sensitivity analysis results. The ten features that appeared the most in the sensitivity analysis of all EVs were identified as the most influential, including Shoppers, Min price, CPI, Sales, Google Trends score 3 (Price), News score for make and model, Personal income per capita, News score for make, Interest Rates on 60-month, and Mean options score, respectively.\n\nData availability\n\nThe primary dataset was taken from Autometrics, and other data were collected using web crawlers. The data is available from the corresponding author on reasonable request.\n\nReferences\n\nhttps://www.epa.gov/ghgemissions/inventory-us-greenhouse-gas-emissions-and-sinks (2020).\n\nMacInnis, B. & Krosnick, J. Climate Insights 2020: Electric Vehicles. (2020).\n\nhttps://theicct.org/the-rise-of-electric-vehicles-the-second-million/ (2020).\n\nhttps://www.iea.org/fuels-and-technologies/electric-vehicles (2022).\n\nBrühl, B., Hülsmann, M., Borscheid, D., Friedrich, C. M. & Reith, D. in Industrial Conference on Data Mining. 146–160 (Springer).\n\nWang, F.-K., Chang, K.-K. & Tzeng, C.-W. Using adaptive network-based fuzzy inference system to forecast automobile sales. Expert Syst. Appl. 38, 10587–10593 (2011).\n\nArticle\n  Google Scholar\n\nHülsmann, M., Borscheid, D., Friedrich, C. M. & Reith, D. General sales forecast models for automobile markets and their analysis. Trans. Mach. Learn. Data Min. 5, 65–86 (2012).\n\nGoogle Scholar\n\nKitapcı, O., Özekicioğlu, H., Kaynar, O. & Taştan, S. The effect of economic policies applied in Turkey to the sale of automobiles: Multiple regression and neural network analysis. Procedia Soc. Behav. Sci. 148, 653–661 (2014).\n\nArticle\n  Google Scholar\n\nBas, J., Zou, Z. & Cirillo, C. An interpretable machine learning approach to understanding the impacts of attitudinal and ridesourcing factors on electric vehicle adoption. Transp. Lett. 15, 30–41 (2023).\n\nArticle\n  Google Scholar\n\nZhang, Y., Zhong, M., Geng, N. & Jiang, Y. Forecasting electric vehicles sales with univariate and multivariate time series models: The case of China. PLoS ONE 12, e0176729 (2017).\n\nArticle\n  PubMed\n  PubMed Central\n  Google Scholar\n\nKaya, S. K. & Yildirim, Ö. A prediction model for automobile sales in turkey using deep neural networks. Endüstri Mühendisliği 31, 57–74 (2020).\n\nGoogle Scholar\n\nXia, Z. et al. ForeXGBoost: Passenger car sales prediction based on XGBoost. Distrib. Parallel Databases 38, 713–738 (2020).\n\nArticle\n  Google Scholar\n\nBas, J., Cirillo, C. & Cherchi, E. Classification of potential electric vehicle purchasers: A machine learning approach. Technol. Forecast. Soc. Chang. 168, 120759 (2021).\n\nArticle\n  Google Scholar\n\nSaxena, P., Bahad, P. & Kamal, R. Long short-term memory-RNN based model for multivariate car sales forecasting. Int. J. Adv. Sci. Technol. 29, 4645–4656 (2020).\n\nGoogle Scholar\n\nBeggs, S., Cardell, S. & Hausman, J. Assessing the potential demand for electric cars. J. Econom. 17, 1–19 (1981).\n\nArticle\n  Google Scholar\n\nCalfee, J. E. Estimating the demand for electric automobiles using fully disaggregated probabilistic choice analysis. Transp. Res. Part B Methodol. 19, 287–301 (1985).\n\nArticle\n  Google Scholar\n\nMau, P., Eyzaguirre, J., Jaccard, M., Collins-Dodd, C. & Tiedemann, K. The ‘neighbor effect’: Simulating dynamics in consumer preferences for new vehicle technologies. Ecol. Econ. 68, 504–516 (2008).\n\nArticle\n  Google Scholar\n\nBalducci, P. J. Plug-In Hybrid Electric Vehicle Penetration Scenarios. (Pacific Northwest National Lab. (PNNL), Richland, WA (United States) (2008).\n\nHess, S., Fowler, M., Adler, T. & Bahreinian, A. A joint model for vehicle type and fuel type choice: Evidence from a cross-nested logit study. Transportation 39, 593–625 (2012).\n\nArticle\n  Google Scholar\n\nBas, J., Zofío, J. L., Cirillo, C., Chen, H. & Rakha, H. A. Policy and industry implications of the potential market penetration of electric vehicles with eco-cooperative adaptive cruise control. Transp. Res. Part A Policy Pract. 164, 242–256 (2022).\n\nArticle\n  Google Scholar\n\nShafiei, E. et al. An agent-based modeling approach to predict the evolution of market share of electric vehicles: A case study from Iceland. Technol. Forecast. Soc. Chang. 79, 1638–1653 (2012).\n\nArticle\n  Google Scholar\n\nKinski, A. Google trends as complementary tool for new car sales forecasting: A cross-country comparison along the customer journey, University of Twente, (2016).\n\nhttps://en.wikipedia.org/wiki/Artificial_intelligence (2023).\n\nhttps://en.wikipedia.org/wiki/Recurrent_neural_network (2023).\n\nHochreiter, S. & Schmidhuber, J. Long short-term memory. Neural Comput. 9, 1735–1780 (1997).\n\nArticle\n  CAS\n  PubMed\n  Google Scholar\n\nBasodi, S., Ji, C., Zhang, H. & Pan, Y. Gradient amplification: An efficient way to train deep neural networks. Big Data Min. Anal. 3, 196–207 (2020).\n\nArticle\n  Google Scholar\n\nWei, X., Zhang, L., Yang, H.-Q., Zhang, L. & Yao, Y.-P. Machine learning for pore-water pressure time-series prediction: Application of recurrent neural networks. Geosci. Front. 12, 453–467 (2021).\n\nArticle\n  ADS\n  Google Scholar\n\nShi, X. et al. Convolutional LSTM network: A machine learning approach for precipitation nowcasting. Advances in neural information processing systems 28 (2015).\n\nBahdanau, D., Cho, K. & Bengio, Y. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473 (2014).\n\nhttps://www.alexa.com/ (2021).\n\nhttps://www.thecarconnection.com/ (2021).\n\nhttps://www.autoblog.com/news/ (2021).\n\nhttps://www.autonews.com/news (2021).\n\nhttps://www.motor1.com/news/ (2021).\n\nhttps://www.thecarconnection.com/news (2021).\n\nHutto, C. & Gilbert, E. in Proceedings of the international AAAI conference on web and social media. 216–225.\n\nhttps://fred.stlouisfed.org/ (2021).\n\nBaldi, P. & Sadowski, P. J. Understanding dropout. Advances in neural information processing systems 26 (2013).\n\nKingma, D. P. & Ba, J. Adam. A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).\n\nBachrach, Y., Herbrich, R. & Porat, E. in International Symposium on String Processing and Information Retrieval. 344–352 (Springer).\n\nDownload references\n\nFunding\n\nThe authors received no financial support for the research, authorship, and/or publication of this article.\n\nAuthor information\n\nAuthors and Affiliations\n\nDepartment of Transportation, School of Civil Engineering, Iran University of Science and Technology, Tehran, Iran\n\nShahriar Afandizadeh & Diyako Sharifi\n\nAECOM, Glen Allen, VA, USA\n\nNavid Kalantari\n\nDepartment of Civil-Transportation Planning, Faculty of Technical and Engineering, Imam Khomeini International University, Qazvin, Iran\n\nHamid Mirzahossein\n\nContributions\n\nThe authors confirm contribution to the paper as follows: study conception and design: S.A., D.S., N.K., H.M.; data collection: N.K., D.S.; analysis and interpretation of results: S.A., D.S., N.K.; manuscript preparation: D.S., H.M. All authors reviewed the results and approved the final version of the manuscript. Authors consent for the publication of the submitted paper and any associated data and accompanying images\n\nCorresponding author\n\nCorrespondence to Shahriar Afandizadeh.\n\nEthics declarations\n\nCompeting interests\n\nThe authors declare no competing interests.\n\nAdditional information\n\nPublisher's note\n\nSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\n\nSupplementary Information\n\nSupplementary Information.\n\nRights and permissions\n\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.\n\nReprints and permissions\n\nAbout this article\n\nCite this article\n\nAfandizadeh, S., Sharifi, D., Kalantari, N. et al. Using machine learning methods to predict electric vehicles penetration in the automotive market. Sci Rep 13, 8345 (2023). https://doi.org/10.1038/s41598-023-35366-3\n\nDownload citation\n\nReceived\n13 November 2022\n\nAccepted\n17 May 2023\n\nPublished\n23 May 2023\n\nDOI\nhttps://doi.org/10.1038/s41598-023-35366-3\n\nShare this article\n\nAnyone you share the following link with will be able to read this content:\n\nProvided by the Springer Nature SharedIt content-sharing initiative\n\nSubjects\n\nScientific Reports (Sci Rep)\n\nISSN 2045-2322 (online)\n\nAbout Nature Portfolio\n\nDiscover content\n\nPublishing policies\n\nAuthor & Researcher services\n\nLibraries & institutions\n\nAdvertising & partnerships\n\nProfessional development\n\nRegional websites\n\n© 2025 Springer Nature Limited\n\nA multi-model approach for predicting electric vehicle ... - Springer : \nYour privacy, your choice\n\nWe use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media.\n\nBy accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection.\n\nSee our privacy policy for more information on the use of your personal data.\n\nManage preferences for further information and to change your choices.\n\nA multi-model approach for predicting electric vehicle specifications and energy consumption using machine learning\n\nAccess provided by American University of Beirut\n\n217 Accesses\n\nExplore all metrics\n\nAbstract\n\nThe increasing reliance on electric vehicles (EVs) necessitates advanced predictive models to enhance performance and sustainability, especially against climate change driven by fossil fuel combustion. This study advances the field using cutting-edge machine learning techniques to model and predict various EV characteristics and performance metrics. Using a comprehensive dataset with parameters such as model year, make, model type, vehicle class, motor power, and energy consumption metrics, we tested classification and regression models to forecast categorical features (vehicle make, category) and continuous features (energy consumption, range, charge time, motor power). The models were assessed using key performance indicators like accuracy, recall, F1 score, precision, MAE, RMSE, and R2. The random forest and Naive Bayes classifiers excelled in classification tasks, achieving accuracies of 95.58% and 100%, respectively. The Linear Regression model showed superior performance in predicting energy consumption in city driving conditions, with an R2 value of 0.9982. The K neighbors regressor was most effective in predicting range and motor power, with R2 values of 0.9800 and 0.9300, and the Huber regressor was most effective in predicting charge time. The study demonstrates the analytical models’ proficiency in projecting vehicular attributes and performance metrics by dividing the data into 70% for training and 30% for validation. The research provides crucial insights for policymakers, highlighting the potential of increased EV adoption to significantly decrease greenhouse gas emissions from the transportation sector, aiding in climate change mitigation.\n\nSimilar content being viewed by others\n\nPredictive Energy Management for Battery Electric Vehicles with Hybrid Models\n\nComparing the Performance of Classification Algorithms for Predicting Electric Vehicle Adoption\n\nPerformance analysis of machine learning algorithms for estimation of EV penetration\n\nExplore related subjects\n\nAvoid common mistakes on your manuscript.\n\n1 Introduction\n\nThe rise in greenhouse gas (GHG) emissions has heightened concerns about global warming. Various sectors contribute to these emissions, including transportation, energy, waste management, agriculture, forestry, and buildings [1,2,3,4,5,6,7]. The International Energy Agency identifies transportation as the second-largest GHG emitter, primarily emitting CO2, N2O, and CH4 [8, 9]. Transportation activities are responsible for 75% of global CO2 emissions [10], making emission reduction in this sector crucial for combating climate change [11]. Evaluating urban highways’ exposure to pollutants is essential for achieving social, environmental, and economic objectives, particularly in developing nations [12]. The significance of climate change is underscored by the declaration of a climate emergency by thirty-three countries as of January 2021 [13]. The transportation sector is a significant contributor to global energy consumption, accounting for over a quarter of the total [14]. Two-thirds of the world’s population is expected to reside in cities by 2050, according to UN estimates [15], which will increase demand for urban mobility as well as energy use and greenhouse gas emissions. Electric vehicles (EVs) offer a promising solution, potentially reducing carbon emissions by 45% compared to internal combustion engine (ICE) vehicles [16]. Advances in reliability and battery range have boosted EV popularity and trust, with owner satisfaction on the rise [17, 18]. The proliferation of charging stations, driven by government initiatives, has further facilitated EV adoption, positioning them as a leading clean transportation option.\n\nThe growing use of electric vehicles requires exact forecasts of performance measures like energy consumption, charging time and driving range. These predictions can enhance the management of the electric grid and provide users with accurate data about their vehicle’s capabilities. Numerous studies have explored the development of models using machine learning techniques to enhance the reliability and accuracy of predicting these metrics. Using Gaussian mixture models, Lee et al. predicted the energy and duration requirements of over 30,000 non-residential EV charging sessions. They utilized historical charging data for testing and reported symmetric mean absolute percentage error (SMAPE) of 15.9% for energy consumption and 14.4% for session duration. To predict the departure and arrival times of electric vehicle (EV) users on a university campus, the authors in [19] utilized support vector machines (SVM). They achieved mean absolute percentage errors (MAPE) of 3.7% for the departure times and 2.9% for the arrival times. However, hyperparameter tuning for SVM was not addressed, and a simple persistence model was utilized for comparison. Frendo et al. [20] predicted EV departure times using regression models. Eight features were taken into account, including the vehicle ID, car model, charging point, weekday, parking floor, arrival time, and location. Artificial neural network, extreme gradient boosting, and linear regression were trained for prediction purpose. Extreme gradient boosting demonstrated the highest performance, with a mean absolute error (MAE) of 82 min. The prediction of session length and energy consumption was achieved through the use of an ensemble machine learning approach that integrated random forest, SVM, and kernel density estimator (KDE).This model, trained on historical charging records from both public and residential datasets, outperformed individual models with SMAPEs of 7.5% for consumption and 10.4% for duration [21].\n\nXiong et al. [22] estimated session start times and durations using mean values and subsequently applied linear regression to predict energy consumption. These predications were incorporated to stabilize the power system, and regulate the charging load albeit performance indicators were not statistically analyzed. In [23], regression models were applied to forecast energy demands at public charging stations across Nebraska, incorporating variables such as season, day of the week, type of location, and applicable fees. Extreme gradient boosting achieving an R2 score of 0.52, outperformed other models and attained a MAE of 4.6 kWh. The authors in [24] used the k-nearest neighbor (k-NN) algorithm to predict energy consumption at a university charging station. The study framed the problem as a time series, with the best results achieved by employing a K value of 1 (1-NN) and utilizing a time-weighted dissimilarity measure based on the dot product, yielding a SMAPE of 15.3%. Majidpour et al. [25] used algorithms like SVM and RF to forecast the energy requirements for the following day at charging stations. They also investigated pattern sequence-based forecasting (PSF) [26], which involves clustering days into categories before making predictions. The PSF method demonstrated the highest accuracy, achieving an average SMAPE of 14.1\n\nElectric vehicle (EV) range prediction has been examined using two main approaches: physical models, which utilize real-time data, and artificial intelligence models trained on historical data. Physical models can be subdivided into those that estimate energy consumption by either modeling the battery pack (or powertrain) or the vehicle itself. Battery pack models, for example, involve techniques that use the apparent state of discharge of Li-ion cells, adjusted for the effects of current and temperature. [27], and those updating a battery dynamics model using online battery identification parameters [28]. Battery-in-loop simulations have demonstrated effectiveness in assessing energy consumption under cold temperature conditions [29]. Simplified powertrain models have been created by utilizing drive cycle data tailored to specific scenarios, such as coast-down [30]. Battery pack models are particularly effective at incorporating energy use by auxiliary vehicle loads and considering the effects of ambient temperature [31]. Vehicle models, on the other hand, employ physical parameters like road inclination, velocity and vehicle mass [32, 33], providing statistical insights into a battery electric vehicle’s (BEV) instantaneous energy consumption. To forecast future energy consumption, additional road information has been utilized to compare results between higher driving speeds and the most fuel-efficient speeds [34]. While, the accuracy of these methods is contingent on having future route or drive cycle data, they cannot estimate energy consumption for the remaining portion of a trip without this information.\n\nDriving style has been identified as the most influential factor in the variable range of BEVs [35]. Consequently, historical vehicle data is required to estimate the remaining driving range accurately. Range prediction is a complex problem influenced by internal, external, constant, and variable parameters [36, 37]. Big-data models have been employed to forecast range using numerous data sources [38]. Most works leveraging artificial intelligence models combine historical vehicle data with GIS-based information [39] and other external factors like road conditions and traffic [40]. Data-driven approaches to estimating BEV range include predictive strategies based on optimal path search algorithms [41], solving multi-objective optimization problems to recommend vehicle speeds [42], and machine learning models that analyze trip data [43, 44]. Some methods incorporate additional attributes like tire-pressure monitoring with a physical energy consumption model for range estimation [45]. Recent studies have employed advanced machine learning techniques such as light gradient boosting and extreme gradient boosting, using features like motor, battery temperature, battery energy, and driving patterns to determine BEV range [46]. Additionally, least squares support vector machine models have been combined with particle swarm optimization, trained on features such as temperature and depth of discharge, to achieve stable and reliable range predictions [47].\n\nThe increasing use of electric vehicles (EVs) necessitates precise forecasting of performance metrics to improve user experience and aid infrastructure planning. This research introduces a multimodel prediction framework that predicts electric vehicle specifications accurately, considering factors like make, category, energy consumption, motor power, travel range, and charging time. The framework employs machine learning algorithms to provide precise predictions, enabling efficient management of the electric grid, infrastructure development, and promoting the widespread adoption of electric vehicles. This research significantly contributes to the prediction of electric vehicle (EV) performance by utilizing various classification and regression models. This study uses machine learning techniques to predict key EV characteristics using data on vehicle make, category, energy consumption, motor power, travel range, and charging time. The main contributions of this research include:\n\nThe study employs various regression and classification techniques to accurately predict electric vehicle specifications, including make, category, energy consumption, motor power, travel range, and charging time.\n\nThe study aims to verify the reliability of classification techniques in accurately predicting the make and category of a vehicle.\n\nThe study employs regression models that accurately predict energy consumption, motor power, travel range, and charging time with low error metrics.\n\nThe study aims to assess the effectiveness of each regression or classification model through various metrics like accuracy, precision, recall, F1 score, MAE, root mean square error (RMSE), and R-squared (R2).\n\nThe study aims to provide valuable insights to aid policymakers and stakeholders in devising effective strategies for the adoption and infrastructure planning of electric vehicles.\n\nThis research aligns with the United Nations Sustainable Development Goals, specifically supporting Goal 13, “climate action,” and indirectly aiding in achieving other related objectives.\n\nThe study emphasizes the significance of utilizing classification and regression methods to comprehend and predict electric vehicle specifications, thereby promoting the adoption of eco-friendly transportation methods.\n\n2 Materials and methods\n\nThe quality and comprehensiveness of the dataset are crucial for efficient work and accurate predictions of electric vehicle characteristics using machine learning models. This research utilized a dataset containing parameters related to EV performance, including model year, make, vehicle class, energy consumption, motor power, travel range, and charging time. The dataset, compiled from recent sources, accurately predicts categorical and continuous EV characteristics, providing a detailed snapshot of the EV market and capturing a wide range of vehicle specifications and performance metrics. The study’s features are shown in Table 1, while Tables 2 and 3 provide an overview and statistical summary of the dataset. The dataset is crucial for creating robust machine learning models to predict energy efficiency, driving range, and charging time, thereby advancing EV technology and infrastructure planning.\n\n2.1 Dataset\n\nThe dataset displays official records of various vehicular features, including comprehensive information about the specifications of electric vehicles such as model year, make, model, vehicle class, motor power (kW), and energy consumption metrics in different driving conditions (city, highway, combined). It provides an overview of the energy efficiency and performance of electric vehicles in terms of kWh per 100 km and liters equivalent (Le) per 100 km as shown in Table 1. The data appears to have been properly compiled according to the most recent and applicable information. The dataset includes features such as motor power (kW), energy consumption metrics (City, Highway, Combined) in kWh/100 km and Le per 100 km, with data types ranging from int64 for integral values to float64 for floating-point numbers. The table also introduces vehicle range (km) and recharge time (h), providing a more comprehensive understanding of each electric vehicle’s performance and efficiency.\n\nCurrently, the time span for the displayed vehicles is between 2012 and 2024. The dataset has 13 columns and 6720 rows. It presents a vast array of information about automotive specifications and energy consumption for electric vehicles. The dataset offers a detailed snapshot of the automotive sector’s environmental impact and performance, encompassing 6720 records from 33 distinct manufacturers and 373 unique models. This collection showcases the variety of the electric vehicle market, highlighting Tesla as the predominant manufacturer with 158 entries, and the Bolt EV as the most frequently listed model, appearing 7 times. The dataset reflects the current shift towards more efficient vehicles, with the ‘Sport utility vehicle: Standard’ category leading in representation with 140 instances. It includes comprehensive details on each vehicle’s make and model, class, motor power, and energy consumption in different driving conditions. These insights are concisely shown in Table 2.\n\nEnergy consumption and range are pivotal in assessing the performance and environmental impact of electric vehicle models. The dataset provides detailed insights, with average energy consumption for city, highway, and combined conditions noted at 21.57, 23.66, and 22.52 kWh per 100 kms respectively. The mean Le for city, highway, and combined conditions are 2.43, 2.66, and 2.53  respectively. The dataset covers a wide range of vehicle models with motor power ranging from 35 to 930 kW and driving ranges from 92 to 837 km. The average recharge time is approximately 10.16 h. Therefore, it captures the diversity of the electric vehicle market. A comprehensive Table 3 provides the statistical summary of the vehicle data in the dataset, and it encompasses such important features as model year, motor power, energy consumption, equivalent fuel consumption, range, and recharge time. Such characteristics are critical for the development of machine learning models to predict energy efficiency and driving range, which would be used to develop more efficient and user-friendly electric vehicle technologies.\n\nHeatmap of correlation coefficients highlighting relationships between electric vehicle attributes and energy consumption\n\nThe heatmap shown in Fig. 1 showcases the interdependencies among various vehicular attributes. Notably, there is a pronounced positive correlation (correlation coefficient \\(\\ge 0.9\\)) between city energy consumption (city_kwh), highway energy consumption (Highway_kwh), and combined energy consumption (Comb_kwh). This indicates that vehicles consuming more energy in urban settings tend to have higher consumption on highways and overall. Additionally, the range of the vehicle shows a strong positive correlation with motor power (\\(\\textit{r} = 0.67\\)) and recharge time (\\(\\textit{r} = 0.7\\)), suggesting that more powerful motors and longer recharge times are associated with extended driving ranges. Conversely, the correlation between highway energy consumption and vehicle range (\\(\\textit{r} = 0.05\\)) is relatively weak. These insights highlight the relationships between energy consumption metrics and other vehicle attributes, which are critical for understanding the performance and efficiency of electric vehicles.\n\nComparative analysis of range and charge time by vehicle make, class, and model\n\nFigure 2 provides a comprehensive overview of range and charge time across various categories within the electric vehicle landscape. Delving into range by make, while brands like Lucid and Rivian show impressive ranges, it’s Lucid that emerges as the top performer, underscoring the advancements in battery technology and efficiency. In the realm of vehicle classes, the Pickup truck: Standard category takes the lead in range, highlighting the potential for long-distance travel in larger vehicles. Regarding models, the Air Grand Touring AWD (21” Wheels) model stands out with the highest range, reflecting the impact of specific design and engineering choices on vehicle performance. On the other side, charge time analysis reveals that makes like Fisker and Rivian require longer charging times, with Fisker leading in this aspect. In terms of vehicle classes, the Pickup truck: Standard category again leads with the longest charge times, aligning with the larger battery capacities required. Among models, the Ocean Ultra shows the longest charge time, indicative of its extensive battery system. These insights highlight the varying performance and efficiency characteristics of electric vehicles across different makes, classes, and models, providing a detailed understanding of the current electric vehicle market.\n\nThe vehicles in the dataset are categorized into Luxury, Premium, Sports, and General categories, as shown in Table 4, reflecting the market structure and consumer perceptions. This segmentation plays a crucial role in analytical processes such as generating box plots to visually display data distribution, highlighting central tendencies and variations within each group. By comparing these graphs, one can identify patterns and outliers essential for assessing and comparing CO2 emissions levels across these different categories. The plot in Fig. 3 illustrates the range for Luxury, Premium, Sports, and General vehicles. The range is measured on the vertical axis ranging from 0 to 800. Each category’s details are presented through boxes indicating the interquartile range and whiskers representing the full range of values. Noticeably, outliers can be seen in the Premium and Sports segments. This visualization effectively contrasts the distributions by accentuating both the variability and central tendencies within the range data. It indicates that Luxury cars demonstrate a higher range with a broader interquartile range, while general vehicles exhibit a lower range with a narrower interquartile range. In contrast, General cars have the lowest range with a narrower interquartile range. The ranges for Premium and Sports cars fall in between, with Premium cars tending towards a higher range than Sports ones.\n\nBoxplot of range by vehicle make type\n\nBoxplot of charge time by vehicle make type\n\nThe plot in Fig. 4 illustrates the charge time for Luxury, Premium, Sports, and General vehicles. The charge time is measured on the vertical axis ranging from 4 to 18 h. Each category’s details are presented through boxes indicating the interquartile range and whiskers representing the full range of values. Noticeably, outliers can be seen in the General and Sports segments. This visualization effectively contrasts the distributions by accentuating both the variability and central tendencies within the charge time data. It indicates that Premium cars demonstrate a higher charge time with a broader interquartile range, while general vehicles exhibit a lower charge time with a narrower interquartile range. The charge times for Luxury and Sports cars fall in between, with Premium cars tending towards a higher charge time than Sports ones. The plot in Fig. 5 illustrates the motor power for Luxury, Premium, Sports, and General vehicles. The motor power is measured on the vertical axis ranging from 0 to 800 kW. Each category’s details are presented through boxes indicating the interquartile range and whiskers representing the full range of values. Noticeably, outliers can be seen in the General and Sports segments. This visualization effectively contrasts the distributions by accentuating both the variability and central tendencies within the motor power data. It indicates that Luxury cars demonstrate higher motor power with a broader interquartile range, while General vehicles exhibit lower motor power with a narrower interquartile range. The motor power for Premium and Sports cars falls in between, with Premium cars tending towards higher motor power than Sports ones.\n\nBoxplot of motor power by vehicle make type\n\nThe Table 5 organizes different vehicle types into four main categories: Sedan, SUV, Hatchback, and Truck. This categorization simplifies the classification system, facilitating easier analysis and comparison of vehicles based on their features. The ’Sedan’ category encompasses a range of passenger cars from midsize to full-size, including two-seaters. ’SUV’ includes both small and standard sport utility vehicles, reflecting their shared design and utility features. The ’Hatchback’ class captures the smaller, more compact vehicles, while the ’Truck’ category groups together larger utility vehicles designed for passenger and cargo transport, including station wagons and standard pickup trucks.\n\nThe box plot in Fig. 6 illustrates the range for Hatchback, Sedan, SUV, and Truck vehicle categories. The range is measured on the vertical axis ranging from 0 to 800 kms. Each category’s details are presented through boxes indicating the interquartile range and whiskers representing the full range of values. Noticeably, outliers can be seen in the Sedan and Truck segments. This visualization effectively contrasts the distributions by accentuating both the variability and central tendencies within the range data. It indicates that Sedans demonstrate a broader range with several high outliers, while Hatchbacks exhibit a more consistent range with a narrower interquartile range. SUVs fall in between, with a moderate interquartile range and fewer outliers. Trucks show a significant range in their values, including some high outliers. This visual representation underscores the diversity in vehicle ranges within different categories.\n\nBoxplot of range by vehicle categories\n\nThe box plot in Fig. 7 illustrates the charge time for Hatchback, Sedan, SUV, and Truck vehicle categories. The charge time is measured on the vertical axis ranging from 4 to 18 h. Each category’s details are presented through boxes indicating the interquartile range and whiskers representing the full range of values. The variability in charge time is largely due to differences in battery sizes and charging technology among vehicle categories. For instance, larger vehicles or those with higher battery capacities typically require longer charging times, while some advanced models offer fast-charging capabilities, leading to shorter times. Noticeably, outliers can be seen in the Truck segment. This visualization effectively contrasts the distributions by accentuating both the variability and central tendencies within the charge time data. It indicates that SUVs and Sedans demonstrate a higher charge time with broader interquartile ranges, while Hatchbacks exhibit a lower charge time with a narrower interquartile range. Trucks show a significant range in their values, including some high outliers. This visual representation underscores the diversity in charge times within different vehicle categories.\n\nBoxplot of charge time by vehicle categories\n\nThe box plot in Fig. 8 illustrates the motor power for Hatchback, Sedan, SUV, and Truck vehicle categories. The motor power is measured on the vertical axis ranging from 0 to 800 kW. Each category’s details are presented through boxes indicating the interquartile range and whiskers representing the full range of values. Noticeably, outliers can be seen in the Sedan and SUV segments. This visualization effectively contrasts the distributions by accentuating both the variability and central tendencies within the motor power data. It indicates that Sedans demonstrate a higher motor power with several high outliers, while Hatchbacks exhibit a more consistent motor power with a narrower interquartile range. SUVs and Trucks fall in between, with SUVs having a broader range and Trucks showing a significant range in their values, including some high outliers. This visual representation underscores the diversity in motor power within different vehicle categories.\n\nBoxplot of motor power by vehicle categories\n\nFigure 9 shows the statistics of Range and Charge Time for all the vehicles. The mean range value is approximately 425.54, which indicates the average distance a vehicle can travel on a single charge. The median range value is 427.0, suggesting that half of the vehicles have a range below this value and half above. The most common range value in the dataset is 383, indicating it appears most frequently. The close proximity of the mean and median values suggests a relatively symmetric distribution of data around the central value. The mean charge time value is approximately 10.16, which indicates the average time required to fully charge a vehicle. The median charge time value is 10.0, suggesting that half of the vehicles have a charge time below this value and half above. The most common charge time value in the dataset is 12.0. The close proximity of the mean and median values, along with their relationship to the mode, provides insights into the distribution of charge times across different vehicles. Moreover, the narrow range observed in the violin plot could indicate consistent charge times across various models, reflecting standardization in charging technology. It may also be partly due to the data cleaning process, where outliers were removed using the IQR method, resulting in a more condensed data distribution.\n\nViolin-plots of range and charge time statistics\n\nTable 6 shows the outliers present in the dataset. The ’Model year’ column has 11 outliers, indicating some variation in the years represented. The ’Motor’ column has 18 outliers, which may reflect extreme values in motor capacity. The ’City (kWh/100 km)’ and ’Combined (kWh/100 km)’ columns have 6 and 8 outliers respectively, while the ’Highway (kWh/100 km)’ column has 23 outliers, indicating variability in energy consumption during highway driving. The ’City (Le/100 km)’, ’Highway (Le/100 km)’, and ’Combined (Le/100 km)’ columns also show outliers, with the ’Highway (Le/100 km)’ column having the most at 23 outliers. The ’Range’ column has 49 outliers, reflecting significant variability in vehicle range. Interestingly, the ’Charge time’ column has no outliers, indicating a consistent charging time across the dataset.\n\nThese outliers were removed using the Interquartile Range (IQR) method. This IQR method ensures the integrity of the dataset by filtering out data points that deviate from the central trend. The IQR is computed as the difference between the third quartile (\\(Q_3\\)) and the first quartile (\\(Q_1\\)), defined as \\(\\text {IQR} = Q_3 - Q_1\\). Any data point below \\(Q_1 - 1.5 \\times \\text {IQR}\\) or above \\(Q_3 + 1.5 \\times \\text {IQR}\\) is classified as an outlier. After excluding outliers using the IQR method, Fig. 10 highlights the updated values for the mean, mode, and median. The mean (\\(\\bar{x}\\)), which is sensitive to extreme values, shifted closer to the central data cluster. The mode remained stable due to its resistance to outliers. The median (\\(m\\)), indicating the middle value of the ordered data, also adjusted slightly, aligning more closely with the densest part of the data distribution. In the case of ’Range,’ there were 49 outliers, resulting in a noticeable change in the violin plot with the maximum range reduced to approximately 700. For ’Charge Time,’ with zero outliers, the violin plot remained unchanged.\n\nImproved violin-plots of range and charge time statistics\n\n3 Evaluation metrics and results analysis\n\nThe performance of each model was assessed using multiple metrics to determine their generalization capabilities and accuracy in predicting unseen data.\n\n3.1 Evaluation metrics\n\nBefore exploring each metric in detail, it is crucial to understand the main evaluation criteria used to measure the performance of classification models. The following metrics were utilized for this purpose:\n\nAccuracy: Measures the proportion of correctly classified instances.\n\nRecall (Sensitivity): Measures the ability to correctly identify positive instances out of all actual positive instances.\n\nPrecision: Measures the proportion of correctly identified positive instances out of all instances classified as positive.\n\nF1 Score: Harmonic mean of precision and recall, providing a balance between the two.\n\nKappa: Measures the agreement between predicted and actual outcomes, considering chance agreement.\n\nMatthews Correlation Coefficient (MCC): Measures the quality of binary classifications, considering true and false positives and negatives.\n\nTraining Time (TT): Represents the time taken by each model to train on the given data.\n\nTo assess the performance of regression models, the following metrics were used:\n\nMean Absolute Error (MAE): Measures the average magnitude of errors in predictions, without considering their direction. It is the average over the test sample of the absolute differences between prediction and actual observation, where all individual differences have equal weight.\n\n, where \\(y_i\\) is the actual value and \\(\\hat{y}_i\\) is the predicted value.\n\nMean Squared Error (MSE): Measures the average of the squares of the errors, which is the average squared difference between the estimated values and the actual value. It gives a higher weight to large errors.\n\nRoot Mean Squared Error (RMSE): Measures the square root of the average of squared differences between prediction and actual observation. It represents the standard deviation of the residuals (prediction errors).\n\nR-squared (R2): Represents the proportion of the variance for a dependent variable that’s explained by an independent variable or variables in a regression model.\n\n, where \\(\\bar{y}\\) is the mean of the actual values.\n\nRoot Mean Squared Logarithmic Error (RMSLE): Measures the ratio between the predicted and the actual value and helps penalize under-predictions more than over-predictions.\n\nMean Absolute Percentage Error (MAPE): Measures the average of the absolute percentage errors of predictions. It expresses accuracy as a percentage.\n\n3.2 Results analysis\n\nIn this section, we will predict vehicle characteristics using both classification and regression models. The categorical features like vehicle make and vehicle class, will be predicted using classification models. On the other hand, continuous variables such as range, charge time and motor power will be predicted using regression models. By utilizing both classification and regression models, we can thoroughly analyze and predict multiple aspects of vehicle characteristics and their environmental impact.\n\nTo predict vehicles based on different make types shown in Tables 4, 7 provides a mapping of these make types. Each category is assigned a unique numerical identifier, establishing a standardized representation for the classification task. Table 8 displays the performance metrics for various classification models used to predict vehicle make types. The random forest classifier provides the best results with an accuracy of 95.58%, supported by its high values in recall, precision, F1 score, Kappa, and MCC, all around the 95% mark, highlighting its capabilities on unseen data. The random forest classifier was tuned through grid search to optimize hyperparameters such as the number of trees, depth of each tree, and the minimum number of samples required to split a node. This optimization improved the model’s generalization on the test data, contributing to its superior performance. The Naive Bayes and extra trees classifiers also show strong performance with accuracies of 95.31% and 95.10%, respectively, and similarly high values in recall, precision, F1 score, Kappa, and MCC. Decision tree classifier and Extreme Gradient Boosting also perform well with accuracies of 91.60%. Light Gradient Boosting Machine shows reliable performance with an accuracy of 87.41%. Conversely, models like SVM with a linear kernel and the dummy classifier show significantly lower accuracies of 40.34% and 37.44%, respectively, reflecting poor predictive performance. Similarly, Ada boost classifier and Logistic Regression exhibit relatively lower accuracies at 78.34% and 80.82%, respectively. Considering training time, Linear Discriminant Analysis stands out with a relatively low training time of 0.126 s, making it computationally efficient compared to models like gradient boosting classifier, which takes significantly longer at 1.383 s. Thus, random forest classifier is the best performer in accurately predicting vehicle make type while Linear Discriminant Analysis offers a balance between accuracy and computational efficiency.\n\nFigure 11 represents a confusion matrix for the best-performing random forest classifier, detailing the performance of the classifier across four vehicle make types: General, Luxury, Premium, and Sports. The matrix serves as a comprehensive tool for evaluating the classifier’s accuracy by juxtaposing actual class labels against predicted ones. Each cell in the matrix quantifies the instances of true class labels (rows) being classified into predicted class labels (columns). Diagonal elements, highlighted in green, signify correctly classified instances, while off-diagonal elements indicate misclassifications. The random forest classifier demonstrates robust performance, evidenced by the majority of instances lying along the diagonal, indicating high accuracy. Specifically, the General category has the most instances with 41 correctly classified samples. Other categories also exhibit high instance counts: Luxury with 4 correctly classified samples, Premium with 66, and Sports with 50 correctly classified samples. However, there are some misclassifications, such as 8 instances of General vehicles being classified as premium and 3 instances of Luxury vehicles being classified as premium. Additional steps to reduce misclassification could include incorporating more features that differentiate vehicle makes, such as charging technology or body style. Employing advanced ensemble techniques, like stacking multiple classifiers, could also help improve classification accuracy. The sparse off-diagonal elements further affirm the classifier’s efficacy, showcasing minimal misclassifications. This matrix allows for an in-depth understanding of the classifier’s strengths and weaknesses across different categories, providing essential insights for refining model performance and addressing specific areas of improvement.\n\nConfusion matrix for random forest classifier\n\nTo predict vehicles based on different vehicle categories, the Table 9 provides a mapping of various vehicle categories. Each category is assigned a unique numerical identifier, establishing a standardized representation for the classification task.\n\nTable 10 shows the performance metrics for the several classification models used to forecast vehicle categories. Naive Bayes achieved an accuracy of 100.00%, with excellent recall, precision, F1 score, Kappa, and Matthews correlation coefficient (MCC) scores, indicating its high capacity to generalize to unknown data. Similarly, both ridge classifier and extra trees classifier achieved an accuracy of 100.00%, further supported by their perfect recall, precision, F1 score, Kappa, and MCC values. Random forest classifier demonstrated strong performance with an accuracy of 99.51%. Logistic Regression (LR) performs well with an accuracy of 92.37%.\n\nGradient boosting classifier and light gradient boosting machine exhibit high predictive skills, with accuracies of 77.83% and 88.43%, respectively. Extreme gradient boosting also achieves good performance with an accuracy of 82.04%. The decision tree classifier shows an accuracy of 83.99%, performing well with good recall, precision, F1 score, Kappa, and MCC values. On the other hand, models with poorer predictive ability, such as the dummy classifier and Support Vector Machine (SVM) with a linear kernel, show much lower accuracies of 42.62% and 37.91%, respectively. The accuracies of the Ada boost classifier and the K neighbors classifier are comparatively lower at 74.65% and 54.24%, respectively. When it comes to computational efficiency, the quadratic and linear discriminant analysis with a very short training time of 0.127 s, is significantly more efficient compared to models like the gradient boosting classifier, which requires 0.742 s. Even though light gradient boosting machine isn’t as accurate as some top-performing models, it still shows effective training times. In conclusion, the decision tree classifier offers a balance between accuracy and computational efficiency, while the ridge and extra trees classifiers stand out for their superior performance in accurately identifying vehicle categories based on the provided data.\n\nFigure 12 shows the confusion matrix for the Naive Bayes classifier, illustrating the model’s performance in predicting vehicle categories. The matrix compares the true class labels against the predicted labels, with the x-axis representing the predicted classes and the y-axis representing the true classes. For the Hatchback category, the model correctly predicted 21 instances with no misclassifications. For the SUV category, the model accurately predicted 74 instances, again with no errors. The Sedan category saw 69 correct predictions and no misclassifications. However, the Truck category had 10 correct predictions but also showed no errors. The confusion matrix highlights the classifier’s strong performance, as evidenced by the diagonal cells showing the total number of correct predictions for each class, while the off-diagonal cells, which would indicate misclassifications, are all zeros. This confirms that the Naive Bayes classifier achieved high performance metrics, including accuracy, precision, recall, F1 score, Kappa, and Matthews correlation coefficient (MCC). Such results demonstrate the model’s robust performance in distinguishing between the various vehicle categories.\n\nConfusion matrix for ridge classifier\n\nTable 11 presents the performance metrics of various regression models used for predicting energy consumption in the city. Linear Regression stands out with a low MAE of 0.1296, MSE of 0.0320, RMSE of 0.1770, and an  R2 of 0.9982, indicating strong performance. Linear Regression was effective because the relationship between city energy consumption and features like motor power and vehicle weight is approximately linear. This straightforward relationship allowed the model to capture the variations in energy consumption efficiently, yielding high predictive accuracy. Bayesian ridge and ridge regression also perform well, with MAEs of 0.1308 and 0.1450, respectively, and R2 values of 0.9981 and 0.9977. Huber regressor, decision tree regressor, and extra trees regressor demonstrate good performance with slightly higher errors and R2 values around 0.9947 to 0.9626. Light gradient boosting machine, gradient boosting regressor, and Elastic Net show moderate performance with R2 values around 0.9565 to 0.9574. Models like Orthogonal Matching Pursuit and Passive Aggressive regressor show significant errors with MAEs around 2.5229 to 2.9677 and R2 values around 0.2605 to 0.4566. The dummy regressor performs poorly with high errors and an R2 of \\(-\\)0.0371, indicating it fails to make useful predictions. Overall, linear regression, Bayesian ridge, and ridge regression emerge as the top performers, whereas the dummy and passive aggressive regressors are the least effective.\n\nTable 12 presents the performance metrics of various regression models used for predicting Range. The K neighbors regressor stands out with a low MAE of 5.1234, MSE of 87.6543, RMSE of 9.3611, and an R2 of 0.9800, indicating strong performance. To prevent overfitting, techniques such as cross-validation and regularization (e.g., Lasso and ridge methods) were applied. Additionally, hyperparameter tuning was performed for models like K neighbors regressor to determine the optimal number of neighbors, which balances model complexity and predictive accuracy. Extra trees regressor and linear regression also perform well, with MAEs of 6.2345 and 6.3456, respectively, and R2 values of 0.9700 and 0.9650. Ridge regression, Bayesian ridge, and Elastic Net show good performance with MAEs around 6.4567 to 7.6789 and R2 values around 0.9500 to 0.9600. Light gradient boosting machine, gradient boosting regressor, and extreme gradient boosting demonstrate moderate performance with slightly higher errors and R2 values around 0.9250 to 0.9350. Models like Huber regressor, random forest regressor, and decision tree regressor have higher errors and lower R2 values, indicating less accurate predictions. Orthogonal Matching Pursuit, Ada boost regressor, and passive aggressive regressor show significant errors with MAEs around 14.6789 to 15.7890 and R2 values around 0.8950 to 0.9000. The dummy regressor performs poorly with high errors and an R2 of 0.8900, indicating it fails to make useful predictions. Overall, the K neighbors regressor, extra trees regressor, and linear regression emerge as the top performers, whereas the dummy and passive aggressive regressors are the least effective.\n\nTable 13 presents the performance metrics of various regression models used for predicting Charge time. The Huber regressor stands out with a relatively low MAE of 0.8999, MSE of 1.7888, RMSE of 1.3203, and an R2 of 0.9760, indicating strong performance. K neighbors regressor and Elastic Net also perform well, with MAEs of 0.9681 and 1.0786, respectively, and R2 values of 0.9600 and 0.9400. Ridge regression, Bayesian ridge, and Lasso Regression show good performance with MAEs around 1.1362 to 1.1980 and R2 values around 0.8400 to 0.8700. Light gradient boosting machine, gradient boosting regressor, and random forest regressor demonstrate moderate performance with slightly higher errors and R2 values around 0.8200 to 0.8500. Models like Ada boost regressor and decision tree regressor have higher errors and lower R2 values, indicating less accurate predictions. Orthogonal matching pursuit, Huber regressor, and K neighbors regressor display even higher error metrics with R2 values below 0.9. Elastic Net, Lasso Regression, and Lasso Least Angle Regression show significant errors with MAEs around 1.19 and R2 values around 0.2. The dummy regressor, serving as a baseline, performs poorly with a negative R2 value, indicating it fails to make useful predictions. The passive aggressive regressor exhibits the highest errors with an MAE of 1.6888 and an R2 of \\(-\\)0.8897, highlighting its ineffectiveness for this task. Overall, the extra trees regressor, Extreme Gradient Boosting, and Light Gradient Boosting Machine emerge as the top performers, whereas the dummy and passive aggressive regressors are the least effective.\n\nTable 14 presents the performance metrics of various regression models used for predicting Motor power. The K neighbors regressor stands out with a relatively low MAE of 3.3325, MSE of 24.9983, RMSE of 4.9902, and an R2 of 0.9300, indicating strong performance. K neighbors regressor was successful due to the local nature of its predictions, which are based on the proximity of similar data points. Motor power tends to exhibit regional clusters within the dataset, making the K neighbors regressor approach effective in capturing the variations across different vehicles. Extra trees regressor and decision tree regressor also perform well, with MAEs of 4.7149 and 5.2527, respectively, and R2 values of 0.8700 and 0.8600. Passive aggressive regressor and Elastic Net show good performance with MAEs around 6.3714 and 7.5136 and R2 values around 0.8500 and 0.8400. Ridge regression, Bayesian ridge, and linear regression demonstrate moderate performance with slightly higher errors and R2 values around 0.8200 to 0.8300. Light gradient boosting machine, gradient boosting regressor, and random forest regressor exhibit good performance with R2 values around 0.8000 to 0.8100. Models like Ada boost regressor and decision tree regressor have higher errors and lower R2 values, indicating less accurate predictions. Orthogonal matching pursuit, Huber regressor, and K neighbors regressor display even higher error metrics with R2 values below 0.7700. Elastic Net, Lasso Regression, and Lasso least angle regression show significant errors with MAEs around 7.6 and R2 values around 0.8350. The dummy regressor, serving as a baseline, performs poorly with an R2 value of 0.7000, indicating it fails to make useful predictions. The passive aggressive regressor exhibits the highest errors with an MAE of 1.6888 and an R2 of \\(-\\)0.8897, highlighting its ineffectiveness for this task. Overall, the K neighbors regressor, emerge as the top performer.\n\n4 Discussion\n\nBased on the study, Table 15 presents a detailed overview of the best models for each prediction job, including important metrics for both classification and regression models. This table emphasizes the usefulness and efficiency of several models in forecasting distinct electric vehicle specifications and performance parameters, aiding in the selection of the most suitable models for specific tasks. For predicting vehicle make type, the random forest model achieved an excellent accuracy of 0.9558, with precision and recall values similarly high. This represents the model’s ability to distinguish between various car makers. The F1 Score of 0.9534 further validates the model’s dependability, balancing accuracy and recall nicely. For the vehicle category, the Naive Bayes classifier excelled with a perfect accuracy of 1.000, indicating the model correctly identified all cases. The precision, recall, and F1 Score of 1.000 reflect the model’s extreme accuracy and recall skills, making it suitable for this job.\n\nFor forecasting energy consumption in city driving conditions, the linear regression model emerged as the best with an R2 value of 0.9982, suggesting an excellent fit between the predicted and actual values. The MAE of 0.1296 and RMSE of 0.1770 are very low, indicating high prediction accuracy. For predicting Range, the K neighbors regressor demonstrated strong performance with an R2 value of 0.9800. The MAE of 5.1234 and RMSE of 9.3611 show that the model’s predictions are close to the actual values. The Charge Time was best predicted by the Huber regressor, with an R2 value of 0.9760, suggesting significant predictive power. The MAE of 0.8999 and RMSE of 1.3203 indicate fairly accurate forecasts, with small variance from the actual values. For predicting Motor Power, the K neighbors regressor produced an R2 value of 0.9300, which is noteworthy. The MAE of 3.3325 and RMSE of 4.9902 reflect relatively accurate forecasts.\n\nThe table clearly indicates that various models excel at different prediction tasks, offering guidance for selecting the appropriate model depending on the specific features being predicted. Random forest and Naive Bayes classifiers are particularly successful for classification tasks, whereas linear regression, K neighbors regressor, and Huber regressor offer higher performance for regression tasks related to vehicle attributes. This detailed description highlights the necessity of selecting the proper model to achieve the greatest forecast accuracy and dependability for different vehicle attributes and environmental evaluations.\n\n5 Conclusions\n\nThis research work employed classification and regression models to predict various electric vehicle characteristics, including make, category, and continuous variables such as energy consumption in city driving, travel range, charge time, and motor power. The study’s results showed that machine learning models can effectively capture and predict essential vehicle characteristics with high accuracy. In classification tasks, the random forest and Naive Bayes classifiers stood out for their superior performance. The random forest classifier proved to be robust and reliable, achieving a 95.58% accuracy in predicting vehicle make, along with high precision, recall, and F1 scores. Similarly, the Naive Bayes classifier excelled in predicting vehicle categories, achieving perfect scores in accuracy, precision, recall, and F1 metrics, demonstrating its exceptional performance. In regression tasks, the Linear Regression model stood out as the best performer for predicting energy consumption in city driving, achieving an impressive R2 value of 0.9982. The K neighbors regressor proved most effective for predicting both range and motor power, with R2 values of 0.9800 and 0.9300, respectively. The Huber regressor excelled in predicting charge time, boasting an R2 value of 0.9760. These models consistently delivered low MAE and RMSE values, highlighting their high accuracy and minimal deviation from actual values.\n\nThe study highlights the critical importance of choosing the right models for specific prediction tasks. Random forest and Naive Bayes classifiers shine in classification tasks, whereas linear regression, K neighbors regressor, and Huber regressor excel in predicting continuous variables. By combining both classification and regression methods, this approach offers a thorough evaluation and prediction of various vehicle characteristics, driving advancements in vehicle technology and environmental assessments. Future research can focus on refining these machine learning models to boost both predictive accuracy and computational efficiency in the automotive field. The code is publicly available for replication and further research at the following GitHub repository: https://github.com/VP-CAST/V2I-V2L/blob/main/EV_prediction_June_18.ipynb.\n\nReferences\n\nSajede A, Mohsen S, Fahime M, Borna A (2022) Factors affecting the emission of pollutants in different types of transportation. Energy Rep. 8:2508–2529. https://doi.org/10.1016/j.egyr.2022.02.036\n\nArticle\n  Google Scholar\n\nMenendez M, Ambühl L (2022) Implementing design and operational measures for sustainable mobility: Lessons from zurich. Sustainability 14(625), https://doi.org/10.3390/su14020625\n\nKlemm C, Wiese F (2022) Indicators for the optimization of sustainable urban energy systems based on energy system modeling. Energy Sustain. Soc. 12(3), https://doi.org/10.1186/s13705-021-00318-4\n\nGórka M, Bezyk Y, Sówka I (2021) Assessment of ghg interactions in the vicinity of the municipal waste landfill site-case study. Energies 14(8259), https://doi.org/10.3390/en14248259\n\nGuo Y, Ma Z, Ren B, Zhao B, Liu P, Zhang J (2022) Effects of humic acid added to controlled-release fertilizer on summer maize yield, nitrogen use efficiency and greenhouse gas emission. Agriculture 12(448) https://doi.org/10.3390/agriculture12030448\n\nStubenrauch J, Garske B, Ekardt F, Hagemann K (2022) European forest governance: Status quo and optimizing options with regard to the paris climate target. Sustainability 14(4365), https://doi.org/10.3390/su14084365\n\nFang D, Mueller C (2021) Mortise-and-tenon joinery for modern timber construction: Quantifying the embodied carbon of an alternative structural connection. Arch. Struct. Constr. 3:11–24. https://doi.org/10.1007/s44100-021-00011-6\n\nArticle\n  Google Scholar\n\nInternational Energy Agency: Data and Statistics: “CO2 Emissions by Sector, World 1990-2019”. https://www.iea.org/data-and-statistics. Accessed: 2023-02-10\n\nProAire: Programa Para Mejorar la Calidad del Aire en Mexicali 2011-2020. https://www.gob.mx/cms/uploads/attachment/file/69289/12_ProAire_Mexicali.pdf. Accessed: 2023-02-10\n\nhang H, Mu JE, McCarl BA, Yu J (2022) The impact of climate change on global energy use. Mitig. Adapt. Strat. Glob. Chang 27(9), https://doi.org/10.1007/s11027-021-09962-5\n\nGarrido P (2013) Co2 emissions arising from the displacement of the population in private transport mode in gran santiago. Rev. Geogr. Espac. 3:69–86\n\nGoogle Scholar\n\nObaid M, Torok A (2021) Macroscopic traffic simulation of autonomous vehicle effects. Vehicles 3:187–196. https://doi.org/10.3390/vehicles3010011\n\nArticle\n  Google Scholar\n\nClimate Emergency Declaration and Mobilisation in Action. https://www.cedamia.org/global/ (2021)\n\nKey World Energy Statistics 2018-Analysis. https://www.iea.org/reports/key-world-energy-statistics-2019 (2020)\n\nUnited Nations Department of Economic and Social Affairs: 68 https://www.un.org/development/desa/en/news/population/2018-revision-of-world-urbanization-prospects.html (2018)\n\nhang X, Gao F, Gong X, Wang Z, Liu Y (2018) Comparison of climate change impact between power system of electric vehicles and internal combustion engine vehicles, 739–747\n\nGlobal EV Outlook 2019-Analysis. https://www.iea.org/reports/global-ev-outlook-2019 (2020)\n\nKwon Y, Son S, Jang K (2020) User satisfaction with battery electric vehicles in south korea. Transp. Res. D Transp. Environ. 82\n\nhuo X (2017) Forecasting Electric Vehicle Arrival & Departure Time on UCSD Campus Using Support Vector Machines. University of California, San Diego, ???\n\nFrendo O, Gaertner N, Stuckenschmidt H (2020) Improving smart charging prioritization by predicting electric vehicle departure time. IEEE Trans. Intell. Transp. Syst. Google Scholar\n\nChung Y-W, Khaki B, Li T, Chu C, Gadh R (2019) Ensemble machine learning-based algorithm for electric vehicle user behavior prediction. Appl. Energy 254. Google Scholar\n\nhiong Y, Chu C-C, Gadh R, Wang B (2017) Distributed optimal vehicle grid integration strategy with user behavior prediction. In: Proc. IEEE Power Energy Soc. Gen. Meeting, pp. 1–5. Google Scholar\n\nAlmaghrebi A, Aljuheshi F, Rafaie M, James K, Alahmad M (2020) Data-driven charging demand prediction at public charging stations using supervised machine learning regression methods. Energies 13(16), 4231. Google Scholar\n\nMajidpour M, Qiu C, Chu P, Gadh R, Pota HR (2015) Fast prediction for sparse time series: Demand forecast of ev charging stations for cell phone applications. IEEE Trans. Ind. Informat. 11(1), 242–250. Google Scholar\n\nMajidpour M, Qiu C, Chu P, Gadh R, Pota HR (2014) A novel forecasting algorithm for electric vehicle charging stations. In: Proc. Int. Conf. Connected Vehicles Expo (ICCVE), pp. 1035–1040. Google Scholar\n\nBokde N, Beck MW, Álvarez FM, Kulat K (2018) A novel imputation methodology for time series based on pattern sequence forecasting. Pattern Recognit. Lett. 116, 88–96. Google Scholar\n\nBarcellona S, Grillo S, Piegari L (2016) A simple battery model for ev range prediction: Theory and experimental validation. In: International Conference on Electrical Systems for Aircraft, Railway, Ship Propulsion and Road Vehicles International Transportation Electrification Conference (ESARS-ITEC), Toulouse, France, pp. 1–7. https://doi.org/10.1109/ESARSITEC.2016.7841441\n\nKessels JTBA, Rosca B, Bergveld HJ, Bosch PPJ (2011) On-line battery identification for electric driving range prediction. In: IEEE Vehicle Power Propulsion Conference, Chicago, IL, pp. 1–6. https://doi.org/10.1109/VPPC.2011.6043022\n\nSarmiento-Carnevali M, Fly A, Piecha P: Electric vehicle cold start range estimation through battery-in-loop simulations within a virtual driving environment. In: SAE Paper No. 2020-01-0453 (2020). doi:10.4271/2020-01-0453\n\nHayes JG, Davis K (2014) Simplified electric vehicle powertrain model for range and energy consumption based on epa coast-down parameters and test validation by argonne national lab data on the nissan leaf. In: IEEE Transportation Electrification Conference and Expo (ITEC), Dearborn, MI, pp. 1–6. https://doi.org/10.1109/ITEC.2014.6861831\n\nLiu K, Wang J, Yamamoto T, Morikawa T (2018) Exploring the interactive effects of ambient temperature and vehicle auxiliary loads on electric vehicle energy consumption. Applied Energy 227:324–331. https://doi.org/10.1016/j.apenergy.2017.08.074\n\nArticle\n  Google Scholar\n\nGebhardt K, Schau V, Rossak WR (2015) Applying stochastic methods for range prediction in e-mobility. In: 15th International Conference on Innovations for Community Services (I4CS), Nuremberg, Germany, pp. 1–4. https://doi.org/10.1109/I4CS.2015.7294483\n\nBolovinou A, Bakas I, Amditis A, Mastrandrea F, Vinciotti W (2014) Online prediction of an electric vehicle remaining range based on regression analysis. In: IEEE International Electric Vehicle Conference (IEVC), Florence, Italy, pp. 1–8. https://doi.org/10.1109/IEVC.2014.7056167\n\nfang J, Besselink I, Nijmeijer H (2015) Electric vehicle energy consumption modelling and prediction based on road information. World Electric Vehicle Journal (WEVJ) 7(3), 447–458, https://doi.org/10.3390/wevj7030447\n\nBirrell SA, McGordon A, Jennings PA (2014) Defining the accuracy of real-world range estimations of an electric vehicle. In: 17th International IEEE Conference on Intelligent Transportation Systems (ITSC), Qingdao, China, pp. 2590–2595. https://doi.org/10.1109/ITSC.2014.6958105\n\narga BO, Sagoian A, Mariasiu F (2019) Prediction of electric vehicle range: A comprehensive review of current issues and challenges. Energies 12(5), 946. https://doi.org/10.3390/en12050946\n\nDeepak S, Amarnath A, U GK, Kochuvila S (2019) Survey on range prediction of electric vehicles. In: Innovations in Power and Advanced Computing Technologies (i-PACT), vol. 1. Vellore, India, pp. 1–7. https://doi.org/10.1109/i-PACT44901.2019.8960179\n\nRahimi-Eichi H, Chow M-Y (2014) Big-data framework for electric vehicle range estimation. In: IECON 2014 - 40th Annual Conference of the IEEE Industrial Electronics Society, Dallas, TX, pp. 5628–5634. https://doi.org/10.1109/IECON.2014.7049362\n\nConradi P, Bouteiller P, Hanßen S: Dynamic cruising range prediction for electric vehicles. In: Meyer, G, Valldorf J. (eds.) Advanced Microsystems for Automotive Applications. VDI-Buch, pp. 269–277. Springer, Berlin, Heidelberg (2011). doi:10.1007/978-3-642-21381-6_26\n\nFerreira JC, Monteiro VDF, Afonso JL: Data mining approach for range prediction of electric vehicle. from https://repositorium.sdum.uminho.pt (2012)\n\nNunzio G.D, Thibault L: Energy-optimal driving range prediction for electric vehicles. In: IEEE Intelligent Vehicles Symposium (IV), Los Angeles, CA, pp. 1608–1613 (2017). doi:10.1109/IVS.2017.7995939\n\nfaz W, Nandi A.K.R, Landers R.G, Koylu U.O: Electric vehicle range prediction for constant speed trip using multi-objective optimization. Journal of Power Sources 275, 435–446 (2015) doi:10.1016/j.jpowsour.2014.11.043\n\nFukushima A, Yano T, Imahara S, Aisu H, Shimokawa Y, Shibata Y (2018) Prediction of energy consumption for new electric vehicle models by machine learning. IET Digital Library 12(9):1174–1180. https://doi.org/10.1049/iet-its.2018.5169\n\nArticle\n  Google Scholar\n\nGebhard L, Golab L, Keshav S, Meer H: Range prediction for electric bicycles. In: Proceedings of the Seventh International Conference on Future Energy Systems (e-Energy ’16), Waterloo, ON, Canada, pp. 1–11 (2016). doi:10.1145/2934328.2934349\n\nFechtner H, Teschner T, Schmuelling B: Range prediction for electric vehicles: Real-time payload detection by tire pressure monitoring. In: IEEE Intelligent Vehicles Symposium (IV), Seoul, South Korea, pp. 767–772 (2015). doi:10.1109/IVS.2015.7225777\n\nhao L, Yao W, Wang Y, Hu J: Machine learning-based method for remaining range prediction of electric vehicles. IEEE Access 8, 212423–212441 (2020) doi:10.1109/access.2020.3039815\n\nang Z, Wang X-H, Wang L-Z, Hu X-F, Fan W-H: Research on electric vehicle (ev) driving range prediction method based on pso-lssvm. In: IEEE International Conference on Prognostics and Health Management (ICPHM), Dallas, TX, pp. 260–265 (2017). doi:10.1109/ICPHM.2017.7998338\n\nDownload references\n\nAcknowledgements\n\nThe authors would like to express their sincere gratitude to the Deanship of Research for funding this project under the project grant titled “Optimizing Electric Vehicle Charging Station Selection: A Machine Learning Approach” (Project Number: RF/DVC/CIRC/24/01). The investigators would also like to thank Sultan Qaboos University for providing a supportive academic environment that facilitated the successful completion of this research.\n\nAuthor information\n\nAuthors and Affiliations\n\nCommunication and Information Research Center, Sultan Qaboos University, Muscat, Oman\n\nAjmal Khan & Mohammed M. Bait-Suwailam\n\nDepartment of Electrical Engineering and Interdisciplinary Research Center for Communication Systems and Sensing (IRC-CSS), King Fahd University of Petroleum & Minerals, Dhahran, Saudi Arabia\n\nNaveed Iqbal\n\nDepartment of Computer Engineering, King Fahd University of Petroleum & Minerals (KFUPM), and Interdisciplinary Research Center for Smart Mobility and Logistics, KFUPM, Dhahran, 31261, Saudi Arabia\n\nZeeshan Kaleem\n\nData Scientist, Showcare Event Solutions Inc, Ontario, Canada\n\nZul Qarnain\n\nDepartment of Electrical & Computer Engineering, Sultan Qaboos University, Muscat, Oman\n\nMohammed M. Bait-Suwailam\n\nCorresponding author\n\nCorrespondence to Mohammed M. Bait-Suwailam.\n\nAdditional information\n\nPublisher's Note\n\nSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\n\nRights and permissions\n\nSpringer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law.\n\nReprints and permissions\n\nAbout this article\n\nCite this article\n\nKhan, A., Iqbal, N., Kaleem, Z. et al. A multi-model approach for predicting electric vehicle specifications and energy consumption using machine learning. J Supercomput 81, 314 (2025). https://doi.org/10.1007/s11227-024-06820-4\n\nDownload citation\n\nAccepted\n07 December 2024\n\nPublished\n20 December 2024\n\nDOI\nhttps://doi.org/10.1007/s11227-024-06820-4\n\nShare this article\n\nAnyone you share the following link with will be able to read this content:\n\nProvided by the Springer Nature SharedIt content-sharing initiative\n\nKeywords\n\nDiscover content\n\nPublish with us\n\nProducts and services\n\nOur brands\n\n212.98.144.16\n\nAmerican University of Beirut (8200692269) - Lebanese Academic Library Consortium (3002060333)\n\n© 2025 Springer Nature\n\nModeling the Impact of Different Policies on Electric Vehicle ... - MDPI : \nModeling the Impact of Different Policies on Electric Vehicle Adoption: An Investigative Study\n\nAbstract\n\n1. Introduction\n\n2. Literature Review\n\n3. Methodology\n\n4. Results and Discussion\n\n5. Conclusions\n\nAuthor Contributions\n\nFunding\n\nData Availability Statement\n\nConflicts of Interest\n\nReferences\n\nShare and Cite\n\nAbas, P.E.; Tan, B. Modeling the Impact of Different Policies on Electric Vehicle Adoption: An Investigative Study. World Electr. Veh. J. 2024, 15, 52. https://doi.org/10.3390/wevj15020052\n\nAbas PE, Tan B. Modeling the Impact of Different Policies on Electric Vehicle Adoption: An Investigative Study. World Electric Vehicle Journal. 2024; 15(2):52. https://doi.org/10.3390/wevj15020052\n\nAbas, Pg Emeroylariffion, and Benedict Tan. 2024. \"Modeling the Impact of Different Policies on Electric Vehicle Adoption: An Investigative Study\" World Electric Vehicle Journal 15, no. 2: 52. https://doi.org/10.3390/wevj15020052\n\nAbas, P. E., & Tan, B. (2024). Modeling the Impact of Different Policies on Electric Vehicle Adoption: An Investigative Study. World Electric Vehicle Journal, 15(2), 52. https://doi.org/10.3390/wevj15020052\n\nArticle Metrics\n\nCitations\n\nArticle Access Statistics\n\nFurther Information\n\nGuidelines\n\nMDPI Initiatives\n\nFollow MDPI\n\nSubscribe to receive issue release notifications and newsletters from MDPI journals\n"
        },
        "AnalyzedArticles": {
            "Machine learning models employed in EV adoption prediction": {
                "Article_Summary": "The study explores machine learning techniques for predicting electric vehicle characteristics, focusing on classification and regression models to forecast vehicle make, category, energy consumption, range, charge time, and motor power. The research demonstrates the effectiveness of machine learning in capturing and predicting essential vehicle attributes with high accuracy, using models like Random Forest, Naive Bayes, Linear Regression, and K-Neighbors Regressor.",
                "ML_Models": "Two-Dimensional Attention Model, Convolutional LSTM (ConvLSTM), Hybrid LSTM with Residual Network"
            },
            "Machine learning models employed in EV charging infrastructure optimization": {
                "Article_Summary": "The research focuses on optimizing machine learning models for anomaly detection in electric vehicle (EV) charging infrastructure using TinyML pruning techniques. The study aims to develop lightweight, efficient ML models that can detect and predict anomalies in EV charging systems with reduced computational complexity and energy consumption.",
                "ML_Models": "Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), Transformer-based Anomaly Detection Models"
            },
            "Machine learning models employed in EV market segmentation analysis": {
                "Article_Summary": "The research focuses on predicting electric vehicle (EV) sales and market penetration using advanced machine learning techniques. The study collected comprehensive data including vehicle specifications, economic indicators, news sentiment, and Google Trends data to develop predictive models for EV market share across different vehicle segments.",
                "ML_Models": "Long Short-Term Memory (LSTM), Convolutional LSTM (ConvLSTM), Hybrid LSTM with Two-Dimensional Attention and Residual Network"
            },
            "Machine learning models employed in EV policy impact assessment": {
                "Article_Summary": "The research explores machine learning methods for predicting electric vehicle (EV) specifications and performance metrics using advanced classification and regression models. The study focuses on predicting vehicle characteristics like make, category, energy consumption, range, charge time, and motor power using various ML techniques to support EV technology advancement and environmental assessments.",
                "ML_Models": "Random Forest Classifier, Naive Bayes Classifier, K-Neighbors Regressor"
            }
        },
        "Relationship": {
            "Machine learning models employed in EV adoption prediction": [
                "The ML models (Regression models, Random Forests, Gradient Boosting Machines) can analyze geographic and vehicle attribute data to predict EV adoption patterns. The Electric_Vehicle_Population_Data table contains rich information about EV distribution, vehicle specifications, and geographic locations that can serve as features for these predictive models."
            ],
            "Machine learning models employed in EV charging infrastructure optimization": [
                "The ML models (Clustering algorithms, Spatial analysis models, Decision trees) can optimize EV charging infrastructure by analyzing the geographic distribution of electric vehicles, their range capabilities, and utility service areas. The database contains crucial location data (Vehicle Location, County, City, Postal Code), vehicle specifications (Electric Range, Electric Vehicle Type), and utility information (Electric Utility) that can be used to identify optimal charging station placements."
            ],
            "Machine learning models employed in EV market segmentation analysis": [
                "The ML models (K-means clustering, Hierarchical clustering, Neural networks) can be used to segment the EV market by grouping similar vehicles and identifying patterns in consumer preferences across different regions and demographics. The database contains rich information about vehicle characteristics, pricing, and geographic distribution that can be leveraged for this analysis."
            ],
            "Machine learning models employed in EV policy impact assessment": [
                "The ML models (Random Forest Classifier, Naive Bayes Classifier, K-Neighbors Regressor) can analyze how policy decisions impact EV adoption patterns over time. The database contains critical policy-related fields (Legislative District, CAFV Eligibility) and temporal/geographic data that allow for tracking adoption trends across different regions and time periods, enabling assessment of policy effectiveness."
            ]
        },
        "Needs": {
            "Machine learning models employed in EV adoption prediction": [
                "For EV adoption prediction, we need geographic data (County, City, State, Postal Code) and vehicle attributes (Make, Model, Electric Range, Base MSRP) as features. These would be processed as categorical variables (location, make, model) and numerical variables (range, price) for regression and tree-based models. The target variable would need to be derived, possibly as EV density per region. The models would perform regression tasks to predict adoption rates or classification to identify high-potential adoption areas."
            ],
            "Machine learning models employed in EV charging infrastructure optimization": [
                "For charging infrastructure optimization, we need geospatial data (Vehicle Location, County, City, Postal Code) as categorical and coordinate inputs for clustering algorithms to identify EV concentration areas. Electric Range (numerical) helps determine charging needs density. Electric Vehicle Type (categorical) informs charging compatibility requirements. Electric Utility (categorical) data helps coordinate with power providers. These features will train unsupervised clustering models to identify optimal charging station locations, supervised decision trees to predict utilization rates, and spatial analysis models to optimize coverage based on EV population density patterns."
            ],
            "Machine learning models employed in EV market segmentation analysis": [
                "For market segmentation analysis, we need categorical data (Make, Model, Electric Vehicle Type) and numerical data (Base MSRP, Electric Range) for clustering algorithms. Geographic data (County, City, Postal Code) and demographic information (2020 Census Tract) will help identify regional preferences. K-means and Hierarchical clustering require normalized numerical features, while Neural networks can handle mixed data types for more complex segmentation. The end goal is classification/clustering of vehicles into market segments based on similar characteristics and regional adoption patterns."
            ],
            "Machine learning models employed in EV policy impact assessment": [
                "For policy impact assessment, we need categorical data (Legislative District, CAFV Eligibility, County, City) and numerical data (Model Year, Electric Range) to train classification models (Random Forest, Naive Bayes) that predict policy eligibility and adoption likelihood, and regression models (K-Neighbors) to forecast adoption rates. Time-series components require properly formatted date fields (Model Year) to track adoption patterns over time, while geographic features need consistent formatting for regional analysis."
            ]
        },
        "ModelsPerTopic": {
            "Machine learning models employed in EV adoption prediction": "Two-Dimensional Attention Model, Convolutional LSTM (ConvLSTM), Hybrid LSTM with Residual Network",
            "Machine learning models employed in EV charging infrastructure optimization": "Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), Transformer-based Anomaly Detection Models",
            "Machine learning models employed in EV market segmentation analysis": "Long Short-Term Memory (LSTM), Convolutional LSTM (ConvLSTM), Hybrid LSTM with Two-Dimensional Attention and Residual Network",
            "Machine learning models employed in EV policy impact assessment": "Random Forest Classifier, Naive Bayes Classifier, K-Neighbors Regressor"
        },
        "ML_Models1": [
            "Regression models, Random Forests, Gradient Boosting Machines",
            "Clustering algorithms, Spatial analysis models, Decision trees",
            "K-means clustering, Hierarchical clustering, Neural networks",
            "Time series analysis, Causal inference models, Bayesian networks"
        ],
        "GPT_Columns": {
            "Machine learning models employed in EV adoption prediction": [
                [
                    {
                        "Electric_Vehicle_Population_Data": [
                            "County",
                            "City",
                            "State",
                            "Postal Code",
                            "Make",
                            "Model",
                            "Electric Range",
                            "Base MSRP",
                            "Electric Vehicle Type",
                            "Model Year",
                            "2020 Census Tract"
                        ]
                    }
                ]
            ],
            "Machine learning models employed in EV charging infrastructure optimization": [
                [
                    {
                        "Electric_Vehicle_Population_Data": [
                            "Vehicle Location",
                            "Electric Range",
                            "County",
                            "City",
                            "Postal Code",
                            "Electric Vehicle Type",
                            "Electric Utility"
                        ]
                    }
                ]
            ],
            "Machine learning models employed in EV market segmentation analysis": [
                [
                    {
                        "Electric_Vehicle_Population_Data": [
                            "Make",
                            "Model",
                            "Base MSRP",
                            "Electric Vehicle Type",
                            "County",
                            "City",
                            "2020 Census Tract"
                        ]
                    }
                ]
            ],
            "Machine learning models employed in EV policy impact assessment": [
                [
                    {
                        "Electric_Vehicle_Population_Data": [
                            "Legislative District",
                            "Clean Alternative Fuel Vehicle (CAFV) Eligibility",
                            "Model Year",
                            "County",
                            "City",
                            "Electric Vehicle Type",
                            "Electric Range"
                        ]
                    }
                ]
            ]
        }
    }
}