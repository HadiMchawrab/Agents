{
    "tables": [
        {
            "data": [
                "Bankrupt?",
                " ROA(C) before interest and depreciation before interest",
                " ROA(A) before interest and % after tax",
                " ROA(B) before interest and depreciation after tax",
                " Operating Gross Margin",
                " Realized Sales Gross Margin",
                " Operating Profit Rate",
                " Pre-tax net Interest Rate",
                " After-tax net Interest Rate",
                " Non-industry income and expenditure/revenue",
                " Continuous interest rate (after tax)",
                " Operating Expense Rate",
                " Research and development expense rate",
                " Cash flow rate",
                " Interest-bearing debt interest rate",
                " Tax rate (A)",
                " Net Value Per Share (B)",
                " Net Value Per Share (A)",
                " Net Value Per Share (C)",
                " Persistent EPS in the Last Four Seasons",
                " Cash Flow Per Share",
                " Revenue Per Share (Yuan ¥)",
                " Operating Profit Per Share (Yuan ¥)",
                " Per Share Net profit before tax (Yuan ¥)",
                " Realized Sales Gross Profit Growth Rate",
                " Operating Profit Growth Rate",
                " After-tax Net Profit Growth Rate",
                " Regular Net Profit Growth Rate",
                " Continuous Net Profit Growth Rate",
                " Total Asset Growth Rate",
                " Net Value Growth Rate",
                " Total Asset Return Growth Rate Ratio",
                " Cash Reinvestment %",
                " Current Ratio",
                " Quick Ratio",
                " Interest Expense Ratio",
                " Total debt/Total net worth",
                " Debt ratio %",
                " Net worth/Assets",
                " Long-term fund suitability ratio (A)",
                " Borrowing dependency",
                " Contingent liabilities/Net worth",
                " Operating profit/Paid-in capital",
                " Net profit before tax/Paid-in capital",
                " Inventory and accounts receivable/Net value",
                " Total Asset Turnover",
                " Accounts Receivable Turnover",
                " Average Collection Days",
                " Inventory Turnover Rate (times)",
                " Fixed Assets Turnover Frequency",
                " Net Worth Turnover Rate (times)",
                " Revenue per person",
                " Operating profit per person",
                " Allocation rate per person",
                " Working Capital to Total Assets",
                " Quick Assets/Total Assets",
                " Current Assets/Total Assets",
                " Cash/Total Assets",
                " Quick Assets/Current Liability",
                " Cash/Current Liability",
                " Current Liability to Assets",
                " Operating Funds to Liability",
                " Inventory/Working Capital",
                " Inventory/Current Liability",
                " Current Liabilities/Liability",
                " Working Capital/Equity",
                " Current Liabilities/Equity",
                " Long-term Liability to Current Assets",
                " Retained Earnings to Total Assets",
                " Total income/Total expense",
                " Total expense/Assets",
                " Current Asset Turnover Rate",
                " Quick Asset Turnover Rate",
                " Working capitcal Turnover Rate",
                " Cash Turnover Rate",
                " Cash Flow to Sales",
                " Fixed Assets to Assets",
                " Current Liability to Liability",
                " Current Liability to Equity",
                " Equity to Long-term Liability",
                " Cash Flow to Total Assets",
                " Cash Flow to Liability",
                " CFO to Assets",
                " Cash Flow to Equity",
                " Current Liability to Current Assets",
                " Liability-Assets Flag",
                " Net Income to Total Assets",
                " Total assets to GNP price",
                " No-credit Interval",
                " Gross Profit to Sales",
                " Net Income to Stockholder's Equity",
                " Liability to Equity",
                " Degree of Financial Leverage (DFL)",
                " Interest Coverage Ratio (Interest expense to EBIT)",
                " Net Income Flag",
                " Equity to Liability"
            ]
        },
        {
            "banking": [
                "age",
                "job",
                "marital",
                "education",
                "default",
                "housing",
                "loan",
                "contact",
                "month",
                "day_of_week",
                "duration",
                "campaign",
                "pdays",
                "previous",
                "poutcome",
                "emp_var_rate",
                "cons_price_idx",
                "cons_conf_idx",
                "euribor3m",
                "nr_employed",
                "y"
            ]
        }
    ],
    "analyzed_topics": [
        {
            "topic": "Machine learning models employed in bankruptcy prediction",
            "ML_Models": "Random Forest, Gradient Boosting, Neural Networks, Logistic Regression",
            "reasoning": "The 'Bankrupt?' column suggests this dataset is for bankruptcy prediction. Financial ratios like ROA, debt ratios, and cash flow metrics are strong predictors. ML models can analyze these financial indicators to identify patterns that precede bankruptcy, helping companies take preventive measures."
        },
        {
            "topic": "Machine learning models employed in financial performance optimization",
            "ML_Models": "XGBoost, Support Vector Machines, Decision Trees, Ensemble Methods",
            "reasoning": "The extensive financial ratios (ROA, operating margins, growth rates) can be used to predict and optimize company performance. ML models can identify which financial metrics most strongly correlate with success, helping management focus on key performance indicators."
        },
        {
            "topic": "Machine learning models employed in customer banking product targeting",
            "ML_Models": "Random Forest, Logistic Regression, K-Nearest Neighbors, Neural Networks",
            "reasoning": "The banking table contains demographic data (age, job, education) and previous campaign results that can predict which customers are likely to accept offers. ML models can optimize marketing campaigns by targeting customers with the highest probability of conversion."
        },
        {
            "topic": "Machine learning models employed in economic trend impact analysis",
            "ML_Models": "Time Series Models, LSTM Networks, Regression Models, Bayesian Networks",
            "reasoning": "The banking table includes economic indicators (emp_var_rate, cons_price_idx, euribor3m) that can be analyzed alongside company financial data to predict how macroeconomic trends affect business performance and bankruptcy risk. This helps companies prepare for economic changes."
        }
    ],
    "csv_files": [
        "csv_test/data.csv",
        "csv_test/banking.csv"
    ],
    "topic": [
        "Machine learning models employed in bankruptcy prediction",
        "Machine learning models employed in financial performance optimization",
        "Machine learning models employed in customer banking product targeting",
        "Machine learning models employed in economic trend impact analysis"
    ],
    "ScrapedArticles": {
        "Machine learning models employed in bankruptcy prediction": "Bankruptcy prediction using machine learning and an application to the ... : \nData Science in Finance and Economics\n\nData Science in Finance and Economics\n\nBankruptcy prediction using machine learning and an application to the case of the COVID-19 recession\n\nJEL Codes: O30, E37, E60\n\nAbstract\n\nBankruptcy prediction is an important problem in finance, since successful predictions would allow stakeholders to take early actions to limit their economic losses. In recent years many studies have explored the application of machine learning models to bankruptcy prediction with financial ratios as predictors. This study extends this research by applying machine learning techniques to a quarterly data set covering financial ratios for a large sample of public U.S. firms from 1970–2019. We find that tree-based ensemble methods, especially XGBoost, can achieve a high degree of accuracy in out-of-sample bankruptcy prediction. We next apply our best model, using XGBoost, to the problem of predicting the overall bankruptcy rate in USA in the second half of 2020, after the COVID-19 pandemic had necessitated a lockdown, leading to a deep recession. Our model supports the prediction, made by leading economists, that the rate of bankruptcies will rise substantially in 2020, but it also suggests that this elevated level will not be much higher than 2010.\n\n1.   Introduction\n\nBankruptcy prediction is the problem of detecting financial distress in businesses which will lead to eventual bankruptcy. Bankruptcy prediction has been studied since at least 1930s. The early models of bankruptcy prediction employed univariate statistical models over financial ratios. The univariate models were followed by multi-variate statistical models such as the famous Altman Z-score model. The recent advances in the field of Machine learning have led to the adoption of Machine learning algorithms for bankruptcy prediction. Machine Learning methods are increasingly being used for bankruptcy prediction using financial ratios. A study by Barboza, Kimura and Altman found that Machine Learning models can outperform classical statistical models like multiple discriminant analysis (MDA) by a significant margin in bankruptcy prediction (Barboza et al., 2017).\n\nBankruptcy prediction is an important for modern economies because early warnings of bankrupt help not only the investor but also public policy makers to take proactive steps to minimize the impact of bankruptcies. The reasons that add to the significance of bankruptcy prediction are as follows:\n\n(1). Better allocation of resources\n\nInstitutional investors, banks, lenders, retail investors are always looking at information that predicts financial distress in publicly traded firms. Early prediction of bankruptcy helps not only the investors and lenders but also the managers of a firm to take corrective action thereby conserving scare economic resources. Efficient allocation of capital is the cornerstone of growth in modern economies.\n\n(2). Input to policy makers\n\nAccurate prediction of bankruptcies of businesses and individuals before they happen gives law makers and policy makers some additional time to alleviate systemic issues that might be causing the bankruptcies. Indeed, with bankruptcies taking center stage in political discourse of many countries, the accurate prediction of bankruptcy is a key input for politicians, bureaucrats and in general for anyone who is making public policy.\n\n(3). Corrective action for business managers\n\nThe early prediction of bankruptcy is likely to highlight business issues thereby giving the company's manager additional time to make decisions that will help avoid bankruptcy. This effect is likely to be more profound in public companies where the management has a fiduciary duty to the shareholders.\n\n(4). Identification of sector wide problems\n\nBankruptcy prediction models that flag firms belonging to a certain sector are likely to be a leading indicator of an upcoming downturn in a certain sector of an economy. With robust models, the business managers and government policy makers would become aware and take corrective action to limit the magnitude and intensity of the downturn in the specific sector. Industry groups in turn has been shown to significantly effect forecasting models (Chava and Jarrow, 2004).\n\n(5). Signal to Investors\n\nInvestors can make better and more informed decisions based on the prediction of bankruptcy models. This not only forces the management of firms to take corrective action but also helps to soften the overall economic fallout that results from the bankruptcies. Empirical studies have shown that investment opportunities are significantly related to likelihood of bankruptcy (Lyandres & Zhdanov, 2007).\n\n(6). Relation to adjacent problems\n\nBankruptcy prediction is often the first step used by ratings agencies to detect financial distress in firms. Based on the predictions of bankruptcy models, ratings agencies investigate and assess credit risk. Getting flagged by bankruptcy prediction models is often the first step that triggers the process of revising credit ratings. A literature survey covering 2000–2013 demonstrates the close relation between bankruptcy prediction and credit risk (García et al., 2015).\n\nMost past studies in bankruptcy prediction including those using Machine Learning have used a relatively small sample of firms and a small number of financial ratios. This study distinguishes itself by using a much larger dataset having data for 21,114 U.S. firms (samples) and 57 financial ratios (features). Our dataset covers US firms from 1970 to 2020. Bankruptcy prediction models have been researched and built since the 1960s. The models built from 1960 to 1990 were primarily statistical models such as univariate, multiple discriminant analysis and logit and probit models. Starting from 1990s machine learning models started outperforming statistical models. Since this study applies the most popular contemporary machine learning algorithms using a big data set, we will compare our model with the machine learning models built since the 1990s. A full listing outlining the comparison with past machine learning studies and models for bankruptcy prediction is shown in the Table 1.\n\nIn this study we have used three popular machine learning techniques—Random Forest, Support Vector Machines, and XGBoost to construct forecasting models. We find that Machine Learning models perform very well, with XGBoost being the most successful technique that achieves an accuracy score of more than 99% in out of sample testing.\n\nWe also apply our XGBoost model to an important current issue, the task of predicting bankruptcies during the second half of 2020. The depth of the recession caused by the lockdowns that have been imposed to contain the COVID-19 pandemic has raised worries that corporate bankruptcies may rise substantially in the near future. According to a report in the New York Times (2020), Edward Altman, a pioneer of bankruptcy prediction research, and the creator of the famous Z score model, expects a \"tsunami of bankruptcies\" that will exceed the number of bankruptcies that followed the 2008 financial crisis. The result from our Machine Learning model confirms Prof Altman's fears that corporate bankruptcies will rise substantially in late 2020 and equal the highs seen during the 2008-09 recession. However, this study finds that the elevated level of bankruptcies will not be significantly different from 2010.\n\nThe previous studies done for bankruptcy prediction have not taken a systematic view of the data used to build the models. The previous studies have been more focused on the models rather than on the data used to build the models. This study offers a much more balanced view where both the data and the models are given equal importance. To begin with, we have use Compustat are a source database to get an exhaustive list of financial ratios over US firms from 1970 to 2020. Compustat is a high-quality database used by several famous finance related papers such as Fama and French (1993). Most of the previous studies have used relatively small datasets as compared to ours. This study takes a systematic look at as many features as possible to train our machine learning models. Our balanced approach is also consistent with the shift from model centric to data centric approach proposed by Andrew Ng (Gil Press, 2021).\n\nThe rest of the paper is structured as follows:\n\nSection 2—Describes the existing literature for bankruptcy prediction.\n\nSection 3—Describes the data and the method used to clean, process, and fit the data into our machine learning models. This section also covers the process used to predict the number of bankruptcies using Q2-2020 ratios.\n\nSection 4—Describes the results observed from the experiments\n\nSection 5—Presents our final comments and discusses the implications of the results.\n\n2.   Literature review\n\nBankruptcy prediction models prior to 1990s were primarily statistical models employing univariate, multivariate and logit & probit techniques. In 1966, Beaver applied univariate analysis in which the predictive ability of 30 financial ratios was tested one at a time to predict bankruptcy (Beaver, 1966). Altman in 1968 performed a multi-variate discriminant analysis (MDA) using 5 ratios to create a linear discriminant function of 5 variables (Altman, 1968). Several variants of MDA were developed in the following years. Edmister used 19 financial ratios to build a linear model for bankruptcy prediction (Edmister, 1972). Deakin found that a linear combination of the 14 ratios could be used to predict bankruptcy five years prior to failure (Deakin, 1972). Ohlson studied the shortcomings of MDA models and built a conditional logit model using maximum likelihood estimation (Ohlson, 1980). The datasets used in all these studies were quite small as compared to modern standards. Ohlson's study for example used a dataset of 2058 firms out of which 105 firms represented the bankrupt class.\n\nThe next phase in the evolution of bankruptcy models started in the 1990s with several machine learning algorithms outperforming the older statistical models. Machine learning models such as Random Forests, Support Vector Machines (SVM) and Gradient Boosted Trees were found to be particularly effective for bankruptcy prediction. Barboza, Kimura and Altman compared statistical models with machine learning (ML) models. They found the Random Forests outperformed Alman's Z-score model by a significant margin (Barboza et al., 2017). These results were corroborated by studies (Joshi et al., 2018; Rustam and Saragih, 2018; Gnip and Drotár, 2019). Support Vector Machine (SVM) was also found to be a very effective machine learning algorithm in several studies. Hang et al. (2004) and Chen et al. (2008) achieved superior results for credit rating classification problem by using SVM. Song et al. (2008) used SVM to predict financial distress. Some studies also found boosted trees-based algorithms to outperform SVM. Wang, Ma and Yang proposed a new boosted tree-based algorithm for bankruptcy prediction which they found to be more effective than SVM (Wang et al., 2014). Heo and Yang (2014) used Adaboost algorithm to predict bankruptcy for Korean construction firm. They found Adaboost to have better accuracy than SVM (Heo and Yang, 2014). A more recent study in 2021 has used XGBoost and Random Forest algorithms to predict bankruptcies over 12 months. This study used a medium sized training dataset containing data for 8959 firms registered in Italy (Perboli and Arabnezad, 2021). Another recent study uses a database of Taiwanese firms to predict bankruptcy. This study used data set contain 96 attributes for 6819 firms to train machine learning models (Wang and Liu, 2021). One common attribute shared by all the forementioned studies is the relatively small size of their training data sets. The datasets used by these studies are small as compared to datasets used in the big data era. The largest training dataset in these studies had just 2600 samples which is quite small.\n\nBased on the literature review, the following trends become apparent:\n\n●  Machine Learning Models are now consistently outperforming statistical models\n\n●  The training data sets used to train the existing machine learning models are relatively small as compared to the data sets used for training models in other application areas.\n\n●  Ensemble methods such as Random Forest and Boosted trees have performed better than other models in bankruptcy prediction.\n\n3.   Data and methodology\n\nThis study differentiates itself from previous studies by using a substantially larger dataset as compared to previous studies. We use a very standard and well documented dataset called Compustat to retrieve the financial ratios. Compustat is a standard financial dataset used in financial research. Compustat has been used by some very popular papers in finance such as Fama and French (1993). We have used 57 financial ratios that are listed in Table 2. Financial ratios are inputs used to train Bankruptcy prediction models. While most studies use fewer financial ratios, this study applies a large set of financial ratios of US Firms from 1970–2020 (50 years) to train Random Forest, SVM and XGBoost Models. This section discusses the overall methodology which includes data cleaning, balancing, model fitting, and analysis of results.\n\nPrevious studies have used small to medium sized data sets for training Machine learning models. This study sets itself apart by using a much larger training dataset. We used financial ratios data set from Compustat. The financial ratios data set was then joined with another dataset called Bankruptcy data set. The bankruptcy data set contains the data such as date of bankruptcy, bankruptcy reason and GVKEY (primary key) while the financial ratios dataset contains all the financial ratios mentioned in Table A.1. The two datasets were programmatically joined using a common field named GVKEY. GVKEY is a unique identifier assigned to each firm. The relation amongst the two datasets that were used to create our labelled training dataset is best represented by the ER schema diagram shown in Figure 1.\n\nThe financial ratios dataset we have used contains 57 financial ratios mentioned in Table A.1 in Appendix A. This is an exhaustive list of features used to train our models. We have included ratios which are often overlooked but are likely to help detect patterns related to edge cases.\n\nThe first step of building a predictive model is data pre-processing and cleaning. The original data from Compustat had 75 financial ratios for 21,114 US firms. This data covered firms established in the US between 1970 and 2020. The dataset contained firms that belonged to 2 classes: bankrupt and non-bankrupt or continuing enterprises. The dataset contains 1212 bankrupt firms and 19,902 non-bankrupt firms. The distribution of data points (samples) belonging to these two classes is summarized in Table 2. The next step was to drop features which had null values for more than 6000 firms out of 21,114 firms. This step ensured that we don't have more than 30% of null values in any feature. The goal is to ensure that the true distribution generating this data is preserved and learned by our machine learning models. 18 features (financial ratios) were dropped from the data set because they had null values for more than 6000 (30% of total number of firms). The dataset now had 75 − 18 = 57 features. Next, we scaled our data to have mean = 0 and variance = 1 using Scikit-learns Standard Scaler class. Scaling is required to ensure that gradient descent converges on the minima of the loss function. The last step of data cleaning was to impute the missing values in the 57 financial ratios (features). For imputing the missing values, we used the KNN algorithm which used three nearest neighbours to estimate the missing value. Further, the weight assigned to each neighbour is a function of its Euclidean distance from the data point with missing value. KNN with 3-neighbours has been found to be effective in preserving the true distribution of the data (Beretta and Santaniello, 2016).\n\nThe cleaned and scaled dataset without any missing values was an imbalanced dataset (see Table 2). The dominant class was the bankruptcy class. Approximately 90% of the samples belonged to the majority class which is non-bankrupt firms. Since the goal of this study is train a classifier to identify bankrupt firms, we decided to balance the classes in our training data. This would ensure that our model would learn about the minority class which is the bankrupt class. This is important in the context of bankruptcy prediction because detecting samples belonging to the bankrupt class. To balance the dataset, we use the Synthetic Minority Over-sampling technique (SMOTE) proposed by Chawla et al. (Chawla et al., 2002). SMOTE generates synthetic samples using the features of the data. The minority class is oversampled by taking a minority class sample and then a line is drawn from this minority class sample to k-nearest minority class samples. Synthetic minority class samples are generated along the line joining the minority class sample to its minority class neighbours. Additionally, to ensure that our balanced dataset facilitated learning of the bankrupt class, we also used Borderline-SVM SMOTE. Borderline-SVM SMOTE technique uses samples close the decision boundary (support vectors) to create synthetic samples (Nguyen et al., 2011). Finally, we used the Adaptive Synthetic Sampling (ADASYN) algorithm of He, Bai, Garcia and Li to generate samples in regions of feature space where the density of minority samples is low (He et al., 2008). The result was a balanced dataset containing 19902 samples of non-bankrupt class and 20,517 bankrupt class. The balanced dataset has 57 financial ratios (features).\n\nThe balanced dataset was then shuffled and split into training set containing 70% of the samples and test set containing 30% of the samples. The purpose of creating a test set is to test the accuracy of the models on data that the models have not been trained on. Collecting metrics based on the test set gives practitioners an idea of the generalization performance of machine learning models.\n\nThe training data set was fitted into three machine learning models. These models are: Random Forest, Support Vector Machine (SVM) and XGBoost. After fitting, the models were then used to predict for samples in the test set to assess their relative performance.\n\nFor comparing the performance of the models, we decided to use Accuracy score, Receiver Operating Curve (ROC) and Area Under ROC Curve (AUC). Accuracy score can be used because we are training our models using a balanced dataset. However, to get a better idea of the True Positive Rate (TPR) and False Positive Rate (FPR) we decided to employ ROC and AUC metrics as well. It is important to compare the TPR and FPR because it is more to avoid False negatives (FN) as compared to False positives (FP). False negative (FN) would be a firm which would go bankrupt but is wrongly classified by our model as a non-bankrupt sample. False positive (FP) on the other hand would be a firm that is not bankrupt but is wrongly classified as a bankrupt firm.\n\nThe goal of this study is to predict number of bankruptcies within the next 30, 90 and 180 days. We trained 3 different models to predict the number of bankruptcies within 30, 90 and 180 days. The models were built and analysed using the same approach. The only difference was that the training and test labels for each model were derived from the bankruptcy date. For example, to train the model for predicting number of bankruptcies within 30 days, we used\n\nwhere\n\nwhere\n\nelse\n\nTherefore, we trained 9 models to predict bankruptcies within 30, 90 and 180 days. For example, for predicting bankruptcy within 30 days we trained Random Forest, SVM and XGBoost. After training the models, we picked the best model based on performance metrics described in previous section and then we used the best model to predict the number of bankruptcies using the latest Q2 2020 financial ratios from Capital IQ. In this final prediction set, we only kept data for firms which did not have any significant gaps or holes. Finally, we used the final prediction set from Q2 2020 to predict the number of bankruptcies we expect to happen over the next 30, 90 and 180 days.\n\n4.   Results\n\nAs mentioned in the previous section, we trained 9 models, using three different techniques, RF, SVM, XGBoost, for predicting bankruptcies over 30, 90 and 180 days. Next, we used the test set to make predictions and then assessed the relative performance. Based on the chosen metrics of accuracy score and Area under ROC curve (ROC AUC), XGBoost outperformed the other models for predicting bankruptcy within 30, 90 and 180 days. The actual scores for accuracy and AUC are presented in Table 3.\n\nThe accuracy score of XGBoost models is consistently better than SVM and Random Forest. This result is also consistent with the ROC curves which are shown in Figure 2 below.\n\nAs seen in Figure 2, the ROC curve for XGBoost is closest to the top left corner thereby covering maximum area under it. XGBoost is therefore the best performing model closely followed by Random Forest. The fact that these metrics are calculated using the test set (containing data which model has not been trained on) gives us confidence in the ability of our models to generalize.\n\nWe present the performance metrics of previous studies in Table 4. Previous studies have used 2 performance metrics: Test accuracy and Area Under ROC curve (AUC). To keep the comparison consistent, we have computed both test accuracy score and AUC for our models (see Table 3). Our best model built using XGBoost significantly outperforms the models built in previous studies. The accuracy of our XGBoost model for prediction bankruptcy within 180 days is 98.69% which is lower than the test accuracy of our XGBoost models for predicting bankruptcies within 30 and 90 days. However, our model for predicting bankruptcies within 180 days has a higher test accuracy (98.69%) than models built in previous studies. Similarly, our model for predicting bankruptcies within 180 days has an AUC score of 0.99 which is higher than the AUC score reported by previous studies. Our performance metrics of accuracy and AUC score are computed over out of training samples which also indicates to the robustness of our results.\n\nNext, we apply our best model, using XGBoost, to the data from Q2-2020 to evaluate the possibility of a substantial upsurge in business bankruptcies in the second half of 2020 because of the deep 2020 recession caused by the pandemic. We apply this best model to the latest available ratios, for Q2-2020, and classify a firm as going bankrupt during the next 30, 90, or 180 days if the predicted probability of bankruptcy is higher than 0.50.\n\nUsing this method, our best model in each category predicted 74 bankruptcies within 30 days, 189 bankruptcies within 90 days and 354 Bankruptcies within 180 days. This prediction is for all firms contained in the S & P Global database, both public and private. The predictions for the number of bankruptcies are summarized in Table 5.\n\nS & P Global has reported a total of 336 actual bankruptcies until the end of June 2020. If we add our prediction of 354 bankruptcies to the actual bankruptcies, then we predict a total of 336 + 354 = 690 bankruptcies in 2020. We summarize our predictions in Table 6 below.\n\nSince the number of firms in the database changes from year to year, we decided to compare the prediction for 2020 with the past by using bankruptcy rates, i.e., the ratio of the number of bankruptcies to the total number of firms. As shown in Table 7, our prediction of 690 bankruptcies in 2020 represents a bankruptcy rate of 4.35% for all US firms. This rate is the highest in the last 10 years. The second highest rate of 4.2%, only slightly lower, was seen in 2010, in the immediate aftermath of the 2008-09 recession. The average rate during the economic expansion years of 2011–2019 was 3.2%, more than a full percentage point lower than the predicted 2020 rate. We conclude that we will indeed see a much higher rate bankruptcies in 2020, but it is unlikely to be substantially larger than in 2010.\n\n5.   Conclusions\n\nWe find that two different Machine Learning algorithms, Random Forest (RF) and Extreme Gradient Boosting (XGBoost) produce accurate predictions of whether a firm will go bankrupt within the next 30, 90, or 180 days, using financial ratios as input features. The XGBoost based models perform exceptionally well, with 99% out-of-sample accuracy. Our training dataset uses a large database of public US firms over a period of 49 years, 1970–2019, and 57 financial ratios. This study has used a substantially larger training dataset as compared to previous studies.\n\nAn application of our best performing XGBoost model to Q2-2020 financial data for a sample of both private and public U.S. firms shows that the bankruptcy rate will climb substantially higher in 2020 than in the expansion years of 2011–2019. However, our model suggests that the rate will be only marginally higher than in 2010.\n\nWe identify the following areas for further research:\n\n●  Adding macro-economic features—It will be interesting to add macro-economic features to training data used for training machine learning models for bankruptcy prediction.\n\n●  Train deep neural networks with different topologies—Another interesting area of research would be to apply different types of deep neural networks such as TabNet and Recurrent neural networks.\n\nConflict of interest\n\nAll authors declare no conflicts of interest in this paper.\n\nReferences\n\nThis article has been cited by:\n\nTop\n\nA Machine Learning Based Framework For Bankruptcy Prediction In ... : \nInformatica is surveyed by:\n\nA MACHINE LEARNING BASED FRAMEWORK FOR BANKRUPTCY PREDICTION IN CORPORATE FINANCES USING EXPLAINABLE AI TECHNIQUES\n\nForecasting bankruptcy within corporate finances is an indispensable endeavor crucial for sustaining business growth and fostering stability. The paper presents a methodology to redefine the conventional approach to bankruptcy prediction within corporate finance. Through the adept utilization of advanced machine learning techniques, notably classification models, a dynamic and adaptable framework is established, enabling the systematic categorization of companies based on their bankruptcy risk profiles. Moreover, the methodology addresses the inherent challenge of data bias by integrating oversampling techniques like the Synthetic Minority Over-sampling Technique (SMOTE), thereby ensuring a more equitable representation of minority class samples and bolstering the model’s predictive accuracy. The resulting model delivers timely and precise forecasts of bankruptcy risk, fortified by crucial recommendations such as the Altman Z-Score for vulnerability assessment, Debt-to-Equity Ratio for insights into leverage, Quick Ratio for assessing liquidity, and Explainable AI Techniques like SHapley Additive exPlanations (SHAP) analysis for transparent interpretations. This comprehensive approach equips stakeholders with tailored recommendations, empowering them to proactively safeguard their organizations’ financial well-being and avert the perils of bankruptcy. The comparative analysis presented in paper demonstrates that the proposed method assesses the bankruptcy risk more accurately. The integration of Explainable AI techniques and key financial metrics helps the stakeholders to take vital decisions about corporate finances.\n\nMaulana, Didit Johar, Siti Saadah, and Prasti Eko Yunanto. ”Kmeans-SMOTE Integration for Handling Imbalance Data in Classifying Financial Distress Companies using SVM and Na¨ıve Bayes.” Jurnal RESTI (Rekayasa Sistem dan Teknologi Informasi) 8, no. 1 (2024): 54-61.\n\nLiashenko, Olena, Tetyana Kravets, and Yevhenii Kostovetskyi. ”Machine learning and data balancing methods for bankruptcy prediction.” Ekonomika 102, no. 2 (2023): 28-46.\n\nEnkhtuya, Tuguldur, and Dae-Ki Kang. ”Bankruptcy Prediction with Explainable Artificial Intelligence for Early-Stage Business Models.” International Journal of Internet, Broadcasting and Communication 15, no. 3 (2023): 58-65.\n\nFan, Mengting, Zan Mo, Qizhi Zhao, and Zhouyang Liang. ”Innovative Insights into Knowledge-Driven Financial Distress Prediction: a Comprehensive XAI Approach.” Journal of the Knowledge Economy (2023): 1-42.\n\nWahyuni, Sari. ”Prediction of Bankruptcy Levels Using the Almant Z-Method Score in Banking Companies on the Indonesia Stock Exchange for the 2018- 2021 Period.” MANKEU (Jurnal Manajemen Keuangan) 1, no. 2 (2023). https://doi.org/10.61167/mnk.v1i2.39.\n\nLokeshnath, B., and M. Sandhya. ”INSOLVENCY AND BANKRUPTCY CODE: A STUDY OF INDIAN BANKS WITH REFERENCE TO ALTMAN Z SCORE.” EPRA International Journal of Economic and Business Review (JEBR) 11, no. 8 (2023): 69-79.\n\nTran, Kim Long, Hoang Anh Le, Thanh Hien Nguyen, and Duc Trung Nguyen. ”Explainable machine learning for financial distress prediction: evidence from Vietnam.” Data 7, no. 11 (2022): 160.\n\nPavlicko, Michal, Marek Durica, and Jaroslav Mazanec. ”Ensemble model of the financial distress prediction in Visegrad group countries.” Mathematics 9, no. 16 (2021): 1886.\n\nAlam, Talha Mahboob, Kamran Shaukat, Mubbashar Mushtaq, Yasir Ali, Matloob Khushi, Suhuai Luo, and Abdul Wahab. ”Corporate bankruptcy prediction: An approach towards better corporate world.” The Computer Journal 64, no. 11 (2021): 1731- 1746.\n\nAnsari, Abdollah, Ibrahim Said Ahmad, Azuraliza Abu Bakar, and Mohd Ridzwan Yaakub. ”A hybrid metaheuristic method in training artificial neural network for bankruptcy prediction.” IEEE access 8 (2020): 176640-176650.\n\nSoui, Makram, Salima Smiti, Mohamed Wiem Mkaouer, and Ridha Ejbali. ”Bankruptcy prediction using stacked auto-encoders.” Applied Artificial Intelligence 34, no. 1 (2020): 80-100.\n\nFares, Omar H., Irfan Butt, and Seung Hwan Mark Lee. ”Utilization of artificial intelligence in the banking sector: a systematic literature review.” Journal of Financial Services Marketing 28, no. 4 (2023): 835-852.\n\nHanif, Ambreen. ”Towards explainable artificial intelligence in banking and financial services.” arXiv preprint arXiv:2112.08441 (2021).\n\nM, Hiran & G, Megavarshini & Sreenivasan, Aswathy & Suresh, Ma. (2023). Machine Learning in the Banking Sector. 1081-1088. 10.46254/AN13.20230313.\n\nBahoo, Salman, Marco Cucculelli, Xhoana Goga, and Jasmine Mondolo. ”Artificial intelligence in Finance: a comprehensive review through bibliometric and content analysis.” SN Business & Economics 4, no. 2 (2024): 23.\n\nSharma, Bhumiswor, P. Srikanth, and S. Jeevananda. ”Financial Distress and Value Pre mium using Altman Revised Z-score Model.” Vision (2023): 09722629231198604.\n\nCındık, Zeynep & Armutlulu, ˙Ismail. (2021). A revision of Altman Z-Score model and a comparative analysis of Turkish companies’ financial distress prediction. Na tional Accounting Review. 3. 237-255. 10.3934/NAR.2021012.\n\nChen, Tsung-Kang, Hsien-Hsing Liao, Geng Dao Chen, Wei-Han Kang, and Yu-Chun Lin. ”Bankruptcy prediction using machine learn ing models with the text-based communicative value of annual reports.” Expert Systems with Applications 233 (2023): 120714.\n\nKim, Hyeongjun, Hoon Cho, and Doojin Ryu. ”Corporate bankruptcy prediction using machine learning methodologies with a focus on sequential data.” Computational Economics 59, no. 3 (2022): 1231-1249.\n\nDablain, Damien & Krawczyk, Bartosz & Chawla, Nitesh. (2022). DeepSMOTE: Fusing Deep Learning and SMOTE for Imbalanced Data. IEEE Transactions on Neural Networks and Learning Systems. PP. 1-15. 10.1109/TNNLS.2021.3136503.\n\nElreedy, Dina, Amir F. Atiya, and Firuz Kamalov. ”A theoretical distribution analysis of synthetic minority oversampling technique (SMOTE) for imbalanced learning.” Machine Learning (2023): 1-21.\n\nHairani, Hairani, Khurniawan Eko Saputro, and Sofiansyah Fadli. ”K-means-SMOTE untuk menangani ketidakseimbangan kelas dalam klasifikasi penyakit diabetes dengan C4. 5, SVM, dan naive Bayes.” Jurnal Teknologi dan Sistem Komputer 8, no. 2 (2020): 89-93.\n\nSalehi, Amir Reza, and Majid Khedmati. ”A cluster-based SMOTE both-sampling (CSBBoost) ensemble algorithm for classifying imbalanced data.” Scientific Reports 14, no. 1 (2024): 5152. 12 Informatica 45 page 501–yyy V. Chandgadkar et al.\n\nKaggle, US Company Bankruptcy Prediction Dataset, https://www.kaggle.com/datasets/utkarshx27/americancompanies-bankruptcy-prediction-datase\n\nInformatica is financially supported by the Slovenian research agency from the Call for co-financing of scientific periodical publications.\n\nWebmaster: Mario Konecki\n\n© 2015 Slovenian Society Informatika | About | Current issue | Calls for papers | Submission\n\nMachine Learning in Bankruptcy Prediction: A Literature Review : \nMachine Learning in Bankruptcy Prediction: A Literature Review\n\nFiles\n\nAuthors\n\nDate\n\nMajor/Subject\n\nMcode\n\nDegree programme\n\nLanguage\n\nPages\n\nAbstract\n\nSupervisor\n\nThesis advisor\n\nKeywords\n\nPermanent link to this item\n\nCollections\n\nWe collect and process your personal information for the following purposes: Authentication, Preferences, Acknowledgement and Statistics.\n",
        "Machine learning models employed in financial performance optimization": "Advancing Financial Risk Prediction and Portfolio Optimization Using ... : \nAdvancing Financial Risk Prediction and Portfolio Optimization Using Machine Learning Techniques\n\nKeywords:\n\nAbstract\n\nThis study explores the application of machine learning models for predicting financial risk and optimizing portfolio management. We compare various machine learning algorithms, including Random Forest, Gradient Boosting, Long Short-Term Memory (LSTM), and Transformer networks, to assess their effectiveness in forecasting asset returns, managing risk, and enhancing portfolio performance. The results demonstrate that machine learning models significantly outperform traditional financial models in terms of prediction accuracy and risk-adjusted returns. Notably, LSTM and Transformer models excel at capturing long-term dependencies in financial data, leading to more robust predictions and improved portfolio outcomes. Feature selection and preprocessing were crucial in maximizing model performance. Portfolio optimization using machine learning models, when combined with traditional optimization techniques, resulted in superior Sharpe and Sortino ratios. These findings highlight the potential of machine learning to enhance real-time financial decision-making, offering more adaptive and resilient strategies for managing investment portfolios in dynamic market environments. This research provides valuable insights into the integration of machine learning for financial risk prediction and portfolio management, with implications for future advancements in the field.\n\nThe American Journal of Management and Economics Innovations\n\n01\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nTYPE\n\nOriginal Research\n\nPAGE NO.\n\n5-20\n\nDOI\n\n10.37547/tajmei/Volume07Issue01-02\n\nOPEN ACCESS\n\nSUBMITED\n\n16 October 2024\n\nACCEPTED\n\n09 December 2024\n\nPUBLISHED\n\n22 January 2025\n\nVOLUME\n\nVol.07 Issue01 2025\n\nCITATION\n\nAftab Uddin, Md Amran Hossen Pabel, Md Imdadul Alam, FNU\nKAMRUZZAMAN, Md Sayem Ul Haque, Md Monir Hosen, Ashadujjaman\nSajal, Mohammad Rasel Miah, & Sandip Kumar Ghosh. (2025).\nAdvancing Financial Risk Prediction and Portfolio Optimization Using\nMachine Learning Techniques. The American Journal of Management\nand Economics Innovations, 7(01), 5\n\n–\n\n20.\n\nhttps://doi.org/10.37547/tajmei/Volume07Issue01-02\n\nCOPYRIGHT\n\n© 2025 Original content from this work may be used under the terms\nof the creative commons attributes 4.0 License.\n\nAdvancing Financial Risk\nPrediction and Portfolio\nOptimization Using\nMachine Learning\nTechniques\n\nAftab Uddin\n\n1\n\n, Md Amran Hossen Pabel\n\n2\n\n, Md\n\nImdadul Alam\n\n3\n\n, FNU KAMRUZZAMAN\n\n4\n\n, Md Sayem\n\nUl Haque\n\n5\n\n, Md Monir Hosen\n\n6\n\n, Ashadujjaman Sajal\n\n7\n\n,\n\nMohammad Rasel Miah\n\n8\n\n, Sandip Kumar Ghosh\n\n9\n\n1\n\nFox School of Business & Management, Temple University, USA\n\n2\n\nMaster’s of Science in Business Analytics Wright State Univer\n\nsity,\n\nOhio, USA\n\n3\n\nMaster of Science in Financial Analysis, Fox School of Business,\n\nTemple University, USA\n\n4\n\nDepartment of Information Technology Project Management &\n\nBusiness Analytics, St. Francis College, USA\n\n5\n\nMBA in Business Analytics, Gannon University, USA\n\n6\n\nMaster of Business Administration in Supply Chain Management,\n\nUniversity of Houston downtown, USA\n\n7\n\nDepartment of Management Science and Quantitative Methods,\n\nGannon University, USA\n\n8\n\nMBA in Accounting, University of the Potomac, Leesburge pike,\n\nFalls church, Virginia, USA\n\n9\n\nDepartment of Business Administration, University of Surrey,\n\nGuildford, Surrey, GU2 7XH, UK\n\nAbstract:\n\nThis study explores the application of machine\n\nlearning models for predicting financial risk and\noptimizing portfolio management. We compare various\nmachine learning algorithms, including Random Forest,\nGradient Boosting, Long Short-Term Memory (LSTM),\nand Transformer networks, to assess their effectiveness\nin forecasting asset returns, managing risk, and\nenhancing\n\nportfolio\n\nperformance.\n\nThe\n\nresults\n\ndemonstrate that machine learning models significantly\noutperform traditional financial models in terms of\nprediction accuracy and risk-adjusted returns. Notably,\nLSTM and Transformer models excel at capturing long-\nterm dependencies in financial data, leading to more\nrobust predictions and improved portfolio outcomes.\nFeature selection and preprocessing were crucial in\nmaximizing model performance. Portfolio optimization\n\nThe American Journal of Management and Economics Innovations\n\n6\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nThe American Journal of Management and Economics Innovations\n\nusing machine learning models, when combined with\ntraditional optimization techniques, resulted in\nsuperior Sharpe and Sortino ratios. These findings\nhighlight the potential of machine learning to enhance\nreal-time financial decision-making, offering more\nadaptive and resilient strategies for managing\ninvestment\n\nportfolios\n\nin\n\ndynamic\n\nmarket\n\nenvironments. This research provides valuable insights\ninto the integration of machine learning for financial\nrisk prediction and portfolio management, with\nimplications for future advancements in the field.\n\nKeywords:\n\nMachine learning, financial risk prediction,\n\nportfolio optimization, asset returns forecasting, risk-\nadjusted returns, LSTM, Transformer networks,\nfeature selection, model evaluation, investment\nstrategies, financial decision-making, Sharpe ratio,\nSortino ratio, deep learning, predictive analytics,\nfinancial modeling.\n\nIntroduction:\n\nIn the field of finance, accurately\n\npredicting financial risk and managing investment\nportfolios are two of the most crucial tasks for both\nindividual and institutional investors. Traditional\nportfolio management methods, based on historical\nprice data and static assumptions, have proven to be\ninsufficient in handling the complexities and volatility\nof modern financial markets. Over the past few years,\nmachine learning (ML) techniques have gained\nsignificant traction in financial analysis due to their\nability to learn from vast amounts of data, uncover\ncomplex patterns, and generate more accurate\npredictions. Machine learning models such as Logistic\nRegression, Random Forest, Gradient Boosting, Long\nShort-Term Memory (LSTM), and Transformer\nnetworks have been successfully applied to various\ndomains, including financial risk prediction, asset\npricing, and portfolio optimization. These models can\npotentially improve asset selection, enhance risk-\nadjusted returns, and provide more resilient\ninvestment strategies in volatile market environments.\n\nThe aim of this research is to explore the use of\nmachine learning models for predicting financial risk\nand optimizing portfolio management. We focus on\ncomparing various models' ability to forecast asset\nreturns, risk profiles, and portfolio performance,\nevaluating their effectiveness through financial metrics\nlike the Sharpe ratio, Sortino ratio, and maximum\ndrawdown. The study intends to provide a\ncomparative analysis of machine learning models in\nterms of their practical utility for portfolio optimization\nand real-time financial decision-making.\n\nBy applying advanced machine learning techniques, this\npaper explores how asset allocation decisions based on\npredictive models can improve overall portfolio\nperformance, enabling more dynamic and informed\ninvestment strategies. Ultimately, this research aims to\nbridge the gap between traditional portfolio\nmanagement practices and the modern advancements\nin machine learning, offering insights into how financial\nrisk prediction can be improved in real-time for optimal\nportfolio construction.\n\nLITERATURE REVIEW\n\nThe integration of machine learning models into\nfinancial risk prediction and portfolio optimization has\nbecome a significant area of research in the past\ndecade. The financial markets' complexity and\nunpredictability have spurred interest in exploring non-\ntraditional approaches to risk management and\ninvestment strategies. Machine learning models have\nshown great promise in overcoming the limitations of\ntraditional models by providing more accurate forecasts\nand adaptive portfolio strategies.\n\nMachine Learning in Financial Risk Prediction\n\nFinancial risk prediction, particularly in the context of\nstock market volatility and asset price movements, has\nbeen an area of growing interest. Early approaches to\nrisk prediction in finance mainly relied on statistical\nmethods, such as Value at Risk (VaR) and GARCH\nmodels, which assume a constant volatility over time\n(Engle, 2001). However, these models often fail to\ncapture the non-linearity and dynamic nature of\nfinancial markets.In contrast, machine learning\nmethods have demonstrated superior predictive power\ndue to their ability to learn from complex data patterns\nand adapt to changes in the market. For instance,\ndecision trees and ensemble methods like Random\nForest and Gradient Boosting have been employed to\npredict stock price movements and assess market risk.\nStudies by Buhlmann and Hothorn (2007) and Chen et\nal. (2018) showed that these models could outperform\ntraditional methods in terms of accuracy and predictive\ncapability. More advanced techniques, such as deep\nlearning models like LSTM (Hochreiter & Schmidhuber,\n1997), have been applied to time-series data for\nforecasting financial market trends and risk. LSTM\nnetworks are particularly useful for capturing long-term\ndependencies in financial data, which is crucial for\nmodeling stock prices and volatility.\n\nMachine Learning in Portfolio Optimization\n\nPortfolio optimization, traditionally based on the\nModern Portfolio Theory (MPT) by Markowitz (1952),\ninvolves selecting a set of assets that minimizes risk for\na given level of expected return. While MPT has been\nwidely used, its reliance on historical data and\n\nThe American Journal of Management and Economics Innovations\n\n7\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nThe American Journal of Management and Economics Innovations\n\nassumptions about returns and covariance often limits\nits applicability in volatile or unpredictable markets.\n\nMachine learning models have enhanced portfolio\noptimization by incorporating predictive capabilities\ninto the asset allocation process. For example,\nmachine learning-based risk prediction models can\nhelp forecast asset returns more accurately, leading to\nbetter portfolio construction. Various studies have\nexplored the integration of machine learning with\nportfolio optimization techniques. For instance, He et\nal. (2017) applied a neural network model for portfolio\noptimization, showing that combining machine\nlearning predictions with traditional optimization\nmethods\n\ncan\n\nsignificantly\n\nimprove\n\nportfolio\n\nperformance. Other studies have explored deep\nreinforcement learning techniques for dynamic\nportfolio optimization, where agents are trained to\nadjust asset allocations over time based on observed\nreturns and risk (Jiang et al., 2017).\n\nIn particular, LSTM and Transformer models have been\nutilized for time-series forecasting in portfolio\noptimization. LSTM models are adept at handling\nsequential data, making them a powerful tool for\npredicting asset returns over time (Fischer & Krauss,\n2018). Transformer models, which have been\nsuccessful in natural language processing tasks, have\nalso been adapted for financial prediction tasks due to\ntheir ability to capture long-range dependencies and\nhandle large datasets efficiently (Li et al., 2020).\n\nComparative Performance of Machine Learning\nModels in Financial Risk and Portfolio Optimization\n\nSeveral studies have compared the performance of\nvarious machine learning algorithms in financial risk\nprediction and portfolio optimization. In general,\nensemble methods such as Random Forest and\nGradient Boosting have shown strong performance in\nterms of both prediction accuracy and risk\nmanagement. For instance, a study by Zhang et al.\n(2019) demonstrated that Gradient Boosting Machines\n(GBM) outperformed traditional models like ARIMA in\npredicting stock market trends. Similarly, Random\nForest models were shown to be effective in portfolio\nconstruction by selecting the most relevant assets\nbased on predicted returns and risks (Li et al., 2020).\n\nDeep learning models, such as LSTM and Transformer\nnetworks, have also emerged as strong contenders in\nfinancial applications. Studies by Fischer and Krauss\n\n(2018) and Zhang et al. (2020) highlighted that LSTM\nnetworks could predict stock prices more accurately and\nprovide better risk-adjusted returns in portfolio\noptimization. Transformer models, although less\nexplored in finance, have demonstrated strong\npotential in handling sequential financial data and\nimproving the robustness of portfolio optimization\nstrategies (Li et al., 2020).\n\nThe literature review reveals that machine learning\nmodels offer substantial improvements over traditional\nfinancial models in terms of risk prediction and portfolio\noptimization. While methods like Random Forest,\nGradient Boosting, and LSTM have been widely applied\nand shown promising results, newer models such as\nTransformer networks hold great potential in further\nenhancing the accuracy and adaptability of financial risk\nprediction and portfolio management. The next sections\nof this paper will compare the performance of various\nmachine learning models in terms of their predictive\naccuracy,\n\nrisk-adjusted\n\nreturns,\n\nand\n\nportfolio\n\nperformance, providing insights into their practical\napplications in real-world financial settings.\n\nMETHODOLOGY\n\nDataset Collection\n\nWe began by gathering diverse financial datasets from\nreliable and widely used sources, including Bloomberg,\nYahoo Finance, Quandl, and Kaggle. These sources\nprovided us with extensive historical data on stock\nprices, financial ratios, economic indicators, and asset\nperformance across multiple asset classes, including\nequities, bonds, commodities, and cryptocurrencies. To\nenrich our dataset, we incorporated sentiment data\nextracted from financial news platforms and social\nmedia channels, leveraging modern sentiment analysis\ntechniques.\n\nTo ensure robustness and temporal relevance, we\nselected a time horizon of ten years, covering a wide\nrange of market conditions such as bull and bear cycles,\nperiods of economic stability, and crises. Additionally,\nwe integrated macroeconomic variables such as interest\nrates, inflation rates, and GDP growth, which play\ncritical roles in financial risk prediction and portfolio\nmanagement. The collected dataset thus captures a\nholistic view of the financial market landscape, enabling\nus to model both micro and macroeconomic factors\neffectively.\n\nThe American Journal of Management and Economics Innovations\n\n8\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nThe American Journal of Management and Economics Innovations\n\nDataset Attributes Table:\n\nAttribute\n\nDescription\n\nType\n\nSource\n\nDate\n\nTimestamp for each observation.\n\nDate/Time Bloomberg, Yahoo\n\nFinance\n\nAsset Name\n\nName or ticker symbol of the financial asset.\n\nCategorical Bloomberg, Yahoo\n\nFinance\n\nClosing Price\n\nDaily closing price of the asset.\n\nNumeric\n\nYahoo Finance\n\nVolume\n\nDaily trading volume of the asset.\n\nNumeric\n\nYahoo Finance\n\nMoving Average\n(MA)\n\nTechnical indicator capturing average price\nover a specified period.\n\nNumeric\n\nCalculated\n\nRelative Strength\nIndex (RSI)\n\nMomentum oscillator measuring speed and\nchange of price movements.\n\nNumeric\n\nCalculated\n\nSentiment Score\n\nAggregated sentiment derived from news and\nsocial media using NLP techniques.\n\nNumeric\n\nNews APIs, Social\nMedia\n\nGDP Growth Rate\n\nQuarterly GDP growth rate, indicative of\neconomic performance.\n\nNumeric\n\nWorld Bank,\nQuandl\n\nInflation Rate\n\nConsumer Price Index (CPI)-based inflation\nrates.\n\nNumeric\n\nQuandl\n\nRisk-Free Rate\n\nYield on a risk-free asset, such as U.S.\nTreasury bills.\n\nNumeric\n\nBloomberg\n\nDataset Preprocessing\n\nPreprocessing the dataset is a crucial step to ensure\nthe quality, consistency, and usability of the data\nbefore applying machine learning models. In our study,\nwe invested significant effort in refining the raw data\nto prepare it for further analysis and modeling.The first\nstep involved handling missing values, which are\ncommon in financial datasets due to market holidays,\nincomplete reporting, or data retrieval issues. We\nadopted different strategies based on the type and\nsignificance of the missing values. For time-series data,\nsuch as asset prices, we utilized forward-fill and\nbackward-fill methods to interpolate missing entries\nwithout disrupting the temporal trends. For\nmacroeconomic indicators with sporadic missing\nvalues, we applied linear interpolation or filled gaps\nusing averages from similar periods. If a feature had an\nexcessive number of missing values (greater than 30%\nof the dataset), we carefully evaluated its relevance\nand either removed it or imputed values using\nadvanced methods like K-Nearest Neighbors (KNN)\nimputation.\n\nOutlier detection and handling were essential to avoid\ndistortions caused by extreme data points. We\nidentified outliers using statistical techniques such as\nz-scores and interquartile ranges (IQR). Once\nidentified, we decided on appropriate treatments\nbased on the context. For instance, we capped outliers\nwithin a predefined range for variables where extreme\nvalues were possible but unlikely to hold predictive\n\nvalue, such as abnormal trading volumes during market\ncrises. In cases where outliers were due to errors or\nanomalies, we replaced them with median values or\nremoved the corresponding records.\n\nNormalization and standardization were applied to\nnumerical features to ensure they were on a\ncomparable scale. Financial variables such as asset\nprices and trading volumes often span different orders\nof magnitude, which can bias machine learning models\nthat rely on distance-based metrics. We standardized\nnumerical features using z-score normalization to\ncenter the data around zero with unit variance.\nAdditionally, log transformation was applied to skewed\nfeatures like asset prices to reduce the impact of heavy\ntails and achieve a more symmetrical distribution.\n\nFor categorical features, such as asset names and\nindustry classifications, we employed encoding\ntechniques to convert them into machine-readable\nformats. One-hot encoding was used for nominal\ncategories to create binary variables without\nintroducing ordinal relationships. For high-cardinality\nfeatures, we grouped less frequent categories into an\n\n“Other” category to reduce dimensionality and\n\ncomputational overhead.\n\nTo ensure temporal alignment, we synchronized all\ntime-series data across multiple sources. This step\ninvolved aggregating daily, weekly, and monthly data to\na common frequency suitable for our analysis. We also\nadjusted timestamps to account for differences in time\nzones and market hours. Special care was taken to\n\nThe American Journal of Management and Economics Innovations\n\n9\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nThe American Journal of Management and Economics Innovations\n\nhandle events such as stock splits, dividend payouts,\nand mergers, which required adjustments to historical\nprices to maintain consistency.\n\nData augmentation was another strategy we employed\nto expand the dataset and capture a broader range of\nscenarios. By generating synthetic data using\nbootstrapping and resampling methods, we improved\nthe robustness of our models in handling diverse\nmarket conditions.\n\nFeature Engineering\n\nFeature engineering was a cornerstone of our\nmethodology, allowing us to derive meaningful\ninsights from raw data and enhance the predictive\npower of our models. This process involved creating\nnew variables, transforming existing ones, and\nincorporating domain-specific knowledge to capture\ncomplex relationships within the financial data.A\nprimary focus of feature engineering was the\nextraction of technical indicators commonly used in\nfinancial analysis. These indicators included moving\naverages (e.g., simple, exponential, and weighted),\nBollinger Bands, and the Relative Strength Index (RSI),\nwhich capture price trends, volatility, and momentum,\nrespectively. We calculated these indicators using\nvarying window lengths to capture both short-term\nand long-term market dynamics.\n\nTo complement technical indicators, we developed\nfeatures based on trading activity, such as average\ndaily volume, volume-price trends, and on-balance\nvolume (OBV). These features provided insights into\nmarket sentiment and the intensity of trading\nbehavior, which are critical for predicting asset\nperformance.\n\nSentiment analysis was another key aspect of our\nfeature engineering. We leveraged natural language\nprocessing (NLP) techniques to analyze textual data\nfrom financial news articles, analyst reports, and social\nmedia posts. Using tools like VADER (Valence Aware\nDictionary and sEntiment Reasoner) and BERT\n(Bidirectional\n\nEncoder\n\nRepresentations\n\nfrom\n\nTransformers), we quantified sentiment polarity and\nintensity. For example, we created sentiment scores\nthat reflected market optimism or pessimism and\ntracked their changes over time. Additionally, we used\ntopic modeling to identify recurring themes in financial\ndiscourse, su\n\nch as “interest rate hikes” or “earnings\n\nexpectations,” and incorporated these as categorical\n\nfeatures.\n\nTo account for temporal dependencies, we engineered\nlagged variables and rolling window statistics. Lagged\nvariables represented past values of features (e.g., the\n\nprevious day’s closing price), enabling our models to\n\nlearn temporal patterns. Rolling statistics, such as\n\nrolling averages and rolling standard deviations,\ncaptured trends and variability over specific time\nhorizons. These features were particularly valuable in\ndetecting shifts in market behavior and predicting\nfuture risks.\n\nInteraction terms were introduced to model complex\nrelationships between variables. For instance, we\ncreated interaction features between macroeconomic\nindicators (e.g., inflation rate) and asset-specific\nvariables (e.g., sector performance) to capture the joint\neffects of external factors and market conditions.\nPolynomial features were also explored to account for\nnon-linear relationships in the data.\n\nDimensionality reduction techniques were employed to\nenhance the interpretability and efficiency of our\nmodels. Principal Component Analysis (PCA) was used\nto condense highly correlated features, such as\ntechnical indicators derived from similar time windows,\ninto fewer components while retaining the majority of\nthe variance.\n\nFinally, we incorporated external datasets to enhance\nthe richness of our features. For example, we used\nweather data to model agricultural commodity\nperformance and geopolitical data to assess risks in\nemerging markets. These additional features provided a\nmore comprehensive view of the factors influencing\nfinancial risks and portfolio returns. By applying these\nadvanced\n\nfeature\n\nengineering\n\ntechniques, we\n\ntransformed our raw dataset into a robust and insightful\nrepresentation of the financial landscape, enabling our\nmodels to achieve superior performance in predicting\nrisks and optimizing portfolios.\n\nFeature Selection\n\nFeature selection is a vital component of our\nmethodology, as it helps to identify the most relevant\nand influential variables from the engineered features\nwhile minimizing redundancy and noise. By selecting an\noptimal subset of features, we aimed to enhance the\ninterpretability and predictive accuracy of our machine\nlearning models while reducing computational\ncomplexity and the risk of overfitting. The feature\nselection process began with a thorough exploratory\ndata analysis (EDA) to assess the statistical properties\nand relationships between features and the target\nvariable. We calculated correlation matrices to identify\nhighly correlated features and utilized visualizations\nsuch as heatmaps and pair plots to better understand\nthese relationships. Features with extremely high\nmulticollinearity (e.g., correlation coefficients greater\nthan 0.85) were flagged for removal or transformation,\nas their inclusion could distort model performance.\n\nNext, we employed statistical tests to evaluate the\nsignificance of individual features. For continuous\n\nThe American Journal of Management and Economics Innovations\n\n10\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nThe American Journal of Management and Economics Innovations\n\nvariables, we conducted univariate tests such as the t-\ntest and ANOVA to measure the variance explained by\neach feature in relation to the target variable. For\ncategorical features, chi-square tests were used to\nassess the independence of features from the target\nvariable. Features that did not demonstrate statistical\nsignificance at a predefined threshold (e.g., p-value <\n0.05) were considered for exclusion. To automate the\nfeature selection process and ensure consistency, we\nused algorithmic techniques such as Recursive Feature\nElimination (RFE). RFE iteratively ranked features by\ntraining the model and removing the least important\nfeature at each step. This process was conducted in\nconjunction with a robust machine learning algorithm,\nsuch as Random Forest or Support Vector Machine, to\nensure reliable feature importance ranking.\n\nAdditionally,\n\nwe\n\napplied\n\ntree-based\n\nfeature\n\nimportance ranking using ensemble methods like\nRandom Forest and Gradient Boosted Trees (e.g.,\nXGBoost and LightGBM). These methods assigned\nimportance scores to each feature based on their\ncontribution to reducing model error. Features with\nlow importance scores were either removed or flagged\nfor further evaluation.\n\nAnother technique we implemented was Lasso\nRegression, a regularized regression method that uses\nL1 penalty to shrink less important coefficients to zero.\nLasso Regression helped us identify and retain only the\nmost impactful features while naturally excluding\nirrelevant or redundant variables.\n\nDimensionality reduction was also explored as part of\nthe feature selection process. Principal Component\nAnalysis (PCA) was used to reduce the dimensionality\nof the dataset by transforming correlated features into\nuncorrelated principal components. While PCA is not\ninherently interpretable, it was particularly useful for\nreducing the computational burden in models sensitive\nto high dimensionality, such as deep learning models.\n\nWe also considered domain knowledge in the feature\nselection process, ensuring that the selected features\naligned with established financial theories and\npractices. For instance, technical indicators like moving\naverages and RSI were prioritized due to their proven\nrelevance in predicting market trends. Similarly,\nmacroeconomic indicators such as GDP growth rate\nand inflation were retained based on their historical\nimpact on financial risk and portfolio performance.\nThrough this multi-step feature selection process, we\nrefined the dataset to include only the most relevant\nand informative features, striking a balance between\nmodel performance and interpretability.\n\nModel Training\n\nModel training formed the core of our methodology,\n\nas it enabled us to leverage advanced machine learning\ntechniques to predict financial risks and optimize\nportfolio management strategies. This stage involved\nselecting\n\nappropriate\n\nalgorithms,\n\noptimizing\n\nhyperparameters, and ensuring that the models\ngeneralize well to unseen data. We began by dividing\nthe dataset into training and testing subsets. To\nmaintain temporal integrity in the financial data, we\nused a time-based split rather than random sampling.\nThe training set comprised historical data, while the\ntesting set represented more recent data, allowing us to\nsimulate\n\nreal-world\n\nscenarios\n\nwhere\n\nfuture\n\nperformance is predicted based on past information.\n\nTo address potential overfitting and ensure robust\nmodel evaluation, we implemented time-series cross-\nvalidation using a walk-forward validation approach. In\nthis method, the training window progressively\nexpanded with each iteration, while the testing window\nmoved forward in time. This technique allowed us to\nassess the model's performance under varying market\nconditions and ensured that the models did not rely on\nhindsight bias. We explored a range of machine learning\nalgorithms to identify the best-performing models for\nour specific problem. These algorithms included linear\nmodels\n\nlike\n\nLogistic\n\nRegression\n\nfor\n\nbaseline\n\ncomparisons, tree-based ensemble methods like\nRandom Forest and Gradient Boosted Trees, and\nadvanced techniques such as Support Vector Machines\n(SVMs) and Neural Networks. For time-series\nforecasting tasks, we utilized specialized models like\nLong Short-Term Memory (LSTM) networks and ARIMA.\n\nHyperparameter tuning played a critical role in\noptimizing model performance. Using grid search and\nrandomized search techniques, we systematically\ntested different combinations of hyperparameters for\neach algorithm. For instance, we tuned the depth and\nnumber of trees in Random Forest, learning rate and\nnumber of estimators in Gradient Boosted Trees, and\nkernel functions in SVMs. For deep learning models, we\nexperimented with network architecture, activation\nfunctions, and learning rates to achieve optimal results.\n\nTo ensure model robustness, we incorporated\nregularization techniques such as L1 and L2 penalties in\nlinear models and dropout layers in neural networks.\nRegularization helped prevent overfitting by penalizing\noverly complex models and encouraging simplicity.\n\nFeature scaling was an integral part of model training,\nparticularly for algorithms sensitive to the scale of input\ndata, such as SVMs and Neural Networks. We\nnormalized or standardized the features as needed,\nensuring that all variables contributed equally to the\nmodel's predictions. Evaluation metrics were carefully\nselected based on the problem domain and target\n\nThe American Journal of Management and Economics Innovations\n\n11\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nThe American Journal of Management and Economics Innovations\n\nobjectives. For classification tasks, we used metrics like\naccuracy, precision, recall, F1-score, and Area Under\nthe Receiver Operating Characteristic Curve (AUC-\nROC). For regression and forecasting tasks, metrics like\nMean Absolute Error (MAE), Mean Squared Error\n(MSE), and Root Mean Squared Error (RMSE) were\nemployed.\n\nFinally, we implemented an ensemble approach to\ncombine the strengths of multiple models. By\naggregating predictions from diverse algorithms using\ntechniques like voting, stacking, and bagging, we\nachieved better generalization and reduced the risk of\nrelying on a single model.\n\nThrough rigorous training, validation, and testing\nprocesses, we developed a suite of machine learning\nmodels capable of accurately predicting financial risks\nand informing portfolio management decisions. These\nmodels were fine-tuned to ensure robustness,\ninterpretability, and adaptability to changing market\ndynamics.\n\nPortfolio Optimization\n\nPortfolio optimization is a critical aspect of our\nmethodology, aimed at constructing an investment\nportfolio that balances risk and return according to\nspecified financial goals and constraints. Using insights\nderived from machine learning predictions, we\ndesigned a systematic framework to allocate assets\nefficiently while minimizing financial risks.We began by\ndefining the optimization objective, which typically\ncenters on maximizing the portfolio's expected return\nfor a given level of risk or minimizing risk for a targeted\nreturn. For this purpose, we leveraged the Modern\nPortfolio Theory (MPT) framework developed by Harry\nMarkowitz, which emphasizes diversification to reduce\nportfolio volatility. The optimization was modeled\nmathematically using the mean-variance optimization\napproach, where the expected returns and covariances\nof asset returns were central components.\n\nTo estimate expected returns, we utilized machine\nlearning models trained on historical financial data.\nThese models generated predictions for future price\nmovements or return rates, providing a more dynamic\nand data-driven approach compared to traditional\nforecasting methods. For risk estimation, we\ncalculated the covariance matrix of asset returns,\nincorporating real-time market data to ensure\naccuracy and responsiveness to current trends.\nIncorporating constraints into the optimization process\nwas an essential step to reflect real-world investment\nconditions. Constraints included limits on individual\nasset weights (e.g., no single asset exceeding 20% of\nthe portfolio), sector-specific caps to avoid over-\nconcentration, and minimum allocations to low-risk\n\nassets like bonds or index funds. Additional constraints,\nsuch as transaction costs and tax implications, were\nconsidered to make the optimization more practical for\nimplementation.\n\nTo solve the optimization problem, we employed\nadvanced algorithms beyond the traditional quadratic\nprogramming methods. Genetic algorithms and particle\nswarm optimization were explored to handle the non-\nlinearities and multiple objectives often present in real-\nworld portfolios. These heuristic approaches provided\nmore flexibility in navigating complex solution spaces,\nparticularly for large portfolios with diverse asset\nclasses.Risk-adjusted performance metrics, such as the\nSharpe Ratio, Sortino Ratio, and Treynor Ratio, were\nused to evaluate the optimized portfolios. These metrics\nallowed us to compare the performance of different\nportfolio configurations while accounting for risk.\nAdditionally, stress testing was conducted by simulating\nextreme market scenarios to assess how the portfolio\nwould perform under adverse conditions, such as\nfinancial crises or sudden economic downturns.\n\nWe further enhanced the optimization process by\nincorporating dynamic rebalancing strategies. Based on\nmachine learning predictions, the portfolio was\nperiodically adjusted to respond to changing market\nconditions, ensuring that it remained aligned with the\ninvestment objectives. For instance, during periods of\nheightened market volatility, the model could\nrecommend shifting allocations toward more stable\nassets like government bonds or defensive stocks.\nFinally, we integrated ethical and environmental\nconsiderations into the optimization process by\nincorporating ESG (Environmental, Social, and\nGovernance) scores. Assets with strong ESG\nperformance were prioritized, aligning the portfolio\nwith sustainable and socially responsible investment\n\npractices. This not only enhanced the portfolio’s appeal\n\nto modern investors but also ensured long-term\nalignment with global sustainability goals.\n\nBy combining advanced machine learning techniques\nwith traditional financial theories, our portfolio\noptimization methodology offered a robust, adaptable,\nand data-driven approach to achieving optimal\ninvestment outcomes.\n\nModel Evaluation, Robustness, and Sensitivity Analysis\n\nModel evaluation, robustness testing, and sensitivity\nanalysis were critical components of our methodology,\nensuring that the developed models were not only\naccurate but also reliable and resilient under varying\nconditions. These steps were essential for validating the\nutility of the models in predicting financial risks and\noptimizing portfolio management.\n\nThe American Journal of Management and Economics Innovations\n\n12\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nThe American Journal of Management and Economics Innovations\n\nModel Evaluation\n\nWe employed a rigorous evaluation framework to\nassess the predictive performance of our models. The\nevaluation process began with selecting appropriate\nmetrics based on the nature of the prediction task. For\nclassification models predicting financial risks, metrics\nsuch as accuracy, precision, recall, F1-score, and the\nArea Under the Receiver Operating Characteristic\nCurve (AUC-ROC) were used. For regression models\nforecasting returns or risk levels, metrics like Mean\nAbsolute Error (MAE), Mean Squared Error (MSE), Root\nMean Squared Error (RMSE), and R-squared were\ncalculated.\n\nCross-validation techniques were implemented to\nensure that the evaluation metrics were not biased by\noverfitting or data leakage. For time-series data, we\nused walk-forward validation, where the training\nwindow was incrementally expanded, and the test\nwindow moved forward in time. This approach\nsimulated real-world conditions where predictions are\nmade on unseen future data, ensuring the robustness\nof the evaluation process.\n\nWe also compared the performance of our machine\nlearning models against baseline models, such as linear\nregression and naive predictors. This comparison\nallowed us to quantify the added value of our\nadvanced models and ensure that the observed\nimprovements were meaningful and statistically\nsignificant.\n\nRobustness Testing\n\nRobustness testing was conducted to ensure that the\nmodels performed consistently across diverse\nscenarios and were not overly sensitive to minor\nperturbations in the data. To achieve this, we\nintroduced controlled variations into the dataset, such\nas adding noise to input features or simulating missing\ndata. The models were then re-evaluated to assess\ntheir stability and resilience under these altered\nconditions.\n\nAdditionally, we conducted out-of-sample testing\nusing data from different time periods or market\nconditions. For instance, models trained on pre-\npandemic data were tested on post-pandemic\nscenarios to evaluate their adaptability to sudden\nmarket shifts. Stress testing was another key\ncomponent, where we simulated extreme market\nconditions, such as rapid interest rate changes or\ngeopolitical shocks, to evaluate the models' ability to\nmaintain predictive accuracy.\n\nSensitivity Analysis\n\nSensitivity analysis was performed to understand the\n\nimpact of individual features on model predictions and\nto ensure the interpretability of the results. This process\ninvolved systematically varying one feature at a time\nwhile holding others constant and observing the\nresulting changes in the model's output. Features that\nhad a disproportionate influence on predictions were\nflagged for further scrutiny.\n\nFeature importance scores from tree-based models,\nsuch as Random Forest and XGBoost, were used to\nquantify the relative importance of each feature. SHAP\n(Shapley Additive Explanations) values were also\ncalculated to provide a more detailed and interpretable\nanalysis of feature contributions. SHAP values allowed\nus to explain individual predictions by attributing them\nto specific features, enhancing transparency and trust in\nthe model.\n\nTo ensure fairness and avoid potential biases in the\nmodel, we conducted fairness testing by evaluating the\nperformance of the models across different subgroups,\nsuch as asset classes, industries, or geographic regions.\nAny observed discrepancies were addressed by\nadjusting the training process or rebalancing the\ndataset. Through this comprehensive evaluation\nframework, we ensured that our models were accurate,\nrobust, and interpretable, capable of delivering reliable\ninsights for financial risk prediction and portfolio\nmanagement under a wide range of conditions.\n\nResults\n\nThe results of our study demonstrate the efficacy of\nmachine learning models in predicting financial risk and\noptimizing portfolio management. Our analysis includes\ndetailed performance metrics, a comparative study,\ninsights into real-time applicability, and implications for\ninvestment strategies. This section delves into model\nperformance across various tasks, identifies the best-\nperforming approach, and explores the practical\nrelevance of these findings in real-world applications.\n\nDataset Overview\n\nThe dataset used for this study provided a\ncomprehensive\n\nset\n\nof\n\nfinancial\n\nattributes,\n\nencompassing macroeconomic indicators, historical\nmarket data, and sector-specific metrics. Key variables\nsuch as price movements, trading volumes, interest\nrates, and corporate performance measures were\nincluded to ensure the models could effectively capture\nthe nuances of financial risk. After preprocessing and\nfeature selection, the dataset comprised 25 high-quality\nfeatures and a target variable representing financial risk\nor expected returns. This robust dataset served as the\nfoundation for building and evaluating the machine\nlearning models.\n\nThe American Journal of Management and Economics Innovations\n\n13\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nThe American Journal of Management and Economics Innovations\n\nModel Performance\n\nClassification Task: Predicting Financial Risk\n\nTo predict financial risk, we framed the problem as a binary classification task and evaluated models using metrics\nsuch as accuracy, precision, recall, F1-score, and Area Under the Curve for Receiver Operating Characteristics\n(AUC-ROC). The results are summarized below:\n\nModel\n\nAccuracy Precision Recall F1-Score AUC-ROC\n\nLogistic Regression\n\n82.4%\n\n81.5%\n\n79.8% 80.6%\n\n0.85\n\nRandom Forest\n\n88.7%\n\n87.9%\n\n86.3% 87.1%\n\n0.91\n\nGradient Boosting\n\n91.2%\n\n90.4%\n\n89.6% 90.0%\n\n0.94\n\nSupport Vector Machine 85.6%\n\n84.8%\n\n83.2% 84.0%\n\n0.88\n\nLSTM\n\n93.4%\n\n92.7%\n\n91.5% 92.1%\n\n0.96\n\nTransformer\n\n94.8%\n\n94.1%\n\n93.0% 93.5%\n\n0.97\n\nThe Transformer-based model delivered the best\nperformance across all classification metrics, with an\naccuracy of 94.8% and an AUC-ROC of 0.97. This\nindicates its exceptional ability to distinguish between\n\nhigh-risk and low-risk scenarios. The LSTM model also\nperformed well, particularly in recall (91.5%), making it\nsuitable for applications where identifying high-risk\ncases is critical.\n\nChart 1: Model Evaluation\n\nRegression Task: Return Forecasting\n\nFor return forecasting, we treated the problem as a regression task and evaluated models using Mean Absolute\nError (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and R-squared. The table below\nsummarizes the results:\n\nModel\n\nMAE MSE RMSE R-squared\n\nLinear Regression 1.72% 0.045 0.067\n\n0.84\n\nRandom Forest\n\n1.28% 0.031 0.056\n\n0.91\n\nGradient Boosting 1.12% 0.027 0.052\n\n0.93\n\nLSTM\n\n0.98% 0.021 0.046\n\n0.95\n\nTransformer\n\n0.91% 0.018 0.042\n\n0.97\n\nThe Transformer-based model excelled in return\nforecasting, achieving the lowest error rates (MAE:\n0.91%, RMSE: 0.042) and the highest R-squared value\n\n(0.97). This demonstrates its ability to provide accurate\nand reliable predictions for financial returns. The LSTM\nmodel followed closely, reflecting its effectiveness in\n\n82.4\n\n0%\n\n88.7\n\n0%\n\n91.2\n\n0%\n\n85.6\n\n0%\n\n93.4\n\n0%\n\n94.8\n\n0%\n\n81.5\n\n0%\n\n87.9\n\n0%\n\n90.4\n\n0%\n\n84.8\n\n0%\n\n92.7\n\n0%\n\n94.1\n\n0%\n\n79.8\n\n0%\n\n86.3\n\n0%\n\n89.6\n\n0%\n\n83.2\n\n0%\n\n91.5\n\n0%\n\n93.0\n\n0%\n\n80.6\n\n0%\n\n87.1\n\n0%\n\n90.0\n\n0%\n\n84.0\n\n0%\n\n92.1\n\n0%\n\n93.5\n\n0%\n\n0.85\n\n0.91\n\n0.94\n\n0.88\n\n0.96\n\n0.97\n\nL O G I S T I C\n\nR E G R E S S I O N\n\nR A N D O M F O R E S T\n\nG R A D I E N T\n\nB O O S T I N G\n\nS U P P O R T\n\nV E C T O R\n\nM A C H I N E\n\nL S T M\n\nT R A N S F O R M E R\n\nMODEL EVALUATION\n\nAccuracy\n\nPrecision\n\nRecall\n\nF1-Score\n\nAUC-ROC\n\nThe American Journal of Management and Economics Innovations\n\n14\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nThe American Journal of Management and Economics Innovations\n\ncapturing temporal dependencies in financial data.\n\nComparative Analysis\n\nA comparative analysis of the models revealed key\ninsights:\n\n1.\n\nPerformance Superiority of Transformers:\n\nTransformers consistently outperformed other models\nin both classification and regression tasks. Their ability\nto handle sequential and high-dimensional data,\ncoupled with their powerful attention mechanisms,\nmade them the most robust and reliable models for\nfinancial risk prediction and return forecasting.\n\n2.\n\nStrengths of LSTMs:\n\nLSTMs also delivered strong performance, particularly\nin scenarios involving time-series data. Their\neffectiveness in recall and low error rates makes them\nan excellent choice for tasks requiring detailed\ntemporal analysis.\n\n3.\n\nTraditional Models as Baselines:\n\nWhile traditional models like Logistic Regression,\nRandom Forest, and Gradient Boosting were\noutperformed by deep learning models, they still\noffered value in terms of simplicity and interpretability.\nThese models can be particularly useful in\nenvironments where computational resources are\nlimited, or transparency is a priority.\n\nReal-Time Applicability\n\nIn real-time applications, the Transformer model\ndemonstrated the best balance of speed and accuracy,\nmaking it ideal for dynamic financial markets. Its\nscalability and ability to process large datasets\nefficiently ensured seamless integration into portfolio\nmanagement systems.\n\nPortfolio Optimization Results\n\nThe application of machine learning-based risk\nprediction and return forecasting models to portfolio\noptimization marked a significant advancement in\nenhancing investment strategies. By integrating\npredictions from our best-performing models\n\n—\n\nspecifically the Transformer and LSTM models\n\n—\n\ninto\n\ntraditional portfolio optimization frameworks, we\nwere able to achieve superior risk-adjusted returns. In\nthis section, we discuss in-depth the results of the\nportfolio optimization process, comparing the\nperformance of different models in terms of Sharpe\nratio, Sortino ratio, and other key metrics. We also\nexplore the impact of incorporating machine learning\npredictions into portfolio management, emphasizing\ntheir real-world value for both institutional and\n\nindividual investors.\n\nPortfolio Construction Approach\n\nTo optimize the portfolio, we used a mean-variance\noptimization approach, which minimizes risk (variance)\nfor a given level of expected return. The portfolio\nconstruction involved the following steps:\n\n1.\n\nRisk Prediction: The risk associated with each\nasset was predicted using the classification\nmodels, and a risk probability was assigned to\neach asset. This served as the basis for\ndetermining which assets to include in the\nportfolio, as well as their expected performance\nunder different market conditions.\n\n2.\n\nReturn Forecasting: The return of each asset\nwas predicted using the regression models, with\na focus on short-term (daily, weekly) and long-\nterm (monthly, yearly) returns. The predicted\nreturns provided an estimate of future\nperformance, serving as a critical input into the\nportfolio optimization process.\n\n3.\n\nAsset Allocation: Using the predicted risk and\nreturn values from the machine learning\nmodels, we applied the Markowitz mean-\nvariance optimization technique to find the\noptimal allocation of capital across the available\nassets. The goal was to achieve the highest\nexpected return for a given level of risk.\n\n4.\n\nRisk Constraints: We incorporated various risk\nconstraints, including maximum exposure to\nindividual assets, sector-specific risk limits, and\noverall portfolio volatility constraints. These risk\nparameters were dynamically adjusted based\non real-time predictions provided by the\nmodels.\n\nPerformance Metrics for Portfolio Optimization\n\nThe effectiveness of portfolio optimization is often\nmeasured by key financial metrics, such as the Sharpe\nratio, Sortino ratio, and maximum drawdown. These\nmetrics are used to assess the risk-adjusted returns and\nthe downside risk of a portfolio.\n\nSharpe Ratio\n\nThe Sharpe ratio measures the excess return per unit of\nrisk (standard deviation). A higher Sharpe ratio indicates\nbetter risk-adjusted performance. In this study, the\nTransformer model-led portfolios consistently delivered\nsuperior\n\nSharpe\n\nratios,\n\nindicating\n\nthat\n\nthey\n\noutperformed traditional models in terms of return\nrelative to risk.\n\nThe American Journal of Management and Economics Innovations\n\n15\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nThe American Journal of Management and Economics Innovations\n\nModel\n\nSharpe Ratio\n\nLogistic Regression 1.21\nRandom Forest\n\n1.36\n\nGradient Boosting\n\n1.48\n\nLSTM\n\n1.59\n\nTransformer\n\n1.72\n\nAs seen in the table above, portfolios optimized with\nTransformer predictions achieved the highest Sharpe\nratio of 1.72, compared to other models, which ranged\nfrom 1.21 to 1.59. This demonstrates the value of\nincorporating advanced machine learning models in\nportfolio construction for enhancing risk-adjusted\nreturns.\n\nSortino Ratio\n\nThe Sortino ratio is a modification of the Sharpe ratio,\nwhich focuses on downside risk (i.e., negative volatility)\nrather than total risk. It is particularly useful for\nassessing portfolios in the context of limiting large\nlosses. A higher Sortino ratio indicates that a portfolio\nhas a better risk-reward profile with respect to negative\noutcomes.\n\nModel\n\nSortino Ratio\n\nLogistic Regression 1.43\nRandom Forest\n\n1.58\n\nGradient Boosting\n\n1.73\n\nLSTM\n\n1.89\n\nTransformer\n\n2.05\n\nThe Transformer-based portfolios achieved the highest\nSortino ratio of 2.05, which suggests that they not only\nperformed well in terms of risk-adjusted returns but\nalso excelled at minimizing downside risk. This is a\ncrucial feature for investors who are focused on\nprotecting their portfolios from large losses.\n\nMaximum Drawdown\n\nMaximum drawdown refers to the largest peak-to-\ntrough decline in the portfolio's value, reflecting the\nworst-case scenario for investors during a specific\nperiod. A lower maximum drawdown indicates that a\nportfolio is less susceptible to severe losses.\n\nModel\n\nMaximum Drawdown (%)\n\nLogistic Regression -12.3%\nRandom Forest\n\n-10.8%\n\nGradient Boosting\n\n-9.7%\n\nLSTM\n\n-7.2%\n\nTransformer\n\n-5.9%\n\nPortfolios constructed using Transformer predictions\nexperienced the smallest maximum drawdown of -\n5.9%, making them the most resilient to market\ndownturns. This aligns with the improved risk\nmanagement associated with machine learning\npredictions.\n\nReal-Time Portfolio Optimization\n\nThe Transformer model’s ability to predict both risk\n\nand return with high accuracy allowed for a dynamic\nportfolio optimization strategy. By continuously\nadjusting asset allocations based on updated\npredictions, the Transformer model-powered portfolio\ncould react to real-time market changes, such as\neconomic shifts or corporate news events, and\noptimize investments accordingly. This real-time\nrebalancing allowed the portfolio to capture emerging\n\nopportunities and mitigate potential risks promptly.\n\nIn contrast, traditional optimization approaches that\nrely solely on historical data or static assumptions did\nnot perform as well in volatile market conditions. As\n\ndemonstrated, the Transformer model’s superior\n\npredictive power allowed for better adaptation to\nmarket fluctuations, providing a more robust\ninvestment strategy.\n\nSensitivity to Market Conditions\n\nOur analysis of portfolio performance across different\nmarket conditions further emphasized the strengths of\nmachine learning-based optimization. We tested the\nportfolios in a variety of simulated market\nenvironments, such as high volatility, low interest rates,\nand market corrections, to understand their resilience\nand adaptability. The Transformer model consistently\n\nThe American Journal of Management and Economics Innovations\n\n16\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nThe American Journal of Management and Economics Innovations\n\nprovided the most stable and profitable portfolios,\neven in challenging market conditions.\n\nAdditionally, sensitivity analysis revealed that the\nTransformer model exhibited robustness in terms of\nasset allocation, where the optimal distribution of\nassets remained largely unaffected by minor\nfluctuations in predicted returns or market volatility.\nThis characteristic is particularly valuable for long-term\ninvestors who are seeking consistent performance\nwithout the need for frequent adjustments.\n\nThe results of our portfolio optimization study\nhighlight the significant advantages of integrating\nmachine learning predictions into investment\nstrategies.\n\nThe\n\nTransformer-based\n\nmodel\n\noutperformed traditional methods across key metrics,\ndelivering higher Sharpe and Sortino ratios, lower\nmaximum drawdowns, and more robust performance\nunder various market conditions. By leveraging real-\ntime predictions, the Transformer model allowed for\nmore adaptive and resilient portfolio construction,\nwhich can offer significant benefits in dynamic financial\nenvironments. This validates the potential of machine\nlearning\n\nto\n\ntransform\n\ntraditional\n\nportfolio\n\nmanagement practices, offering investors better risk\nmanagement, enhanced returns, and improved overall\nportfolio performance.\n\nCONCLUSION\n\nThis study has explored the application of machine\nlearning models for predicting financial risk and\noptimizing\n\nportfolio management,\n\noffering\n\na\n\ncomprehensive comparative analysis of various\nalgorithms in real-time financial decision-making. By\nleveraging advanced machine learning techniques,\nsuch as Random Forest, Gradient Boosting, Long Short-\nTerm Memory (LSTM), and Transformer networks, we\nhave demonstrated the potential to significantly\nenhance traditional methods in predicting market risks\nand constructing optimized portfolios. The results of\nthis research indicate that machine learning models,\nparticularly those based on ensemble methods and\ndeep learning architectures, can outperform classical\nfinancial models in terms of prediction accuracy, risk-\nadjusted returns, and portfolio performance. Among\nthe models analyzed, LSTM and Transformer networks\nhave shown exceptional promise due to their ability to\ncapture long-term dependencies in financial data,\nproviding more robust predictions in dynamic and\nvolatile market conditions.\n\nOur study also highlighted the importance of careful\nfeature engineering, preprocessing, and model\nevaluation, all of which are crucial to ensure the\nreliability and validity of the predictions. Feature\nselection emerged as a key step in improving the\n\nmodels' performance, with the incorporation of both\nfinancial indicators and external macroeconomic factors\nenhancing the overall results. In terms of portfolio\noptimization, machine learning models, when combined\nwith traditional optimization methods, offered superior\nperformance, particularly in maximizing risk-adjusted\nreturns such as the Sharpe and Sortino ratios. The\ndynamic nature of portfolio construction, powered by\nmachine learning, enables more responsive and\nadaptive strategies in real-world scenarios. While the\nresults of this study are promising, there are several\navenues for future research. Further exploration of\nhybrid models combining machine learning techniques\nand traditional financial theories could lead to even\nmore efficient portfolio management systems.\nAdditionally, enhancing model robustness and\nsensitivity through real-time data feeds and scenario\ntesting will be crucial for improving the resilience of\nfinancial models in unpredictable market conditions.\n\nIn conclusion, this research contributes to the growing\ndiv of knowledge on the application of machine\nlearning in finance, offering valuable insights into the\npractical use of these techniques for risk prediction and\nportfolio optimization. As financial markets continue to\nevolve, the integration of machine learning models will\nplay a pivotal role in helping investors navigate\nuncertainty, optimize returns, and make data-driven\ndecisions that ultimately lead to more efficient and\neffective financial management strategies.\n\nBy bridging the gap between traditional finance and\nmodern machine learning technologies, this study paves\nthe way for more sophisticated, adaptive, and\nintelligent portfolio management systems in the future.\n\nAcknowledgement: All the Author Contributed Equally.\n\nREFERENCE\n\n1.\n\nTauhedur Rahman, Md Kafil Uddin, Biswanath\nBhattacharjee, Md Siam Taluckder, Sanjida\nNowshin Mou, Pinky Akter, Md Shakhaowat\nHossain, Md Rashel Miah, & Md Mohibur\nRahman. (2024). BLOCKCHAIN APPLICATIONS IN\nBUSINESS OPERATIONS AND SUPPLY CHAIN\nMANAGEMENT BY MACHINE LEARNING.\nInternational Journal of Computer Science &\nInformation\n\nSystem,\n\n9(11),\n\n17\n\n–\n\n30.\n\nhttps://doi.org/10.55640/ijcsis/Volume09Issue\n11-03\n\n2.\n\nMd Jamil Ahmmed, Md Mohibur Rahman,\nAshim Chandra Das, Pritom Das, Tamanna\nPervin, Sadia Afrin, Sanjida Akter Tisha, Md\nMehedi Hassan, & Nabila Rahman. (2024).\nCOMPARATIVE\n\nANALYSIS\n\nOF\n\nMACHINE\n\nLEARNING ALGORITHMS FOR BANKING FRAUD\nDETECTION: A STUDY ON PERFORMANCE,\n\nThe American Journal of Management and Economics Innovations\n\n17\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nThe American Journal of Management and Economics Innovations\n\nPRECISION, AND REAL-TIME APPLICATION.\nInternational Journal of Computer Science &\nInformation\n\nSystem,\n\n9(11),\n\n31\n\n–\n\n44.\n\nhttps://doi.org/10.55640/ijcsis/Volume09Issu\ne11-04\n\n3.\n\nNafis Anjum, Md Nad Vi Al Bony, Murshida\nAlam, Mehedi Hasan, Salma Akter, Zannatun\nFerdus, Md Sayem Ul Haque, Radha Das, &\nSadia\n\nSultana.\n\n(2024).\n\nCOMPARATIVE\n\nANALYSIS OF SENTIMENT ANALYSIS MODELS\nON BANKING INVESTMENT IMPACT BY\nMACHINE\n\nLEARNING\n\nALGORITHM.\n\nInternational Journal of Computer Science &\nInformation\n\nSystem,\n\n9(11),\n\n5\n\n–\n\n16.\n\nhttps://doi.org/10.55640/ijcsis/Volume09Issu\ne11-02\n\n4.\n\nDas, A. C., Mozumder, M. S. A., Hasan, M. A.,\nBhuiyan, M., Islam, M. R., Hossain, M. N., ... &\nAlam, M. I. (2024). MACHINE LEARNING\nAPPROACHES FOR DEMAND FORECASTING:\nTHE IMPACT OF CUSTOMER SATISFACTION ON\nPREDICTION ACCURACY. The American Journal\nof Engineering and Technology, 6(10), 42-53.\n\n5.\n\nAkter, S., Mahmud, F., Rahman, T., Ahmmed,\nM. J., Uddin, M. K., Alam, M. I., ... & Jui, A. H.\n(2024). A COMPREHENSIVE STUDY OF\nMACHINE LEARNING APPROACHES FOR\nCUSTOMER SENTIMENT ANALYSIS IN BANKING\nSECTOR. The American Journal of Engineering\nand Technology, 6(10), 100-111.\n\n6.\n\nMd Risalat Hossain Ontor, Asif Iqbal, Emon\nAhmed, Tanvirahmedshuvo, & Ashequr\nRahman.\n\n(2024).\n\nLEVERAGING\n\nDIGITAL\n\nTRANSFORMATION AND SOCIAL MEDIA\nANALYTICS FOR OPTIMIZING US FASHION\n\nBRANDS’\n\nPERFORMANCE:\n\nA\n\nMACHINE\n\nLEARNING APPROACH. International Journal of\nComputer Science & Information System,\n9(11),\n\n45\n\n–\n\n56.\n\nhttps://doi.org/10.55640/ijcsis/Volume09Issu\ne11-05\n\n7.\n\nRahman, A., Iqbal, A., Ahmed, E., & Ontor, M.\nR. H. (2024). PRIVACY-PRESERVING MACHINE\nLEARNING: TECHNIQUES, CHALLENGES, AND\nFUTURE DIRECTIONS IN SAFEGUARDING\nPERSONAL\n\nDATA\n\nMANAGEMENT.\n\nInternational journal of business and\nmanagement sciences, 4(12), 18-32.\n\n8.\n\nMd Jamil Ahmmed, Md Mohibur Rahman,\nAshim Chandra Das, Pritom Das, Tamanna\nPervin, Sadia Afrin, Sanjida Akter Tisha, Md\nMehedi Hassan, & Nabila Rahman. (2024).\nCOMPARATIVE\n\nANALYSIS\n\nOF\n\nMACHINE\n\nLEARNING ALGORITHMS FOR BANKING FRAUD\nDETECTION: A STUDY ON PERFORMANCE,\nPRECISION, AND REAL-TIME APPLICATION.\nInternational Journal of Computer Science &\nInformation\n\nSystem,\n\n9(11),\n\n31\n\n–\n\n44.\n\nhttps://doi.org/10.55640/ijcsis/Volume09Issue\n11-04\n\n9.\n\nArif, M., Ahmed, M. P., Al Mamun, A., Uddin, M.\nK., Mahmud, F., Rahman, T., ... & Helal, M.\n(2024). DYNAMIC PRICING IN FINANCIAL\nTECHNOLOGY:\n\nEVALUATING\n\nMACHINE\n\nLEARNING\n\nSOLUTIONS\n\nFOR\n\nMARKET\n\nADAPTABILITY. International Interdisciplinary\nBusiness Economics Advancement Journal,\n5(10), 13-27.\n\n10.\n\nUddin, M. K., Akter, S., Das, P., Anjum, N., Akter,\nS., Alam, M., ... & Pervin, T. (2024). MACHINE\nLEARNING-BASED EARLY DETECTION OF KIDNEY\nDISEASE:\n\nA\n\nCOMPARATIVE\n\nSTUDY\n\nOF\n\nPREDICTION MODELS AND PERFORMANCE\nEVALUATION. International Journal of Medical\nScience and Public HealthResearch, 5(12),58-\n75.\n\n11.\n\nBuhlmann, P., & Hothorn, T. (2007). Boosting\nalgorithms: Regularization, prediction and\nmodel selection. Statistical Science, 22(4), 477-\n504. https://doi.org/10.1214/07-STS241\n\n12.\n\nChen, Y., Zhang, T., & Xu, H. (2018). Forecasting\nstock returns with machine learning. Journal of\nFinancial\n\nData\n\nScience,\n\n1(1),\n\n1-26.\n\nhttps://doi.org/10.3905/jfds.2018.1.1.1\n\n13.\n\nEngle, R. F. (2001). GARCH 101: The use of\nARCH/GARCH models in applied econometrics.\nJournal of Economic Perspectives, 15(4), 157-\n168. https://doi.org/10.1257/jep.15.4.157\n\n14.\n\nFischer, T., & Krauss, C. (2018). Deep learning\nwith long short-term memory networks for\nfinancial market predictions. European Journal\nof Operational Research, 270(2), 654-669.\nhttps://doi.org/10.1016/j.ejor.2018.03.024\n\n15.\n\nHe, K., Zhang, X., Ren, S., & Sun, J. (2017). Deep\nresidual learning for image recognition. In\nProceedings of the IEEE conference on\ncomputer vision and pattern recognition (pp.\n770-778).\n\n16.\n\nHochreiter, S., & Schmidhuber, J. (1997). Long\nshort-term memory. Neural Computation, 9(8),\n1735-1780.\nhttps://doi.org/10.1162/neco.1997.9.8.1735\n\n17.\n\nJiang, Z., Xu, Z., & Liang, J. (2017). A deep\nreinforcement learning framework for the\nfinancial portfolio management problem. arXiv\n\nThe American Journal of Management and Economics Innovations\n\n18\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nThe American Journal of Management and Economics Innovations\n\npreprint arXiv:1706.10059.\n\n18.\n\nLi, Y., Li, Y., & Zhang, C. (2020). Transformer-\nbased financial market prediction models: A\nreview. Financial Innovation, 6(1), 1-14.\nhttps://doi.org/10.1186/s40854-020-00191-9\n\n19.\n\nMarkowitz, H. (1952). Portfolio selection. The\nJournal\n\nof\n\nFinance,\n\n7(1),\n\n77-91.\n\nhttps://doi.org/10.1111/j.1540-\n6261.1952.tb01525.x\n\n20.\n\nZhang, Z., Zhang, H., & Li, Q. (2019). Stock\nmarket forecasting with gradient boosting\nmachines. Journal of Computational Finance,\n23(2),\n\n89-114.\n\nhttps://doi.org/10.21314/JCF.2019.197\n\n21.\n\nShak, M. S., Uddin, A., Rahman, M. H., Anjum,\nN., Al Bony, M. N. V., Alam, M., ... & Pervin, T.\n(2024). INNOVATIVE MACHINE LEARNING\nAPPROACHES\n\nTO\n\nFOSTER\n\nFINANCIAL\n\nINCLUSION IN MICROFINANCE. International\nInterdisciplinary\n\nBusiness\n\nEconomics\n\nAdvancement Journal, 5(11), 6-20.\n\n22.\n\nNaznin, R., Sarkar, M. A. I., Asaduzzaman, M.,\nAkter, S., Mou, S. N., Miah, M. R., ... & Sajal, A.\n(2024).\n\nENHANCING\n\nSMALL\n\nBUSINESS\n\nMANAGEMENT\n\nTHROUGH\n\nMACHINE\n\nLEARNING: A COMPARATIVE STUDY OF\nPREDICTIVE\n\nMODELS\n\nFOR\n\nCUSTOMER\n\nRETENTION, FINANCIAL FORECASTING, AND\nINVENTORY OPTIMIZATION. International\nInterdisciplinary\n\nBusiness\n\nEconomics\n\nAdvancement Journal, 5(11), 21-32.\n\n23.\n\nBhattacharjee, B., Mou, S. N., Hossain, M. S.,\nRahman, M. K., Hassan, M. M., Rahman, N., ...\n& Haque, M. S. U. (2024). MACHINE LEARNING\nFOR COST ESTIMATION AND FORECASTING IN\nBANKING: A COMPARATIVE ANALYSIS OF\nALGORITHMS.\n\nFrontline\n\nMarketing,\n\nManagement and Economics Journal, 4(12),\n66-83.\n\n24.\n\nRahman, A., Iqbal, A., Ahmed, E., & Ontor, M.\nR. H. (2024). PRIVACY-PRESERVING MACHINE\nLEARNING: TECHNIQUES, CHALLENGES, AND\nFUTURE DIRECTIONS IN SAFEGUARDING\nPERSONAL DATA MANAGEMENT. Frontline\nMarketing, Management and Economics\nJournal, 4(12), 84-106.\n\n25.\n\nAl Mamun, A., Hossain, M. S., Rishad, S. S. I.,\nRahman, M. M., Shakil, F., Choudhury, M. Z. M.\nE., ... & Sultana, S. (2024). MACHINE LEARNING\nFOR\n\nSTOCK\n\nMARKET\n\nSECURITY\n\nMEASUREMENT: A COMPARATIVE ANALYSIS\nOF SUPERVISED, UNSUPERVISED, AND DEEP\n\nLEARNING MODELS. The American Journal of\nEngineering and Technology, 6(11), 63-76.\n\n26.\n\nDas, A. C., Rishad, S. S. I., Akter, P., Tisha, S. A.,\nAfrin, S., Shakil, F., ... & Rahman, M. M. (2024).\nENHANCING BLOCKCHAIN SECURITY WITH\nMACHINE LEARNING: A COMPREHENSIVE\nSTUDY OF ALGORITHMS AND APPLICATIONS.\nThe American Journal of Engineering and\nTechnology, 6(12), 150-162.\n\n27.\n\nMiah, J., Khan, R. H., Ahmed, S., & Mahmud, M.\nI. (2023, June). A comparative study of detecting\ncovid 19 by using chest X-ray images\n\n–\n\nA deep\n\nlearning approach. In 2023 IEEE World AI IoT\nCongress (AIIoT) (pp. 0311-0316). IEEE.\n\n28.\n\nKhan, R. H., Miah, J., Nipun, S. A. A., & Islam, M.\n(2023, March). A Comparative Study of Machine\nLearning classifiers to analyze the Precision of\nMyocardial Infarction prediction. In 2023 IEEE\n13th Annual Computing and Communication\nWorkshop and Conference (CCWC) (pp. 0949-\n0954). IEEE.\n\n29.\n\nKayyum, S., Miah, J., Shadaab, A., Islam, M. M.,\nIslam, M., Nipun, S. A. A., ... & Al Faisal, F. (2020,\nJanuary). Data analysis on myocardial infarction\nwith the help of machine learning algorithms\nconsidering distinctive or non-distinctive\nfeatures. In 2020 International Conference on\nComputer Communication and Informatics\n(ICCCI) (pp. 1-7). IEEE.\n\n30.\n\nIslam, M. M., Nipun, S. A. A., Islam, M., Rahat,\nM. A. R., Miah, J., Kayyum, S., ... & Al Faisal, F.\n(2020). An empirical study to predict myocardial\ninfarction using k-means and hierarchical\nclustering. In Machine Learning, Image\nProcessing, Network Security and Data\nSciences: Second International Conference,\nMIND 2020, Silchar, India, July 30-31, 2020,\nProceedings, Part II 2 (pp. 120-130). Springer\nSingapore.\n\n31.\n\nMiah, J., Ca, D. M., Sayed, M. A., Lipu, E. R.,\nMahmud, F., & Arafat, S. Y. (2023, November).\nImproving Cardiovascular Disease Prediction\nThrough Comparative Analysis of Machine\nLearning Models: A Case Study on Myocardial\nInfarction.\n\nIn\n\n2023\n\n15th\n\nInternational\n\nConference on Innovations in Information\nTechnology (IIT) (pp. 49-54). IEEE.\n\n32.\n\nKhan, R. H., Miah, J., Rahat, M. A. R., Ahmed, A.\nH., Shahriyar, M. A., & Lipu, E. R. (2023,\nSeptember). A Comparative Analysis of\nMachine Learning Approaches for Chronic\nKidney Disease Detection. In 2023 8th\n\nThe American Journal of Management and Economics Innovations\n\n19\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nThe American Journal of Management and Economics Innovations\n\nInternational\n\nConference\n\non\n\nElectrical,\n\nElectronics and Information Engineering\n(ICEEIE) (pp. 1-6). IEEE.\n\n33.\n\nMiah, J., Cao, D. M., Sayed, M. A., Taluckder,\nM. S., Haque, M. S., & Mahmud, F. (2023).\nAdvancing Brain Tumor Detection: A Thorough\nInvestigation of CNNs, Clustering, and SoftMax\nClassification in the Analysis of MRI Images.\narXiv preprint arXiv:2310.17720.\n\n34.\n\nRahman, M. M., Islam, A. M., Miah, J., Ahmad,\nS., & Mamun, M. (2023, June). sleepWell:\nStress Level Prediction Through Sleep Data.\nAre You Stressed?. In 2023 IEEE World AI IoT\nCongress (AIIoT) (pp. 0229-0235). IEEE.\n\n35.\n\nRahman, M. M., Islam, A. M., Miah, J., Ahmad,\nS., & Hasan, M. M. (2023, June). Empirical\nAnalysis with Component Decomposition\nMethods for Cervical Cancer Risk Assessment.\nIn 2023 IEEE World AI IoT Congress (AIIoT) (pp.\n0513-0519). IEEE.\n\n36.\n\nKhan, R. H., Miah, J., Nipun, S. A. A., Islam, M.,\nAmin, M. S., & Taluckder, M. S. (2023,\nSeptember). Enhancing Lung Cancer Diagnosis\nwith Machine Learning Methods and\nSystematic Review Synthesis. In 2023 8th\nInternational\n\nConference\n\non\n\nElectrical,\n\nElectronics and Information Engineering\n(ICEEIE) (pp. 1-5). IEEE.\n\n37.\n\nMiah, J. (2024). HOW FAMILY DNA CAN CAUSE\nLUNG CANCER USING MACHINE LEARNING.\nInternational Journal of Medical Science and\nPublic Health Research, 5(12), 8-14.\n\n38.\n\nMiah, J., Khan, R. H., Linkon, A. A., Bhuiyan, M.\nS., Jewel, R. M., Ayon, E. H., ... & Tanvir Islam,\nM. (2024). Developing a Deep Learning\nMethodology to Anticipate the Onset of\nDiabetic Retinopathy at an Early Stage. In\nInnovative and Intelligent Digital Technologies;\nTowards an Increased Efficiency: Volume 1\n(pp.\n\n77-91).\n\nCham:\n\nSpringer\n\nNature\n\nSwitzerland.\n\n39.\n\nRahman, M. M., Akhi, S. S., Hossain, S., Ayub,\nM. I., Siddique, M. T., Nath, A., ... & Hassan, M.\nM. (2024). EVALUATING MACHINE LEARNING\nMODELS\n\nFOR\n\nOPTIMAL\n\nCUSTOMER\n\nSEGMENTATION\n\nIN\n\nBANKING:\n\nA\n\nCOMPARATIVE STUDY. The American Journal\nof Engineering and Technology, 6(12), 68-83.\n\n40.\n\nDas, P., Pervin, T., Bhattacharjee, B., Karim, M.\nR., Sultana, N., Khan, M. S., ... & Kamruzzaman,\nF. N. U. (2024). OPTIMIZING REAL-TIME\nDYNAMIC PRICING STRATEGIES IN RETAIL AND\n\nE-COMMERCE USING MACHINE LEARNING\nMODELS. The American Journal of Engineering\nand Technology, 6(12), 163-177.\n\n41.\n\nHossain, M. N., Hossain, S., Nath, A., Nath, P. C.,\nAyub, M. I., Hassan, M. M., ... & Rasel, M.\n(2024).\n\nENHANCED\n\nBANKING\n\nFRAUD\n\nDETECTION: A COMPARATIVE ANALYSIS OF\nSUPERVISED\n\nMACHINE\n\nLEARNING\n\nALGORITHMS.\n\nAmerican\n\nResearch\n\nIndex\n\nLibrary, 23-35.\n\n42.\n\nShak, M. S., Mozumder, M. S. A., Hasan, M. A.,\nDas, A. C., Miah, M. R., Akter, S., & Hossain, M.\nN. (2024). OPTIMIZING RETAIL DEMAND\nFORECASTING: A PERFORMANCE EVALUATION\nOF MACHINE LEARNING MODELS INCLUDING\nLSTM AND GRADIENT BOOSTING. The American\nJournal of Engineering and Technology, 6(09),\n67-80.\n\n43.\n\nDas, A. C., Mozumder, M. S. A., Hasan, M. A.,\nBhuiyan, M., Islam, M. R., Hossain, M. N., ... &\nAlam, M. I. (2024). MACHINE LEARNING\nAPPROACHES FOR DEMAND FORECASTING: THE\nIMPACT OF CUSTOMER SATISFACTION ON\nPREDICTION ACCURACY. The American Journal\nof Engineering and Technology, 6(10), 42-53.\n\n44.\n\nHossain, M. N., Anjum, N., Alam, M., Rahman,\nM. H., Taluckder, M. S., Al Bony, M. N. V., ... &\nJui, A. H. (2024). PERFORMANCE OF MACHINE\nLEARNING ALGORITHMS FOR LUNG CANCER\nPREDICTION:\n\nA\n\nCOMPARATIVE\n\nSTUDY.\n\nInternational Journal of Medical Science and\nPublic Health Research, 5(11), 41-55.\n\n45.\n\nAhmmed, M. J., Rahman, M. M., Das, A. C., Das,\nP., Pervin, T., Afrin, S., ... & Rahman, N. (2024).\nCOMPARATIVE\n\nANALYSIS\n\nOF\n\nMACHINE\n\nLEARNING ALGORITHMS FOR BANKING FRAUD\nDETECTION: A STUDY ON PERFORMANCE,\nPRECISION, AND REAL-TIME APPLICATION.\nAmerican Research Index Library, 31-44.\n\n46.\n\nAl Bony, M. N. V., Das, P., Pervin, T., Shak, M. S.,\nAkter, S., Anjum, N., ... & Rahman, M. K. (2024).\nCOMPARATIVE PERFORMANCE ANALYSIS OF\nMACHINE\n\nLEARNING\n\nALGORITHMS\n\nFOR\n\nBUSINESS INTELLIGENCE: A STUDY ON\nCLASSIFICATION AND REGRESSION MODELS.\nFrontline\n\nMarketing,\n\nManagement\n\nand\n\nEconomics Journal, 4(11), 72-92.\n\n47.\n\nHasan, M., Pathan, M. K. M., & Kabir, M. F.\n(2024). Functionalized Mesoporous Silica\nNanoparticles as Potential Drug Delivery Vehicle\nagainst Colorectal Cancer. Journal of Medical\nand Health Studies, 5(3), 56-62.\n\nThe American Journal of Management and Economics Innovations\n\n20\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nThe American Journal of Management and Economics Innovations\n\n48.\n\nHasan, M. (2023). SURFACE-ENGINEERED\nMINERAL PARTICLES FOR GATED DRUG\nDELIVERY, GENE TRANSFER AND SUNSCREEN\nFORMULATIONS.\n\n49.\n\nHasan, M., Kabir, M. F., & Pathan, M. K. M.\n(2024). PEGylation of Mesoporous Silica\nNanoparticles for Drug Delivery Applications.\nJournal of Chemistry Studies, 3(2), 01-06.\n\n50.\n\nHasan, M., Evett, C. G., & Burton, J. (2024).\nAdvances in Nanoparticle-Based Targeted\nDrug Delivery Systems for Colorectal Cancer\nTherapy:\n\nA\n\nReview.\n\narXiv\n\npreprint\n\narXiv:2409.05222.\n\n51.\n\nHasan, M., & Mahama, M. T. (2024).\nUncovering the complex mechanisms behind\nnanomaterials-based\n\nplasmon-driven\n\nphotocatalysis through the utilization of\nSurface-Enhanced Raman Spectroscopies.\narXiv preprint arXiv:2408.13927.\n\nReferences\n\nTauhedur Rahman, Md Kafil Uddin, Biswanath Bhattacharjee, Md Siam Taluckder, Sanjida Nowshin Mou, Pinky Akter, Md Shakhaowat Hossain, Md Rashel Miah, & Md Mohibur Rahman. (2024). BLOCKCHAIN APPLICATIONS IN BUSINESS OPERATIONS AND SUPPLY CHAIN MANAGEMENT BY MACHINE LEARNING. International Journal of Computer Science & Information System, 9(11), 17–30. https://doi.org/10.55640/ijcsis/Volume09Issue11-03\n\nMd Jamil Ahmmed, Md Mohibur Rahman, Ashim Chandra Das, Pritom Das, Tamanna Pervin, Sadia Afrin, Sanjida Akter Tisha, Md Mehedi Hassan, & Nabila Rahman. (2024). COMPARATIVE ANALYSIS OF MACHINE LEARNING ALGORITHMS FOR BANKING FRAUD DETECTION: A STUDY ON PERFORMANCE, PRECISION, AND REAL-TIME APPLICATION. International Journal of Computer Science & Information System, 9(11), 31–44. https://doi.org/10.55640/ijcsis/Volume09Issue11-04\n\nNafis Anjum, Md Nad Vi Al Bony, Murshida Alam, Mehedi Hasan, Salma Akter, Zannatun Ferdus, Md Sayem Ul Haque, Radha Das, & Sadia Sultana. (2024). COMPARATIVE ANALYSIS OF SENTIMENT ANALYSIS MODELS ON BANKING INVESTMENT IMPACT BY MACHINE LEARNING ALGORITHM. International Journal of Computer Science & Information System, 9(11), 5–16. https://doi.org/10.55640/ijcsis/Volume09Issue11-02\n\nDas, A. C., Mozumder, M. S. A., Hasan, M. A., Bhuiyan, M., Islam, M. R., Hossain, M. N., ... & Alam, M. I. (2024). MACHINE LEARNING APPROACHES FOR DEMAND FORECASTING: THE IMPACT OF CUSTOMER SATISFACTION ON PREDICTION ACCURACY. The American Journal of Engineering and Technology, 6(10), 42-53.\n\nAkter, S., Mahmud, F., Rahman, T., Ahmmed, M. J., Uddin, M. K., Alam, M. I., ... & Jui, A. H. (2024). A COMPREHENSIVE STUDY OF MACHINE LEARNING APPROACHES FOR CUSTOMER SENTIMENT ANALYSIS IN BANKING SECTOR. The American Journal of Engineering and Technology, 6(10), 100-111.\n\nMd Risalat Hossain Ontor, Asif Iqbal, Emon Ahmed, Tanvirahmedshuvo, & Ashequr Rahman. (2024). LEVERAGING DIGITAL TRANSFORMATION AND SOCIAL MEDIA ANALYTICS FOR OPTIMIZING US FASHION BRANDS’ PERFORMANCE: A MACHINE LEARNING APPROACH. International Journal of Computer Science & Information System, 9(11), 45–56. https://doi.org/10.55640/ijcsis/Volume09Issue11-05\n\nRahman, A., Iqbal, A., Ahmed, E., & Ontor, M. R. H. (2024). PRIVACY-PRESERVING MACHINE LEARNING: TECHNIQUES, CHALLENGES, AND FUTURE DIRECTIONS IN SAFEGUARDING PERSONAL DATA MANAGEMENT. International journal of business and management sciences, 4(12), 18-32.\n\nMd Jamil Ahmmed, Md Mohibur Rahman, Ashim Chandra Das, Pritom Das, Tamanna Pervin, Sadia Afrin, Sanjida Akter Tisha, Md Mehedi Hassan, & Nabila Rahman. (2024). COMPARATIVE ANALYSIS OF MACHINE LEARNING ALGORITHMS FOR BANKING FRAUD DETECTION: A STUDY ON PERFORMANCE, PRECISION, AND REAL-TIME APPLICATION. International Journal of Computer Science & Information System, 9(11), 31–44. https://doi.org/10.55640/ijcsis/Volume09Issue11-04\n\nArif, M., Ahmed, M. P., Al Mamun, A., Uddin, M. K., Mahmud, F., Rahman, T., ... & Helal, M. (2024). DYNAMIC PRICING IN FINANCIAL TECHNOLOGY: EVALUATING MACHINE LEARNING SOLUTIONS FOR MARKET ADAPTABILITY. International Interdisciplinary Business Economics Advancement Journal, 5(10), 13-27.\n\nUddin, M. K., Akter, S., Das, P., Anjum, N., Akter, S., Alam, M., ... & Pervin, T. (2024). MACHINE LEARNING-BASED EARLY DETECTION OF KIDNEY DISEASE: A COMPARATIVE STUDY OF PREDICTION MODELS AND PERFORMANCE EVALUATION. International Journal of Medical Science and Public HealthResearch, 5(12),58-75.\n\nBuhlmann, P., & Hothorn, T. (2007). Boosting algorithms: Regularization, prediction and model selection. Statistical Science, 22(4), 477-504. https://doi.org/10.1214/07-STS241\n\nChen, Y., Zhang, T., & Xu, H. (2018). Forecasting stock returns with machine learning. Journal of Financial Data Science, 1(1), 1-26. https://doi.org/10.3905/jfds.2018.1.1.1\n\nEngle, R. F. (2001). GARCH 101: The use of ARCH/GARCH models in applied econometrics. Journal of Economic Perspectives, 15(4), 157-168. https://doi.org/10.1257/jep.15.4.157\n\nFischer, T., & Krauss, C. (2018). Deep learning with long short-term memory networks for financial market predictions. European Journal of Operational Research, 270(2), 654-669. https://doi.org/10.1016/j.ejor.2018.03.024\n\nHe, K., Zhang, X., Ren, S., & Sun, J. (2017). Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 770-778).\n\nHochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural Computation, 9(8), 1735-1780. https://doi.org/10.1162/neco.1997.9.8.1735\n\nJiang, Z., Xu, Z., & Liang, J. (2017). A deep reinforcement learning framework for the financial portfolio management problem. arXiv preprint arXiv:1706.10059.\n\nLi, Y., Li, Y., & Zhang, C. (2020). Transformer-based financial market prediction models: A review. Financial Innovation, 6(1), 1-14. https://doi.org/10.1186/s40854-020-00191-9\n\nMarkowitz, H. (1952). Portfolio selection. The Journal of Finance, 7(1), 77-91. https://doi.org/10.1111/j.1540-6261.1952.tb01525.x\n\nZhang, Z., Zhang, H., & Li, Q. (2019). Stock market forecasting with gradient boosting machines. Journal of Computational Finance, 23(2), 89-114. https://doi.org/10.21314/JCF.2019.197\n\nShak, M. S., Uddin, A., Rahman, M. H., Anjum, N., Al Bony, M. N. V., Alam, M., ... & Pervin, T. (2024). INNOVATIVE MACHINE LEARNING APPROACHES TO FOSTER FINANCIAL INCLUSION IN MICROFINANCE. International Interdisciplinary Business Economics Advancement Journal, 5(11), 6-20.\n\nNaznin, R., Sarkar, M. A. I., Asaduzzaman, M., Akter, S., Mou, S. N., Miah, M. R., ... & Sajal, A. (2024). ENHANCING SMALL BUSINESS MANAGEMENT THROUGH MACHINE LEARNING: A COMPARATIVE STUDY OF PREDICTIVE MODELS FOR CUSTOMER RETENTION, FINANCIAL FORECASTING, AND INVENTORY OPTIMIZATION. International Interdisciplinary Business Economics Advancement Journal, 5(11), 21-32.\n\nBhattacharjee, B., Mou, S. N., Hossain, M. S., Rahman, M. K., Hassan, M. M., Rahman, N., ... & Haque, M. S. U. (2024). MACHINE LEARNING FOR COST ESTIMATION AND FORECASTING IN BANKING: A COMPARATIVE ANALYSIS OF ALGORITHMS. Frontline Marketing, Management and Economics Journal, 4(12), 66-83.\n\nRahman, A., Iqbal, A., Ahmed, E., & Ontor, M. R. H. (2024). PRIVACY-PRESERVING MACHINE LEARNING: TECHNIQUES, CHALLENGES, AND FUTURE DIRECTIONS IN SAFEGUARDING PERSONAL DATA MANAGEMENT. Frontline Marketing, Management and Economics Journal, 4(12), 84-106.\n\nAl Mamun, A., Hossain, M. S., Rishad, S. S. I., Rahman, M. M., Shakil, F., Choudhury, M. Z. M. E., ... & Sultana, S. (2024). MACHINE LEARNING FOR STOCK MARKET SECURITY MEASUREMENT: A COMPARATIVE ANALYSIS OF SUPERVISED, UNSUPERVISED, AND DEEP LEARNING MODELS. The American Journal of Engineering and Technology, 6(11), 63-76.\n\nDas, A. C., Rishad, S. S. I., Akter, P., Tisha, S. A., Afrin, S., Shakil, F., ... & Rahman, M. M. (2024). ENHANCING BLOCKCHAIN SECURITY WITH MACHINE LEARNING: A COMPREHENSIVE STUDY OF ALGORITHMS AND APPLICATIONS. The American Journal of Engineering and Technology, 6(12), 150-162.\n\nMiah, J., Khan, R. H., Ahmed, S., & Mahmud, M. I. (2023, June). A comparative study of detecting covid 19 by using chest X-ray images–A deep learning approach. In 2023 IEEE World AI IoT Congress (AIIoT) (pp. 0311-0316). IEEE.\n\nKhan, R. H., Miah, J., Nipun, S. A. A., & Islam, M. (2023, March). A Comparative Study of Machine Learning classifiers to analyze the Precision of Myocardial Infarction prediction. In 2023 IEEE 13th Annual Computing and Communication Workshop and Conference (CCWC) (pp. 0949-0954). IEEE.\n\nKayyum, S., Miah, J., Shadaab, A., Islam, M. M., Islam, M., Nipun, S. A. A., ... & Al Faisal, F. (2020, January). Data analysis on myocardial infarction with the help of machine learning algorithms considering distinctive or non-distinctive features. In 2020 International Conference on Computer Communication and Informatics (ICCCI) (pp. 1-7). IEEE.\n\nIslam, M. M., Nipun, S. A. A., Islam, M., Rahat, M. A. R., Miah, J., Kayyum, S., ... & Al Faisal, F. (2020). An empirical study to predict myocardial infarction using k-means and hierarchical clustering. In Machine Learning, Image Processing, Network Security and Data Sciences: Second International Conference, MIND 2020, Silchar, India, July 30-31, 2020, Proceedings, Part II 2 (pp. 120-130). Springer Singapore.\n\nMiah, J., Ca, D. M., Sayed, M. A., Lipu, E. R., Mahmud, F., & Arafat, S. Y. (2023, November). Improving Cardiovascular Disease Prediction Through Comparative Analysis of Machine Learning Models: A Case Study on Myocardial Infarction. In 2023 15th International Conference on Innovations in Information Technology (IIT) (pp. 49-54). IEEE.\n\nKhan, R. H., Miah, J., Rahat, M. A. R., Ahmed, A. H., Shahriyar, M. A., & Lipu, E. R. (2023, September). A Comparative Analysis of Machine Learning Approaches for Chronic Kidney Disease Detection. In 2023 8th International Conference on Electrical, Electronics and Information Engineering (ICEEIE) (pp. 1-6). IEEE.\n\nMiah, J., Cao, D. M., Sayed, M. A., Taluckder, M. S., Haque, M. S., & Mahmud, F. (2023). Advancing Brain Tumor Detection: A Thorough Investigation of CNNs, Clustering, and SoftMax Classification in the Analysis of MRI Images. arXiv preprint arXiv:2310.17720.\n\nRahman, M. M., Islam, A. M., Miah, J., Ahmad, S., & Mamun, M. (2023, June). sleepWell: Stress Level Prediction Through Sleep Data. Are You Stressed?. In 2023 IEEE World AI IoT Congress (AIIoT) (pp. 0229-0235). IEEE.\n\nRahman, M. M., Islam, A. M., Miah, J., Ahmad, S., & Hasan, M. M. (2023, June). Empirical Analysis with Component Decomposition Methods for Cervical Cancer Risk Assessment. In 2023 IEEE World AI IoT Congress (AIIoT) (pp. 0513-0519). IEEE.\n\nKhan, R. H., Miah, J., Nipun, S. A. A., Islam, M., Amin, M. S., & Taluckder, M. S. (2023, September). Enhancing Lung Cancer Diagnosis with Machine Learning Methods and Systematic Review Synthesis. In 2023 8th International Conference on Electrical, Electronics and Information Engineering (ICEEIE) (pp. 1-5). IEEE.\n\nMiah, J. (2024). HOW FAMILY DNA CAN CAUSE LUNG CANCER USING MACHINE LEARNING. International Journal of Medical Science and Public Health Research, 5(12), 8-14.\n\nMiah, J., Khan, R. H., Linkon, A. A., Bhuiyan, M. S., Jewel, R. M., Ayon, E. H., ... & Tanvir Islam, M. (2024). Developing a Deep Learning Methodology to Anticipate the Onset of Diabetic Retinopathy at an Early Stage. In Innovative and Intelligent Digital Technologies; Towards an Increased Efficiency: Volume 1 (pp. 77-91). Cham: Springer Nature Switzerland.\n\nRahman, M. M., Akhi, S. S., Hossain, S., Ayub, M. I., Siddique, M. T., Nath, A., ... & Hassan, M. M. (2024). EVALUATING MACHINE LEARNING MODELS FOR OPTIMAL CUSTOMER SEGMENTATION IN BANKING: A COMPARATIVE STUDY. The American Journal of Engineering and Technology, 6(12), 68-83.\n\nDas, P., Pervin, T., Bhattacharjee, B., Karim, M. R., Sultana, N., Khan, M. S., ... & Kamruzzaman, F. N. U. (2024). OPTIMIZING REAL-TIME DYNAMIC PRICING STRATEGIES IN RETAIL AND E-COMMERCE USING MACHINE LEARNING MODELS. The American Journal of Engineering and Technology, 6(12), 163-177.\n\nHossain, M. N., Hossain, S., Nath, A., Nath, P. C., Ayub, M. I., Hassan, M. M., ... & Rasel, M. (2024). ENHANCED BANKING FRAUD DETECTION: A COMPARATIVE ANALYSIS OF SUPERVISED MACHINE LEARNING ALGORITHMS. American Research Index Library, 23-35.\n\nShak, M. S., Mozumder, M. S. A., Hasan, M. A., Das, A. C., Miah, M. R., Akter, S., & Hossain, M. N. (2024). OPTIMIZING RETAIL DEMAND FORECASTING: A PERFORMANCE EVALUATION OF MACHINE LEARNING MODELS INCLUDING LSTM AND GRADIENT BOOSTING. The American Journal of Engineering and Technology, 6(09), 67-80.\n\nDas, A. C., Mozumder, M. S. A., Hasan, M. A., Bhuiyan, M., Islam, M. R., Hossain, M. N., ... & Alam, M. I. (2024). MACHINE LEARNING APPROACHES FOR DEMAND FORECASTING: THE IMPACT OF CUSTOMER SATISFACTION ON PREDICTION ACCURACY. The American Journal of Engineering and Technology, 6(10), 42-53.\n\nHossain, M. N., Anjum, N., Alam, M., Rahman, M. H., Taluckder, M. S., Al Bony, M. N. V., ... & Jui, A. H. (2024). PERFORMANCE OF MACHINE LEARNING ALGORITHMS FOR LUNG CANCER PREDICTION: A COMPARATIVE STUDY. International Journal of Medical Science and Public Health Research, 5(11), 41-55.\n\nAhmmed, M. J., Rahman, M. M., Das, A. C., Das, P., Pervin, T., Afrin, S., ... & Rahman, N. (2024). COMPARATIVE ANALYSIS OF MACHINE LEARNING ALGORITHMS FOR BANKING FRAUD DETECTION: A STUDY ON PERFORMANCE, PRECISION, AND REAL-TIME APPLICATION. American Research Index Library, 31-44.\n\nAl Bony, M. N. V., Das, P., Pervin, T., Shak, M. S., Akter, S., Anjum, N., ... & Rahman, M. K. (2024). COMPARATIVE PERFORMANCE ANALYSIS OF MACHINE LEARNING ALGORITHMS FOR BUSINESS INTELLIGENCE: A STUDY ON CLASSIFICATION AND REGRESSION MODELS. Frontline Marketing, Management and Economics Journal, 4(11), 72-92.\n\nHasan, M., Pathan, M. K. M., & Kabir, M. F. (2024). Functionalized Mesoporous Silica Nanoparticles as Potential Drug Delivery Vehicle against Colorectal Cancer. Journal of Medical and Health Studies, 5(3), 56-62.\n\nHasan, M. (2023). SURFACE-ENGINEERED MINERAL PARTICLES FOR GATED DRUG DELIVERY, GENE TRANSFER AND SUNSCREEN FORMULATIONS.\n\nHasan, M., Kabir, M. F., & Pathan, M. K. M. (2024). PEGylation of Mesoporous Silica Nanoparticles for Drug Delivery Applications. Journal of Chemistry Studies, 3(2), 01-06.\n\nHasan, M., Evett, C. G., & Burton, J. (2024). Advances in Nanoparticle-Based Targeted Drug Delivery Systems for Colorectal Cancer Therapy: A Review. arXiv preprint arXiv:2409.05222.\n\nHasan, M., & Mahama, M. T. (2024). Uncovering the complex mechanisms behind nanomaterials-based plasmon-driven photocatalysis through the utilization of Surface-Enhanced Raman Spectroscopies. arXiv preprint arXiv:2408.13927.\n\ninLibrary — is a scientific electronic library built on the paradigm of open science (Open Science), the main tasks of which are the popularization of science and scientific activities, public quality control of scientific publications, the development of interdisciplinary research, a modern institute of scientific review, increasing the citation of Uzbek science and building a knowledge infrastructure.\n\nCONTACTS:\n\nRepublic of Uzbekistan, Tashkent, Parkent street 51, floor 2\n\n(+998) 99-006-61-10\n\ninfo@inscience.uz\n\nNAVIGATION:\n\nThe Synergy of AI and Financial Engineering in Forecasting Models : \nThe Synergy of AI and Financial Engineering in Forecasting Models\n\nIntroduction\n\nIn today's fast-paced financial landscape, the integration of Artificial Intelligence (AI) into traditional financial engineering has transformed the field of forecasting models significantly. With advancements in machine learning, data analytics, and computational power, numerical predictions in finance are now more accurate and adaptive to the ever-changing market conditions. Whether investors aim to anticipate stock price movements, assess risks, or optimize portfolios, leveraging AI techniques in financial engineering has become indispensable.\n\nThis article delves into the intricate relationship between AI and financial engineering, examining how these dynamic fields converge to enhance forecasting models. We will explore the fundamental concepts of financial engineering, the transformative role of AI, the methodologies employed, and the potential implications for investors and financial institutions alike. Through this exploration, we aim to shed light on the profound impact that this synergy has on financial decision-making processes.\n\nThe Foundation of Financial Engineering\n\nUnderstanding Financial Engineering\n\nAt its core, financial engineering is the application of quantitative methods and mathematical tools to solve problems related to finance. It involves designing innovative financial instruments, creating risk management strategies, and structuring complex financial transactions. Professionals in this field, often equipped with degrees in mathematics, statistics, economics, and computer science, employ models to analyze market dynamics, assess derivatives pricing, and manage investment portfolios.\n\nOne of the prime objectives of financial engineering is to understand and manage risks associated with financial uncertainty. This involves a comprehensive study of various financial instruments and their behavior under different economic scenarios. The complexity and non-linearity of financial markets necessitate the use of sophisticated mathematical models and computational simulations, such as Monte Carlo simulations and stochastic calculus, to anticipate market fluctuations and optimize trading strategies effectively.\n\nHistorical Context and Evolution\n\nThe roots of financial engineering can be traced back to the mid-20th century when academics and financial professionals began to develop quantitative models to price options and other derivatives. The introduction of the Black-Scholes model in 1973 marked a pivotal moment in the field, enabling more structured approaches to pricing and risk assessment. As computers became more powerful and accessible, the speed and complexity of financial models exponentially increased, allowing for better simulations and predictions.\n\nHowever, despite its mathematical rigor, traditional financial engineering often faced limitations in adaptability and learning capabilities. As the financial markets became increasingly volatile and influenced by an array of factors like geopolitical events, economic indicators, and market sentiment, relying solely on static models proved insufficient. This paved the way for the incorporation of AI into financial engineering, as it offered a more dynamic approach to modeling and forecasting.\n\nThe Role of Data in Financial Engineering\n\nData is the lifeblood of financial engineering. With the advent of big data, professionals can now access a vast array of structured and unstructured data sources, from stock prices and trading volumes to social media sentiment and economic indicators. The challenge lies in not just accumulating this data but also processing and interpreting it effectively.\n\nFinancial engineers utilize statistical techniques and algorithms to analyze historical data and build predictive models based on identified patterns and trends. The integration of AI enhances this process by automating data analysis, uncovering hidden correlations, and enabling real-time predictions. As a result, financial institutions are now better equipped to adapt to sudden market changes, adjust their trading strategies accordingly, and ultimately enhance their profitability.\n\nThe Emergence of AI in Financial Engineering\n\nThe Impact of Machine Learning\n\nMachine learning, a subset of AI, leverages algorithms that enable computers to learn from data and improve their performance without explicit programming. In financial engineering, machine learning techniques have become indispensable in enhancing forecasting models. Traditional methods often relied on fixed equations and assumptions based on historical data, which can overlook intricate relationships within the data.\n\nBy employing machine learning models—such as regression trees, random forests, and neural networks—financial engineers can build more robust and flexible predictive models. These models exhibit the ability to adapt to new data, accommodating changing market conditions seamlessly. For instance, by inputting time-series data into a machine learning model, analysts can uncover hidden trends that inform trading strategies and risk management processes.\n\nAdditionally, machine learning algorithms can improve the accuracy of predicting extreme market events or black swan events, which have significant implications for risk management. Traditional models often struggled to forecast such events due to their rarity, but AI-enhanced models can identify subtle patterns that may precede these occurrences.\n\nNatural Language Processing (NLP) in Financial Forecasting\n\nNatural Language Processing, a branch of AI focused on the interaction between computers and human language, has opened new avenues in financial engineering. By harnessing NLP techniques, financial analysts can extract valuable insights from unstructured data sources like news articles, earnings call transcripts, and social media feeds. Such information can significantly impact market sentiment and stock prices, making it a vital component in enhancing forecasting models.\n\nFor instance, sentiment analysis, a common application of NLP, assesses public emotion and opinion regarding specific stocks or the overall market. By analyzing the sentiment behind news headlines or social media chatter, financial engineers can gauge market fluctuations and adjust their predictive models accordingly. Data derived from sentiment analysis can be integrated with traditional financial metrics to create hybrid models that provide a more holistic view of market dynamics.\n\nReinforcement Learning for Dynamic Decision-Making\n\nReinforcement learning is another emerging area of AI that holds vast potential for financial engineering. Unlike traditional machine learning methods that learn from historical data, reinforcement learning involves training algorithms through trial-and-error interactions in an environment—essentially learning from the outcomes of different decision-making actions.\n\nIn finance, reinforcement learning can be employed to develop trading algorithms capable of adapting strategies in real-time based on market behavior. For example, a reinforcement learning algorithm can simulate various trading strategies, receiving reinforcement in the form of rewards (profits) or penalties (losses) based on its actions. This enables the algorithm to continuously learn and improve its trading decisions over time.\n\nThe use of reinforcement learning models can result in more dynamic and responsive trading practices, allowing financial institutions to maintain a competitive edge in rapidly changing markets. The synergy between financial engineering and AI will likely lead to further innovations in dynamic decision-making processes.\n\nChallenges and Considerations\n\nData Quality and Ethical Concerns\n\nDespite the numerous advantages AI brings to financial engineering, challenges remain regarding the quality of data input into these systems. Poor data quality can lead to inaccurate forecasts, financial losses, and reputational damage for organizations. Thus, it is vital for financial engineers to prioritize data cleaning and validation processes before applying AI techniques.\n\nMoreover, ethical concerns surrounding AI in finance also warrant attention. Issues such as data privacy, algorithmic bias, and transparency pose significant challenges that financial institutions must address. Regulatory frameworks may need to evolve to encompass the unique aspects of AI-driven financial models, ensuring accountability and fair practices within the industry.\n\nOverfitting and Model Complexity\n\nAnother challenge with implementing AI in financial forecasting is the risk of overfitting. This occurs when a model performs exceptionally well on training data but fails to generalize its predictions to unseen data. Financial markets are influenced by a plethora of unpredictable variables, and as AI models become increasingly complex, the risk of overfitting becomes more pronounced.\n\nFinanciers must strike a balance between model complexity and interpretability. While intricate models may yield higher accuracy, they may also become less transparent and harder to understand. Achieving this balance requires continuous validation and testing against real-world scenarios to ensure models remain robust and adaptive.\n\nThe Need for Interdisciplinary Collaboration\n\nThe successful integration of AI in financial engineering necessitates collaboration between various disciplines. Financial engineers, data scientists, and AI experts must work closely to design and implement forecasting models that are both innovative and practical. This interdisciplinary approach can foster the development of comprehensive solutions that address intricate financial challenges effectively.\n\nMoreover, a collaborative environment encourages knowledge sharing, paving the way for unique ideas and methodologies that leverage the strengths of each discipline. As AI continues to evolve, creating interdisciplinary teams will be essential in driving innovation within the financial sector.\n\nConclusion\n\nThe synergy between Artificial Intelligence and financial engineering represents a paradigm shift in how financial forecasting models are developed and implemented. By harnessing advanced machine learning techniques, natural language processing, and reinforcement learning, financial professionals can now create dynamic models that improve accuracy and adaptability in an ever-evolving financial landscape.\n\nAs AI continues to mature, its integration into financial engineering will likely yield further advancements and innovations, empowering investors and institutions to make informed decisions based on enhanced predictive capabilities. Nevertheless, critical challenges remain, including data quality, ethical considerations, and the potential for overfitting. To navigate these challenges and maximize the benefits of AI, collaboration among interdisciplinary teams will be paramount.\n\nUltimately, the fusion of AI with financial engineering heralds a new era in forecasting models, enabling stakeholders to grasp complex market dynamics, harness valuable insights, and adapt to emerging trends in real time. In this journey toward improved forecasting techniques, the commitment to responsible data management, transparency, and ethical practices will be the cornerstones of building a sustainable and trustworthy financial future.\n\nIf you want to read more articles similar to The Synergy of AI and Financial Engineering in Forecasting Models, you can visit the Financial Forecasting category.\n\nYou Must Read\n\nIntegrating Personalization Algorithms with Existing Systems\n\nThe Impact of Deep Learning Model Size on Performance\n\nA Comprehensive Guide to Chatbot Data Preparation with ML\n\nCategories\n\nRelated Posts\n\nIntegrating Machine Learning Algorithms into HR Hiring Processes\n\nExploring the Role of AI in Satellite Imagery for Urban Planning\n\nExploring Ensemble Learning Methods in Clinical Applications\n\nTerms and Conditions\n\nPrivacy Policy\n\nCookie Policy\n\nAbout Us\n\nContact Us\n",
        "Machine learning models employed in customer banking product targeting": "AI-Driven Customer Segmentation and Targeting in Retail Banking ... : \nAI-Driven Customer Segmentation and Targeting in Retail Banking: Improving Marketing Strategies and Customer Retention\n\nAI-Driven Customer Segmentation and Targeting in Retail Banking: Improving Marketing Strategies and Customer Retention\n\nIn the contemporary landscape of retail banking, the advent of Artificial Intelligence (AI) has ushered in transformative advancements in customer segmentation and targeting, which are pivotal to optimizing marketing strategies and enhancing customer retention. This paper delves into the application of AI technologies in refining customer segmentation processes and crafting targeted marketing strategies, underpinned by data-driven insights. The integration of AI in these domains is analyzed through various methodological frameworks and practical implementations, highlighting its efficacy in dissecting complex customer datasets to generate actionable insights.\n\nAI-driven customer segmentation leverages machine learning algorithms and advanced analytics to process and interpret vast quantities of customer data, facilitating a granular understanding of customer behaviors, preferences, and demographic characteristics. Traditional segmentation approaches, often limited by their reliance on static criteria and historical data, are significantly outperformed by AI methodologies which utilize dynamic, real-time data inputs. This dynamic capability allows for the development of more nuanced customer profiles, which in turn supports the creation of highly tailored marketing strategies.\n\nThe paper explores various AI techniques, including supervised and unsupervised learning models, clustering algorithms, and natural language processing (NLP), that are employed to dissect customer data. Supervised learning models, such as decision trees and neural networks, are particularly effective in predicting customer behaviors and preferences based on historical data. Unsupervised learning models, including k-means clustering and hierarchical clustering, are utilized to uncover hidden patterns and groupings within customer datasets. Furthermore, NLP techniques are instrumental in analyzing customer interactions and feedback, providing additional layers of insight into customer sentiment and preferences.\n\nCase studies of retail banking institutions that have successfully implemented AI-driven segmentation strategies illustrate the practical benefits of these technologies. These case studies highlight significant improvements in marketing effectiveness, evidenced by increased response rates to targeted campaigns and enhanced customer engagement. Additionally, the paper discusses the impact of AI on customer retention, emphasizing how predictive analytics can identify at-risk customers and inform retention strategies tailored to individual needs.\n\nThe challenges associated with implementing AI-driven customer segmentation are also examined. Issues such as data privacy, algorithmic bias, and the integration of AI systems with legacy banking infrastructure are discussed in detail. Addressing these challenges is crucial for ensuring the ethical and effective application of AI technologies in retail banking.\n\nThe paper concludes with a discussion on future trends in AI-driven customer segmentation and targeting, including the potential for integrating emerging technologies such as blockchain for enhanced data security and the evolving role of AI in personalizing banking experiences. As the banking sector continues to evolve, the role of AI in shaping marketing strategies and improving customer retention is expected to become increasingly significant.\n\nDownloads\n\nReferences\n\nJ. Smith and A. Brown, \"Machine Learning in Banking: An Overview of the Applications and Trends,\" IEEE Transactions on Neural Networks and Learning Systems, vol. 31, no. 4, pp. 1245-1256, April 2020.\n\nM. Patel, \"Data-Driven Customer Segmentation Using Clustering Techniques,\" Journal of Financial Data Science, vol. 7, no. 2, pp. 88-101, Summer 2021.\n\nL. Zhang, Q. Yang, and M. Liu, \"Applications of Neural Networks in Retail Banking: A Review,\" IEEE Access, vol. 9, pp. 30456-30465, 2021.\n\nA. Johnson and H. Kumar, \"AI and Customer Experience: A Case Study of Retail Banking,\" Proceedings of the IEEE Conference on Artificial Intelligence, pp. 1123-1131, 2022.\n\nS. Roberts et al., \"Unsupervised Learning Techniques for Customer Segmentation in Banking,\" International Journal of Data Science and Analytics, vol. 10, no. 3, pp. 211-225, March 2023.\n\nP. Lee and R. Chen, \"Natural Language Processing for Analyzing Customer Feedback in Banking,\" IEEE Transactions on Computational Social Systems, vol. 8, no. 5, pp. 1052-1063, October 2022.\n\nB. Williams and C. Zhang, \"K-Means Clustering for Market Segmentation: An Empirical Study,\" IEEE Transactions on Big Data, vol. 6, no. 1, pp. 30-41, February 2020.\n\nJ. Wilson and E. Turner, \"Hierarchical Clustering Approaches for Customer Profiling,\" Journal of Banking and Finance, vol. 45, pp. 67-79, January 2021.\n\nR. Harris, \"The Impact of AI on Marketing Strategies in Retail Banking,\" IEEE Transactions on Marketing, vol. 8, no. 2, pp. 150-162, August 2021.\n\nV. Clark and T. Davis, \"Evaluating the Effectiveness of AI-Driven Customer Retention Strategies,\" Journal of Financial Technology, vol. 12, no. 4, pp. 96-109, April 2023.\n\nK. Edwards and L. Murphy, \"Challenges in Integrating AI with Legacy Banking Systems,\" IEEE Transactions on Systems, Man, and Cybernetics, vol. 51, no. 6, pp. 4015-4024, June 2021.\n\nN. Anderson, \"Privacy and Security Considerations in AI-Driven Customer Segmentation,\" Proceedings of the IEEE International Conference on Data Privacy, pp. 58-64, 2022.\n\nD. Jackson and R. Brooks, \"Bias in AI Models for Financial Services: A Comprehensive Review,\" IEEE Transactions on Artificial Intelligence, vol. 7, no. 3, pp. 112-124, March 2021.\n\nH. Lee, \"Blockchain Integration for Enhanced Data Security in Banking,\" Journal of Financial Security, vol. 16, no. 2, pp. 85-99, June 2023.\n\nG. Roberts and A. Singh, \"Impact of AI on Customer Engagement in Retail Banking,\" IEEE Transactions on Customer Relations, vol. 9, no. 1, pp. 34-47, January 2022.\n\nC. Brown and M. White, \"Quantitative Benefits of AI-Driven Marketing Initiatives,\" Journal of Quantitative Finance, vol. 14, no. 3, pp. 201-214, May 2021.\n\nJ. Green and L. Adams, \"Future Trends in AI for Customer Segmentation,\" IEEE Transactions on Future Technologies, vol. 5, no. 4, pp. 250-261, October 2023.\n\nR. Williams and J. Harris, \"Emerging AI Technologies in Banking: Potential and Challenges,\" Proceedings of the IEEE Future Tech Conference, pp. 213-220, 2024.\n\nS. Thomas and H. Johnson, \"Regulatory and Compliance Concerns for AI in Banking,\" IEEE Transactions on Regulatory Technology, vol. 3, no. 2, pp. 132-144, April 2022.\n\nA. Patel and B. Morris, \"Innovations in AI-Driven Customer Targeting Strategies,\" Journal of Applied AI Research, vol. 19, no. 2, pp. 1\n\nPublished\n\nHow to Cite\n\nIssue\n\nSection\n\nLicense\n\nThis work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.\n\nLicense Terms\n\nOwnership and Licensing:\n\nAuthors of this research paper submitted to the journal owned and operated by The Science Brigade Group retain the copyright of their work while granting the journal certain rights. Authors maintain ownership of the copyright and have granted the journal a right of first publication. Simultaneously, authors agreed to license their research papers under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License.\n\nLicense Permissions:\n\nUnder the CC BY-NC-SA 4.0 License, others are permitted to share and adapt the work, as long as proper attribution is given to the authors and acknowledgement is made of the initial publication in the Journal. This license allows for the broad dissemination and utilization of research papers.\n\nAdditional Distribution Arrangements:\n\nAuthors are free to enter into separate contractual arrangements for the non-exclusive distribution of the journal's published version of the work. This may include posting the work to institutional repositories, publishing it in journals or books, or other forms of dissemination. In such cases, authors are requested to acknowledge the initial publication of the work in this Journal.\n\nOnline Posting:\n\nAuthors are encouraged to share their work online, including in institutional repositories, disciplinary repositories, or on their personal websites. This permission applies both prior to and during the submission process to the Journal. Online sharing enhances the visibility and accessibility of the research papers.\n\nResponsibility and Liability:\n\nAuthors are responsible for ensuring that their research papers do not infringe upon the copyright, privacy, or other rights of any third party. The Science Brigade Publishers disclaim any liability or responsibility for any copyright infringement or violation of third-party rights in the research papers.\n\nPlaudit\n\nLicense Terms\n\nOwnership and Licensing:\n\nAuthors of this research paper submitted to the Journal of Science & Technology retain the copyright of their work while granting the journal certain rights. Authors maintain ownership of the copyright and have granted the journal a right of first publication. Simultaneously, authors agreed to license their research papers under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License.\n\nLicense Permissions:\n\nUnder the CC BY-NC-SA 4.0 License, others are permitted to share and adapt the work, as long as proper attribution is given to the authors and acknowledgement is made of the initial publication in the Journal of Science & Technology. This license allows for the broad dissemination and utilization of research papers.\n\nAdditional Distribution Arrangements:\n\nAuthors are free to enter into separate contractual arrangements for the non-exclusive distribution of the journal's published version of the work. This may include posting the work to institutional repositories, publishing it in journals or books, or other forms of dissemination. In such cases, authors are requested to acknowledge the initial publication of the work in the Journal of Science & Technology.\n\nOnline Posting:\n\nAuthors are encouraged to share their work online, including in institutional repositories, disciplinary repositories, or on their personal websites. This permission applies both prior to and during the submission process to the Journal of Science & Technology. Online sharing enhances the visibility and accessibility of the research papers.\n\nResponsibility and Liability:\n\nAuthors are responsible for ensuring that their research papers do not infringe upon the copyright, privacy, or other rights of any third party. The Journal of Science & Technology and The Science Brigade Publishers disclaim any liability or responsibility for any copyright infringement or violation of third-party rights in the research papers.\n\nThe Journal of Science & Technology (JST) is a peer-reviewed, open-access journal that publishes original research articles, reviews, and short communications in all areas of science and technology. The journal welcomes submissions from all researchers, regardless of their geographic location or institutional affiliation.\n\nJournal of Science & Technology\nThe Science Brigade Publishers,\nA unit of Libertatem Media Private Limited\nF104, Anand Square, Tragad IOC Road, Chandkheda, Ahmedabad 382470\nWebsite - thesciencebrigade.com\nEmail - thesciencebrigade@gmail.com\nWhatsApp Support - Start Chat\n\n© Platform & Workflow by: Open Journal Systems\n",
        "Machine learning models employed in economic trend impact analysis": "Machine learning forecasting in the macroeconomic environment: the case ... : \nYour privacy, your choice\n\nWe use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media.\n\nBy accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection.\n\nSee our privacy policy for more information on the use of your personal data.\n\nManage preferences for further information and to change your choices.\n\nMachine learning forecasting in the macroeconomic environment: the case of the US output gap\n\n198 Accesses\n\n1 Citation\n\nExplore all metrics\n\nAbstract\n\nThis paper aims to forecast deviations of the US output measured by the industrial production index (IPI), from its long-run potential output, known as output gaps. These gaps are important for policymakers when designing relevant economic policies, especially when a negative output gap may show economic slack or underperformance, often associated with higher unemployment and low inflation. We use a dataset that includes 32 explanatory economic and financial variables and 18 lags of the IPI, spanning the period from 2000:1 to 2022:12, resulting in 50 variables and 276 monthly observations. The dataset is fed to five well-established machine learning (ML) methods, namely decision trees, random forests, XGBoost, long short-term memory (LSTM) and support vector machines (SVMs), coupled with the linear, the RBF and the polynomial kernel. Moreover, we use the standard elastic net logit method from the area of econometrics as a benchmark. Our results indicate that the tree-based ML techniques perform better in-sample, and the best overall forecasting model is the XGBoost achieving an out-of-sample accuracy of 91.67%.\n\nThis is a preview of subscription content, log in via an institution to check access.\n\nAccess this article\n\nSubscribe and save\n\nBuy Now\n\nPrice includes VAT (Lebanon)\n\nInstant access to the full article PDF.\n\nInstitutional subscriptions\n\nSimilar content being viewed by others\n\nMachine Learning in Macroeconomics: Application to DSGE Models\n\nBenchmark Analysis of Machine Learning Methods to Forecast the U.S. Annual Inflation Rate During a High-Decile Inflation Period\n\nOpening the Black Box: Machine Learning Interpretability and Inference Tools with an Application to Economic Forecasting\n\nExplore related subjects\n\nNotes\n\nKiley (2013) discusses three alternative definitions of the output gap: “the deviation of output from its long-run stochastic trend (i.e., the “Beveridge–Nelson cycle”); the deviation of output from the level consistent with current technologies and normal utilization of capital and labor input (i.e., the “production-function approach”); and the deviation of output from “flexible-price” output (i.e., its “natural rate”), page 1.\n\nOkun's law is an empirically observed relationship between unemployment and negative changes in output. According to this empirical relationship, a 1% increase in unemployment can be related to a 2% decrease in GDP, Ball et al (2017). Nevertheless, there are doubts for this empirical relationship, Lee (2000).\n\nReferences\n\nAguiar M, Gopinath G (2007) Emerging market business cycles: the cycle is the trend. J Polit Econ 115(1):69–102\n\nArticle\n  Google Scholar\n\nAlthnian A, AlSaeed D, Al-Baity H, Samha A, Dris AB, Alzakari N, Abou Elwafa A, Kurdi H (2021) Impact of dataset size on classification performance: an empirical evaluation in the medical domain. Appl Sci 11(2):796\n\nArticle\n  Google Scholar\n\nAraujo D, Pereira AM, Simões M (2020) Predicting the output gap: a comparison of machine learning models and economic techniques. J Appl Econ 23(1):47–64\n\nGoogle Scholar\n\nAssunção JB, Fernandes PA (2024) A robust method to date recessions and compute output gaps: the Portuguese case. Port Econ. https://doi.org/10.1007/s10258-024-00259-4\n\nArticle\n  Google Scholar\n\nBall L, Leigh D, Loungani P (2017) Okun’s law: Fit at 50? J Money Credit Bank 49(7):1413–1441\n\nArticle\n  Google Scholar\n\nBarigozzi M, Luciani M (2023) Measuring the output gap using large datasets. Rev Econ Stat 105(6):1500–1514\n\nArticle\n  Google Scholar\n\nBerger T, Kempa B (2011) Bayesian estimation of the output gap for a small open economy: The case of Canada. Econ Lett 112(1):107–112\n\nArticle\n  Google Scholar\n\nBerger T, Morley J, Wong B (2023) Nowcasting the output gap. J Econom 232(1):18–34\n\nArticle\n  Google Scholar\n\nBernhardsen T, Eitrheim Ø, Jore AS, Røisland Ø (2005) Real-time data for Norway: challenges for monetary policy. N Am J Econ Finance 16(3):333–349\n\nArticle\n  Google Scholar\n\nBlanchard O, Amighini A, Giavazzi F (2010) Macroeconomics: a European PERSPECTIVE. Pearson Education\n\nGoogle Scholar\n\nBreiman L (1996) Bagging predictors. Mach Learn 24(2):123–140\n\nArticle\n  Google Scholar\n\nBreiman L (2001) Random forests. Mach Learn 45:5–32\n\nArticle\n  Google Scholar\n\nBreiman L, Friedman JH, Olshen RA, Stone CJ (1984) Classification and regression trees. Wadsworth. Inc., Monterey, California, USA\n\nGoogle Scholar\n\nCamba-Mendez G, Rodriguez-Palenzuela D (2003) Assessment criteria for output gap estimates. Econ Model 20(3):529–562\n\nArticle\n  Google Scholar\n\nCampbell JY, Pflueger C, Viceira LM (2020) Macroeconomic drivers of bond and equity risks. J Polit Econ 128(8):3148–3185\n\nArticle\n  Google Scholar\n\nCayen JP, Van Norden S (2005) The reliability of Canadian output-gap estimates. N Am J Econ Finance 16(3):373–393\n\nArticle\n  Google Scholar\n\nChen T, Guestrin C (2016) Xgboost: a scalable tree boosting system. In: Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, pp 785–794\n\nChen X, Ishwaran H (2012) Random forests for genomic data analysis. Genomics 99(6):323–329\n\nArticle\n  Google Scholar\n\nCicceri G, Inserra G, Limosani M (2020) A machine learning approach to forecast economic recessions—an Italian case study. Mathematics 8(2):241\n\nArticle\n  Google Scholar\n\nCortes C, Vapnik V (1995) Support-vector networks. Mach Learn 20(3):273–297\n\nArticle\n  Google Scholar\n\nDou B, Zhu Z, Merkurjev E, Ke L, Chen L, Jiang J, Zhu Y, Liu J, Zhang B, Wei GW (2023) Machine learning methods for small data challenges in molecular science. Chem Rev 123(13):8736–8780\n\nArticle\n  Google Scholar\n\nDubbert T, Kempa B (2024) Nowcasting the output gap with shadow rates. Econ Lett 236:111583\n\nArticle\n  Google Scholar\n\nDupasquier C, Guay A, St-Amant P (1999) A survey of alternative methodologies for estimating potential output and the output gap. J Macroecon 21(3):577–595\n\nArticle\n  Google Scholar\n\nGogas P, Papadimitriou T (2021) Machine learning in economics and finance. Comput Econ 57:1–4\n\nArticle\n  Google Scholar\n\nGogas P, Papadimitriou T, Chrysanthidou E (2015) Yield curve point triplets in recession forecasting. Int Finance 18(2):207–226\n\nArticle\n  Google Scholar\n\nGogas P, Papadimitriou T, Matthaiou M, Chrysanthidou E (2014) Yield curve and recession forecasting in a machine learning framework. Comput Econ 45(4):635–645\n\nArticle\n  Google Scholar\n\nGogas P, Papadimitriou T, Sofianos E (2019) Money neutrality, monetary aggregates and machine learning. Algorithms 12(7):137\n\nArticle\n  Google Scholar\n\nGogas P, Papadimitriou T, Sofianos E (2021) Forecasting unemployment in the euro area with machine learning. J Forecast 41(3):551–566\n\nArticle\n  Google Scholar\n\nGranados C, Parra-Amado D (2024) Estimating the output gap after COVID: how to address unprecedented macroeconomic variations. Econ Model 135:106711\n\nArticle\n  Google Scholar\n\nHaider A, Safdar Ullah K (2008) Estimating output gap for Pakistan economy: structural and statistical approaches (working paper)\n\nHauzenberger N, Huber F, Klieber K (2023) Real-time inflation forecasting using non-linear dimension reduction techniques. Int J Forecast 39(2):901–921\n\nArticle\n  Google Scholar\n\nHochreiter S, Schmidhuber J (1997) Long short-term memory. Neural Comput 9(8):1735–1780\n\nArticle\n  Google Scholar\n\nHodrick R, Prescott E (1997) Postwar US business cycles: an empirical investigation. J Money Credit Bank 29(1):1\n\nArticle\n  Google Scholar\n\nJašová M, Moessner R, Takáts E (2020) Domestic and global output gaps as inflation drivers: What does the Phillips curve tell? Econ Model 87:238–253\n\nArticle\n  Google Scholar\n\nKatris C (2019) Prediction of unemployment rates with time series and Machine Learning Techniques. Comput Econ 55(2):673–706\n\nArticle\n  Google Scholar\n\nKiley MT (2013) Output gaps. J Macroecon 37:1–18\n\nArticle\n  Google Scholar\n\nKokol P, Kokol M, Zagoranski S (2022) Machine learning on small size samples: a synthetic knowledge synthesis. Sci Prog. https://doi.org/10.1177/00368504211029777\n\nArticle\n  Google Scholar\n\nLee J (2000) The robustness of Okun’s law: Evidence from OECD countries. J Macroecon 22(2):331–356\n\nArticle\n  Google Scholar\n\nMarcellino M, Musso A (2011) The reliability of real-time estimates of the euro area output gap. Econ Model 28(4):1842–1856\n\nArticle\n  Google Scholar\n\nMorley J, Wong B (2020) Estimating and accounting for the output gap with large Bayesian vector autoregressions. J Appl Economet 35(1):1–18\n\nArticle\n  Google Scholar\n\nMouchtaris D, Sofianos E, Gogas P, Papadimitriou T (2021) Forecasting natural gas spot prices with machine learning. Energies 14(18):5782\n\nArticle\n  Google Scholar\n\nOkun AM (1963) Potential GNP: its measurement and significance. Cowles Foundation for Research in Economics at Yale University\n\nOrphanides A (2001) Monetary policy rules based on real-time data. Am Econ Rev 91(4):964–985\n\nArticle\n  Google Scholar\n\nOrphanides A, Van Norden S (2002) The unreliability of output-gap estimates in real time. Rev Econ Stat 84(4):569–583\n\nArticle\n  Google Scholar\n\nPérez-Pons M, Parra-Dominguez J, Omatu S, Herrera-Viedma E, Corchado J (2021) Machine learning and traditional econometric models: a systematic mapping study. J Artif Intell Soft Comput Res 12(2):79–100\n\nArticle\n  Google Scholar\n\nPhillips AW (1958) The relation between unemployment and the rate of change of money wage rates in the United Kingdom, 1861–1957. Economica 25(100):283–299\n\nGoogle Scholar\n\nQuast J, Wolters MH (2022) Reliable real-time output gap estimates based on a modified Hamilton filter. J Bus Econ Stat 40(1):152–168\n\nArticle\n  Google Scholar\n\nRussell SJ, Norvig P (2016) Artificial intelligence: a modern approach. Pearson\n\nSofianos E, Gogas P, Papadimitriou T (2021) Mind the gap: Forecasting euro-area output gaps with machine learning. Appl Econ Lett 29(19):1824–1828\n\nArticle\n  Google Scholar\n\nSofianos E, Zaganidis E, Papadimitriou T, Gogas P (2024) Forecasting east and west coast gasoline prices with tree-based machine learning algorithms. Energies 17(6):1296\n\nArticle\n  Google Scholar\n\nXu P, Ji X, Li M, Lu W (2023) Small data machine learning in materials science. Npj Comput Mater. https://doi.org/10.1038/s41524-023-01000-z\n\nArticle\n  Google Scholar\n\nYoon J (2020) Forecasting of real GDP growth using machine learning models: gradient boosting and Random Forest approach. Comput Econ 57(1):247–265\n\nArticle\n  Google Scholar\n\nZou H, Hastie T (2005) Regularization and variable selection via the elastic net. J R Stat Soc Ser B (Stat Methodol) 67(2):301–320\n\nArticle\n  Google Scholar\n\nZhou S (2022) An analysis of the small sample datasets based on machine learning. In: Proceedings of the 2022 6th international conference on electronic information technology and computer engineering, vol 11, pp 1654–1658\n\nDownload references\n\nFunding\n\nThe first author would like to acknowledge that this work is part of the Interdisciplinary Thematic Institute MAKErS of the ITI 2021–2028 program of the University of Strasbourg, CNRS and INSERM. It has received financial support from the IdEx Unistra (ANR-10-IDEX-0002), and from the “Programme Investissement d'Avenir” as part of the SFRI-STRAT'US project(s) (ANR-20-SFRI-0012).\n\nAuthor information\n\nAuthors and Affiliations\n\nBureau d’Economie Théorique et Appliquée (ΒΕΤΑ), University of Strasbourg, University of Lorraine, CNRS, 67000, Strasbourg, France\n\nEmmanouil Sofianos\n\nDepartment of Finance and Accounting, Rennes School of Business, 2 Rue Robert d’Arbrissel, 35065, Rennes, France\n\nChristos Alexakis\n\nDepartment of Economics, Democritus University of Thrace, Komotini, Greece\n\nPeriklis Gogas & Theophilos Papadimitriou\n\nCorresponding author\n\nCorrespondence to Christos Alexakis.\n\nEthics declarations\n\nConflict of interest\n\nThe authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.\n\nAdditional information\n\nPublisher's Note\n\nSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\n\nAppendix\n\nAppendix\n\nTables 3 and 4 and Figs. 3, 4, 5, 6, 7, 8, 9 and 10.\n\nROC curve for the optimal SVM model coupled with the linear kernel (out of sample)\n\nROC curve for the optimal SVM model coupled with the RBF kernel (out of sample)\n\nROC curve for the optimal SVM model coupled with the polynomial kernel (out-of-sample)\n\nROC curve for the optimal decision tree model (out of sample)\n\nROC curve for the optimal random forest model (out of sample)\n\nROC curve for the optimal XGBoost model (out of sample)\n\nROC curve for the optimal LSTM model (out-of-sample)\n\nROC curve for the optimal elastic net logit model (out-of-sample)\n\nRights and permissions\n\nSpringer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law.\n\nReprints and permissions\n\nAbout this article\n\nCite this article\n\nSofianos, E., Alexakis, C., Gogas, P. et al. Machine learning forecasting in the macroeconomic environment: the case of the US output gap. Econ Change Restruct 58, 9 (2025). https://doi.org/10.1007/s10644-024-09849-w\n\nDownload citation\n\nReceived\n23 April 2024\n\nAccepted\n26 December 2024\n\nPublished\n09 January 2025\n\nDOI\nhttps://doi.org/10.1007/s10644-024-09849-w\n\nKeywords\n\nJEL Classification\n\nDiscover content\n\nPublish with us\n\nProducts and services\n\nOur brands\n\n178.135.19.63\n\nNot affiliated\n\n© 2025 Springer Nature\n"
    },
    "AnalyzedArticles": {
        "Machine learning models employed in bankruptcy prediction": {
            "Article_Summary": "The research focuses on using machine learning models for bankruptcy prediction, specifically applying XGBoost, Random Forest, and Support Vector Machines to a large dataset of 21,114 US firms from 1970-2020 with 57 financial ratios. The study demonstrates that machine learning models, particularly XGBoost, can achieve over 99% accuracy in predicting corporate bankruptcies. The research applied the best-performing model to predict bankruptcies during the COVID-19 recession, finding that while bankruptcy rates will increase substantially in 2020, they are not expected to significantly exceed the levels seen in 2010.",
            "ML_Models": "XGBoost, Support Vector Machines (SVM), Borderline-SVM SMOTE"
        },
        "Machine learning models employed in financial performance optimization": {
            "Article_Summary": "The article explores the synergy between Artificial Intelligence (AI) and financial engineering, focusing on how advanced machine learning techniques can enhance financial forecasting models. The research highlights the transformation of traditional financial engineering through AI methods like machine learning, natural language processing (NLP), and reinforcement learning, enabling more dynamic and adaptive predictive models for financial risk assessment and portfolio optimization.",
            "ML_Models": "Transformer Networks, Long Short-Term Memory (LSTM), Reinforcement Learning Algorithms"
        },
        "Machine learning models employed in customer banking product targeting": {
            "Article_Summary": "The article discusses AI-driven customer segmentation in retail banking, focusing on how machine learning techniques can analyze complex customer datasets to create more personalized marketing strategies and improve customer retention. The approach involves processing real-time customer data to develop nuanced customer profiles and predict behaviors more accurately than traditional methods.",
            "ML_Models": "Decision Trees, K-Means Clustering, Hierarchical Clustering"
        },
        "Machine learning models employed in economic trend impact analysis": {
            "Article_Summary": "The research focuses on forecasting US output gaps using machine learning techniques, analyzing deviations of industrial production index from long-run potential output. The study uses a comprehensive dataset of 32 economic and financial variables with 18 industrial production index lags, spanning 2000-2022, to predict economic performance and potential slack.",
            "ML_Models": "XGBoost, Support Vector Machines (SVM), Decision Trees"
        }
    },
    "Relationship": {
        "Machine learning models employed in bankruptcy prediction": [
            "The bankruptcy prediction models (XGBoost, SVM, Borderline-SVM SMOTE) directly relate to the 'data' table which contains comprehensive financial indicators and the 'Bankrupt?' target variable. These models analyze financial ratios, profitability metrics, debt structures, and cash flow indicators to predict company bankruptcy risk."
        ],
        "Machine learning models employed in financial performance optimization": [
            "The financial performance optimization ML models (XGBoost, SVMs, Decision Trees, Ensemble Methods) can leverage the extensive financial data in the 'data' table to predict bankruptcy risk and identify key financial performance indicators. The models can analyze financial ratios, profitability metrics, and growth indicators to optimize financial decision-making and performance."
        ],
        "Machine learning models employed in customer banking product targeting": [
            "The banking dataset contains customer demographic and campaign data that can be used with clustering algorithms (K-Means, Hierarchical Clustering) to segment customers into distinct groups based on similar characteristics. Decision Trees can then be applied to predict which customer segments are most likely to respond positively to specific banking products or marketing campaigns."
        ],
        "Machine learning models employed in economic trend impact analysis": [
            "The ML models (XGBoost, SVM, Decision Trees) can analyze how economic indicators from the banking table correlate with financial metrics in the data table to predict bankruptcy risk and business performance under different economic conditions. These models can identify patterns between macroeconomic factors and company financial health."
        ]
    },
    "Needs": {
        "Machine learning models employed in bankruptcy prediction": [
            "For bankruptcy prediction, we need the 'Bankrupt?' column as the binary target variable (classification task), with financial indicators as features. XGBoost requires numerical inputs from financial ratios, while SVM models will benefit from normalized versions of these metrics. Borderline-SVM SMOTE addresses class imbalance issues common in bankruptcy datasets where non-bankrupt cases typically outnumber bankrupt ones. The model will perform binary classification to determine bankruptcy risk based on financial health indicators."
        ],
        "Machine learning models employed in financial performance optimization": [
            "For financial performance optimization, we need numerical features from the financial ratios and indicators to train classification and regression models. The 'Bankrupt?' column serves as the target variable for classification models predicting bankruptcy risk. The financial ratios and performance metrics will be used as features to identify patterns and correlations with financial success or failure. The models require normalized numerical data and can benefit from feature selection techniques to identify the most predictive financial indicators."
        ],
        "Machine learning models employed in customer banking product targeting": [
            "For customer segmentation using K-Means and Hierarchical Clustering, we need demographic and financial behavior data as numerical or properly encoded categorical features. The selected columns provide personal attributes and banking relationship information that can create meaningful customer segments. For Decision Trees, we need these same features as predictors with 'y' (campaign outcome) as the target variable for a classification task. Age should be numerical, while categorical variables like job, education, and marital status need to be encoded. The end goal is to classify customers into segments and predict their likelihood of accepting banking products."
        ],
        "Machine learning models employed in economic trend impact analysis": [
            "For economic trend impact analysis, we need numerical features from both tables to train classification and regression models. The bankruptcy indicator (classification target) from the data table combined with financial ratios will be correlated with economic indicators from the banking table. XGBoost and Decision Trees require properly scaled numerical inputs with minimal missing values, while SVM needs normalized data. The models will predict how economic shifts impact bankruptcy probability and financial performance metrics."
        ]
    },
    "ModelsPerTopic": {
        "Machine learning models employed in bankruptcy prediction": "XGBoost, Support Vector Machines (SVM), Borderline-SVM SMOTE",
        "Machine learning models employed in financial performance optimization": "Transformer Networks, Long Short-Term Memory (LSTM), Reinforcement Learning Algorithms",
        "Machine learning models employed in customer banking product targeting": "Decision Trees, K-Means Clustering, Hierarchical Clustering",
        "Machine learning models employed in economic trend impact analysis": "XGBoost, Support Vector Machines (SVM), Decision Trees"
    },
    "ML_Models1": [
        "Random Forest, Gradient Boosting, Neural Networks, Logistic Regression",
        "XGBoost, Support Vector Machines, Decision Trees, Ensemble Methods",
        "Random Forest, Logistic Regression, K-Nearest Neighbors, Neural Networks",
        "Time Series Models, LSTM Networks, Regression Models, Bayesian Networks"
    ],
    "GPT_Columns": {
        "Machine learning models employed in bankruptcy prediction": [
            [
                {
                    "data": [
                        "Bankrupt?",
                        "ROA(C) before interest and depreciation before interest",
                        "Debt ratio %",
                        "Cash flow rate",
                        "Total debt/Total net worth",
                        "Net Income to Total Assets",
                        "Operating Profit Rate"
                    ]
                }
            ]
        ],
        "Machine learning models employed in financial performance optimization": [
            [
                {
                    "data": [
                        "Bankrupt?",
                        "ROA(C) before interest and depreciation before interest",
                        "Operating Gross Margin",
                        "Operating Profit Rate",
                        "Cash flow rate",
                        "Total Asset Growth Rate",
                        "Debt ratio %"
                    ]
                }
            ]
        ],
        "Machine learning models employed in customer banking product targeting": [
            [
                {
                    "banking": [
                        "age",
                        "job",
                        "education",
                        "marital",
                        "housing",
                        "loan",
                        "campaign"
                    ]
                }
            ]
        ],
        "Machine learning models employed in economic trend impact analysis": [
            [
                {
                    "data": [
                        "Bankrupt?",
                        "ROA(C) before interest and depreciation before interest",
                        "Operating Profit Rate",
                        "Cash flow rate",
                        "Debt ratio %",
                        "Net worth/Assets",
                        "Total Asset Turnover"
                    ]
                },
                {
                    "banking": [
                        "emp_var_rate",
                        "cons_price_idx",
                        "cons_conf_idx",
                        "euribor3m",
                        "nr_employed",
                        "y",
                        "duration"
                    ]
                }
            ]
        ]
    },
    "AdjustedColumns": {}
}