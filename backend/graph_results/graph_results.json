{
    "tables": [
        {
            "data": [
                "Bankrupt?",
                " ROA(C) before interest and depreciation before interest",
                " ROA(A) before interest and % after tax",
                " ROA(B) before interest and depreciation after tax",
                " Operating Gross Margin",
                " Realized Sales Gross Margin",
                " Operating Profit Rate",
                " Pre-tax net Interest Rate",
                " After-tax net Interest Rate",
                " Non-industry income and expenditure/revenue",
                " Continuous interest rate (after tax)",
                " Operating Expense Rate",
                " Research and development expense rate",
                " Cash flow rate",
                " Interest-bearing debt interest rate",
                " Tax rate (A)",
                " Net Value Per Share (B)",
                " Net Value Per Share (A)",
                " Net Value Per Share (C)",
                " Persistent EPS in the Last Four Seasons",
                " Cash Flow Per Share",
                " Revenue Per Share (Yuan ¥)",
                " Operating Profit Per Share (Yuan ¥)",
                " Per Share Net profit before tax (Yuan ¥)",
                " Realized Sales Gross Profit Growth Rate",
                " Operating Profit Growth Rate",
                " After-tax Net Profit Growth Rate",
                " Regular Net Profit Growth Rate",
                " Continuous Net Profit Growth Rate",
                " Total Asset Growth Rate",
                " Net Value Growth Rate",
                " Total Asset Return Growth Rate Ratio",
                " Cash Reinvestment %",
                " Current Ratio",
                " Quick Ratio",
                " Interest Expense Ratio",
                " Total debt/Total net worth",
                " Debt ratio %",
                " Net worth/Assets",
                " Long-term fund suitability ratio (A)",
                " Borrowing dependency",
                " Contingent liabilities/Net worth",
                " Operating profit/Paid-in capital",
                " Net profit before tax/Paid-in capital",
                " Inventory and accounts receivable/Net value",
                " Total Asset Turnover",
                " Accounts Receivable Turnover",
                " Average Collection Days",
                " Inventory Turnover Rate (times)",
                " Fixed Assets Turnover Frequency",
                " Net Worth Turnover Rate (times)",
                " Revenue per person",
                " Operating profit per person",
                " Allocation rate per person",
                " Working Capital to Total Assets",
                " Quick Assets/Total Assets",
                " Current Assets/Total Assets",
                " Cash/Total Assets",
                " Quick Assets/Current Liability",
                " Cash/Current Liability",
                " Current Liability to Assets",
                " Operating Funds to Liability",
                " Inventory/Working Capital",
                " Inventory/Current Liability",
                " Current Liabilities/Liability",
                " Working Capital/Equity",
                " Current Liabilities/Equity",
                " Long-term Liability to Current Assets",
                " Retained Earnings to Total Assets",
                " Total income/Total expense",
                " Total expense/Assets",
                " Current Asset Turnover Rate",
                " Quick Asset Turnover Rate",
                " Working capitcal Turnover Rate",
                " Cash Turnover Rate",
                " Cash Flow to Sales",
                " Fixed Assets to Assets",
                " Current Liability to Liability",
                " Current Liability to Equity",
                " Equity to Long-term Liability",
                " Cash Flow to Total Assets",
                " Cash Flow to Liability",
                " CFO to Assets",
                " Cash Flow to Equity",
                " Current Liability to Current Assets",
                " Liability-Assets Flag",
                " Net Income to Total Assets",
                " Total assets to GNP price",
                " No-credit Interval",
                " Gross Profit to Sales",
                " Net Income to Stockholder's Equity",
                " Liability to Equity",
                " Degree of Financial Leverage (DFL)",
                " Interest Coverage Ratio (Interest expense to EBIT)",
                " Net Income Flag",
                " Equity to Liability"
            ]
        },
        {
            "banking": [
                "age",
                "job",
                "marital",
                "education",
                "default",
                "housing",
                "loan",
                "contact",
                "month",
                "day_of_week",
                "duration",
                "campaign",
                "pdays",
                "previous",
                "poutcome",
                "emp_var_rate",
                "cons_price_idx",
                "cons_conf_idx",
                "euribor3m",
                "nr_employed",
                "y"
            ]
        }
    ],
    "analyzed_topics": [
        {
            "topic": "Machine learning models employed in bankruptcy prediction",
            "ML_Models": "Random Forest, Gradient Boosting, Neural Networks, Logistic Regression",
            "reasoning": "The 'Bankrupt?' column suggests this dataset is for bankruptcy prediction. Financial ratios like ROA, debt ratios, and cash flow metrics are strong predictors. ML models can analyze these financial indicators to identify patterns that precede bankruptcy, helping companies take preventive measures."
        },
        {
            "topic": "Machine learning models employed in financial performance optimization",
            "ML_Models": "XGBoost, Support Vector Machines, Decision Trees, Ensemble Methods",
            "reasoning": "The extensive financial ratios (ROA, operating margins, growth rates) can be used to predict and optimize company performance. ML models can identify which financial metrics most strongly correlate with success, helping management focus on key performance indicators."
        },
        {
            "topic": "Machine learning models employed in customer banking product targeting",
            "ML_Models": "Random Forest, Logistic Regression, K-Means Clustering, Naive Bayes",
            "reasoning": "The banking table contains demographic data (age, job, education) and previous campaign results, ideal for predicting which customers are likely to accept offers. ML models can optimize marketing campaigns by targeting the right customers with appropriate financial products."
        },
        {
            "topic": "Machine learning models employed in economic trend impact analysis",
            "ML_Models": "Time Series Models, LSTM Networks, Prophet, Regression Models",
            "reasoning": "The banking table includes economic indicators (emp_var_rate, cons_price_idx, euribor3m) that can be analyzed alongside company financial data to predict how macroeconomic trends affect business performance and bankruptcy risk, enabling proactive strategic adjustments."
        }
    ],
    "csv_files": [
        "csv_test/data.csv",
        "csv_test/banking.csv"
    ],
    "topic": [
        "Machine learning models employed in bankruptcy prediction",
        "Machine learning models employed in financial performance optimization",
        "Machine learning models employed in customer banking product targeting",
        "Machine learning models employed in economic trend impact analysis"
    ],
    "ScrapedArticles": {
        "Machine learning models employed in bankruptcy prediction": "Bankruptcy prediction using machine learning and an application to the ... : \nData Science in Finance and Economics\n\nData Science in Finance and Economics\n\nBankruptcy prediction using machine learning and an application to the case of the COVID-19 recession\n\nJEL Codes: O30, E37, E60\n\nAbstract\n\nBankruptcy prediction is an important problem in finance, since successful predictions would allow stakeholders to take early actions to limit their economic losses. In recent years many studies have explored the application of machine learning models to bankruptcy prediction with financial ratios as predictors. This study extends this research by applying machine learning techniques to a quarterly data set covering financial ratios for a large sample of public U.S. firms from 1970–2019. We find that tree-based ensemble methods, especially XGBoost, can achieve a high degree of accuracy in out-of-sample bankruptcy prediction. We next apply our best model, using XGBoost, to the problem of predicting the overall bankruptcy rate in USA in the second half of 2020, after the COVID-19 pandemic had necessitated a lockdown, leading to a deep recession. Our model supports the prediction, made by leading economists, that the rate of bankruptcies will rise substantially in 2020, but it also suggests that this elevated level will not be much higher than 2010.\n\n1.   Introduction\n\nBankruptcy prediction is the problem of detecting financial distress in businesses which will lead to eventual bankruptcy. Bankruptcy prediction has been studied since at least 1930s. The early models of bankruptcy prediction employed univariate statistical models over financial ratios. The univariate models were followed by multi-variate statistical models such as the famous Altman Z-score model. The recent advances in the field of Machine learning have led to the adoption of Machine learning algorithms for bankruptcy prediction. Machine Learning methods are increasingly being used for bankruptcy prediction using financial ratios. A study by Barboza, Kimura and Altman found that Machine Learning models can outperform classical statistical models like multiple discriminant analysis (MDA) by a significant margin in bankruptcy prediction (Barboza et al., 2017).\n\nBankruptcy prediction is an important for modern economies because early warnings of bankrupt help not only the investor but also public policy makers to take proactive steps to minimize the impact of bankruptcies. The reasons that add to the significance of bankruptcy prediction are as follows:\n\n(1). Better allocation of resources\n\nInstitutional investors, banks, lenders, retail investors are always looking at information that predicts financial distress in publicly traded firms. Early prediction of bankruptcy helps not only the investors and lenders but also the managers of a firm to take corrective action thereby conserving scare economic resources. Efficient allocation of capital is the cornerstone of growth in modern economies.\n\n(2). Input to policy makers\n\nAccurate prediction of bankruptcies of businesses and individuals before they happen gives law makers and policy makers some additional time to alleviate systemic issues that might be causing the bankruptcies. Indeed, with bankruptcies taking center stage in political discourse of many countries, the accurate prediction of bankruptcy is a key input for politicians, bureaucrats and in general for anyone who is making public policy.\n\n(3). Corrective action for business managers\n\nThe early prediction of bankruptcy is likely to highlight business issues thereby giving the company's manager additional time to make decisions that will help avoid bankruptcy. This effect is likely to be more profound in public companies where the management has a fiduciary duty to the shareholders.\n\n(4). Identification of sector wide problems\n\nBankruptcy prediction models that flag firms belonging to a certain sector are likely to be a leading indicator of an upcoming downturn in a certain sector of an economy. With robust models, the business managers and government policy makers would become aware and take corrective action to limit the magnitude and intensity of the downturn in the specific sector. Industry groups in turn has been shown to significantly effect forecasting models (Chava and Jarrow, 2004).\n\n(5). Signal to Investors\n\nInvestors can make better and more informed decisions based on the prediction of bankruptcy models. This not only forces the management of firms to take corrective action but also helps to soften the overall economic fallout that results from the bankruptcies. Empirical studies have shown that investment opportunities are significantly related to likelihood of bankruptcy (Lyandres & Zhdanov, 2007).\n\n(6). Relation to adjacent problems\n\nBankruptcy prediction is often the first step used by ratings agencies to detect financial distress in firms. Based on the predictions of bankruptcy models, ratings agencies investigate and assess credit risk. Getting flagged by bankruptcy prediction models is often the first step that triggers the process of revising credit ratings. A literature survey covering 2000–2013 demonstrates the close relation between bankruptcy prediction and credit risk (García et al., 2015).\n\nMost past studies in bankruptcy prediction including those using Machine Learning have used a relatively small sample of firms and a small number of financial ratios. This study distinguishes itself by using a much larger dataset having data for 21,114 U.S. firms (samples) and 57 financial ratios (features). Our dataset covers US firms from 1970 to 2020. Bankruptcy prediction models have been researched and built since the 1960s. The models built from 1960 to 1990 were primarily statistical models such as univariate, multiple discriminant analysis and logit and probit models. Starting from 1990s machine learning models started outperforming statistical models. Since this study applies the most popular contemporary machine learning algorithms using a big data set, we will compare our model with the machine learning models built since the 1990s. A full listing outlining the comparison with past machine learning studies and models for bankruptcy prediction is shown in the Table 1.\n\nIn this study we have used three popular machine learning techniques—Random Forest, Support Vector Machines, and XGBoost to construct forecasting models. We find that Machine Learning models perform very well, with XGBoost being the most successful technique that achieves an accuracy score of more than 99% in out of sample testing.\n\nWe also apply our XGBoost model to an important current issue, the task of predicting bankruptcies during the second half of 2020. The depth of the recession caused by the lockdowns that have been imposed to contain the COVID-19 pandemic has raised worries that corporate bankruptcies may rise substantially in the near future. According to a report in the New York Times (2020), Edward Altman, a pioneer of bankruptcy prediction research, and the creator of the famous Z score model, expects a \"tsunami of bankruptcies\" that will exceed the number of bankruptcies that followed the 2008 financial crisis. The result from our Machine Learning model confirms Prof Altman's fears that corporate bankruptcies will rise substantially in late 2020 and equal the highs seen during the 2008-09 recession. However, this study finds that the elevated level of bankruptcies will not be significantly different from 2010.\n\nThe previous studies done for bankruptcy prediction have not taken a systematic view of the data used to build the models. The previous studies have been more focused on the models rather than on the data used to build the models. This study offers a much more balanced view where both the data and the models are given equal importance. To begin with, we have use Compustat are a source database to get an exhaustive list of financial ratios over US firms from 1970 to 2020. Compustat is a high-quality database used by several famous finance related papers such as Fama and French (1993). Most of the previous studies have used relatively small datasets as compared to ours. This study takes a systematic look at as many features as possible to train our machine learning models. Our balanced approach is also consistent with the shift from model centric to data centric approach proposed by Andrew Ng (Gil Press, 2021).\n\nThe rest of the paper is structured as follows:\n\nSection 2—Describes the existing literature for bankruptcy prediction.\n\nSection 3—Describes the data and the method used to clean, process, and fit the data into our machine learning models. This section also covers the process used to predict the number of bankruptcies using Q2-2020 ratios.\n\nSection 4—Describes the results observed from the experiments\n\nSection 5—Presents our final comments and discusses the implications of the results.\n\n2.   Literature review\n\nBankruptcy prediction models prior to 1990s were primarily statistical models employing univariate, multivariate and logit & probit techniques. In 1966, Beaver applied univariate analysis in which the predictive ability of 30 financial ratios was tested one at a time to predict bankruptcy (Beaver, 1966). Altman in 1968 performed a multi-variate discriminant analysis (MDA) using 5 ratios to create a linear discriminant function of 5 variables (Altman, 1968). Several variants of MDA were developed in the following years. Edmister used 19 financial ratios to build a linear model for bankruptcy prediction (Edmister, 1972). Deakin found that a linear combination of the 14 ratios could be used to predict bankruptcy five years prior to failure (Deakin, 1972). Ohlson studied the shortcomings of MDA models and built a conditional logit model using maximum likelihood estimation (Ohlson, 1980). The datasets used in all these studies were quite small as compared to modern standards. Ohlson's study for example used a dataset of 2058 firms out of which 105 firms represented the bankrupt class.\n\nThe next phase in the evolution of bankruptcy models started in the 1990s with several machine learning algorithms outperforming the older statistical models. Machine learning models such as Random Forests, Support Vector Machines (SVM) and Gradient Boosted Trees were found to be particularly effective for bankruptcy prediction. Barboza, Kimura and Altman compared statistical models with machine learning (ML) models. They found the Random Forests outperformed Alman's Z-score model by a significant margin (Barboza et al., 2017). These results were corroborated by studies (Joshi et al., 2018; Rustam and Saragih, 2018; Gnip and Drotár, 2019). Support Vector Machine (SVM) was also found to be a very effective machine learning algorithm in several studies. Hang et al. (2004) and Chen et al. (2008) achieved superior results for credit rating classification problem by using SVM. Song et al. (2008) used SVM to predict financial distress. Some studies also found boosted trees-based algorithms to outperform SVM. Wang, Ma and Yang proposed a new boosted tree-based algorithm for bankruptcy prediction which they found to be more effective than SVM (Wang et al., 2014). Heo and Yang (2014) used Adaboost algorithm to predict bankruptcy for Korean construction firm. They found Adaboost to have better accuracy than SVM (Heo and Yang, 2014). A more recent study in 2021 has used XGBoost and Random Forest algorithms to predict bankruptcies over 12 months. This study used a medium sized training dataset containing data for 8959 firms registered in Italy (Perboli and Arabnezad, 2021). Another recent study uses a database of Taiwanese firms to predict bankruptcy. This study used data set contain 96 attributes for 6819 firms to train machine learning models (Wang and Liu, 2021). One common attribute shared by all the forementioned studies is the relatively small size of their training data sets. The datasets used by these studies are small as compared to datasets used in the big data era. The largest training dataset in these studies had just 2600 samples which is quite small.\n\nBased on the literature review, the following trends become apparent:\n\n●  Machine Learning Models are now consistently outperforming statistical models\n\n●  The training data sets used to train the existing machine learning models are relatively small as compared to the data sets used for training models in other application areas.\n\n●  Ensemble methods such as Random Forest and Boosted trees have performed better than other models in bankruptcy prediction.\n\n3.   Data and methodology\n\nThis study differentiates itself from previous studies by using a substantially larger dataset as compared to previous studies. We use a very standard and well documented dataset called Compustat to retrieve the financial ratios. Compustat is a standard financial dataset used in financial research. Compustat has been used by some very popular papers in finance such as Fama and French (1993). We have used 57 financial ratios that are listed in Table 2. Financial ratios are inputs used to train Bankruptcy prediction models. While most studies use fewer financial ratios, this study applies a large set of financial ratios of US Firms from 1970–2020 (50 years) to train Random Forest, SVM and XGBoost Models. This section discusses the overall methodology which includes data cleaning, balancing, model fitting, and analysis of results.\n\nPrevious studies have used small to medium sized data sets for training Machine learning models. This study sets itself apart by using a much larger training dataset. We used financial ratios data set from Compustat. The financial ratios data set was then joined with another dataset called Bankruptcy data set. The bankruptcy data set contains the data such as date of bankruptcy, bankruptcy reason and GVKEY (primary key) while the financial ratios dataset contains all the financial ratios mentioned in Table A.1. The two datasets were programmatically joined using a common field named GVKEY. GVKEY is a unique identifier assigned to each firm. The relation amongst the two datasets that were used to create our labelled training dataset is best represented by the ER schema diagram shown in Figure 1.\n\nThe financial ratios dataset we have used contains 57 financial ratios mentioned in Table A.1 in Appendix A. This is an exhaustive list of features used to train our models. We have included ratios which are often overlooked but are likely to help detect patterns related to edge cases.\n\nThe first step of building a predictive model is data pre-processing and cleaning. The original data from Compustat had 75 financial ratios for 21,114 US firms. This data covered firms established in the US between 1970 and 2020. The dataset contained firms that belonged to 2 classes: bankrupt and non-bankrupt or continuing enterprises. The dataset contains 1212 bankrupt firms and 19,902 non-bankrupt firms. The distribution of data points (samples) belonging to these two classes is summarized in Table 2. The next step was to drop features which had null values for more than 6000 firms out of 21,114 firms. This step ensured that we don't have more than 30% of null values in any feature. The goal is to ensure that the true distribution generating this data is preserved and learned by our machine learning models. 18 features (financial ratios) were dropped from the data set because they had null values for more than 6000 (30% of total number of firms). The dataset now had 75 − 18 = 57 features. Next, we scaled our data to have mean = 0 and variance = 1 using Scikit-learns Standard Scaler class. Scaling is required to ensure that gradient descent converges on the minima of the loss function. The last step of data cleaning was to impute the missing values in the 57 financial ratios (features). For imputing the missing values, we used the KNN algorithm which used three nearest neighbours to estimate the missing value. Further, the weight assigned to each neighbour is a function of its Euclidean distance from the data point with missing value. KNN with 3-neighbours has been found to be effective in preserving the true distribution of the data (Beretta and Santaniello, 2016).\n\nThe cleaned and scaled dataset without any missing values was an imbalanced dataset (see Table 2). The dominant class was the bankruptcy class. Approximately 90% of the samples belonged to the majority class which is non-bankrupt firms. Since the goal of this study is train a classifier to identify bankrupt firms, we decided to balance the classes in our training data. This would ensure that our model would learn about the minority class which is the bankrupt class. This is important in the context of bankruptcy prediction because detecting samples belonging to the bankrupt class. To balance the dataset, we use the Synthetic Minority Over-sampling technique (SMOTE) proposed by Chawla et al. (Chawla et al., 2002). SMOTE generates synthetic samples using the features of the data. The minority class is oversampled by taking a minority class sample and then a line is drawn from this minority class sample to k-nearest minority class samples. Synthetic minority class samples are generated along the line joining the minority class sample to its minority class neighbours. Additionally, to ensure that our balanced dataset facilitated learning of the bankrupt class, we also used Borderline-SVM SMOTE. Borderline-SVM SMOTE technique uses samples close the decision boundary (support vectors) to create synthetic samples (Nguyen et al., 2011). Finally, we used the Adaptive Synthetic Sampling (ADASYN) algorithm of He, Bai, Garcia and Li to generate samples in regions of feature space where the density of minority samples is low (He et al., 2008). The result was a balanced dataset containing 19902 samples of non-bankrupt class and 20,517 bankrupt class. The balanced dataset has 57 financial ratios (features).\n\nThe balanced dataset was then shuffled and split into training set containing 70% of the samples and test set containing 30% of the samples. The purpose of creating a test set is to test the accuracy of the models on data that the models have not been trained on. Collecting metrics based on the test set gives practitioners an idea of the generalization performance of machine learning models.\n\nThe training data set was fitted into three machine learning models. These models are: Random Forest, Support Vector Machine (SVM) and XGBoost. After fitting, the models were then used to predict for samples in the test set to assess their relative performance.\n\nFor comparing the performance of the models, we decided to use Accuracy score, Receiver Operating Curve (ROC) and Area Under ROC Curve (AUC). Accuracy score can be used because we are training our models using a balanced dataset. However, to get a better idea of the True Positive Rate (TPR) and False Positive Rate (FPR) we decided to employ ROC and AUC metrics as well. It is important to compare the TPR and FPR because it is more to avoid False negatives (FN) as compared to False positives (FP). False negative (FN) would be a firm which would go bankrupt but is wrongly classified by our model as a non-bankrupt sample. False positive (FP) on the other hand would be a firm that is not bankrupt but is wrongly classified as a bankrupt firm.\n\nThe goal of this study is to predict number of bankruptcies within the next 30, 90 and 180 days. We trained 3 different models to predict the number of bankruptcies within 30, 90 and 180 days. The models were built and analysed using the same approach. The only difference was that the training and test labels for each model were derived from the bankruptcy date. For example, to train the model for predicting number of bankruptcies within 30 days, we used\n\nwhere\n\nwhere\n\nelse\n\nTherefore, we trained 9 models to predict bankruptcies within 30, 90 and 180 days. For example, for predicting bankruptcy within 30 days we trained Random Forest, SVM and XGBoost. After training the models, we picked the best model based on performance metrics described in previous section and then we used the best model to predict the number of bankruptcies using the latest Q2 2020 financial ratios from Capital IQ. In this final prediction set, we only kept data for firms which did not have any significant gaps or holes. Finally, we used the final prediction set from Q2 2020 to predict the number of bankruptcies we expect to happen over the next 30, 90 and 180 days.\n\n4.   Results\n\nAs mentioned in the previous section, we trained 9 models, using three different techniques, RF, SVM, XGBoost, for predicting bankruptcies over 30, 90 and 180 days. Next, we used the test set to make predictions and then assessed the relative performance. Based on the chosen metrics of accuracy score and Area under ROC curve (ROC AUC), XGBoost outperformed the other models for predicting bankruptcy within 30, 90 and 180 days. The actual scores for accuracy and AUC are presented in Table 3.\n\nThe accuracy score of XGBoost models is consistently better than SVM and Random Forest. This result is also consistent with the ROC curves which are shown in Figure 2 below.\n\nAs seen in Figure 2, the ROC curve for XGBoost is closest to the top left corner thereby covering maximum area under it. XGBoost is therefore the best performing model closely followed by Random Forest. The fact that these metrics are calculated using the test set (containing data which model has not been trained on) gives us confidence in the ability of our models to generalize.\n\nWe present the performance metrics of previous studies in Table 4. Previous studies have used 2 performance metrics: Test accuracy and Area Under ROC curve (AUC). To keep the comparison consistent, we have computed both test accuracy score and AUC for our models (see Table 3). Our best model built using XGBoost significantly outperforms the models built in previous studies. The accuracy of our XGBoost model for prediction bankruptcy within 180 days is 98.69% which is lower than the test accuracy of our XGBoost models for predicting bankruptcies within 30 and 90 days. However, our model for predicting bankruptcies within 180 days has a higher test accuracy (98.69%) than models built in previous studies. Similarly, our model for predicting bankruptcies within 180 days has an AUC score of 0.99 which is higher than the AUC score reported by previous studies. Our performance metrics of accuracy and AUC score are computed over out of training samples which also indicates to the robustness of our results.\n\nNext, we apply our best model, using XGBoost, to the data from Q2-2020 to evaluate the possibility of a substantial upsurge in business bankruptcies in the second half of 2020 because of the deep 2020 recession caused by the pandemic. We apply this best model to the latest available ratios, for Q2-2020, and classify a firm as going bankrupt during the next 30, 90, or 180 days if the predicted probability of bankruptcy is higher than 0.50.\n\nUsing this method, our best model in each category predicted 74 bankruptcies within 30 days, 189 bankruptcies within 90 days and 354 Bankruptcies within 180 days. This prediction is for all firms contained in the S & P Global database, both public and private. The predictions for the number of bankruptcies are summarized in Table 5.\n\nS & P Global has reported a total of 336 actual bankruptcies until the end of June 2020. If we add our prediction of 354 bankruptcies to the actual bankruptcies, then we predict a total of 336 + 354 = 690 bankruptcies in 2020. We summarize our predictions in Table 6 below.\n\nSince the number of firms in the database changes from year to year, we decided to compare the prediction for 2020 with the past by using bankruptcy rates, i.e., the ratio of the number of bankruptcies to the total number of firms. As shown in Table 7, our prediction of 690 bankruptcies in 2020 represents a bankruptcy rate of 4.35% for all US firms. This rate is the highest in the last 10 years. The second highest rate of 4.2%, only slightly lower, was seen in 2010, in the immediate aftermath of the 2008-09 recession. The average rate during the economic expansion years of 2011–2019 was 3.2%, more than a full percentage point lower than the predicted 2020 rate. We conclude that we will indeed see a much higher rate bankruptcies in 2020, but it is unlikely to be substantially larger than in 2010.\n\n5.   Conclusions\n\nWe find that two different Machine Learning algorithms, Random Forest (RF) and Extreme Gradient Boosting (XGBoost) produce accurate predictions of whether a firm will go bankrupt within the next 30, 90, or 180 days, using financial ratios as input features. The XGBoost based models perform exceptionally well, with 99% out-of-sample accuracy. Our training dataset uses a large database of public US firms over a period of 49 years, 1970–2019, and 57 financial ratios. This study has used a substantially larger training dataset as compared to previous studies.\n\nAn application of our best performing XGBoost model to Q2-2020 financial data for a sample of both private and public U.S. firms shows that the bankruptcy rate will climb substantially higher in 2020 than in the expansion years of 2011–2019. However, our model suggests that the rate will be only marginally higher than in 2010.\n\nWe identify the following areas for further research:\n\n●  Adding macro-economic features—It will be interesting to add macro-economic features to training data used for training machine learning models for bankruptcy prediction.\n\n●  Train deep neural networks with different topologies—Another interesting area of research would be to apply different types of deep neural networks such as TabNet and Recurrent neural networks.\n\nConflict of interest\n\nAll authors declare no conflicts of interest in this paper.\n\nReferences\n\nThis article has been cited by:\n\nTop\n\nMachine Learning in Bankruptcy Prediction: A Literature Review : \nMachine Learning in Bankruptcy Prediction: A Literature Review\n\nFiles\n\nAuthors\n\nDate\n\nMajor/Subject\n\nMcode\n\nDegree programme\n\nLanguage\n\nWe collect and process your personal information for the following purposes: Authentication, Preferences, Acknowledgement and Statistics.\n\nPredicting Financial Distress Using Machine Learning Techniques : \nYour privacy, your choice\n\nWe use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media.\n\nBy accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection.\n\nSee our privacy policy for more information on the use of your personal data.\n\nManage preferences for further information and to change your choices.\n\nPredicting Financial Distress Using Machine Learning Techniques\n\n3 Accesses\n\nExplore all metrics\n\nAbstract\n\nBankruptcy in future would lead to heavy losses, and attempts should be made to reduce it and prevent such a loss in advance. Potential misclassification of potential and futurist bankruptcy can be referred to as an audit failure. Predicting bankruptcy for different users, including investors, auditors, creditors and regulators, is essential. Various prediction models have been considered in other studies, and this research study includes multiple techniques like random forest, ANN, and logistic regression. The main reason behind the prediction of financial distress is that it will help ensure an increase in compatibility with the decision-making process. In this study, 1111 companies were considered liquidated and restructured by NCLT since its inception, i.e., 2016. Of these, 342 companies had their resolution plan approved from 2017 to 18 till December 2023, while 769 companies were liquidated. The selected companies’ financial information has been considered for the last five years, and machine learning (Random forest, Artificial neural network) and traditional models (Logistic regression) have been used to predict the outcome of the firm (in terms of bankruptcy or restructuring) with their respective level of accuracy. The study, firstly, reveals that machine learning models have better predictive accuracy than statistical models. Secondly, the model’s predictive accuracy is highest near the year/event of distress; as we move further from the year of liquidation/restructuring, the accuracy declines. Thirdly, financial variables and firm-specific characteristics have better precision and accuracy than only assessing the firms based on economic parameters.\n\nThis is a preview of subscription content, log in via an institution to check access.\n\nAccess this article\n\nSubscribe and save\n\nBuy Now\n\nPrice includes VAT (Lebanon)\n\nInstant access to the full article PDF.\n\nInstitutional subscriptions\n\nSimilar content being viewed by others\n\nPrediction of Bankruptcy Using Machine Learning Models\n\nFirms Default Prediction with Machine Learning\n\nPredicting distress: a post Insolvency and Bankruptcy Code 2016 analysis\n\nNotes\n\nBankruptcy and Liquidation have been used interchangeably.\n\nRestructuring and reorganisation have been used interchangeably as reorganisation is financial restructuring.\n\nReferences\n\nAbu-Mostafa, Y. S., Atiya, A. F., Magdon-Ismail, M., & White, H. (2001). Introduction to the special issue on neural networks in financial engineering. IEEE Transactions on Neural Networks, 12(4), 653–656. https://doi.org/10.1109/TNN.2001.935079\n\nArticle\n  Google Scholar\n\nAddo, P. M., Guegan, D., & Hassani, B. (2018). Credit risk analysis using machine and deep learning models. Risks, 6(2), 38. https://doi.org/10.3390/risks6020038\n\nArticle\n  Google Scholar\n\nAdnan Aziz, M., & Dar, H. A. (2006). Predicting corporate bankruptcy: Where we stand? Corporate Governance: THe International Journal of Business in Society, 6(1), 18–33. https://doi.org/10.1108/14720700610649436\n\nArticle\n  Google Scholar\n\nAker, Y., & Karavardar, A. (2023). Using Machine Learning Methods in Financial Distress Prediction: Sample of Small and Medium Sized Enterprises Operating in Turkey. Ege Akademik Bakis (Ege Academic Review).\n\nAlamsyah, A., Kristanti, N., & Kristanti, F. T. (2021). Early warning model for financial distress using Artificial Neural Network. In IOP Conference Series: Materials Science and Engineering (Vol. 1098, No. 5, p. 052103). IOP Publishing.\n\nAl-Kassar, T. A., & Soileau, J. S. (2014). Financial performance evaluation and bankruptcy prediction (failure). Arab Economic and Business Journal, 9(2), 147–155. https://doi.org/10.1016/j.aebj.2014.05.010\n\nArticle\n  Google Scholar\n\nAlmaskati, N., Bird, R., Yeung, D., & Lu, Y. (2021). A horse race of models and estimation methods for predicting bankruptcy. Advances in Accounting, 52, 100513. https://doi.org/10.1016/j.adiac.2021.100513\n\nArticle\n  Google Scholar\n\nAltman, E. (1968). Financial ratios, discriminant analysis and the prediction of corporate bankruptcy. Journal of Finance, 23, 589–609. https://doi.org/10.1111/j.1540-6261.1968.tb00843.x\n\nArticle\n  Google Scholar\n\nAltman, E. I., Iwanicz-Drozdowska, M., Laitinen, E. K., & Suvas, A. (2017). Financial distress prediction in an international context: A review and empirical analysis of Altman’s Z-score model. Journal of International Financial Management & Accounting, 28(2), 131–171. https://doi.org/10.1111/jifm.12053\n\nArticle\n  Google Scholar\n\nAltman, E. I., Sabato, G., & Wilson, N. (2010). The value of non-financial information in SME risk management. Journal of Credit Risk, 6(2), 95–127.\n\nArticle\n  Google Scholar\n\nAlvi, J., & Arif, I. (2024). Credit scorecards & forecasting default events–A novel story of non-financial listed companies in Pakistan. Asia-Pacific Financial Markets. https://doi.org/10.1007/s10690-024-09494-3\n\nArticle\n  Google Scholar\n\nAnandarajan, M., Lee, P., & Anandarajan, A. (2001). Bankruptcy prediction of financially stressed firms: An examination of the predictive accuracy of artificial neural networks. Intelligent Systems in Accounting, Finance and Management, 10(2), 69–81. https://doi.org/10.1002/isaf.199\n\nArticle\n  Google Scholar\n\nArora, P., & Saurabh, S. (2022). Predicting distress: A post Insolvency and Bankruptcy Code 2016 analysis. Journal of Economics and Finance, 46(3), 604–622. https://doi.org/10.1007/s12197-022-09582-y\n\nArticle\n  Google Scholar\n\nAshraf, S., Félix, G. S. E., & Serrasqueiro, Z. (2019). Do traditional financial distress prediction models predict the early warning signs of financial distress? Journal of Risk and Financial Management, 12(2), 55. https://doi.org/10.3390/jrfm12020055\n\nArticle\n  Google Scholar\n\nBalasubramanian, S. A., GS, R., P, S., & Natarajan, T. (2019). Modeling corporate financial distress using financial and non-financial variables: The case of Indian listed companies. International Journal of Law and Management., 61(3/4), 457–484. https://doi.org/10.1108/IJLMA-04-2018-0078\n\nArticle\n  Google Scholar\n\nBapat, V., & Nagale, A. (2014). Comparison of bankruptcy prediction models: Evidence from India. Accounting and Finance Research, 3(4), 91–98.\n\nArticle\n  Google Scholar\n\nBeaver, W. H. (1966). Financial ratios as predictors of failure. Journal of Accounting Research, 4, 71–111. https://doi.org/10.2307/249017\n\nArticle\n  Google Scholar\n\nBehr, A., & Weinblat, J. (2017). Default prediction using balance-sheet data: A comparison of models. Journal of Risk Finance, 18(5), 523–540. https://doi.org/10.1108/JRF-01-2017-0003\n\nArticle\n  Google Scholar\n\nBellovary, J. L., Giacomino, D. E., & Akers, M. D. (2007). A review of bankruptcy prediction studies: 1930 to present. Journal of Financial Education, 33, 1–42.\n\nGoogle Scholar\n\nBeniwal, M., Singh, A., & Kumar, N. (2023). Forecasting long-term stock prices of global indices: A forward-validating Genetic Algorithm optimization approach for Support Vector Regression. Applied Soft Computing, 145, 110566. https://doi.org/10.1016/j.asoc.2023.110566\n\nArticle\n  Google Scholar\n\nBhandari, S. B., & Iyer, R. (2013). Predicting business failure using cash flow statement based measures. Managerial Finance, 39(7), 667–676. https://doi.org/10.1108/03074351311323455\n\nArticle\n  Google Scholar\n\nBhimani, A., Gulamhussen, M. A., & Lopes, S. D. (2010). Accounting and non-accounting determinants of default: An analysis of privately-held firms. Journal of Accounting and Public Policy, 29, 517–532.\n\nArticle\n  Google Scholar\n\nBolek, M., & Gniadkowska-Szymańska, A. (2023). Is the growth of companies influencing their financial condition depending on their size: S&P 500 listed companies example. Asia-Pacific Financial Markets, 30(2), 323–337. https://doi.org/10.1007/s10690-022-09376-6\n\nArticle\n  Google Scholar\n\nCanbas, S., Cabuk, A., & Kilic, S. B. (2005). Prediction of commercial bank failure via multivariate statistical analysis of financial structures: The Turkish case. European Journal of Operational Research, 166(2), 528–546. https://doi.org/10.1016/j.ejor.2004.03.023\n\nArticle\n  Google Scholar\n\nCharalambakis, E. C., & Garrett, I. (2019). On corporate financial distress prediction: What can we learn from private firms in a developing economy? Evidence from Greece. Review of Quantitative Finance and Accounting, 52, 467–491.\n\nArticle\n  Google Scholar\n\nChen, K. C., & Church, B. K. (1996). Going concern opinions and the market’s reaction to bankruptcy filings. Accounting Review, 117–128.\n\nClement, C. (2020). Machine learning in bankruptcy prediction–A review. Journal of Public Administration, Finance and Law, (17), 178–196.\n\nDeAngelo, H., DeAngelo, L., & Skinner, D. J. (1994). Accounting choice in troubled companies. Journal of Accounting and Economics, 17(1/2), 113–143.\n\nArticle\n  Google Scholar\n\nDeFond, M. L., & Jiambalvo, J. (1994). Debt covenant violation and manipulation of accruals. Journal of Accounting and Economics, 17(1–2), 145–176. https://doi.org/10.1016/0165-4101(94)90008-6\n\nArticle\n  Google Scholar\n\nDielman, T. E., & Oppenheimer, H. R. (1984). An examination of investor behavior during periods of large dividend changes. Journal of Financial and Quantitative Analysis, 19(2), 197–216. https://doi.org/10.2307/2330898\n\nArticle\n  Google Scholar\n\nFoster, B. P., Ward, T. J., & Woodroof, J. (1998). An analysis of the usefulness of debt defaults and going concern opinions in bankruptcy risk assessment. Journal of Accounting, Auditing & Finance, 13(3), 351–371. https://doi.org/10.1177/0148558X9801300311(Originalworkpublished1998)\n\nArticle\n  Google Scholar\n\nGajpal, P. P., Ganesh, L. S., & Rajendran, C. (1994). Criticality analysis of spare parts using the analytic hierarchy process. International Journal of Production Economics, 35, 293–297.\n\nArticle\n  Google Scholar\n\nGalindo, J., & Tamayo, P. (2000). Credit risk assessment using statistical and machine learning: Basic methodology and risk modeling applications. Computational Economics, 15, 107–143. https://doi.org/10.1023/A:1008699112516\n\nArticle\n  Google Scholar\n\nGepp, A., Kumar, K., & Bhattacharya, S. (2010). Business failure prediction using decision trees. Journal of Forecasting, 29, 536–555. https://doi.org/10.1002/for.1153\n\nArticle\n  Google Scholar\n\nGilson, S. C., John, K., & Lang, L. H. (1990). Troubled debt restructurings: An empirical study of private reorganization of firms in default. Journal of Financial Economics, 27(2), 315–353. https://doi.org/10.1016/0304-405X(90)90059-9\n\nArticle\n  Google Scholar\n\nGiroux, G. A., & Wiggins, C. E. (1983). Chapter XI and corporate resuscitation. Financial Executive, 36-41.\n\nGiroux, G. A., & Wiggins, C. E. (1984). An events approach to corporate bankruptcy. Journal of Bank Research, 15(3), 179–187.\n\nGoogle Scholar\n\nGolbayani, P., Florescu, I., & Chatterjee, R. (2020). A comparative study of forecasting corporate credit ratings using neural networks, support vector machines, and decision trees. The North American Journal of Economics and Finance, 54, 101251. https://doi.org/10.1016/j.najef.2020.101251\n\nArticle\n  Google Scholar\n\nGupta, V. (2022). Bankruptcy prediction using machine learning techniques: Evidence on Indian companies under insolvency and bankruptcy code. Journal of Prediction Markets, 16(2), 77–100.\n\nArticle\n  Google Scholar\n\nHalteh, K., Alkhouri, R., Ziadat, S., & Haddad, F. (2024). Fintech Unicorns Forecaster: An AI Approach For Financial Distress Prediction. Migration Letters, 21(S4), Article S4.\n\nHellwig, K.-P. (2021). Predicting fiscal crises: A machine learning approach. IMF Working Papers. 150.\n\nHenley, W., & Hand, D. J. (1996). Ak-nearest-neighbour classifier for assessing consumer credit risk. Journal of the Royal Statistical Society Series d: the Statistician, 45(1), 77–95. https://doi.org/10.2307/2348414\n\nArticle\n  Google Scholar\n\nHsieh, S.-J. (1993). A note on the optimal cutoff point in bankruptcy prediction models. Journal of Business Finance & Accounting, 20(3), 457–464. https://doi.org/10.1111/j.1468-5957.1993.tb00268.x\n\nArticle\n  Google Scholar\n\nJain, A. K., & Gupta, B. B. (2018). Towards detection of phishing websites on client-side using machine learning based approach. Telecommunication Systems, 68, 687–700. https://doi.org/10.1007/s11235-017-0414-0\n\nArticle\n  Google Scholar\n\nJapkowicz, N., & Shah, M. (2011). Evaluating Learning Algorithms: A Classification Perspective. Cambridge University Press. https://doi.org/10.1017/CBO9780511921803\n\nBook\n  Google Scholar\n\nJohn, T. A., & John, K. (1993). Top-management compensation and capital structure. The Journal of Finance, 48, 949–974. https://doi.org/10.1111/j.1540-6261.1993.tb04026.x\n\nArticle\n  Google Scholar\n\nJones, S., & Hensher, D. A. (2004). Predicting firm financial distress: A mixed logit model. The Accounting Review, 79, 1011–1038. https://doi.org/10.2308/accr.2004.79.4.1011\n\nArticle\n  Google Scholar\n\nKhemakhem, S., & Boujelbene, Y. (2018). Predicting credit risk on the basis of financial and non-financial variables and data mining. Review of Accounting and Finance, 17(3), 316–340. https://doi.org/10.1108/RAF-07-2017-0143\n\nArticle\n  Google Scholar\n\nLi, K. (2024). Does innovation relieve corporate financial distress? Asia-Pacific Financial Markets. https://doi.org/10.1007/s10690-023-09445-4\n\nArticle\n  Google Scholar\n\nLi, Z., Crook, J., & Andreeva, G. (2014). Chinese companies distress prediction: An application of data envelopment analysis. The Journal of the Operational Research Society, 65(3), 466–479.\n\nArticle\n  Google Scholar\n\nLiang, C., Berant, J., Le, Q., Forbus, K.D., and Lao, N. (2016). Neural symbolic machines: learning semantic parsers on freebase with weak supervision. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 23–33, Vancouver, Canada. Association for Computational Linguistics.\n\nLiang, D., Tsai, C.-F., & Wu, H.-T. (2015). The effect of feature selection on financial distress prediction. Knowledge-Based Systems, 73, 289–297. https://doi.org/10.1016/j.knosys.2014.10.010\n\nArticle\n  Google Scholar\n\nLu, D., Popuri, K., Ding, G. W., et al. (2018). Multimodal and multiscale deep neural networks for the early diagnosis of Alzheimer’s disease using structural MR and FDG-PET images. Science and Reports, 8, 5697. https://doi.org/10.1038/s41598-018-22871-z\n\nArticle\n  Google Scholar\n\nMalakauskas, A., & Lakštutienė, A. (2021). Financial distress prediction for small and medium enterprises using machine learning techniques. Engineering Economics, 32(1), 4–14. https://doi.org/10.5755/j01.ee.32.1.27382\n\nArticle\n  Google Scholar\n\nMartin, D. (1977). Early warning of bank failure: A logit regression approach. Journal of Banking & Finance, 1(3), 249–276. https://doi.org/10.1016/0378-4266(77)90022-X\n\nArticle\n  Google Scholar\n\nMironiuc, M., Carp, M., & Chersan, I. C. (2015). The relevance of financial reporting on the performance of quoted romanian companies in the context of adopting the IFRS. Procedia Economics and Finance, 20, 404–413. https://doi.org/10.1016/S2212-5671(15)00090-8\n\nArticle\n  Google Scholar\n\nMorum, A., & Roy, D. (2013). Financial indicators of corporate sickness: A study of Indian steel industry. South Asian Journal of Management, 20(2), 85–101.\n\nGoogle Scholar\n\nNair, J., & Sachdeva, J. K. (2016). Indicators of financial distress: An empirical study of Indian Textile sector. Journal of Global Economy, 12, 101–110. https://doi.org/10.1956/jge.v12i2.418\n\nArticle\n  Google Scholar\n\nNational Industrial Classification | Ministry of Statistics and Program Implementation | Government Of India (mospi.gov.in)\n\nOhlson, J. A. (1980). Financial ratios and the probabilistic prediction of bankruptcy. Journal of Accounting Research, 18, 109–131. https://doi.org/10.2307/2490395\n\nArticle\n  Google Scholar\n\nOoghe, H., & De Prijcker, S. (2008). Failure processes and causes of company bankruptcy: A typology. Management Decision, 46(2), 223–242. https://doi.org/10.1108/00251740810854131\n\nArticle\n  Google Scholar\n\nÖzdamar, K. (2002). Statistical data analysis with package programs-1 (4. Print). Kaan Bookstore.\n\nPaula, L. F., Fritz, B., Prates, D. (2020). The metamorphosis of external vulnerability from ‘original sin’ to ‘original sin redux’: Currency hierarchy and financial globalisation in emerging economies. UFRJ, Instituto de Economia, Discussion Paper 033, November\n\nSehgal, S., Mishra, R. K., Deisting, F., & Vashisht, R. (2021). On the determinants and prediction of corporate financial distress in India. Managerial Finance, 47(10), 1428–1447. https://doi.org/10.1108/MF-06-2020-0332\n\nArticle\n  Google Scholar\n\nShrivastava, A., Kumar, K., & Kumar, N. (2018). Business distress prediction using bayesian logistic model for indian firms. Risks, 6(4), 113. https://doi.org/10.3390/risks6040113\n\nArticle\n  Google Scholar\n\nShrivastava, A., Kumar, N., Kumar, K., & Gupta, S. (2020). Corporate distress prediction using random forest and tree net for India. Journal of Management and Science, 1(1), 1–11. https://doi.org/10.26524/jms.2020.1\n\nArticle\n  Google Scholar\n\nSinha, N., Kakkar, N. K., & Gupta, V. (2009). Unleash the power of creativity and innovation. International Journal of Sustainable Strategic Management, 1, 417.\n\nArticle\n  Google Scholar\n\nSmith, C. W., Jr., & Warner, J. B. (1979). On financial contracting: An analysis of bond covenants. Journal of Financial Economics, 57(2), 117–161. https://doi.org/10.1016/0304-405X(79)90011-4\n\nArticle\n  Google Scholar\n\nSu, E.-D., & Huang, S.-M. (2010). Comparing firm failure predictions between logit, KMV, and ZPP models: Evidence from Taiwan’s electronics industry. Asia-Pacific Financial Markets, 17(3), 209–239. https://doi.org/10.1007/s10690-010-9113-5\n\nArticle\n  Google Scholar\n\nSuresh, K., Saxena, A., & Srikanth, M. (2023). Comparing financial debt choices of existing and new SMEs in Indian manufacturing sector. Asia-Pacific Financial Markets, 30(3), 445–456. https://doi.org/10.1007/s10690-022-09382-8\n\nArticle\n  Google Scholar\n\nTang, H., & Zhang, C. (2019). Investment risk, return gap, and financialization of non-listed non-financial firms in China⁎. Pacific-Basin Finance Journal, 58, 101213.\n\nArticle\n  Google Scholar\n\nTuretsky, H. F. (1997). An empirical investigation of firm longevity: A model of the ex ante predictors of financial distress. Virginia Commonwealth University.\n\nGoogle Scholar\n\nTuretsky, H. F., & McEwen, R. A. (2001). An empirical investigation of firm longevity: A model of the ex ante predictors of financial distress. Review of Quantitative Finance and Accounting, 16, 323–343. https://doi.org/10.1023/A:1011291425075\n\nArticle\n  Google Scholar\n\nVaradraj, B., & Abhay, N. (2014). Comparison of bankruptcy prediction models: Evidence from India. Accounting and Finance Research, 3, 5743–5743. https://doi.org/10.5430/afr.v3n4p91\n\nArticle\n  Google Scholar\n\nwww.ibbi.gov.in\n\nYeh, I. C., & Lien, C. H. (2009). The comparisons of data mining techniques for the predictive accuracy of probability of default of credit card clients. Expert Systems with Applications, 36(2), 2473–2480. https://doi.org/10.1016/j.eswa.2007.12.020\n\nArticle\n  Google Scholar\n\nZmijewski, M. E. (1984). Methodological issues related to the estimation of financial distress prediction models. Journal of Accounting Research, 22, 59–82. https://doi.org/10.2307/2490859\n\nArticle\n  Google Scholar\n\nDownload references\n\nAuthor information\n\nAuthors and Affiliations\n\nDelhi Technological University, Delhi, 110089, India\n\nPallavi Sethi, Archana Singh & Vikas Gupta\n\nCorresponding author\n\nCorrespondence to Pallavi Sethi.\n\nEthics declarations\n\nConflict of interest\n\nThe authors declare no conflict of interest.\n\nAdditional information\n\nPublisher's Note\n\nSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\n\nRights and permissions\n\nSpringer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law.\n\nReprints and permissions\n\nAbout this article\n\nCite this article\n\nSethi, P., Singh, A. & Gupta, V. Predicting Financial Distress Using Machine Learning Techniques. Asia-Pac Financ Markets (2025). https://doi.org/10.1007/s10690-025-09525-7\n\nDownload citation\n\nAccepted\n05 March 2025\n\nPublished\n24 April 2025\n\nDOI\nhttps://doi.org/10.1007/s10690-025-09525-7\n\nKeywords\n\nDiscover content\n\nPublish with us\n\nProducts and services\n\nOur brands\n\n178.135.19.63\n\nNot affiliated\n\n© 2025 Springer Nature\n",
        "Machine learning models employed in financial performance optimization": "Deep Learning Models Meet Financial Data Modalities : \nHelp | Advanced Search\n\nComputer Science > Machine Learning\n\nDeep Learning Models Meet Financial Data Modalities\n\nSubmission history\n\nAccess Paper:\n\nReferences & Citations\n\nBookmark\n\nBibliographic and Citation Tools\n\narXiv Operational Status\nGet status notifications via email or slack\n\nMachine learning for financial forecasting, planning and analysis ... : \nYour privacy, your choice\n\nWe use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media.\n\nBy accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection.\n\nSee our privacy policy for more information on the use of your personal data.\n\nManage preferences for further information and to change your choices.\n\nMachine learning for financial forecasting, planning and analysis: recent developments and pitfalls\n\nYou have full access to this\nopen access\narticle\n\n40k Accesses\n\n1 Altmetric\n\nExplore all metrics\n\nAbstract\n\nThis article is an introduction to machine learning for financial forecasting, planning and analysis (FP&A). Machine learning appears well suited to support FP&A with the highly automated extraction of information from large amounts of data. However, because most traditional machine learning techniques focus on forecasting (prediction), we discuss the particular care that must be taken to avoid the pitfalls of using them for planning and resource allocation (causal inference). While the naive application of machine learning usually fails in this context, the recently developed double machine learning framework can address causal questions of interest. We review the current literature on machine learning in FP&A and illustrate in a simulation study how machine learning can be used for both forecasting and planning. We also investigate how forecasting and planning improve as the number of data points increases.\n\nSimilar content being viewed by others\n\nIntegrating Decision Analytics and Advanced Modeling in Financial and Economic Systems Through Artificial Intelligence\n\nApplication of Machine Learning in Financial Asset Price Prediction and Allocation\n\nData Mining in Finance: Current Advances and Future Challenges\n\nExplore related subjects\n\nAvoid common mistakes on your manuscript.\n\n1 Introduction\n\nAccurate financial forecasts and plans for effective and efficient resource allocation are core deliverables of the finance function in modern companies. Particularly, in volatile or fast-evolving market environments, fast and reliable forecasting and planning are crucial (Becker et al. 2016). High-quality forecasting is among the defining characteristics of strong finance functions (Roos et al. 2020). It is therefore hardly surprising that most larger companies have dedicated teams for financial planning and analysis (FP&A) within their finance function.\n\nThe increasing availability of big data, coupled with new analysis techniques, provides an opportunity for FP&A to generate more and better insights at a faster pace, generating more value for the company. Machine learning is a set of techniques developed in computer science and statistics that appear particularly well suited to this context. The aim of our paper is to show how machine learning can be used for FP&A and which pitfalls can arise in the process. Machine learning has been applied successfully to a variety of predictive tasks, including fraud detection and financial forecasting. Planning and resource allocation, however, represent tasks of a different nature, because they require understanding the effect of an active intervention in a system, such as the market for a product. For this reason, they are causal problems, which are harder to model with machine learning. A large field within machine learning revolves around pattern recognition. Patterns in data, based on correlations, are learned and then used for predictions. In causal tasks, an understanding of the underlying (causal) mechanisms is important when evaluating the effects of interventions (e.g., the implementation of a new business strategy). The emerging field of causal machine learning uses machine learning algorithms for such questions. For instance, the recently developed double machine learning framework reduces the impact of imperfect model specifications, which are hard to avoid in practice in the context of causal analysis.\n\nWe structure this paper as follows. In Sect. 2, we briefly review the role of FP&A. Section 3 provides a short, focused overview of machine learning. In particular, we highlight the pitfall of not distinguishing between forecasting and planning. In Sect. 4, we present the results of our literature review, which finds surprisingly few publications of machine learning applications in FP&A. In Sect. 5, we describe and provide the results from a simulation study. We compare a machine learning technique, the lasso, to a linear regression based on the ordinary least squares (OLS) method. In our analysis, we refer back to the distinction between forecasting and planning from Sect. 3, and show how the results differ between the lasso and OLS for both tasks. Finally, we also quantify the benefit of additional data in this simulation.\n\n2 The role of FP&A\n\nGiven the importance of financial forecasting, planning and analysis (FP&A) in modern corporations, most larger companies have dedicated teams for these tasks within their finance function, even though the exact organizational design and naming of the department may vary.\nFootnote\n1\n\nThe overarching goal of FP&A is to inform and support decisions of management and the board of directors (Oesterreich et al. 2019). FP&A pursues this goal via different routes, helping determine which projects in the company portfolio create value (and are consequently worth funding), and preparing company-wide forecasts and financial plans to ensure that the company can reach its financial goals in the short and long term (Roos et al. 2019). Investments in research and development (R&D) or the expansion of production capacity are balanced with financial obligations to debt holders or equity investors and tax authorities (Brealey et al. 2020). Financial plans are also an important step in the translation of a company’s strategic priorities into concrete operational actions. These actions contribute to focusing the organization and the deployed resources behind common goals.\n\nAnalyzing the business environment and business dynamics is an integral part of the work performed by FP&A. The insights generated through such analysis can inform the development of forecasts and plans and help in the assessment of how likely these plans are to succeed. During the the execution phase of plans, these insights allow FP&A to understand why actual results may deviate from the plan and to recommend corrective actions. This need for business acumen is likely to continue, even when advanced forecasting methods like those described in this article are used (Möller et al. 2020).\n\nThe time horizons considered for financial forecasts and plans usually range from 1 month to several years (Roos et al. 2019; Fischer 2009). The choice of time horizon depends on company-specific circumstances and objectives; for instance, stock-market listed companies typically put additional weight on quarterly figures. In practice, most companies create forecasts and plans for the next fiscal year (sometimes called a budget), which additionally can serve as a management control mechanism (Strauß and Zecher 2013). Rolling forecasts are another form of plan. These are characterized by regular updates, which are typically performed on a monthly or quarterly basis (Hansen 2011).\n\nFP&A relies in large part on quantitative analysis to generate forecasts and plans. Accounting systems are a major internal data source for FP&A (Garrison et al. 2006; Gray and Alles 2015), covering items related to sales (turnover), expenses, and balance sheet positions, which are especially important for cash flow analysis. Other important internal sources of data include those related to human resources (employee numbers, wage costs), supply chain and production (manufacturing costs at various levels of granularity), and R&D (product development costs, success rates, timelines).\n\nExternal data sources include market- or product-specific information, such as the size and development of the market and market shares. The exact nature and granularity of these data depends largely on the product or question under analysis, as well as the investment required to access the relevant data (Gray and Alles 2015). For instance, it is not uncommon in the consumer goods industry to have access to transaction-level data (Taddy 2019), covering one’s own and competitor products. However, information at this level of specificity is typically used by the marketing and sales department for product-specific tactics. In contrast, FP&A often uses macroeconomic indicators, including GDP, inflation and currency rates.\n\nThe development and spread of comprehensive, company-wide IT systems in recent decades has increased the amount and variety of data readily available to FP&A. Increasing digitalization will further accentuate this development, with big data as the crystallizing term. The “Three V’s”, a common framework to define big data (Laney 2001), allow us to look at the different dimensions that drive this development. First, the amount of information generated, captured and thus accessible for FP&A activities is growing (volume). Second, the speed of information creation and its accessibility is accelerating (velocity); as a consequence, the speed at which information must be analyzed and acted upon increases, too. This calls for automated, real-time analytics and evidence-based planning (Gandomi and Haider 2015). Third, more and more types of information are being gathered or generated and can be analyzed (variety); for instance, stock-market analysts apply sentiment analysis to extract information relevant to stock prices from text documents.\n\nIn addition, other dimensions of big data have been proposed (Gandomi and Haider 2015). In the context of FP&A, the additional dimensions of veracity and complexity appear especially relevant. Thanks to the more widespread use of digital tools, the need for data transparency and scrutiny within many companies is increasing, as well. In turn, the need to ensure data quality and reliability is growing (veracity). Moreover, (big) data are generated through multiple sources, both from inside and outside the company. This requires data cleaning, data matching and, ideally centralized storage, which facilitates accessibility (complexity).\n\nAs mentioned above, a key output of FP&A is financial forecasts and plans. For data that are more numerous, available more quickly, and are more diverse and of better quality than in the past, FP&A needs to choose adequate tools, such as those provided by machine learning.\n\n3 Introduction to machine learning\n\nWhile there is no uniform definition of machine learning, it can be described as a collection of methods that automatically build predictions from complex data (Taddy 2019). In essence, machine learning deploys a function-fitting strategy aiming to find a useful approximation of the function that underlies the predictive relationship between input and output data (Hastie et al. 2009). In this search for patterns in data (Bishop et al. 2006), which, to a large extent, is executed autonomously, machine learning draws on statistical tools and algorithmic approaches from computer science. In particular, machine learning aims to cope with the situation of high-dimensional data. High dimensionality occurs when the number of input variables (independent variables, features) used to predict the output (dependent) variable is large compared to the number of observations available. Classical statistical techniques do not work in this setting (Taddy 2019).\n\nThe three broad categories of machine learning are supervised learning, unsupervised learning and reinforcement learning. Supervised learning is concerned with predicting the value of an output variable based on the values of a set of input variables. For this, supervised learning relies on a set of input and output variables that are jointly observed for each data point (Hastie et al. 2009). A practical example is to predict the sales of a product using input variables such as time of the year, price level, advertising expenditures and availability of competitor products. In contrast, unsupervised learning consists only of a set of input observations for which the joint distribution is known. However, there is no observed output (response). The goal is to directly infer the properties of these observations (Hastie et al. 2009). Classifying customers into (previously unknown) customer archetypes based on their observed characteristics such as buying behavior, age, gender and socio-economic status is an example of unsupervised learning. In reinforcement learning, the algorithm performs a trial-and-error search to maximize a numeric reward signal, in direct interaction with its environment (Sutton and Barto 2018). By interacting with its environment, the algorithm creates its own data from which it can learn. Games such as checkers, chess and go are classical examples in which reinforcement learning is applied. Sometimes cited as a fourth category, semi-supervised learning falls between supervised and unsupervised learning, combining a small amount of fully labeled data as in supervised learning and a large amount of unlabeled data as in unsupervised learning. The objective is to improve supervised learning in situations in which labeled data are scarce (Zhu and Goldberg 2009). For the purposes of FP&A objectives, which mostly revolve around producing forecasts from a set of inputs and assumptions, the predominant choice is typically supervised methods.\n\nMachine learning methods appear especially suitable for the core FP&A task of forecasting because of their focus on predictive performance. These methods manage to identify generalizable patterns that work well on new data, i.e., data outside of the training sample (Mullainathan and Spiess 2017). Through their ability to identify complex structures that have not been specified in advance, they lend themselves to support a high degree of automation in the generation of forecasts. This flexibility has the additional advantage that many off-the-shelf algorithms perform surprisingly well on a variety of tasks. In addition, a large selection of machine learning algorithms are available and are technically easy to use (Mullainathan and Spiess 2017), making them attractive for practitioners.\n\nBesides forecasting, the second core task of FP&A is to provide recommendations for the design of financial plans and for potential corrective actions when deviations from plans occur. In statistical terminology, this requires causal inference techniques, which are fundamentally different from forecasting. Consider the trivial example of hotel occupancy rates and room prices (Athey 2018). High room prices coincide with high occupancy rates. Thus, price variations are strongly predictive of hotel occupancy. If the goal is to make a forecast, we do not need to be concerned with understanding why occupancy was high. However, if we want to recommend an action to increase the occupancy rate (an intervention) or imagine in retrospect what the occupancy rate would have been if the room rates had been different [“counterfactual” (Pearl and Mackenzie 2018) or “potential outcome” (Rubin 2005)], FP&A requires a causal understanding of the business dynamics. To conclude with this example, a plan consisting of a room price increase will not lead to higher occupancy. Most likely, prices have increased in the past in reaction to high demand, which was stimulated by other factors (e.g., the holiday season). While this trivial example seems obvious, it illustrates a major pitfall: many companies struggle in practice to identify truly causal measures for the effectiveness of their promotional activities. Blake et al. (2015) discuss this phenomenon in the context of large-scale field experiments conducted at the e-commerce platform eBay.\n\nFor interventional and counterfactual analysis, data-driven approaches need to produce reliable estimates for the parameters that govern the relationship between input and output variables. Machine learning algorithms are typically not built for this purpose. Historically, the machine learning community has pursued the goal of maximizing predictive performance as opposed to understanding model parameters (Taddy 2019); however, using a tool built for forecasting and assuming that it also possesses the properties required for causal inference in economic applications can be misleading (Mullainathan and Spiess 2017). Maximizing the predictive power of a model to use it for interventional analysis represents a major trap. Indeed, it may even be necessary to sacrifice predictive accuracy to arrive at a correct understanding of the relationships that are relevant for making decisions about interventions (Athey 2018). The current lack of understanding of cause–effect connections is even cited as a fundamental obstacle for machine learning by some authors (Pearl 2019). Nevertheless, many inference procedures include prediction tasks as an important step (Mullainathan and Spiess 2017). Machine learning is especially suited for this step in high-dimensional settings (Belloni et al. 2014b). The double machine learning framework (Chernozhukov et al. 2017), which we will apply in Sect. 5, allows us to take advantage of the predictive performance of machine learning algorithms when seeking solutions for causal problems.\n\n4 Literature review\n\nWe conducted a search of the literature across Google, Google Scholar and finance journals on the use of machine learning in FP&A. The use of quantitative methods in the broad field of finance has been studied intensively for close to 40 years (Ozbayoglu et al. 2020), in part because of the general availability of data in this field, the existence of many areas of implementation and the substantial economic impact of financial decisions. Our search yielded surprisingly few recent publications on the use of machine learning explicitly in FP&A and related fields. The key thrust of machine learning in finance is directed towards various applications ultimately linked to forecasting and trading financial instruments such as stocks, bonds, currencies and derivatives. Credit scoring and fraud detection are other major areas. Examples of recent surveys include Ozbayoglu et al. (2020) and Henrique et al. (2019).\n\nWe see two possible reasons for the apparent scarcity of publications on machine learning in FP&A. First, time-series forecasting has been thoroughly covered and researched for many years (De Gooijer et al. 2006). A large variety of tools for this purpose have been developed, both from an academic and theoretical perspective, as well as from the perspective of practitioners, including easy to use off-the-shelf software (Küsters et al. 2006). From a practical FP&A perspective, these tools, together with the domain knowledge of the experts working in the FP&A function, allow practitioners to arrive at results that—by and large—serve sufficiently well to meet the objective of developing financial plans. Especially, practitioners may therefore perceive machine learning as a “so-so” technology (Acemoglu and Restrepo 2018), which is not (yet) quite worth their (full) attention. Thus, the intrinsic urge to look for new tools, including machine learning, in FP&A is still less pronounced than it is, for instance, in stock-market forecasting, where even a relatively small improvement in forecasting accuracy can yield significant economic payoff. We believe that this will change with the further deployment of digitalization and the consequent increase in data availability as described above. Besides improving the precision of financial forecasts, automated forecasts driven by machine learning can also lead to a substantial reduction in costs and to increased flexibility given that the traditional process is quite labor- and time-intensive.\n\nSecond, we hypothesize the following reason for the limited number of publications on machine learning in FP&A. The initial development of artificial intelligence and machine learning methods was driven mostly by academia. Because these methods are highly relevant for industrial applications, companies (in particular in the tech field) have shown strong interest in applying and developing them further. Indeed, some of the large tech companies host their own dedicated research teams. However, the limited availability of skilled professionals represents a hurdle to fast diffusion in all corporate functions of a company. Therefore, the application of machine learning for FP&A is still rare in the finance function, even though a host of machine learning publications by the industry has already appeared in other functional areas.\nFootnote\n2 Management consultancies have also discovered the benefit of machine learning for finance and FP&A. However, their publications remain general and directional in nature (see, for instance, Balakrishnan et al. 2020; Roos et al. 2020; Tucker et al. 2017; Chandra et al. 2018).\n\nOne company that has made public its use of machine learning in FP&A in scientific papers is Microsoft Corporation. In the past several years, Microsoft appears to have followed an innovative approach with machine learning in FP&A as witnessed by three publications from its employees. One paper (Gajewar et al. 2016) compares the performance of random forests to that of traditional time-series methods such as autoregressive integrated moving average (ARIMA), error trend and seasonality (ETS, a variant of exponential smoothing) and seasonal-trend decomposition using loess (STL, another variant of smoothing) for forecasting quarterly revenues by major geographic region and at the global level up to 1 year into the future. Based on their exploratory analysis, the random forest model with a restricted number of features outperformed the traditional time-series methods and the forecasts generated by the domain experts in the Microsoft FP&A department.\n\nA second paper (Barker et al. 2018) describes a machine learning-based solution that forecasts revenue on a quarterly basis, including individual forecasts for 30 products in three different business segments. Specifically, the machine learning forecast used an elastic net, a random forest, a K-nearest-neighbor and a support vector machine. The winner model was then selected via back-testing. The forecasts generated in this way proved to be more accurate than the traditional forecasts generated by FP&A in approximately 70% of the cases. The paper cites the ability to incorporate external information (e.g., temperature as a driver for electricity demand) in regression frameworks as an advantage of these over pure (standard) time-series models. While classical time-series are good at capturing trends and seasonality, they often struggle to incorporate external data. In particular, they generally lack a regularization mechanism, leading to low out-of-sample accuracy for new forecasts, especially in high-dimensional settings. Many machine learning methods include by design mechanisms to avoid overfitting (e.g., regularization for ridge, lasso and elastic net).\n\nBarker et al. (2018) also highlight some requirements that arise from the intent to use the results of machine learning forecasts in a practical manner in a corporate setting. Traditionally, FP&A works with a point estimate, coupled with an estimation of the risks and opportunities around this mid-point. Risks and opportunities typically consist of a list of items or events that will materially impact the business results if they do not turn out as assumed in the mid-point forecast (Conine and McDonald 2017). Judgmental probability estimates provided by subject matter experts are often attached to these items, together with a quantification of the expected impact under the different scenarios.\nFootnote\n3 For forecasts generated by traditional statistical or machine learning models, prediction intervals are therefore an important element for FP&A practitioners to quantify the risk in the forecast. However, prediction intervals are not typically part of machine learning models. The solution proposed by Barker et al. (2018) consists of creating intervals from out-of-sample error distributions obtained during back-testing. Other practical requirements in a corporate environment are the need for a mostly automated solution allowing for fast forecast generation as well as the need to ensure high security standards for data storage, processing and access. Financial data such as sales and profits are highly sensitive, and companies are reluctant to release them into public cloud environments. Barker et al. (2018) explain the details of their workflow automation and security controls, which revolve around the Microsoft Azure cloud-computing platform.\n\nThe third publication (Koenecke and Gajewar 2020) evaluated deep neural networks traditionally used in natural language processing (encoder–decoder LSTMs) and computer vision (dilated convolutional neural networks) to forecast company revenues. The approach incorporated transfer and curriculum learning. For the products and time period under study in this publication, deep neural networks improved predictive accuracy compared to the company’s internal baseline, which combined traditional statistical and machine learning methods other than deep neural networks.\n\nIn another example of applied machine learning in the area of FP&A, Daimler Mobility used an undisclosed library of machine learning algorithms to generate a monthly forecast set, spanning the next 18 months and updated monthly (Unger and Rodt 2019). In this respect, the approach followed the concept of a rolling forecast. The forecasted set of values comprised key financial performance indicators that were representative of Daimler Mobility’s car rental, leasing, financing and fleet management business. According to Unger and Rodt (2019), one of the key advantages of this approach compared to the traditional way of forecasting and budgeting is the speed with which updated forecasts are available, allowing faster adoption of corrective action.\n\nThese papers all discuss modern machine learning methods for financial forecasting. In the next section, we will show that these approaches cannot be applied directly to inference problems and how the double machine learning framework overcomes this problem. A first example will illustrate the use of machine learning techniques in FP&A for forecasting. A second example will serve to illustrate the use of double machine learning for planning (inference). Finally, we will explore whether having additional data improves the results for both the forecasting and planning tasks.\n\n5 Simulation example\n\nIn this section, we provide the results of a small simulation study. The design of the simulation reflects the setting, types of data and questions that the FP&A department in a large, multinational company could face. We will start with an example in which FP&A is predominantly interested in the accuracy of sales forecasting. We will then carry this example forward into a question related to planning. In this second example, FP&A is interested in assessing the effectiveness of promotional activities in generating sales; in other words, the question of interest relates to causal inference and the answer to this question can inform decisions about resource planning. Finally, we will investigate how the results change if the FP&A department obtains additional data points for their tasks.\n\n5.1 Forecasting\n\nAssume for our stylized simulation the following setting:\nFootnote\n4 for a given month n, the FP&A department would like to forecast the sales \\(y_{n}\\) of a specific product or service. FP&A has collected monthly data over 5 years (\\(N=60\\)) for sales as well as a set of \\(P=40\\) factors or features that FP&A believes could be predictive of these sales. We represent these factors as \\(x_{p,n}\\) and the corresponding sales with \\(y_{n}\\).\nFootnote\n5 In practice, there can be a wide range of factors depending on the product or service. Examples include weather conditions and various macroeconomic indicators, but also specific customer shipment patterns or the current competitive market situation. Note that the size of the feature set can easily reach 40 plausible predictors once an initial, smaller feature set is increased due to the inclusion of transformed and newly created features. This step, called feature engineering, can include the creation of lagged variables (e.g., when the effect of the economic situation affects sales several months later) or interaction effects (e.g., when a particular weather situation coincides with a peak shipment date, nullifying or exacerbating the effect of the peak shipment date). A further example is the transformation of categorical variables into several binary values via the so-called one-hot encoding (e.g., when classifying the competitive market situation as “highly competitive”, “moderately competitive”, “not competitive” and the like).\n\nIn addition to developing a set of 40 features, FP&A measures the promotional activity carried out by the company for the product under investigation during the reference timeframe. We denote this promotional activity as \\(d_{n}\\). For the purpose of this illustrative simulation, we work with the assumption that the promotional activity can be measured using a single variable. In other words, we do not enter into promotional mix considerations with interaction effects among the different promotional tools. In practice, this single variable could be a summary measure such as the amount of money spent on promotion and advertising; another possibility for a summary measure could be the number of customer calls or minutes of customer interaction. For forecasting and planning activities performed by FP&A at aggregate levels, such as the regional, divisional or group levels, an approach like this, based on a summary measure, is sometimes applied. Extending the analysis to include several marketing variables is possible without any major changes.\n\nGiven the nature and intent of promotional activity, it appears natural for FP&A to include \\(d_{n}\\) in the list of likely predictors for the sales forecasting model. Furthermore, estimating the effect of the promotional activity on sales represents an important question for FP&A, which we will address in the second part of this section, dedicated to planning.\n\nTo evaluate the accuracy of the sales forecasts, we will follow an out-of-sample evaluation approach. Only the first four years (48 data points) are used to build and train the forecasting models. FP&A then compares the forecasts generated by the models to the actual values from the last year in the available dataset (12 data points). Note that these 12 data points have been intentionally excluded from the model creation phase. While more sophisticated training and evaluation strategies exist (e.g., rolling evaluation windows), the described approach is sufficient for the purpose of this simulation study, because the out-of-sample forecasting performance is evaluated separately for each simulation.\n\nFor our simulation, we generate the data as \\(n=1, \\ldots , N\\) independent and identically distributed (i.i.d.) draws from the following model:\n\nand\n\nwith \\(x\\sim \\mathcal {N}(0,\\Sigma )\\) where \\(\\Sigma\\) is a \\(p \\times p\\) matrix with \\(\\Sigma _{k,j}=c^{|j-k |}\\), \\(\\varepsilon \\sim \\mathcal {N}(0,2)\\) and \\(\\nu \\sim \\mathcal {N}(0,2)\\).\n\nThe second equation captures confounding, i.e., variables that are simultaneously correlated with the outcome variable and the variable of interest. By setting \\(\\alpha = 0\\), we assume that the promotional activity undertaken by the company has no effect on sales, i.e., that the promotion efforts are, in reality, a waste of resources. With \\(c = 0.3\\), we include some moderate correlation\nFootnote\n6 between features, which can be expected if several features from the same general background (e.g., macroeconomic factors) are included in the model.\n\nWe set \\(\\beta = 0\\), except for \\(\\beta _{39}\\) and \\(\\beta _{40}\\), both of which we set equal to 1. Thus, out of the 40 features included in the analysis, only two are actually related to sales. Similarly, we set \\(\\gamma = 0\\), except for \\(\\gamma _{39}\\) and \\(\\gamma _{40}\\), both of which we also set equal to 1. The two features related to sales also determine the amount of promotional activity \\(d_{n}\\).\nFootnote\n7\\(\\varepsilon\\) and \\(\\nu\\) are random error terms (so-called noise). We report results based on 1000 simulation replications.\n\nIt is important to remind ourselves that the FP&A department naturally does not know any details about this data generation process. Only an oracle would know that, in reality, solely 2 of the 40 plausible predictors are linked to sales and that the coefficient in the data-generating process is 0 for the other 38 features. This situation characterizes sparse models. In such models, only a small number of many potential predictors and/or control variables are actually relevant (Belloni et al. 2014a). Identifying them leads to a correct model specification and is the main challenge.\nFootnote\n8 Additionally, FP&A does not know that the promotional activity \\(d_{n}\\) is correlated with the two features that have non-zero coefficients with respect to sales and that the promotional activity has no influence on sales (\\(\\alpha\\), the parameter of interest, is zero). We will come back to this point when we discuss inference.\n\nWe now provide results for two forecasting approaches. Both have in common that they rely—in this case correctly—on the typical assumption of a linear relationship between the output variable Y (sales) and the full set of regressors X, which includes 40 presumably predictive features and one variable reflecting promotional activity\n\nThe first approach is a traditional linear regression based on the ordinary least squares (OLS) method. Formally, OLS optimizes the parameters in such a way as to minimize the mean squared error (MSE)\n\nwhere \\(x'_i\\hat{\\beta }\\) corresponds to the predicted sales value.\n\nThe second approach, post-lasso, is a classic machine learning technique. To estimate the coefficients, lasso uses a regularization strategy that is suited to high-dimensional problems in which the number of predictors exceeds or approaches the number of observations, as is the case in our simulation. In the first step, the lasso regression is performed. In the second (i.e., post-lasso) step, the method fits OLS on the coefficients selected in the first step. Formally, lasso optimizes the parameters to minimize MSE subject to a penalty for using parameters\n\nwhere \\(x'_i\\hat{\\beta }\\) corresponds again to the predicted sales value.\n\nThe key difference between the lasso and OLS is that lasso minimizes a penalized MSE, in which the penalty amount corresponds to the absolute amount of each parameter included in the model, scaled by the tuning- or hyperparameter \\(\\lambda\\)\n\nA detailed discussion of the theory behind regularization approaches would go beyond the scope of this article. Readers are referred, among many possible sources, to Hastie et al. (2009), Bühlmann and van de Geer (2011) and Taddy (2019). Taddy (2019) sees regularization as “the key to modern statistics” by virtue of its ability to prevent overfitting in high-dimensional settings. Instead, we will recall a few characteristics of the lasso that are particularly relevant to our FP&A example and the corresponding simulation.\n\nThe full name of the lasso (“least absolute shrinkage and selection operator”) indicates two important characteristics. First, as we can see in the formula for \\(\\mathrm{Penalty}_\\mathrm{Lasso}\\), the absolute size of the coefficients included in the model represents a cost in the minimization of the MSE. Lasso will therefore shrink the coefficients towards zero. This makes the prediction system more stable and avoids overfitting. Second, the lasso-specific penalty in the form of the absolute value of the coefficients has the property that some parameters will be exactly equal to zero. In other words, the lasso will fully exclude some variables from the model and therefore perform automatic variable selection.\n\nAs indicated above, the lasso can handle situations in which the number of predictors approaches or even exceeds the number of observations. In our case, the number of predictors (including the measure of promotional activity) is 41 and the number of observations is 48. Although OLS can still be calculated, we will see that its out-of-sample predictive accuracy becomes extremely unreliable. If we were to chose a simulation scenario with 48 or more predictors, OLS could no longer be computed. A second challenge for OLS in settings with many predictors is the increased risk of correlation among the predictors. If predictors are highly correlated among themselves, or if, in an extreme case, there is an exact linear relationship between two predictors (multicollinearity), OLS estimates become unstable. For instance, macroeconomic variables tend to be strongly correlated.\n\nAn important ingredient in the lasso is the size of the penalty, which depends on the tuning parameter \\(\\lambda\\). \\(\\lambda\\) is not determined by the lasso itself, but needs to be selected. Intuitively, \\(\\lambda\\) plays a role in filtering the relevant variables. Several strategies to select \\(\\lambda\\) have been proposed in the literature and are used by practitioners. The most common are cross-validation strategies and information criteria such as Akaike’s or Bayes’ information criterion. Our simulation study uses the data-dependent penalty level proposed by Belloni and Chernozhukov (2013). We refer interested readers to this source for details.\n\nCompared to the standard lasso approach, which induces bias due to the shrinkage of coefficients, post-lasso has the advantage of a smaller bias, even if the model selected in the first step by lasso fails to include some of the true predictors. It also converges at a faster rate towards the true parameter values if the model selected by lasso correctly includes all true predictors (in addition to some irrelevant predictors). If lasso selects exactly (only) the true predictors, the post-lasso coefficient estimators are equal to the ones produced by an oracle that is aware of the underlying data-generating process (Belloni et al. 2012, 2014a).\n\nTable 1 summarizes the results of 1000 simulation runs for the forecasting task, comparing OLS to post-lasso.\n\nWe report the forecast accuracy in terms of average root-mean-squared error (RMSE) over all simulation runs both on the in-sample and the out-of-sample data set. As outlined above, the in-sample data set consists of 48 data points, which are used to build and train the models. The out-of-sample data set consists of 12 data points, which are intentionally not used in the model construction (“hold-out sample”), allowing the model to be evaluated on new, previously unseen data. The strong focus on forecasting performance on previously unseen data is a hallmark of the machine learning approach.\n\nOn the in-sample data, OLS produces a higher predictive accuracy than post-lasso, with an RMSE of 0.738 which is nearly one-third that of the post-lasso RMSE of 1.991. However, the real interest of the FP&A department here is not to model past sales data. Rather, the predictive performance on new data is what matters to FP&A; this is why, the out-of-sample data have been set aside. Here, the OLS RMSE increases substantially to 5.321, more than twice as high as the post-lasso RMSE of 2.162.\n\nWe can draw two main conclusions from the simulation. First, the RMSE of standard OLS increases significantly between in-sample and out-of-sample data. With nearly as many features (regressors) as observations in the model, the resulting overfitting is immediately exposed when OLS is evaluated using previously unseen data. Second, the post-lasso RMSE is relatively stable between the in-sample and out-of-sample data. The in-sample performance is thus already indicative of the true predictive power when post-lasso is used on unseen data. Lasso achieves this through the regularization strategy described above, which leads to a very selective inclusion of features and thus parsimonious models. For reference, of the 40 available features in the simulation, post-lasso retains an average of only 1.2 as relevant and shrinks the coefficients of all the others to exactly zero. As a reminder, our simulation includes only two truly relevant features. The out-of-sample RMSE for post-lasso is thus slightly hihger than the perfect RMSE score of 2.0 (equal to the standard error that was selected for the noise parameter \\(\\varepsilon\\)), which would be achieved by an oracle.\n\nFigure 1 shows the distribution of the out-of-sample RMSE for the post-lasso forecast over the 1000 simulation runs. The distribution of the errors follows approximately a normal distribution (overlaid as a red line). From a practical perspective, the risk of generating a highly incorrect lasso forecast is therefore limited. Furthermore, the right tail of the lasso errors ends before the mean of the OLS error. This provides additional reassurance when relying on lasso.\n\nDistribution of the out-of-sample RMSE for the post-lasso forecast (bars), compared to the normal distribution (red line) (colour figure online)\n\n5.2 Planning\n\nWe will now discuss the use of machine learning in financial planning. To come back to our example, the task for the FP&A department consists of evaluating the effectiveness of promotional activity in generating sales; in statistical parlance, the task relates to statistical inference of the effect of a treatment or intervention (i.e., the promotional activity) on an outcome (i.e., sales). This estimate forms the basis for planning and optimizing marketing activities. In our simulation examples, evaluating the effectiveness of promotion equates to estimating the parameter \\(\\alpha\\). As the parameter of interest, \\(\\alpha\\) corresponds to the effect of the promotional activity on sales, also called the “lift” in business applications. Let us remind ourselves that in our simulation, only two features are relevant for the sales forecast and that these two features also determine the amount of promotional activity. Thus, we are dealing with confounders, because these two features are correlated with both the treatment and the outcome. Moreover, we have set \\(\\alpha\\) to zero, which effectively means that the promotional activity does not have an impact on sales.\n\nIn a business environment, this setting could correspond to an ice cream vendor at the beach who spends money on promotion whenever the weather is warm and sunny on the weekends. He ascribes the increased ice cream sales, or at least a part of them, to his promotional efforts, whereas in reality, it is the favorable weather on the weekend that makes people come to the beach and enjoy his ice cream. Similar to the forecasting exercise, the FP&A department is obviously not aware of the data-generating process governing the simulation and needs to find a way to estimate \\(\\alpha\\).\n\nOne approach to estimating the effect of promotion could be to use the parameter estimate for \\(\\alpha\\) from the lasso model employed in sales forecasting. However, lasso shrinks parameter estimates because of the penalty loading used in the regularization process and therefore does not generate unbiased estimates of the parameter values, even though it allocates the least possible penalty amount to large signals while retaining the stable behavior of a convex penalty (Taddy 2019). Additionally, lasso estimates predictors sparingly insofar as it sets many parameter estimates to exactly zero. In many cases, the factor measuring promotional activity “may not make it” into the second step of the post-lasso procedure. It is therefore not meaningful to infer from the forecasting model the effectiveness of the promotional activities. We have previously highlighted the warning by Mullainathan and Spiess (2017) and Athey (2018) that using a tool built for forecasting and assuming that its parameters possess the properties required for inference can be misleading.\n\nWith the above in mind, one could decide to pursue a hybrid solution with the following approach. Because the lasso has identified the most relevant features for prediction, we carry these forward into the inference model. Additionally, we include in the model the variable of interest (the intervention), which in our example is the variable that represents promotional activity. In a sense, we force this variable of interest into the model. We then estimate the parameter values for all of these features using OLS, which allows us to perform inference on the parameter estimates. In particular, we are able to interpret our parameter of interest \\(\\alpha\\) in this model. In our example, \\(\\alpha\\) will tell us the effectiveness of the promotional activities. Intuitively, a model that is constructed in this way can be understood as attempting to estimate the effect of promotional activity, while controlling for other factors with proven high predictive power from the forecasting model. For the ice cream vendor at the beach, this corresponds to controlling for the effect of the favorable weather during the weekend and thus deriving an isolated estimate of the effect of promotional activity on sales. This approach can be represented as\n\nwith \\(p*\\) corresponding to the subset of all p features for which \\(\\hat{\\beta }_\\mathrm{Lasso}\\) is non-zero.\n\nWe will see from the simulation results that this approach, which we will call “naive”, grossly fails to discover the true value of the parameter of interest, when modern machine learning methods are used in high-dimensional settings; still, it is widely used by practitioners and applied researchers. In our model, the promotional activity measure is correlated with the features that concomitantly and directly influence sales. In the presence of such confounders, the naive approach will fail.\n\nIn short, the naive approach will suffer from omitted variable bias. This is because machine learning methods capture the features correlated with the outcome variable and deliver good predictive performance but often miss variables that are correlated weakly with the outcome but correlated more strongly with the intervention variable. Missing these variables does not harm predictive performance but biases the estimation of the intervention effect, leading to invalid post-selection inference.\n\nFor an approach to be valid, it must overcome this problem of imperfect model selection and related omitted variable bias. Double or debiased machine learning, as proposed by Chernozhukov et al. (2017), is one way to do so. The fundamental idea\nFootnote\n9 is to reduce, for the estimation of the parameter of interest (i.e., the intervention variable), the sensitivity with respect to errors in selecting and estimating the nuisance parameters (i.e., the other predictors in the model). Technically, this can be achieved by regressing residuals on residuals. The first set of residuals is generated by regressing the outcome variable on the control features, notably using regularizing machine learning methods such as (post-)lasso, random forests, boosted trees or other methods suited for high-dimensional settings. The second set of residuals is generated by regressing the treatment variable on the control features, again using modern machine learning methods. This auxiliary step helps to control for the confounders that might lead to omitted variable bias. Finally, the first set of residuals is regressed on the second set of residuals. The parameter value obtained in this residuals-on-residuals regression represents the effect of the treatment variable on the outcome. This procedure is known as Frisch–Waugh–Lovell partialling out. In our simulation study, machine learning methods are used for partialling out. This approach allows for valid inference compared to the naive approach.\n\nTranslated into our stylized simulation, the first regression relates sales to the 40 presumably predictive features; the differences between the predictions \\(\\hat{y}_{n}\\) from this first regression and the actual outcomes (sales) y constitute the first set of residuals \\(r^{1}_{n}\\)\n\nThe second regression relates the promotional activity score d to the 40 presumably predictive features; the differences between the predictions from this second regression \\(\\hat{d}_{n}\\) and the actual outcomes (promotional activity) \\({d}_{n}\\) constitute the second set of residuals \\(r^{2}_{n}\\)\n\nConcretely, we will use a post-lasso approach in the regressions to derive both sets of residuals, but in principle, any other machine learning method could be used, such as random forests or support vector machines. Finally, we regress the residuals from the first regression onto the residuals from the second regression to obtain an estimate for the parameter of interest, \\(\\alpha\\), which represents the impact of promotional activities on sales\n\nThis approach works well in practice, because the residuals-on-residuals approach makes the estimation of the treatment effect less sensitive to errors in the model specification. Athey (2018) provides an intuitive explanation: “[...] in high dimensions, mistakes in estimating nuisance parameters are likely, but working with residualized variables makes the estimation of the average treatment effect orthogonal to errors in estimating nuisance parameters.” This is why the family of approaches that use this principle is also referred to as orthogonal machine learning (Taddy 2019). Interested readers are referred to the literature for an in-depth theoretical discussion, including underlying assumptions and formal proofs, which is beyond the scope of this paper. Key sources include Belloni et al. (2014a) and Chernozhukov et al. (2015, 2018). To implement our simulation, we use the partialling-out approach as defined by Chernozhukov et al. (2016) and report the corresponding results under this label.\n\nTable 2 summarizes the results of the two approaches (i.e., “naive” and “partialling out”) from 1000 simulation runs. We report the mean estimate for \\(\\alpha\\), the standard deviation of the estimate and the corresponding t-statistic and p value for a two-sided test of whether the mean is different from zero. The rejection rate represents the proportion of individual simulation runs in which the ingoing assumption of \\(\\alpha\\)=0 has been rejected based on the t test (at the customary 5% significance level). In other words, these are the instances in which the model incorrectly suggests an effect (positive or negative) of promotional activity on sales.\n\nThe simulation results provide several insights. First, and this is the main point we seek to make, the naive approach grossly fails to discover the true value of \\(\\alpha\\), because it suffers from significant bias. Put simply in the context of our simulation, this bias represents systematic over-estimation of \\(\\alpha\\) and thus over-estimation of the effectiveness of promotion. On average, the naive approach estimates a value for \\(\\alpha\\) of 0.1604, compared to a true value of zero. The partialling-out approach also yields an average positive value for \\(\\alpha\\) of 0.0081, but is much closer to the true value of zero. Relatively speaking, the bias of the naive approach is roughly 20 times higher than that of the partialling-out approach.\n\nA second point is that the standard deviation of the estimates for \\(\\alpha\\) are similar for both approaches. Figures 2 (naive approach) and 3 (partialling-out approach) show the distribution of the estimates for \\(\\alpha\\) from the 1000 simulation runs compared to a normal distribution curve. Visual inspection suggests that the shapes of both distributions are well approximated by a normal distribution. Of course, the center of the distribution for the naive approach is clearly shifted to the right of zero. This reinforces the point made above that bias is induced by the naive approach.\n\nDistribution of estimator for \\(\\alpha\\) from the naive approach\n\nDistribution of estimator for \\(\\alpha\\) from the partialling-out approach\n\nTable 2 also reports the t-statistic and corresponding p value for a two-sided test of whether the mean estimate of \\(\\alpha\\) is zero. Under the naive approach, this hypothesis would be rejected with high confidence (t-statistic of 30), reinforcing the incorrect belief that the promotional efforts positively affect sales. Under the partialling-out approach, the hypothesis of no effect from promotional efforts would not be rejected at the customary 5% threshold level (t-statistic of 1.93). In practice, the FP&A department would of course not benefit from this kind of insight as they would not have access to repeated estimates for \\(\\alpha\\). With the advantage of being able to run multiple simulations, we can use this information to support the point of significant bias in the naive approach. Nevertheless, the rejection rate, reported in the last line of Table 2, provides a good indication of how often FP&A would make an incorrect decision. For each individual run in the simulation, this metric records whether FP&A would (incorrectly) reject the assumption that \\(\\alpha\\) is zero at the typical 5% significance level. Under the naive approach, this would happen 46% of the time. Put differently, a bit less than half of the time, FP&A would incorrectly assume that promotional activity does have an effect on sales. With partialling-out, this error drops to slightly below 5%.\nFootnote\n10\n\nIn summary, by relying on the naive approach, the FP&A department (or the ice cream vendor) would substantially overestimate the causal effect of the promotional activity on sales. Consequently, this activity would probably be maintained or even increased for this product or service, even though in reality, it does not increase sales. Put differently, the company would draw up plans that allocate resources wastefully on this particular product or market. The impact from falling into this trap could multiply even further across the organization if the results of such an analysis were used as a benchmark for similar products, services or geographic markets. This might happen, for example, if data are not readily available for a particular product (for example, one that is being newly launched) and the decision is made to extrapolate from existing (and potentially wrong) information. Such a situation is even more likely when the existing information appears plausible and suitable\nFootnote\n11 and, in addition, is perceived as objective, unbiased (in the sense of free from human/cognitive bias) or even scientific, because it was generated using data-driven methods.\n\n5.3 The value of data\n\nIn 2017, “The Economist” (Economist, 2017) asserted in the title of its May 6 edition that data are now the world’s most valuable resource. Questions about the value of data as a resource and production factor have generated great interest in academia and policy institutes. One consideration within this vast topic is a (hypothesized) positive feedback loop: more data lead to more data-driven insights, allowing a company to serve its customers better, to attract more customers and, in turn, to collect even more data. Nevertheless, there seems to be a broad consensus that data are generally governed by decreasing returns to scale, like any other production factor (Varian 2018; Bajari et al. 2019).\n\nIn this paper, we will limit ourselves to a short discussion of how the number of observations affects the accuracy achieved by the forecasting and inference methods used by the FP&A department within the frame of our simulation. For empirical results, we refer interested readers to Bajari et al. (2019), which contains a study of the performance of Amazon’s retail forecasting system. The study finds performance gains in the time dimension (i.e., from longer data history), but not in the product dimension (i.e., panel data forecasts do not improve with more products within a category). An interesting finding is the overall improvement of forecasts over time (controlling for the length of data history and the number of products), suggesting positive effects from improved technology (e.g., new machine learning models, better hardware or adaptation of organizational practices).\n\nIn our simulation, the hypothetical FP&A department uses a training set of 48 observations, 40 predictive features and one variable of interest for inference (i.e., the measure of promotional activity). In many real-life applications relevant to FP&A departments, the number of observations available for analysis is typically limited. More observations may simply not exist; for instance, new products generate sales data starting only from their launch date. Even if data do exist, collecting, accessing and, if necessary, curating them come at a cost; for instance, companies may limit the amount of directly accessible data history due to system constraints, or data generated prior to the introduction of new software may be inaccessible, in full or in part.\n\nLet us now explore simulation results assuming that the FP&A department has invested in expanding the training set of observations to 60, 72 or 96. The number of features (i.e., 40), the variable of interest (promotional activity measure) and the overall simulation set-up remain unchanged.\nFootnote\n12 We again run 1000 simulations. What is the return on accuracy of expanding the observation set?\nFootnote\n13\n\nTable 3 reports the forecasting results based on 60, 72 and 96 observations compared to the previous simulation based on 48 observations. For OLS, the in-sample accuracy drops, as witnessed by the increase in RMSE to 1.507 (for 96 observations) from the initial RMSE of 0.738 with 48 observations. However, the out-of-sample accuracy increases: the corresponding RMSE drops to 2.561 (for 96 observations) from the previous RMSE of 5.321 based on 48 observations. In fact, the additional observations reduce the extent of overfitting seen in the initial setting. With 40 features and (only) 48 observations, OLS was actually close to the point of failing. This point would have been reached if the number of features had been equal to or exceeded the number of observations. Intuitively, OLS moves further away from this point by expanding the set of observations (and keeping the number of features constant).\n\nFor post-lasso, the results based on 60, 72 and 96 observations are quite similar to those obtained with 48 observations. Neither the in-sample nor the out-of-sample RMSE change notably. As expected and unlike OLS, post-lasso already deals well with the initial situation in which the number of features is close to the number of observations and benefits only marginally from the increase in observations. Put differently, post-lasso does not require investing in the generation or acquisition of additional data. Our finding is consistent with standard stochastic theory.\nFootnote\n14\n\nIn summary, while having more data is generally beneficial, expanding the observation set for forecasting in our simulation study creates a tangible advantage only for OLS. If the FP&A department employs post-lasso, which is the preferable method in this setting, the gain in precision from expanding the observation set is very small and, for many practical applications, would not warrant the effort.\n\nWe will now look at inference, which entails estimating the (causal) effect of promotional activities on sales. Table 4 reports the inference results for \\(\\alpha\\) based on 60, 72 and 96 training observations compared to the previous simulation based on 48 observations. Recall that the true value of \\(\\alpha\\) is zero. For OLS, as the number of observations increases, the mean estimate for \\(\\alpha\\) decreases to 0.0617 (for 96 observations) from the previous estimate of 0.1604 with 48 observations. However, based on a standard t test, this value is still significantly different from zero (t-statistic of 13.257). In comparison, for the partialling-out approach, the mean estimate for \\(\\alpha\\) declines from 0.0081 with 48 observations to 0.0042 for 96 observations, with a minimum of \\(-\\) 0.0008 in the simulation run based on 72 observations. In all three additional scenarios, it is not statistically different from zero (t-statistic of 1.381, \\(-\\) 0.217 and 1.400, respectively).\n\nThe expanded set of observations reduces the bias of the naive approach. Intuitively, the risk of imperfect model selection described above becomes smaller. Still, the naive approach exhibits significant bias compared to the true value of \\(\\alpha\\). For the partialling-out approach, the additional observations lead to a mean estimate for \\(\\alpha\\) that comes even closer to the true value. Depending on the required precision of the estimate, the FP&A department could benefit from the additional set of observations in its analysis. Again, our finding is consistent with standard theory on convergence rates (see, for instance, Bühlmann and van de Geer 2011 or Belloni and Chernozhukov 2013). Whereas post-lasso converges for forecasting towards the true parameter value at a relatively slower rate of \\(n^{-1/4}\\), the double machine learning estimator of the treatment effect converges at the faster rate of \\(n^{-1/2}\\) (i.e., the same rate as OLS).\n\n6 Conclusion\n\nDigitalization, especially when it couples large amounts of data with appropriate tools for analysis, represents an important opportunity for the financial planning and analysis function. In this article, we have provided an introductory overview of machine learning in this context. By reviewing several relevant theoretical aspects of machine learning and discussing the results of a simulation study, we have demonstrated how machine learning may prove useful for FP&A practitioners. We have paid special attention to explain the distinction between forecasting and planning tasks, the first of which involves prediction and the latter of which involves causal inference. We see the confusion of these two concepts as a major pitfall that practitioners should strive to avoid. Specific approaches to causal machine learning have begun to gain traction, as awareness has increased that the naive application of machine learning can fail in applications that go beyond prediction. This applies to all modern machine learning methods in a high-dimensional setting.\n\nOur article has several limitations. It was impossible to cover the vast number of machine learning techniques that exist. Depending on the causal question at hand, a range of econometric approaches (e.g., instrumental variables, synthetic controls or regression discontinuity designs) coupled with machine learning methods may be suitable. We intentionally used a simple data generation process in our simulation; additional elements such as trends or seasonal components or a real-life example could complement our simulation study. Despite these limitations, we believe that our article can be a valuable source of insights into the ways in which FP&A can benefit from machine learning. With it, we hope to contribute to the adoption of machine learning in this area and help practitioners avoid common mistakes.\n\nNotes\n\nIn some companies, the (short-term) plans formally expressed in budgets are prepared by controllers (management accountants) within the accounting department (Garrison et al. 2006), while the strategy department formulates the directional (long-term) plans.\n\nFor instance, www.bosch.com/de/forschung/know-how/publikationen (accessed Feb 23, 2021) contains a collection by Robert Bosch GmbH.\n\nOther methods with a very similar intent exist. Examples are the quantification of a best and worst case in addition to the normal or base case, or sensitivity analysis with varying degrees of sophistication.\n\nWe have intentionally kept the simulation example simple. For instance, we have not added any time-series-specific effects such as a trend component or serially correlated error terms. This allows us to focus on the key elements. For instance, the \\(N=60\\) data points could represent observations in different countries or sub-markets, which would warrant a cross-sectional approach to the analysis. The conclusions presented in the simulation example will remain largely unchanged.\n\nThis is a case of supervised learning, because we have observations for both the input (\\(x_{p,n}\\)) and the output (\\(y_{n}\\)).\n\nThe value of c represents the correlation between immediate neighbor features (e.g., feature \\(x_{p}\\) and feature \\(x_{p+1}\\)). Due to the way \\(\\Sigma\\) is constructed, the correlation decays quickly as the distance between features increases (e.g., feature \\(x_{p}\\) and \\(x_{p+3}\\) have only a correlation of \\(c^{3}\\), which is 0.027 for \\(c=0.3\\)).\n\nA simple example can help clarify the intuition behind this setting. Ice cream sales on the beach are probably positively related to weather conditions (feature 1) and the day of the week (feature 2). At the same time, the ice cream salesperson may decide to run some promotional activity when weather conditions are favorable on a weekend. Thus, the same features have an influence both on sales and on promotional activity. We will revert to this illustrative example in the section on planning.\n\nBy construction, our simulation example is exactly sparse, with parameter values for all non-relevant features exactly equal to zero. For practical applications, a more realistic assumption is approximate sparsity, meaning that all or many features can have non-zero parameter values. Nevertheless, only a limited number of features are needed to approximate the true relationship with sufficient accuracy. We refer interested readers to Belloni et al. (2010). Our simulation could easily be extended to such a setting. Results would remain largely unchanged.\n\nDouble machine learning also uses cross-fitting, an efficient way of data splitting. Interested readers are referred to Chernozhukov et al. (2017).\n\nNote that one would expect an error rate here of around 5% from a correct model, because the 5% significance level corresponds to a 5% probability of rejecting the null hypothesis when it is, in reality, true.\n\nBlake et al. (2015) highlight in their paper that “[...] the incentives faced by advertising firms, publishers, analytics consulting firms, and even marketing executives within companies, are all aligned with increasing advertising budgets.”\n\nWe intentionally do not allow the number of features to grow with the sample size (see for instance Belloni et al. 2010) to isolate the effect of the additional observations clearly. In practice, a significant extension of the number of observations may require including additional control features.\n\nThe natural way to think about the expansion is to assume that the department “digs out” additional historical observations. However, from a theoretical standpoint, the department could also wait 1, 2 or 4 years, respectively, and gather the additional data points over time. In this case, the change in forecasting accuracy could be mistaken for a technology or learning effect by an outside observer.\n\nSee, for instance, Bühlmann and van de Geer (2011) or Belloni and Chernozhukov (2013). Post-lasso converges towards the true parameter value at a rate of \\(n^{-1/4}\\), which is slower than the OLS rate of \\(n^{-1/2}\\). The value of additional data is thus generally smaller for post-lasso than for OLS.\n\nReferences\n\nAcemoglu, D., & Restrepo, P. (2018). Artificial intelligence, automation, and work. The economics of artificial intelligence: an agenda (pp. 197–236). University of Chicago Press. https://doi.org/10.7208/chicago/9780226613475.001.0001.\n\nChapter\n  Google Scholar\n\nAthey, S. (2018). The impact of machine learning on economics. The economics of artificial intelligence: an agenda (pp. 507–547). University of Chicago Press.\n\nGoogle Scholar\n\nBajari, P., Chernozhukov, V., Hortaçsu, A., & Suzuki, J. (2019). The impact of big data on firm performance: an empirical investigation. AEA Papers and Proceedings, 109, 33–37. https://doi.org/10.1257/pandp.20191000.\n\nArticle\n  Google Scholar\n\nBalakrishnan, T., Chui, M., Hall, B., & Henke, N. (2020). Global survey: the state of AI in 2020. McKinsey & Company. https://www.mckinsey.com/business-functions/mckinsey-analytics/our-insights/global-survey-the-state-of-ai-in-2020. Accessed 6 Dec 2020.\n\nBarker, J., Gajewar, A., Golyaev, K., Bansal, G., & Conners, M. (2018). Secure and automated enterprise revenue forecasting. In AAAI, pp. 7657–7664.\n\nBecker, S. D., Mahlendorf, M. D., Schäffer, U., & Thaten, M. (2016). Budgeting in times of economic crisis. Contemporary Accounting Research, 33, 1489–1517. https://doi.org/10.1111/1911-3846.12222.\n\nArticle\n  Google Scholar\n\nBelloni, A., Chen, D., Chernozhukov, V., & Hansen, C. (2012). Sparse models and methods for optimal instruments with an application to eminent domain. Econometrica, 80, 2369–2429. https://doi.org/10.3982/ECTA9626.\n\nArticle\n  Google Scholar\n\nBelloni, A., & Chernozhukov, V. (2013). Least squares after model selection in high-dimensional sparse models. Bernoulli, 19, 521–547. https://doi.org/10.3150/11-BEJ410.\n\nArticle\n  Google Scholar\n\nBelloni, A., Chernozhukov, V., & Hansen, C. (2010). Inference for high-dimensional sparse econometric models. In Advances in Economics and Econometrics. 10th World Congress of Econometric Society, Aug 2010 III, pp. 245–295. ArXiv, 2011.\n\nBelloni, A., Chernozhukov, V., & Hansen, C. (2014a). High-dimensional methods and inference on structural and treatment effects. Journal of Economic Perspectives, 28, 29–50. https://doi.org/10.1257/jep.28.2.29.\n\nArticle\n  Google Scholar\n\nBelloni, A., Chernozukov, V., & Hansen, C. (2014b). Inference on treatment effects after selection among high-dimensional controls. The Review of Economic Studies, 81, 608–650.\n\nArticle\n  Google Scholar\n\nBishop, C. M. (2006). Pattern recognition and machine learning. Information science and statistics. Springer (Softcover published in 2016).\n\nGoogle Scholar\n\nBlake, T., Nosko, C., & Tadelis, S. (2015). Consumer heterogeneity and paid search effectiveness: a large-scale field experiment. Econometrica, 83, 155–174. https://doi.org/10.3982/ECTA12423.\n\nArticle\n  Google Scholar\n\nBrealey, R. A., Myers, S. C., & Franklin, A. (2020). Principles of corporate finance (13th ed.). McGraw-Hill Education.\n\nGoogle Scholar\n\nBühlmann, P., & van de Geer, S. (2011). Statistics for high-dimensional data: methods, theory and applications. Springer series in statistics. Springer.\n\nBook\n  Google Scholar\n\nChandra, K., Plaschke, F., & Seth, I. (2018). Memo to the CFO: get in front of digital finance - or get left back. McKinsey & Company. https://www.mckinsey.com/business-functions/strategy-and-corporate-finance/our-insights/memo-to-the-cfo-get-in-front-of-digital-finance-or-get-left-back. Accessed 10 Dec 2020.\n\nChernozhukov, V., Chetverikov, D., Demirer, M., Duflo, E., Hansen, C., & Newey, W. (2017). Double/debiased/neyman machine learning of treatment effects. American Economic Review, 107, 261–65. https://doi.org/10.1257/aer.p20171038.\n\nArticle\n  Google Scholar\n\nChernozhukov, V., Chetverikov, D., Demirer, M., Duflo, E., Hansen, C., Newey, W., & Robins, J. (2018). Double/debiased machine learning for treatment and structural parameters. The Econometrics Journal, 21, C1–C68. https://doi.org/10.1111/ectj.12097.\n\nArticle\n  Google Scholar\n\nChernozhukov, V., Hansen, C., & Spindler, M. (2015). Valid post-selection and post-regularization inference: an elementary, general approach. Annual Review of Economics, 7, 649–688. https://doi.org/10.1146/annurev-economics-012315-015826.\n\nArticle\n  Google Scholar\n\nChernozhukov, V., Hansen, C., & Spindler, M. (2016). High-dimensional metrics in R. arXiv:1603.01700v2.\n\nConine, T. C., & McDonald, M. (2017). The application of variance analysis in FP&A organizations: survey evidence and recommendations for enhancement. Journal of Accounting and Finance, 17, 54–70.\n\nGoogle Scholar\n\nDe Gooijer, J. G., & Hyndman, R. J. (2006). 25 years of time series forecasting. International Journal of Forecasting, 22, 443–473. https://doi.org/10.1016/j.ijforecast.2006.01.001 (twenty five years of forecasting).\n\nArticle\n  Google Scholar\n\nEconomist (2017). The world’s most valuable resource is no longer oil, but data. https://www.economist.com/leaders/2017/05/06/the-worlds-most-valuable-resource-is-no-longer-oil-but-data. Accessed 6 Dec 2020.\n\nFischer, E. O. (2009). Finanzwirtschaft für Anfänger. Lehr- und Handbücher zur entscheidungsorientierten Betriebswirtschaft. Oldenbourg.\n\nGoogle Scholar\n\nGajewar, A., & Bansal, G. (2016). Revenue forecasting for enterprise products. arXiv:1701.06624.\n\nGandomi, A., & Haider, M. (2015). Beyond the hype: big data concepts, methods, and analytics. International Journal of Information Management, 35, 137–144. https://doi.org/10.1016/j.ijinfomgt.2014.10.007.\n\nArticle\n  Google Scholar\n\nGarrison, R. H., Noreen, E. W., & Brewer, P. C. (2006). Managerial accounting. McGraw-Hill/Irwin.\n\nGoogle Scholar\n\nGray, G. L., & Alles, M. (2015). Data fracking strategy: why management accountants need it. Management Accounting Quarterly, 16, 22–33.\n\nGoogle Scholar\n\nHansen, S. C. (2011). A theoretical analysis of the impact of adopting rolling budgets, activity-based budgeting and beyond budgeting. European Accounting Review, 20, 289–319. https://doi.org/10.1080/09638180.2010.496260.\n\nArticle\n  Google Scholar\n\nHastie, T., Tibshirani, R., & Friedman, J. (2009). The elements of statistical learning: data mining, inference, and prediction (2nd ed.). Springer-Verlag.\n\nBook\n  Google Scholar\n\nHenrique, B. M., Sobreiro, V. A., & Kimura, H. (2019). Literature review: machine learning techniques applied to financial market prediction. Expert Systems with Applications, 124, 226–251. https://doi.org/10.1016/j.eswa.2019.01.012.\n\nArticle\n  Google Scholar\n\nKoenecke, A., & Gajewar, A. (2020). Curriculum learning in deep neural networks for financial forecasting. In V. Bitetta, I. Bordino, A. Ferretti, F. Gullo, S. Pascolutti, & G. Ponti (Eds.), Mining data for financial applications (pp. 16–31). Springer International Publishing.\n\nChapter\n  Google Scholar\n\nKüsters, U., McCullough, B. D., & Bell, M. (2006). Forecasting software: past, present and future. International Journal of Forecasting, 22, 599–615. https://doi.org/10.1016/j.ijforecast.2006.03.004 (twenty five years of forecasting).\n\nArticle\n  Google Scholar\n\nLaney, D. (2001). 3-D data management: controlling data volume, velocity and variety. Application Delivery Strategies by META Group Inc., Gartner. https://blogs.gartner.com/doug-laney/files/2012/01/ad949-3DData-Management-Controlling-Data-Volume-Velocity-andVariety.pdf. Accessed 30 July 2020.\n\nMöller, K., Schäffer, U., & Verbeeten, F. (2020). Digitalization in management accounting and control: an editorial. Journal of Management Control, 31, 1–8. https://doi.org/10.1007/s00187-020-00300-5.\n\nArticle\n  Google Scholar\n\nMullainathan, S., & Spiess, J. (2017). Machine learning: an applied econometric approach. Journal of Economic Perspectives, 31, 87–106. https://doi.org/10.1257/jep.31.2.87.\n\nArticle\n  Google Scholar\n\nOesterreich, T. D., Teuteberg, F., Bensberg, F., & Buscher, G. (2019). The controlling profession in the digital age: understanding the impact of digitisation on the controller’s job roles, skills and competences. International Journal of Accounting Information Systems. https://doi.org/10.1016/j.accinf.2019.100.\n\nArticle\n  Google Scholar\n\nOzbayoglu, A. M., Gudelek, M. U., & Sezer, O. B. (2020). Deep learning for financial applications: a survey. Applied Soft Computing, 93, 106384. https://doi.org/10.1016/j.asoc.2020.106384.\n\nArticle\n  Google Scholar\n\nPearl, J. (2019). The seven tools of causal inference, with reflections on machine learning. Communications of the ACM, 62, 54–60. https://doi.org/10.1145/3241036.\n\nArticle\n  Google Scholar\n\nPearl, J., & Mackenzie, D. (2018). The book of why: the new science of cause and effect (1st ed.). Basic Books Inc.\n\nGoogle Scholar\n\nRoos, A., Tucker, J., Rodt, M., Stange, S., Ego, P., Boudadi, A., & Sheth, H. (2020). Lessons from best-in-class CFOs. Boston Consulting Group. https://www.bcg.com/publications/2020/lessons-best-in-class-cfos. Accessed 29 July 2020.\n\nRoss, S. A., Westerfield, R. W., & Jordan, B. D. (2019). Fundamentals of corporate finance (12th ed.). McGraw-Hill Education.\n\nGoogle Scholar\n\nRubin, D. B. (2005). Causal inference using potential outcomes. Journal of the American Statistical Association, 100, 322–331. https://doi.org/10.1198/016214504000001880.\n\nArticle\n  Google Scholar\n\nStrauß, E., & Zecher, C. (2013). Management control systems: a review. Journal of Management Control, 23, 233–268. https://doi.org/10.1007/s00187-012-0158-7.\n\nArticle\n  Google Scholar\n\nSutton, R. S., & Barto, A. G. (2018). Reinforcement learning: an introduction. Adaptive computation and machine learning series. MIT Press.\n\nGoogle Scholar\n\nTaddy, M. (2019). Business data science: combining machine learning and economics to optimize, automate, and accelerate business decisions. McGraw-Hill Education.\n\nGoogle Scholar\n\nTucker, J., Foldesy, J., Roos, A., & Rodt, M. (2017). How digital CFOs are transforming finance. Boston Consulting Group. https://www.bcg.com/publications/2017/function-excellence-how-digital-cfo-transforming-finance. Accessed 10 Dec 2020.\n\nUnger, G., & Rodt, M. (2019). The art of forward-looking steering: the power of algorithmic forecasting. Boston Consulting Group. https://www.bcg.com/publications/2019/power-of-algorithmic-forecasting. Accessed 30 Nov 2020.\n\nVarian, H. (2018). Artificial intelligence, economics, and industrial organization. The economics of artificial intelligence: an agenda (pp. 399–419). University of Chicago Press. https://doi.org/10.7208/chicago/9780226613475.001.0001.\n\nChapter\n  Google Scholar\n\nZhu, X., & Goldberg, A. B. (2009). Introduction to semi-supervised learning. Synthesis Lectures on Artificial Intelligence and Machine Learning, 3, 1–130. https://doi.org/10.2200/S00196ED1V01Y200906AIM006.\n\nArticle\n  Google Scholar\n\nDownload references\n\nAcknowledgements\n\nWe thank the editor and two anonymous referees for their very helpful comments and suggestions.\n\nFunding\n\nOpen Access funding enabled and organized by Projekt DEAL.\n\nAuthor information\n\nAuthors and Affiliations\n\nNovartis International AG, Novartis Campus, 4002, Basel, Switzerland\n\nHelmut Wasserbacher\n\nHamburg Business School, University of Hamburg, Moorweidenstr. 18, 20148, Hamburg, Germany\n\nMartin Spindler\n\nCorresponding author\n\nCorrespondence to Martin Spindler.\n\nAdditional information\n\nPublisher's Note\n\nSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\n\nThe views and opinions expressed in this document are those of the first author, and do not necessarily reflect the official policy or position of Novartis or any of its officers.\n\nRights and permissions\n\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.\n\nReprints and permissions\n\nAbout this article\n\nCite this article\n\nWasserbacher, H., Spindler, M. Machine learning for financial forecasting, planning and analysis: recent developments and pitfalls. Digit Finance 4, 63–88 (2022). https://doi.org/10.1007/s42521-021-00046-2\n\nDownload citation\n\nReceived\n27 May 2021\n\nAccepted\n17 November 2021\n\nPublished\n16 December 2021\n\nIssue Date\nMarch 2022\n\nDOI\nhttps://doi.org/10.1007/s42521-021-00046-2\n\nShare this article\n\nAnyone you share the following link with will be able to read this content:\n\nProvided by the Springer Nature SharedIt content-sharing initiative\n\nKeywords\n\nJEL Classification\n\nDiscover content\n\nPublish with us\n\nProducts and services\n\nOur brands\n\n178.135.19.63\n\nNot affiliated\n\n© 2025 Springer Nature\n\nThe Synergy of AI and Financial Engineering in Forecasting Models : \nThe Synergy of AI and Financial Engineering in Forecasting Models\n\nIntroduction\n\nIn today's fast-paced financial landscape, the integration of Artificial Intelligence (AI) into traditional financial engineering has transformed the field of forecasting models significantly. With advancements in machine learning, data analytics, and computational power, numerical predictions in finance are now more accurate and adaptive to the ever-changing market conditions. Whether investors aim to anticipate stock price movements, assess risks, or optimize portfolios, leveraging AI techniques in financial engineering has become indispensable.\n\nThis article delves into the intricate relationship between AI and financial engineering, examining how these dynamic fields converge to enhance forecasting models. We will explore the fundamental concepts of financial engineering, the transformative role of AI, the methodologies employed, and the potential implications for investors and financial institutions alike. Through this exploration, we aim to shed light on the profound impact that this synergy has on financial decision-making processes.\n\nThe Foundation of Financial Engineering\n\nUnderstanding Financial Engineering\n\nAt its core, financial engineering is the application of quantitative methods and mathematical tools to solve problems related to finance. It involves designing innovative financial instruments, creating risk management strategies, and structuring complex financial transactions. Professionals in this field, often equipped with degrees in mathematics, statistics, economics, and computer science, employ models to analyze market dynamics, assess derivatives pricing, and manage investment portfolios.\n\nOne of the prime objectives of financial engineering is to understand and manage risks associated with financial uncertainty. This involves a comprehensive study of various financial instruments and their behavior under different economic scenarios. The complexity and non-linearity of financial markets necessitate the use of sophisticated mathematical models and computational simulations, such as Monte Carlo simulations and stochastic calculus, to anticipate market fluctuations and optimize trading strategies effectively.\n\nHistorical Context and Evolution\n\nThe roots of financial engineering can be traced back to the mid-20th century when academics and financial professionals began to develop quantitative models to price options and other derivatives. The introduction of the Black-Scholes model in 1973 marked a pivotal moment in the field, enabling more structured approaches to pricing and risk assessment. As computers became more powerful and accessible, the speed and complexity of financial models exponentially increased, allowing for better simulations and predictions.\n\nHowever, despite its mathematical rigor, traditional financial engineering often faced limitations in adaptability and learning capabilities. As the financial markets became increasingly volatile and influenced by an array of factors like geopolitical events, economic indicators, and market sentiment, relying solely on static models proved insufficient. This paved the way for the incorporation of AI into financial engineering, as it offered a more dynamic approach to modeling and forecasting.\n\nThe Role of Data in Financial Engineering\n\nData is the lifeblood of financial engineering. With the advent of big data, professionals can now access a vast array of structured and unstructured data sources, from stock prices and trading volumes to social media sentiment and economic indicators. The challenge lies in not just accumulating this data but also processing and interpreting it effectively.\n\nFinancial engineers utilize statistical techniques and algorithms to analyze historical data and build predictive models based on identified patterns and trends. The integration of AI enhances this process by automating data analysis, uncovering hidden correlations, and enabling real-time predictions. As a result, financial institutions are now better equipped to adapt to sudden market changes, adjust their trading strategies accordingly, and ultimately enhance their profitability.\n\nThe Emergence of AI in Financial Engineering\n\nThe Impact of Machine Learning\n\nMachine learning, a subset of AI, leverages algorithms that enable computers to learn from data and improve their performance without explicit programming. In financial engineering, machine learning techniques have become indispensable in enhancing forecasting models. Traditional methods often relied on fixed equations and assumptions based on historical data, which can overlook intricate relationships within the data.\n\nBy employing machine learning models—such as regression trees, random forests, and neural networks—financial engineers can build more robust and flexible predictive models. These models exhibit the ability to adapt to new data, accommodating changing market conditions seamlessly. For instance, by inputting time-series data into a machine learning model, analysts can uncover hidden trends that inform trading strategies and risk management processes.\n\nAdditionally, machine learning algorithms can improve the accuracy of predicting extreme market events or black swan events, which have significant implications for risk management. Traditional models often struggled to forecast such events due to their rarity, but AI-enhanced models can identify subtle patterns that may precede these occurrences.\n\nNatural Language Processing (NLP) in Financial Forecasting\n\nNatural Language Processing, a branch of AI focused on the interaction between computers and human language, has opened new avenues in financial engineering. By harnessing NLP techniques, financial analysts can extract valuable insights from unstructured data sources like news articles, earnings call transcripts, and social media feeds. Such information can significantly impact market sentiment and stock prices, making it a vital component in enhancing forecasting models.\n\nFor instance, sentiment analysis, a common application of NLP, assesses public emotion and opinion regarding specific stocks or the overall market. By analyzing the sentiment behind news headlines or social media chatter, financial engineers can gauge market fluctuations and adjust their predictive models accordingly. Data derived from sentiment analysis can be integrated with traditional financial metrics to create hybrid models that provide a more holistic view of market dynamics.\n\nReinforcement Learning for Dynamic Decision-Making\n\nReinforcement learning is another emerging area of AI that holds vast potential for financial engineering. Unlike traditional machine learning methods that learn from historical data, reinforcement learning involves training algorithms through trial-and-error interactions in an environment—essentially learning from the outcomes of different decision-making actions.\n\nIn finance, reinforcement learning can be employed to develop trading algorithms capable of adapting strategies in real-time based on market behavior. For example, a reinforcement learning algorithm can simulate various trading strategies, receiving reinforcement in the form of rewards (profits) or penalties (losses) based on its actions. This enables the algorithm to continuously learn and improve its trading decisions over time.\n\nThe use of reinforcement learning models can result in more dynamic and responsive trading practices, allowing financial institutions to maintain a competitive edge in rapidly changing markets. The synergy between financial engineering and AI will likely lead to further innovations in dynamic decision-making processes.\n\nChallenges and Considerations\n\nData Quality and Ethical Concerns\n\nDespite the numerous advantages AI brings to financial engineering, challenges remain regarding the quality of data input into these systems. Poor data quality can lead to inaccurate forecasts, financial losses, and reputational damage for organizations. Thus, it is vital for financial engineers to prioritize data cleaning and validation processes before applying AI techniques.\n\nMoreover, ethical concerns surrounding AI in finance also warrant attention. Issues such as data privacy, algorithmic bias, and transparency pose significant challenges that financial institutions must address. Regulatory frameworks may need to evolve to encompass the unique aspects of AI-driven financial models, ensuring accountability and fair practices within the industry.\n\nOverfitting and Model Complexity\n\nAnother challenge with implementing AI in financial forecasting is the risk of overfitting. This occurs when a model performs exceptionally well on training data but fails to generalize its predictions to unseen data. Financial markets are influenced by a plethora of unpredictable variables, and as AI models become increasingly complex, the risk of overfitting becomes more pronounced.\n\nFinanciers must strike a balance between model complexity and interpretability. While intricate models may yield higher accuracy, they may also become less transparent and harder to understand. Achieving this balance requires continuous validation and testing against real-world scenarios to ensure models remain robust and adaptive.\n\nThe Need for Interdisciplinary Collaboration\n\nThe successful integration of AI in financial engineering necessitates collaboration between various disciplines. Financial engineers, data scientists, and AI experts must work closely to design and implement forecasting models that are both innovative and practical. This interdisciplinary approach can foster the development of comprehensive solutions that address intricate financial challenges effectively.\n\nMoreover, a collaborative environment encourages knowledge sharing, paving the way for unique ideas and methodologies that leverage the strengths of each discipline. As AI continues to evolve, creating interdisciplinary teams will be essential in driving innovation within the financial sector.\n\nConclusion\n\nThe synergy between Artificial Intelligence and financial engineering represents a paradigm shift in how financial forecasting models are developed and implemented. By harnessing advanced machine learning techniques, natural language processing, and reinforcement learning, financial professionals can now create dynamic models that improve accuracy and adaptability in an ever-evolving financial landscape.\n\nAs AI continues to mature, its integration into financial engineering will likely yield further advancements and innovations, empowering investors and institutions to make informed decisions based on enhanced predictive capabilities. Nevertheless, critical challenges remain, including data quality, ethical considerations, and the potential for overfitting. To navigate these challenges and maximize the benefits of AI, collaboration among interdisciplinary teams will be paramount.\n\nUltimately, the fusion of AI with financial engineering heralds a new era in forecasting models, enabling stakeholders to grasp complex market dynamics, harness valuable insights, and adapt to emerging trends in real time. In this journey toward improved forecasting techniques, the commitment to responsible data management, transparency, and ethical practices will be the cornerstones of building a sustainable and trustworthy financial future.\n\nIf you want to read more articles similar to The Synergy of AI and Financial Engineering in Forecasting Models, you can visit the Financial Forecasting category.\n\nYou Must Read\n\nIntegrating Personalization Algorithms with Existing Systems\n\nThe Impact of Deep Learning Model Size on Performance\n\nA Comprehensive Guide to Chatbot Data Preparation with ML\n\nCategories\n\nRelated Posts\n\nIntegrating Machine Learning Algorithms into HR Hiring Processes\n\nExploring the Role of AI in Satellite Imagery for Urban Planning\n\nExploring Ensemble Learning Methods in Clinical Applications\n\nTerms and Conditions\n\nPrivacy Policy\n\nCookie Policy\n\nAbout Us\n\nContact Us\n",
        "Machine learning models employed in customer banking product targeting": "AI-Driven Customer Segmentation and Targeting in Retail Banking ... : \nAI-Driven Customer Segmentation and Targeting in Retail Banking: Improving Marketing Strategies and Customer Retention\n\nAI-Driven Customer Segmentation and Targeting in Retail Banking: Improving Marketing Strategies and Customer Retention\n\nIn the contemporary landscape of retail banking, the advent of Artificial Intelligence (AI) has ushered in transformative advancements in customer segmentation and targeting, which are pivotal to optimizing marketing strategies and enhancing customer retention. This paper delves into the application of AI technologies in refining customer segmentation processes and crafting targeted marketing strategies, underpinned by data-driven insights. The integration of AI in these domains is analyzed through various methodological frameworks and practical implementations, highlighting its efficacy in dissecting complex customer datasets to generate actionable insights.\n\nAI-driven customer segmentation leverages machine learning algorithms and advanced analytics to process and interpret vast quantities of customer data, facilitating a granular understanding of customer behaviors, preferences, and demographic characteristics. Traditional segmentation approaches, often limited by their reliance on static criteria and historical data, are significantly outperformed by AI methodologies which utilize dynamic, real-time data inputs. This dynamic capability allows for the development of more nuanced customer profiles, which in turn supports the creation of highly tailored marketing strategies.\n\nThe paper explores various AI techniques, including supervised and unsupervised learning models, clustering algorithms, and natural language processing (NLP), that are employed to dissect customer data. Supervised learning models, such as decision trees and neural networks, are particularly effective in predicting customer behaviors and preferences based on historical data. Unsupervised learning models, including k-means clustering and hierarchical clustering, are utilized to uncover hidden patterns and groupings within customer datasets. Furthermore, NLP techniques are instrumental in analyzing customer interactions and feedback, providing additional layers of insight into customer sentiment and preferences.\n\nCase studies of retail banking institutions that have successfully implemented AI-driven segmentation strategies illustrate the practical benefits of these technologies. These case studies highlight significant improvements in marketing effectiveness, evidenced by increased response rates to targeted campaigns and enhanced customer engagement. Additionally, the paper discusses the impact of AI on customer retention, emphasizing how predictive analytics can identify at-risk customers and inform retention strategies tailored to individual needs.\n\nThe challenges associated with implementing AI-driven customer segmentation are also examined. Issues such as data privacy, algorithmic bias, and the integration of AI systems with legacy banking infrastructure are discussed in detail. Addressing these challenges is crucial for ensuring the ethical and effective application of AI technologies in retail banking.\n\nThe paper concludes with a discussion on future trends in AI-driven customer segmentation and targeting, including the potential for integrating emerging technologies such as blockchain for enhanced data security and the evolving role of AI in personalizing banking experiences. As the banking sector continues to evolve, the role of AI in shaping marketing strategies and improving customer retention is expected to become increasingly significant.\n\nDownloads\n\nReferences\n\nJ. Smith and A. Brown, \"Machine Learning in Banking: An Overview of the Applications and Trends,\" IEEE Transactions on Neural Networks and Learning Systems, vol. 31, no. 4, pp. 1245-1256, April 2020.\n\nM. Patel, \"Data-Driven Customer Segmentation Using Clustering Techniques,\" Journal of Financial Data Science, vol. 7, no. 2, pp. 88-101, Summer 2021.\n\nL. Zhang, Q. Yang, and M. Liu, \"Applications of Neural Networks in Retail Banking: A Review,\" IEEE Access, vol. 9, pp. 30456-30465, 2021.\n\nA. Johnson and H. Kumar, \"AI and Customer Experience: A Case Study of Retail Banking,\" Proceedings of the IEEE Conference on Artificial Intelligence, pp. 1123-1131, 2022.\n\nS. Roberts et al., \"Unsupervised Learning Techniques for Customer Segmentation in Banking,\" International Journal of Data Science and Analytics, vol. 10, no. 3, pp. 211-225, March 2023.\n\nP. Lee and R. Chen, \"Natural Language Processing for Analyzing Customer Feedback in Banking,\" IEEE Transactions on Computational Social Systems, vol. 8, no. 5, pp. 1052-1063, October 2022.\n\nB. Williams and C. Zhang, \"K-Means Clustering for Market Segmentation: An Empirical Study,\" IEEE Transactions on Big Data, vol. 6, no. 1, pp. 30-41, February 2020.\n\nJ. Wilson and E. Turner, \"Hierarchical Clustering Approaches for Customer Profiling,\" Journal of Banking and Finance, vol. 45, pp. 67-79, January 2021.\n\nR. Harris, \"The Impact of AI on Marketing Strategies in Retail Banking,\" IEEE Transactions on Marketing, vol. 8, no. 2, pp. 150-162, August 2021.\n\nV. Clark and T. Davis, \"Evaluating the Effectiveness of AI-Driven Customer Retention Strategies,\" Journal of Financial Technology, vol. 12, no. 4, pp. 96-109, April 2023.\n\nK. Edwards and L. Murphy, \"Challenges in Integrating AI with Legacy Banking Systems,\" IEEE Transactions on Systems, Man, and Cybernetics, vol. 51, no. 6, pp. 4015-4024, June 2021.\n\nN. Anderson, \"Privacy and Security Considerations in AI-Driven Customer Segmentation,\" Proceedings of the IEEE International Conference on Data Privacy, pp. 58-64, 2022.\n\nD. Jackson and R. Brooks, \"Bias in AI Models for Financial Services: A Comprehensive Review,\" IEEE Transactions on Artificial Intelligence, vol. 7, no. 3, pp. 112-124, March 2021.\n\nH. Lee, \"Blockchain Integration for Enhanced Data Security in Banking,\" Journal of Financial Security, vol. 16, no. 2, pp. 85-99, June 2023.\n\nG. Roberts and A. Singh, \"Impact of AI on Customer Engagement in Retail Banking,\" IEEE Transactions on Customer Relations, vol. 9, no. 1, pp. 34-47, January 2022.\n\nC. Brown and M. White, \"Quantitative Benefits of AI-Driven Marketing Initiatives,\" Journal of Quantitative Finance, vol. 14, no. 3, pp. 201-214, May 2021.\n\nJ. Green and L. Adams, \"Future Trends in AI for Customer Segmentation,\" IEEE Transactions on Future Technologies, vol. 5, no. 4, pp. 250-261, October 2023.\n\nR. Williams and J. Harris, \"Emerging AI Technologies in Banking: Potential and Challenges,\" Proceedings of the IEEE Future Tech Conference, pp. 213-220, 2024.\n\nS. Thomas and H. Johnson, \"Regulatory and Compliance Concerns for AI in Banking,\" IEEE Transactions on Regulatory Technology, vol. 3, no. 2, pp. 132-144, April 2022.\n\nA. Patel and B. Morris, \"Innovations in AI-Driven Customer Targeting Strategies,\" Journal of Applied AI Research, vol. 19, no. 2, pp. 1\n\nPublished\n\nHow to Cite\n\nIssue\n\nSection\n\nLicense\n\nThis work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.\n\nLicense Terms\n\nOwnership and Licensing:\n\nAuthors of this research paper submitted to the journal owned and operated by The Science Brigade Group retain the copyright of their work while granting the journal certain rights. Authors maintain ownership of the copyright and have granted the journal a right of first publication. Simultaneously, authors agreed to license their research papers under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License.\n\nLicense Permissions:\n\nUnder the CC BY-NC-SA 4.0 License, others are permitted to share and adapt the work, as long as proper attribution is given to the authors and acknowledgement is made of the initial publication in the Journal. This license allows for the broad dissemination and utilization of research papers.\n\nAdditional Distribution Arrangements:\n\nAuthors are free to enter into separate contractual arrangements for the non-exclusive distribution of the journal's published version of the work. This may include posting the work to institutional repositories, publishing it in journals or books, or other forms of dissemination. In such cases, authors are requested to acknowledge the initial publication of the work in this Journal.\n\nOnline Posting:\n\nAuthors are encouraged to share their work online, including in institutional repositories, disciplinary repositories, or on their personal websites. This permission applies both prior to and during the submission process to the Journal. Online sharing enhances the visibility and accessibility of the research papers.\n\nResponsibility and Liability:\n\nAuthors are responsible for ensuring that their research papers do not infringe upon the copyright, privacy, or other rights of any third party. The Science Brigade Publishers disclaim any liability or responsibility for any copyright infringement or violation of third-party rights in the research papers.\n\nPlaudit\n\nLicense Terms\n\nOwnership and Licensing:\n\nAuthors of this research paper submitted to the Journal of Science & Technology retain the copyright of their work while granting the journal certain rights. Authors maintain ownership of the copyright and have granted the journal a right of first publication. Simultaneously, authors agreed to license their research papers under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License.\n\nLicense Permissions:\n\nUnder the CC BY-NC-SA 4.0 License, others are permitted to share and adapt the work, as long as proper attribution is given to the authors and acknowledgement is made of the initial publication in the Journal of Science & Technology. This license allows for the broad dissemination and utilization of research papers.\n\nAdditional Distribution Arrangements:\n\nAuthors are free to enter into separate contractual arrangements for the non-exclusive distribution of the journal's published version of the work. This may include posting the work to institutional repositories, publishing it in journals or books, or other forms of dissemination. In such cases, authors are requested to acknowledge the initial publication of the work in the Journal of Science & Technology.\n\nOnline Posting:\n\nAuthors are encouraged to share their work online, including in institutional repositories, disciplinary repositories, or on their personal websites. This permission applies both prior to and during the submission process to the Journal of Science & Technology. Online sharing enhances the visibility and accessibility of the research papers.\n\nResponsibility and Liability:\n\nAuthors are responsible for ensuring that their research papers do not infringe upon the copyright, privacy, or other rights of any third party. The Journal of Science & Technology and The Science Brigade Publishers disclaim any liability or responsibility for any copyright infringement or violation of third-party rights in the research papers.\n\nThe Journal of Science & Technology (JST) is a peer-reviewed, open-access journal that publishes original research articles, reviews, and short communications in all areas of science and technology. The journal welcomes submissions from all researchers, regardless of their geographic location or institutional affiliation.\n\nJournal of Science & Technology\nThe Science Brigade Publishers,\nA unit of Libertatem Media Private Limited\nF104, Anand Square, Tragad IOC Road, Chandkheda, Ahmedabad 382470\nWebsite - thesciencebrigade.com\nEmail - thesciencebrigade@gmail.com\nWhatsApp Support - Start Chat\n\n© Platform & Workflow by: Open Journal Systems\n\nCustomer Segmentation in Banking: Examples - Analytics Yogi : \nCustomer Segmentation in Banking: Examples\n\nEver wondered how some banks seem to know exactly what their customers need, almost before the customers do? They’re probably leveraging the power of customer segmentation. We all know how vital it is for any businesses including banks to truly understand their customers in today’s competitive landscape. And that’s where the magic of customer segmentation comes into play. It is enabling banks to dive deep into customer data and extract actionable insights, influencing everything from crafting personalized experiences to strategic decision making.\n\nIn this blog post, we’re going to learn about customer segmentation use cases in banking, showcasing how it’s going to impact product development, risk management, and customer acquisition. Machine learning is taking customer segmentation from ‘helpful’ to ‘indispensable,’ opening up new avenues and making the whole process smarter and more efficient. Whether you’re a product manager wanting to fine-tune your segmentation strategy or a data scientist curious about how machine learning is revolutionizing the banking industry, we will learn about key concepts related to customer segmentation.\n\nTable of Contents\n\nCustomer Segmentation Use Cases in Banking\n\nCustomer segmentation is an incredibly versatile tool and can aid in various business applications in the banking industry beyond personalizing the omnichannel experience. Machine learning algorithms can analyze vast and diverse datasets to identify patterns that may not be apparent to human analysts. This could include transactional data, demographic information, web browsing behavior, social media activity, customer service interactions, and more. By effectively utilizing ML, banks can understand their customers in much more nuanced ways and form more precise segments. The following represents some key use cases of customer segmentation in banking:\n\nHere are a few examples of how customer segmentation can leverage machine learning for different use cases in banking:\n\nConclusion\n\nIn an era where data is abundant and technology continues to advance at lightning speed, banks must leverage tools like machine learning and customer segmentation to stay competitive and customer-focused. From product development to risk management, these techniques provide a powerful means to understand and address diverse customer needs, tailor experiences, and drive overall business performance.\n\nBanks that successfully employ ML-driven customer segmentation will have the distinct advantage of being able to anticipate customer needs, create personalized offerings, and build stronger, more profitable relationships. In this landscape, the question isn’t whether banks should adopt machine learning and customer segmentation – it’s how fast they can adapt and innovate using these tools.\n\nChatGPT Prompts (250+)\n\nRecent Posts\n\nData Science / AI Trends\n\nFree Online Tools\n\nMore...\n\nNewsletter\n\nTag Cloud\n\nRecent Comments\n\nI found it very helpful. However the differences are not too understandable for me\n\nVery Nice Explaination. Thankyiu very much,\n\nin your case E respresent Member or Oraganization which include on e or more peers?\n\nSuch a informative post. Keep it up\n\nThank you....for your support. you given a good solution for me.\n",
        "Machine learning models employed in economic trend impact analysis": "Machine learning forecasting in the macroeconomic environment: the case ... : \nYour privacy, your choice\n\nWe use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media.\n\nBy accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection.\n\nSee our privacy policy for more information on the use of your personal data.\n\nManage preferences for further information and to change your choices.\n\nMachine learning forecasting in the macroeconomic environment: the case of the US output gap\n\n198 Accesses\n\n1 Citation\n\nExplore all metrics\n\nAbstract\n\nThis paper aims to forecast deviations of the US output measured by the industrial production index (IPI), from its long-run potential output, known as output gaps. These gaps are important for policymakers when designing relevant economic policies, especially when a negative output gap may show economic slack or underperformance, often associated with higher unemployment and low inflation. We use a dataset that includes 32 explanatory economic and financial variables and 18 lags of the IPI, spanning the period from 2000:1 to 2022:12, resulting in 50 variables and 276 monthly observations. The dataset is fed to five well-established machine learning (ML) methods, namely decision trees, random forests, XGBoost, long short-term memory (LSTM) and support vector machines (SVMs), coupled with the linear, the RBF and the polynomial kernel. Moreover, we use the standard elastic net logit method from the area of econometrics as a benchmark. Our results indicate that the tree-based ML techniques perform better in-sample, and the best overall forecasting model is the XGBoost achieving an out-of-sample accuracy of 91.67%.\n\nThis is a preview of subscription content, log in via an institution to check access.\n\nAccess this article\n\nSubscribe and save\n\nBuy Now\n\nPrice includes VAT (Lebanon)\n\nInstant access to the full article PDF.\n\nInstitutional subscriptions\n\nSimilar content being viewed by others\n\nMachine Learning in Macroeconomics: Application to DSGE Models\n\nBenchmark Analysis of Machine Learning Methods to Forecast the U.S. Annual Inflation Rate During a High-Decile Inflation Period\n\nOpening the Black Box: Machine Learning Interpretability and Inference Tools with an Application to Economic Forecasting\n\nExplore related subjects\n\nNotes\n\nKiley (2013) discusses three alternative definitions of the output gap: “the deviation of output from its long-run stochastic trend (i.e., the “Beveridge–Nelson cycle”); the deviation of output from the level consistent with current technologies and normal utilization of capital and labor input (i.e., the “production-function approach”); and the deviation of output from “flexible-price” output (i.e., its “natural rate”), page 1.\n\nOkun's law is an empirically observed relationship between unemployment and negative changes in output. According to this empirical relationship, a 1% increase in unemployment can be related to a 2% decrease in GDP, Ball et al (2017). Nevertheless, there are doubts for this empirical relationship, Lee (2000).\n\nReferences\n\nAguiar M, Gopinath G (2007) Emerging market business cycles: the cycle is the trend. J Polit Econ 115(1):69–102\n\nArticle\n  Google Scholar\n\nAlthnian A, AlSaeed D, Al-Baity H, Samha A, Dris AB, Alzakari N, Abou Elwafa A, Kurdi H (2021) Impact of dataset size on classification performance: an empirical evaluation in the medical domain. Appl Sci 11(2):796\n\nArticle\n  Google Scholar\n\nAraujo D, Pereira AM, Simões M (2020) Predicting the output gap: a comparison of machine learning models and economic techniques. J Appl Econ 23(1):47–64\n\nGoogle Scholar\n\nAssunção JB, Fernandes PA (2024) A robust method to date recessions and compute output gaps: the Portuguese case. Port Econ. https://doi.org/10.1007/s10258-024-00259-4\n\nArticle\n  Google Scholar\n\nBall L, Leigh D, Loungani P (2017) Okun’s law: Fit at 50? J Money Credit Bank 49(7):1413–1441\n\nArticle\n  Google Scholar\n\nBarigozzi M, Luciani M (2023) Measuring the output gap using large datasets. Rev Econ Stat 105(6):1500–1514\n\nArticle\n  Google Scholar\n\nBerger T, Kempa B (2011) Bayesian estimation of the output gap for a small open economy: The case of Canada. Econ Lett 112(1):107–112\n\nArticle\n  Google Scholar\n\nBerger T, Morley J, Wong B (2023) Nowcasting the output gap. J Econom 232(1):18–34\n\nArticle\n  Google Scholar\n\nBernhardsen T, Eitrheim Ø, Jore AS, Røisland Ø (2005) Real-time data for Norway: challenges for monetary policy. N Am J Econ Finance 16(3):333–349\n\nArticle\n  Google Scholar\n\nBlanchard O, Amighini A, Giavazzi F (2010) Macroeconomics: a European PERSPECTIVE. Pearson Education\n\nGoogle Scholar\n\nBreiman L (1996) Bagging predictors. Mach Learn 24(2):123–140\n\nArticle\n  Google Scholar\n\nBreiman L (2001) Random forests. Mach Learn 45:5–32\n\nArticle\n  Google Scholar\n\nBreiman L, Friedman JH, Olshen RA, Stone CJ (1984) Classification and regression trees. Wadsworth. Inc., Monterey, California, USA\n\nGoogle Scholar\n\nCamba-Mendez G, Rodriguez-Palenzuela D (2003) Assessment criteria for output gap estimates. Econ Model 20(3):529–562\n\nArticle\n  Google Scholar\n\nCampbell JY, Pflueger C, Viceira LM (2020) Macroeconomic drivers of bond and equity risks. J Polit Econ 128(8):3148–3185\n\nArticle\n  Google Scholar\n\nCayen JP, Van Norden S (2005) The reliability of Canadian output-gap estimates. N Am J Econ Finance 16(3):373–393\n\nArticle\n  Google Scholar\n\nChen T, Guestrin C (2016) Xgboost: a scalable tree boosting system. In: Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, pp 785–794\n\nChen X, Ishwaran H (2012) Random forests for genomic data analysis. Genomics 99(6):323–329\n\nArticle\n  Google Scholar\n\nCicceri G, Inserra G, Limosani M (2020) A machine learning approach to forecast economic recessions—an Italian case study. Mathematics 8(2):241\n\nArticle\n  Google Scholar\n\nCortes C, Vapnik V (1995) Support-vector networks. Mach Learn 20(3):273–297\n\nArticle\n  Google Scholar\n\nDou B, Zhu Z, Merkurjev E, Ke L, Chen L, Jiang J, Zhu Y, Liu J, Zhang B, Wei GW (2023) Machine learning methods for small data challenges in molecular science. Chem Rev 123(13):8736–8780\n\nArticle\n  Google Scholar\n\nDubbert T, Kempa B (2024) Nowcasting the output gap with shadow rates. Econ Lett 236:111583\n\nArticle\n  Google Scholar\n\nDupasquier C, Guay A, St-Amant P (1999) A survey of alternative methodologies for estimating potential output and the output gap. J Macroecon 21(3):577–595\n\nArticle\n  Google Scholar\n\nGogas P, Papadimitriou T (2021) Machine learning in economics and finance. Comput Econ 57:1–4\n\nArticle\n  Google Scholar\n\nGogas P, Papadimitriou T, Chrysanthidou E (2015) Yield curve point triplets in recession forecasting. Int Finance 18(2):207–226\n\nArticle\n  Google Scholar\n\nGogas P, Papadimitriou T, Matthaiou M, Chrysanthidou E (2014) Yield curve and recession forecasting in a machine learning framework. Comput Econ 45(4):635–645\n\nArticle\n  Google Scholar\n\nGogas P, Papadimitriou T, Sofianos E (2019) Money neutrality, monetary aggregates and machine learning. Algorithms 12(7):137\n\nArticle\n  Google Scholar\n\nGogas P, Papadimitriou T, Sofianos E (2021) Forecasting unemployment in the euro area with machine learning. J Forecast 41(3):551–566\n\nArticle\n  Google Scholar\n\nGranados C, Parra-Amado D (2024) Estimating the output gap after COVID: how to address unprecedented macroeconomic variations. Econ Model 135:106711\n\nArticle\n  Google Scholar\n\nHaider A, Safdar Ullah K (2008) Estimating output gap for Pakistan economy: structural and statistical approaches (working paper)\n\nHauzenberger N, Huber F, Klieber K (2023) Real-time inflation forecasting using non-linear dimension reduction techniques. Int J Forecast 39(2):901–921\n\nArticle\n  Google Scholar\n\nHochreiter S, Schmidhuber J (1997) Long short-term memory. Neural Comput 9(8):1735–1780\n\nArticle\n  Google Scholar\n\nHodrick R, Prescott E (1997) Postwar US business cycles: an empirical investigation. J Money Credit Bank 29(1):1\n\nArticle\n  Google Scholar\n\nJašová M, Moessner R, Takáts E (2020) Domestic and global output gaps as inflation drivers: What does the Phillips curve tell? Econ Model 87:238–253\n\nArticle\n  Google Scholar\n\nKatris C (2019) Prediction of unemployment rates with time series and Machine Learning Techniques. Comput Econ 55(2):673–706\n\nArticle\n  Google Scholar\n\nKiley MT (2013) Output gaps. J Macroecon 37:1–18\n\nArticle\n  Google Scholar\n\nKokol P, Kokol M, Zagoranski S (2022) Machine learning on small size samples: a synthetic knowledge synthesis. Sci Prog. https://doi.org/10.1177/00368504211029777\n\nArticle\n  Google Scholar\n\nLee J (2000) The robustness of Okun’s law: Evidence from OECD countries. J Macroecon 22(2):331–356\n\nArticle\n  Google Scholar\n\nMarcellino M, Musso A (2011) The reliability of real-time estimates of the euro area output gap. Econ Model 28(4):1842–1856\n\nArticle\n  Google Scholar\n\nMorley J, Wong B (2020) Estimating and accounting for the output gap with large Bayesian vector autoregressions. J Appl Economet 35(1):1–18\n\nArticle\n  Google Scholar\n\nMouchtaris D, Sofianos E, Gogas P, Papadimitriou T (2021) Forecasting natural gas spot prices with machine learning. Energies 14(18):5782\n\nArticle\n  Google Scholar\n\nOkun AM (1963) Potential GNP: its measurement and significance. Cowles Foundation for Research in Economics at Yale University\n\nOrphanides A (2001) Monetary policy rules based on real-time data. Am Econ Rev 91(4):964–985\n\nArticle\n  Google Scholar\n\nOrphanides A, Van Norden S (2002) The unreliability of output-gap estimates in real time. Rev Econ Stat 84(4):569–583\n\nArticle\n  Google Scholar\n\nPérez-Pons M, Parra-Dominguez J, Omatu S, Herrera-Viedma E, Corchado J (2021) Machine learning and traditional econometric models: a systematic mapping study. J Artif Intell Soft Comput Res 12(2):79–100\n\nArticle\n  Google Scholar\n\nPhillips AW (1958) The relation between unemployment and the rate of change of money wage rates in the United Kingdom, 1861–1957. Economica 25(100):283–299\n\nGoogle Scholar\n\nQuast J, Wolters MH (2022) Reliable real-time output gap estimates based on a modified Hamilton filter. J Bus Econ Stat 40(1):152–168\n\nArticle\n  Google Scholar\n\nRussell SJ, Norvig P (2016) Artificial intelligence: a modern approach. Pearson\n\nSofianos E, Gogas P, Papadimitriou T (2021) Mind the gap: Forecasting euro-area output gaps with machine learning. Appl Econ Lett 29(19):1824–1828\n\nArticle\n  Google Scholar\n\nSofianos E, Zaganidis E, Papadimitriou T, Gogas P (2024) Forecasting east and west coast gasoline prices with tree-based machine learning algorithms. Energies 17(6):1296\n\nArticle\n  Google Scholar\n\nXu P, Ji X, Li M, Lu W (2023) Small data machine learning in materials science. Npj Comput Mater. https://doi.org/10.1038/s41524-023-01000-z\n\nArticle\n  Google Scholar\n\nYoon J (2020) Forecasting of real GDP growth using machine learning models: gradient boosting and Random Forest approach. Comput Econ 57(1):247–265\n\nArticle\n  Google Scholar\n\nZou H, Hastie T (2005) Regularization and variable selection via the elastic net. J R Stat Soc Ser B (Stat Methodol) 67(2):301–320\n\nArticle\n  Google Scholar\n\nZhou S (2022) An analysis of the small sample datasets based on machine learning. In: Proceedings of the 2022 6th international conference on electronic information technology and computer engineering, vol 11, pp 1654–1658\n\nDownload references\n\nFunding\n\nThe first author would like to acknowledge that this work is part of the Interdisciplinary Thematic Institute MAKErS of the ITI 2021–2028 program of the University of Strasbourg, CNRS and INSERM. It has received financial support from the IdEx Unistra (ANR-10-IDEX-0002), and from the “Programme Investissement d'Avenir” as part of the SFRI-STRAT'US project(s) (ANR-20-SFRI-0012).\n\nAuthor information\n\nAuthors and Affiliations\n\nBureau d’Economie Théorique et Appliquée (ΒΕΤΑ), University of Strasbourg, University of Lorraine, CNRS, 67000, Strasbourg, France\n\nEmmanouil Sofianos\n\nDepartment of Finance and Accounting, Rennes School of Business, 2 Rue Robert d’Arbrissel, 35065, Rennes, France\n\nChristos Alexakis\n\nDepartment of Economics, Democritus University of Thrace, Komotini, Greece\n\nPeriklis Gogas & Theophilos Papadimitriou\n\nCorresponding author\n\nCorrespondence to Christos Alexakis.\n\nEthics declarations\n\nConflict of interest\n\nThe authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.\n\nAdditional information\n\nPublisher's Note\n\nSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\n\nAppendix\n\nAppendix\n\nTables 3 and 4 and Figs. 3, 4, 5, 6, 7, 8, 9 and 10.\n\nROC curve for the optimal SVM model coupled with the linear kernel (out of sample)\n\nROC curve for the optimal SVM model coupled with the RBF kernel (out of sample)\n\nROC curve for the optimal SVM model coupled with the polynomial kernel (out-of-sample)\n\nROC curve for the optimal decision tree model (out of sample)\n\nROC curve for the optimal random forest model (out of sample)\n\nROC curve for the optimal XGBoost model (out of sample)\n\nROC curve for the optimal LSTM model (out-of-sample)\n\nROC curve for the optimal elastic net logit model (out-of-sample)\n\nRights and permissions\n\nSpringer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law.\n\nReprints and permissions\n\nAbout this article\n\nCite this article\n\nSofianos, E., Alexakis, C., Gogas, P. et al. Machine learning forecasting in the macroeconomic environment: the case of the US output gap. Econ Change Restruct 58, 9 (2025). https://doi.org/10.1007/s10644-024-09849-w\n\nDownload citation\n\nReceived\n23 April 2024\n\nAccepted\n26 December 2024\n\nPublished\n09 January 2025\n\nDOI\nhttps://doi.org/10.1007/s10644-024-09849-w\n\nKeywords\n\nJEL Classification\n\nDiscover content\n\nPublish with us\n\nProducts and services\n\nOur brands\n\n178.135.19.63\n\nNot affiliated\n\n© 2025 Springer Nature\n\nThe Intersection of Artificial Intelligence and Economic Forecasting ... : \nThe Intersection of Artificial Intelligence and Economic Forecasting Transforming Financial Models for Greater Predictive Accuracy\n\nArticle Sidebar\n\nMain Article Content\n\nAbstract\n\nThis paper examines how four AI subfields machine learning, deep learning, and natural language processing are enhancing the field of economic forecasting by providing new forms of insight and more flexibility in economic trend analysis. AI in economic forecasting is disrupting economic models, and its impact provides more precision over traditional financial models. New challenges arise with complexity in the global economy where traditional theories and structures remain ineffective in the fast delivery of data to equip economists with the relevant information on the state of the economy. The features of the main algorithms used in machine learning and natural language processing are compared and evaluated in view of their possibilities for handling extensive data and predicting economic tendencies and values. This research indicates the implementation of AI and the uses for AI in economic modeling, as well as the issues that may arise, such as data protection and model explainability. The evidence suggests the use of AI in enhancing the precision and flexibility of various economic forecasting models. AI provided stakeholders with a useful and reliable strategy for forecasting economic changes, market trends, and the critical issues within specific industries. It sees that incorporating AI in economic forecasting is possible and does offer transformative benefits, given that, though not only seasoned with ethical dilemmas and data management issues, it does provide a more solid and stronger form-based decision-making in a fast-changing economic environment.\n\nArticle Details\n\nScopus Link\n\nMake a Submission\n\nImp Links\n\nHome\n\nCurrent Issue\n\nArchive\n\nGuide for Authors\n\nJournal Ethics & Policies\n\nEditorial Board\n\nIndexing\n\nDownloads\n\nCopyright Form\nPaper Template\n\n© Library Progress International\n\neISSN: 2320-317X\npISSN: 0970-1052\n"
    },
    "AnalyzedArticles": {
        "Machine learning models employed in bankruptcy prediction": {
            "Article_Summary": "The research focuses on bankruptcy prediction using machine learning techniques, specifically analyzing financial distress in companies. The study uses a comprehensive dataset of 21,114 U.S. firms from 1970-2020, covering 57 financial ratios. The primary goal is to develop accurate predictive models for identifying potential corporate bankruptcies, with a special emphasis on understanding bankruptcy risks during the COVID-19 recession.",
            "ML_Models": "XGBoost, Support Vector Machines (SVM), Random Forest"
        },
        "Machine learning models employed in financial performance optimization": {
            "Article_Summary": "The articles discuss the integration of machine learning and AI techniques in financial forecasting and engineering, focusing on advanced predictive models that can adapt to complex market dynamics. The research highlights how machine learning methods like neural networks, reinforcement learning, and natural language processing can enhance financial prediction accuracy by processing large, diverse datasets and uncovering hidden patterns.",
            "ML_Models": "Deep Neural Networks, Reinforcement Learning Models, Natural Language Processing Models"
        },
        "Machine learning models employed in customer banking product targeting": {
            "Article_Summary": "The articles discuss AI-driven customer segmentation in retail banking, focusing on using machine learning to analyze complex customer datasets for more precise targeting, personalized marketing strategies, and improved customer retention. The approach involves processing real-time customer data to create dynamic customer profiles and predictive insights.",
            "ML_Models": "Neural Networks, Natural Language Processing (NLP), Hierarchical Clustering"
        },
        "Machine learning models employed in economic trend impact analysis": {
            "Article_Summary": "The research focuses on using machine learning techniques to forecast the US output gap, which represents deviations of industrial production from its long-run potential output. The study uses a comprehensive dataset of 32 economic and financial variables spanning from 2000 to 2022, demonstrating the application of ML models in macroeconomic forecasting. The research highlights the importance of output gap predictions for policymakers in understanding economic performance, unemployment, and inflation trends.",
            "ML_Models": "XGBoost, Support Vector Machines (SVM) with linear/RBF/polynomial kernels, Long Short-Term Memory (LSTM)"
        }
    },
    "Relationship": {
        "Machine learning models employed in bankruptcy prediction": [
            "The bankruptcy prediction models (XGBoost, SVM, Random Forest) directly align with the 'data' table which contains extensive financial indicators and the 'Bankrupt?' target variable. These models can analyze financial ratios, profitability metrics, and leverage indicators to predict company bankruptcy risk."
        ],
        "Machine learning models employed in financial performance optimization": [
            "The financial performance optimization ML models (XGBoost, SVMs, Decision Trees, Ensemble Methods) can analyze the extensive financial ratios in the 'data' table to predict bankruptcy risk and identify key performance indicators. These models can process the numerous financial metrics to find patterns that correlate with financial success or failure, enabling proactive management decisions."
        ],
        "Machine learning models employed in customer banking product targeting": [
            "The banking dataset contains customer demographic information, contact details, economic indicators, and campaign outcomes that are ideal for customer targeting models. The ML models (Random Forest, Logistic Regression, K-Means Clustering, Naive Bayes) can analyze patterns in customer attributes and previous campaign responses to predict which customers are most likely to accept specific banking products, optimizing marketing efforts and increasing conversion rates."
        ],
        "Machine learning models employed in economic trend impact analysis": [
            "The ML models (XGBoost, SVM, LSTM) are well-suited for analyzing how economic trends impact financial performance. The data table contains bankruptcy indicators and financial ratios, while the banking table includes economic indicators. These models can establish relationships between macroeconomic factors and company financial health to predict bankruptcy risk based on economic conditions."
        ]
    },
    "Needs": {
        "Machine learning models employed in bankruptcy prediction": [
            "For bankruptcy prediction, we need numerical financial indicators as features and the 'Bankrupt?' column as the binary target variable (0/1). The ML models (XGBoost, SVM, Random Forest) will perform classification to determine bankruptcy risk. Financial ratios like ROA, debt ratios, and cash flow metrics will be normalized before training. The models will output probability scores indicating likelihood of bankruptcy, with performance evaluated using metrics like precision, recall, and AUC."
        ],
        "Machine learning models employed in financial performance optimization": [
            "For financial performance optimization, we need numerical data from the financial ratios to train classification and regression models. The 'Bankrupt?' column serves as the target variable for classification models predicting bankruptcy risk. The financial ratios provide features for both classification and regression tasks. XGBoost and ensemble methods require normalized numerical data and can handle the various financial metrics to identify patterns that predict performance outcomes. The models will need to be trained on historical data with known outcomes to learn which combinations of financial indicators are most predictive of success or failure."
        ],
        "Machine learning models employed in customer banking product targeting": [
            "For customer banking product targeting, we need categorical features (job, marital, education) that will require encoding, and numerical features (age, duration, economic indicators) that may need scaling. The target variable 'y' indicates whether a customer subscribed to a product, making this a binary classification problem. The models will be trained to predict the likelihood of a customer accepting an offer based on their profile and economic conditions, requiring both feature engineering of demographic data and proper handling of campaign history variables."
        ],
        "Machine learning models employed in economic trend impact analysis": [
            "For economic trend impact analysis, we need numerical features from both tables. The financial indicators from the data table will serve as target variables or dependent features, while the economic indicators from the banking table will be independent variables. XGBoost and SVM will be used for classification (predicting bankruptcy) and regression (predicting financial ratios), requiring normalized numerical inputs. LSTM networks will analyze time-series patterns in both economic indicators and financial performance, requiring sequential data with consistent time intervals. The models will need to be trained on historical data where economic changes can be correlated with subsequent financial outcomes."
        ]
    },
    "ModelsPerTopic": {
        "Machine learning models employed in bankruptcy prediction": "XGBoost, Support Vector Machines (SVM), Random Forest",
        "Machine learning models employed in financial performance optimization": "Deep Neural Networks, Reinforcement Learning Models, Natural Language Processing Models",
        "Machine learning models employed in customer banking product targeting": "Neural Networks, Natural Language Processing (NLP), Hierarchical Clustering",
        "Machine learning models employed in economic trend impact analysis": "XGBoost, Support Vector Machines (SVM) with linear/RBF/polynomial kernels, Long Short-Term Memory (LSTM)"
    },
    "ML_Models1": [
        "Random Forest, Gradient Boosting, Neural Networks, Logistic Regression",
        "XGBoost, Support Vector Machines, Decision Trees, Ensemble Methods",
        "Random Forest, Logistic Regression, K-Means Clustering, Naive Bayes",
        "Time Series Models, LSTM Networks, Prophet, Regression Models"
    ],
    "GPT_Columns": {
        "Machine learning models employed in bankruptcy prediction": [
            [
                {
                    "data": [
                        "Bankrupt?",
                        "ROA(C) before interest and depreciation before interest",
                        "Debt ratio %",
                        "Cash flow rate",
                        "Total debt/Total net worth",
                        "Net Income to Total Assets",
                        "Operating Profit Rate"
                    ]
                }
            ]
        ],
        "Machine learning models employed in financial performance optimization": [
            [
                {
                    "data": [
                        "Bankrupt?",
                        "ROA(C) before interest and depreciation before interest",
                        "Operating Profit Rate",
                        "Cash flow rate",
                        "Debt ratio %",
                        "Net worth/Assets",
                        "Total Asset Turnover",
                        "Working Capital to Total Assets"
                    ]
                }
            ]
        ],
        "Machine learning models employed in customer banking product targeting": [
            [
                {
                    "banking": [
                        "age",
                        "job",
                        "marital",
                        "education",
                        "housing",
                        "loan",
                        "duration",
                        "campaign",
                        "previous",
                        "poutcome",
                        "emp_var_rate",
                        "cons_conf_idx",
                        "euribor3m",
                        "y"
                    ]
                }
            ]
        ],
        "Machine learning models employed in economic trend impact analysis": [
            [
                {
                    "data": [
                        "Bankrupt?",
                        "ROA(C) before interest and depreciation before interest",
                        "Cash flow rate",
                        "Total debt/Total net worth",
                        "Debt ratio %",
                        "Net Income to Total Assets",
                        "Liability to Equity"
                    ]
                },
                {
                    "banking": [
                        "emp_var_rate",
                        "cons_price_idx",
                        "cons_conf_idx",
                        "euribor3m",
                        "nr_employed",
                        "y",
                        "duration"
                    ]
                }
            ]
        ]
    },
    "AdjustedColumns": {}
}