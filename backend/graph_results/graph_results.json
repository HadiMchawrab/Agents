{
    "tables": [
        {
            "data": [
                "Bankrupt?",
                " ROA(C) before interest and depreciation before interest",
                " ROA(A) before interest and % after tax",
                " ROA(B) before interest and depreciation after tax",
                " Operating Gross Margin",
                " Realized Sales Gross Margin",
                " Operating Profit Rate",
                " Pre-tax net Interest Rate",
                " After-tax net Interest Rate",
                " Non-industry income and expenditure/revenue",
                " Continuous interest rate (after tax)",
                " Operating Expense Rate",
                " Research and development expense rate",
                " Cash flow rate",
                " Interest-bearing debt interest rate",
                " Tax rate (A)",
                " Net Value Per Share (B)",
                " Net Value Per Share (A)",
                " Net Value Per Share (C)",
                " Persistent EPS in the Last Four Seasons",
                " Cash Flow Per Share",
                " Revenue Per Share (Yuan ¥)",
                " Operating Profit Per Share (Yuan ¥)",
                " Per Share Net profit before tax (Yuan ¥)",
                " Realized Sales Gross Profit Growth Rate",
                " Operating Profit Growth Rate",
                " After-tax Net Profit Growth Rate",
                " Regular Net Profit Growth Rate",
                " Continuous Net Profit Growth Rate",
                " Total Asset Growth Rate",
                " Net Value Growth Rate",
                " Total Asset Return Growth Rate Ratio",
                " Cash Reinvestment %",
                " Current Ratio",
                " Quick Ratio",
                " Interest Expense Ratio",
                " Total debt/Total net worth",
                " Debt ratio %",
                " Net worth/Assets",
                " Long-term fund suitability ratio (A)",
                " Borrowing dependency",
                " Contingent liabilities/Net worth",
                " Operating profit/Paid-in capital",
                " Net profit before tax/Paid-in capital",
                " Inventory and accounts receivable/Net value",
                " Total Asset Turnover",
                " Accounts Receivable Turnover",
                " Average Collection Days",
                " Inventory Turnover Rate (times)",
                " Fixed Assets Turnover Frequency",
                " Net Worth Turnover Rate (times)",
                " Revenue per person",
                " Operating profit per person",
                " Allocation rate per person",
                " Working Capital to Total Assets",
                " Quick Assets/Total Assets",
                " Current Assets/Total Assets",
                " Cash/Total Assets",
                " Quick Assets/Current Liability",
                " Cash/Current Liability",
                " Current Liability to Assets",
                " Operating Funds to Liability",
                " Inventory/Working Capital",
                " Inventory/Current Liability",
                " Current Liabilities/Liability",
                " Working Capital/Equity",
                " Current Liabilities/Equity",
                " Long-term Liability to Current Assets",
                " Retained Earnings to Total Assets",
                " Total income/Total expense",
                " Total expense/Assets",
                " Current Asset Turnover Rate",
                " Quick Asset Turnover Rate",
                " Working capitcal Turnover Rate",
                " Cash Turnover Rate",
                " Cash Flow to Sales",
                " Fixed Assets to Assets",
                " Current Liability to Liability",
                " Current Liability to Equity",
                " Equity to Long-term Liability",
                " Cash Flow to Total Assets",
                " Cash Flow to Liability",
                " CFO to Assets",
                " Cash Flow to Equity",
                " Current Liability to Current Assets",
                " Liability-Assets Flag",
                " Net Income to Total Assets",
                " Total assets to GNP price",
                " No-credit Interval",
                " Gross Profit to Sales",
                " Net Income to Stockholder's Equity",
                " Liability to Equity",
                " Degree of Financial Leverage (DFL)",
                " Interest Coverage Ratio (Interest expense to EBIT)",
                " Net Income Flag",
                " Equity to Liability"
            ]
        },
        {
            "banking": [
                "age",
                "job",
                "marital",
                "education",
                "default",
                "housing",
                "loan",
                "contact",
                "month",
                "day_of_week",
                "duration",
                "campaign",
                "pdays",
                "previous",
                "poutcome",
                "emp_var_rate",
                "cons_price_idx",
                "cons_conf_idx",
                "euribor3m",
                "nr_employed",
                "y"
            ]
        }
    ],
    "analyzed_topics": [
        {
            "topic": "Machine learning models employed in bankruptcy prediction",
            "ML_Models": "Random Forest, Gradient Boosting, Neural Networks, Logistic Regression",
            "reasoning": "The 'Bankrupt?' column suggests this dataset is for bankruptcy prediction. Financial ratios like ROA, debt ratios, and cash flow metrics are strong predictors. ML models can analyze these financial indicators to identify patterns that precede bankruptcy, helping companies take preventive measures."
        },
        {
            "topic": "Machine learning models employed in financial performance optimization",
            "ML_Models": "XGBoost, Support Vector Machines, Decision Trees, Ensemble Methods",
            "reasoning": "The extensive financial ratios (ROA, operating margins, growth rates) can be used to predict and optimize company performance. ML models can identify which financial metrics most strongly correlate with success, helping management focus on key performance indicators."
        },
        {
            "topic": "Machine learning models employed in customer banking product targeting",
            "ML_Models": "Random Forest, Logistic Regression, K-Means Clustering, Naive Bayes",
            "reasoning": "The banking table contains demographic data (age, job, education) and previous campaign results, ideal for predicting which customers are likely to accept offers. ML models can optimize marketing campaigns by targeting the right customers with appropriate financial products."
        },
        {
            "topic": "Machine learning models employed in economic trend impact analysis",
            "ML_Models": "Time Series Models, LSTM Networks, Regression Analysis, Prophet",
            "reasoning": "The banking table includes economic indicators (emp_var_rate, cons_price_idx, euribor3m) that can be analyzed alongside company financial data to predict how macroeconomic trends affect business performance and bankruptcy risk, enabling proactive strategic adjustments."
        }
    ],
    "csv_files": [
        "csv_test/data.csv",
        "csv_test/banking.csv"
    ],
    "topic": [
        "Machine learning models employed in bankruptcy prediction",
        "Machine learning models employed in financial performance optimization",
        "Machine learning models employed in customer banking product targeting",
        "Machine learning models employed in economic trend impact analysis"
    ],
    "ScrapedArticles": {
        "Machine learning models employed in bankruptcy prediction": "Bankruptcy prediction using machine learning and an application to the ... : \nData Science in Finance and Economics\n\nData Science in Finance and Economics\n\nBankruptcy prediction using machine learning and an application to the case of the COVID-19 recession\n\nJEL Codes: O30, E37, E60\n\nAbstract\n\nBankruptcy prediction is an important problem in finance, since successful predictions would allow stakeholders to take early actions to limit their economic losses. In recent years many studies have explored the application of machine learning models to bankruptcy prediction with financial ratios as predictors. This study extends this research by applying machine learning techniques to a quarterly data set covering financial ratios for a large sample of public U.S. firms from 1970–2019. We find that tree-based ensemble methods, especially XGBoost, can achieve a high degree of accuracy in out-of-sample bankruptcy prediction. We next apply our best model, using XGBoost, to the problem of predicting the overall bankruptcy rate in USA in the second half of 2020, after the COVID-19 pandemic had necessitated a lockdown, leading to a deep recession. Our model supports the prediction, made by leading economists, that the rate of bankruptcies will rise substantially in 2020, but it also suggests that this elevated level will not be much higher than 2010.\n\n1.   Introduction\n\nBankruptcy prediction is the problem of detecting financial distress in businesses which will lead to eventual bankruptcy. Bankruptcy prediction has been studied since at least 1930s. The early models of bankruptcy prediction employed univariate statistical models over financial ratios. The univariate models were followed by multi-variate statistical models such as the famous Altman Z-score model. The recent advances in the field of Machine learning have led to the adoption of Machine learning algorithms for bankruptcy prediction. Machine Learning methods are increasingly being used for bankruptcy prediction using financial ratios. A study by Barboza, Kimura and Altman found that Machine Learning models can outperform classical statistical models like multiple discriminant analysis (MDA) by a significant margin in bankruptcy prediction (Barboza et al., 2017).\n\nBankruptcy prediction is an important for modern economies because early warnings of bankrupt help not only the investor but also public policy makers to take proactive steps to minimize the impact of bankruptcies. The reasons that add to the significance of bankruptcy prediction are as follows:\n\n(1). Better allocation of resources\n\nInstitutional investors, banks, lenders, retail investors are always looking at information that predicts financial distress in publicly traded firms. Early prediction of bankruptcy helps not only the investors and lenders but also the managers of a firm to take corrective action thereby conserving scare economic resources. Efficient allocation of capital is the cornerstone of growth in modern economies.\n\n(2). Input to policy makers\n\nAccurate prediction of bankruptcies of businesses and individuals before they happen gives law makers and policy makers some additional time to alleviate systemic issues that might be causing the bankruptcies. Indeed, with bankruptcies taking center stage in political discourse of many countries, the accurate prediction of bankruptcy is a key input for politicians, bureaucrats and in general for anyone who is making public policy.\n\n(3). Corrective action for business managers\n\nThe early prediction of bankruptcy is likely to highlight business issues thereby giving the company's manager additional time to make decisions that will help avoid bankruptcy. This effect is likely to be more profound in public companies where the management has a fiduciary duty to the shareholders.\n\n(4). Identification of sector wide problems\n\nBankruptcy prediction models that flag firms belonging to a certain sector are likely to be a leading indicator of an upcoming downturn in a certain sector of an economy. With robust models, the business managers and government policy makers would become aware and take corrective action to limit the magnitude and intensity of the downturn in the specific sector. Industry groups in turn has been shown to significantly effect forecasting models (Chava and Jarrow, 2004).\n\n(5). Signal to Investors\n\nInvestors can make better and more informed decisions based on the prediction of bankruptcy models. This not only forces the management of firms to take corrective action but also helps to soften the overall economic fallout that results from the bankruptcies. Empirical studies have shown that investment opportunities are significantly related to likelihood of bankruptcy (Lyandres & Zhdanov, 2007).\n\n(6). Relation to adjacent problems\n\nBankruptcy prediction is often the first step used by ratings agencies to detect financial distress in firms. Based on the predictions of bankruptcy models, ratings agencies investigate and assess credit risk. Getting flagged by bankruptcy prediction models is often the first step that triggers the process of revising credit ratings. A literature survey covering 2000–2013 demonstrates the close relation between bankruptcy prediction and credit risk (García et al., 2015).\n\nMost past studies in bankruptcy prediction including those using Machine Learning have used a relatively small sample of firms and a small number of financial ratios. This study distinguishes itself by using a much larger dataset having data for 21,114 U.S. firms (samples) and 57 financial ratios (features). Our dataset covers US firms from 1970 to 2020. Bankruptcy prediction models have been researched and built since the 1960s. The models built from 1960 to 1990 were primarily statistical models such as univariate, multiple discriminant analysis and logit and probit models. Starting from 1990s machine learning models started outperforming statistical models. Since this study applies the most popular contemporary machine learning algorithms using a big data set, we will compare our model with the machine learning models built since the 1990s. A full listing outlining the comparison with past machine learning studies and models for bankruptcy prediction is shown in the Table 1.\n\nIn this study we have used three popular machine learning techniques—Random Forest, Support Vector Machines, and XGBoost to construct forecasting models. We find that Machine Learning models perform very well, with XGBoost being the most successful technique that achieves an accuracy score of more than 99% in out of sample testing.\n\nWe also apply our XGBoost model to an important current issue, the task of predicting bankruptcies during the second half of 2020. The depth of the recession caused by the lockdowns that have been imposed to contain the COVID-19 pandemic has raised worries that corporate bankruptcies may rise substantially in the near future. According to a report in the New York Times (2020), Edward Altman, a pioneer of bankruptcy prediction research, and the creator of the famous Z score model, expects a \"tsunami of bankruptcies\" that will exceed the number of bankruptcies that followed the 2008 financial crisis. The result from our Machine Learning model confirms Prof Altman's fears that corporate bankruptcies will rise substantially in late 2020 and equal the highs seen during the 2008-09 recession. However, this study finds that the elevated level of bankruptcies will not be significantly different from 2010.\n\nThe previous studies done for bankruptcy prediction have not taken a systematic view of the data used to build the models. The previous studies have been more focused on the models rather than on the data used to build the models. This study offers a much more balanced view where both the data and the models are given equal importance. To begin with, we have use Compustat are a source database to get an exhaustive list of financial ratios over US firms from 1970 to 2020. Compustat is a high-quality database used by several famous finance related papers such as Fama and French (1993). Most of the previous studies have used relatively small datasets as compared to ours. This study takes a systematic look at as many features as possible to train our machine learning models. Our balanced approach is also consistent with the shift from model centric to data centric approach proposed by Andrew Ng (Gil Press, 2021).\n\nThe rest of the paper is structured as follows:\n\nSection 2—Describes the existing literature for bankruptcy prediction.\n\nSection 3—Describes the data and the method used to clean, process, and fit the data into our machine learning models. This section also covers the process used to predict the number of bankruptcies using Q2-2020 ratios.\n\nSection 4—Describes the results observed from the experiments\n\nSection 5—Presents our final comments and discusses the implications of the results.\n\n2.   Literature review\n\nBankruptcy prediction models prior to 1990s were primarily statistical models employing univariate, multivariate and logit & probit techniques. In 1966, Beaver applied univariate analysis in which the predictive ability of 30 financial ratios was tested one at a time to predict bankruptcy (Beaver, 1966). Altman in 1968 performed a multi-variate discriminant analysis (MDA) using 5 ratios to create a linear discriminant function of 5 variables (Altman, 1968). Several variants of MDA were developed in the following years. Edmister used 19 financial ratios to build a linear model for bankruptcy prediction (Edmister, 1972). Deakin found that a linear combination of the 14 ratios could be used to predict bankruptcy five years prior to failure (Deakin, 1972). Ohlson studied the shortcomings of MDA models and built a conditional logit model using maximum likelihood estimation (Ohlson, 1980). The datasets used in all these studies were quite small as compared to modern standards. Ohlson's study for example used a dataset of 2058 firms out of which 105 firms represented the bankrupt class.\n\nThe next phase in the evolution of bankruptcy models started in the 1990s with several machine learning algorithms outperforming the older statistical models. Machine learning models such as Random Forests, Support Vector Machines (SVM) and Gradient Boosted Trees were found to be particularly effective for bankruptcy prediction. Barboza, Kimura and Altman compared statistical models with machine learning (ML) models. They found the Random Forests outperformed Alman's Z-score model by a significant margin (Barboza et al., 2017). These results were corroborated by studies (Joshi et al., 2018; Rustam and Saragih, 2018; Gnip and Drotár, 2019). Support Vector Machine (SVM) was also found to be a very effective machine learning algorithm in several studies. Hang et al. (2004) and Chen et al. (2008) achieved superior results for credit rating classification problem by using SVM. Song et al. (2008) used SVM to predict financial distress. Some studies also found boosted trees-based algorithms to outperform SVM. Wang, Ma and Yang proposed a new boosted tree-based algorithm for bankruptcy prediction which they found to be more effective than SVM (Wang et al., 2014). Heo and Yang (2014) used Adaboost algorithm to predict bankruptcy for Korean construction firm. They found Adaboost to have better accuracy than SVM (Heo and Yang, 2014). A more recent study in 2021 has used XGBoost and Random Forest algorithms to predict bankruptcies over 12 months. This study used a medium sized training dataset containing data for 8959 firms registered in Italy (Perboli and Arabnezad, 2021). Another recent study uses a database of Taiwanese firms to predict bankruptcy. This study used data set contain 96 attributes for 6819 firms to train machine learning models (Wang and Liu, 2021). One common attribute shared by all the forementioned studies is the relatively small size of their training data sets. The datasets used by these studies are small as compared to datasets used in the big data era. The largest training dataset in these studies had just 2600 samples which is quite small.\n\nBased on the literature review, the following trends become apparent:\n\n●  Machine Learning Models are now consistently outperforming statistical models\n\n●  The training data sets used to train the existing machine learning models are relatively small as compared to the data sets used for training models in other application areas.\n\n●  Ensemble methods such as Random Forest and Boosted trees have performed better than other models in bankruptcy prediction.\n\n3.   Data and methodology\n\nThis study differentiates itself from previous studies by using a substantially larger dataset as compared to previous studies. We use a very standard and well documented dataset called Compustat to retrieve the financial ratios. Compustat is a standard financial dataset used in financial research. Compustat has been used by some very popular papers in finance such as Fama and French (1993). We have used 57 financial ratios that are listed in Table 2. Financial ratios are inputs used to train Bankruptcy prediction models. While most studies use fewer financial ratios, this study applies a large set of financial ratios of US Firms from 1970–2020 (50 years) to train Random Forest, SVM and XGBoost Models. This section discusses the overall methodology which includes data cleaning, balancing, model fitting, and analysis of results.\n\nPrevious studies have used small to medium sized data sets for training Machine learning models. This study sets itself apart by using a much larger training dataset. We used financial ratios data set from Compustat. The financial ratios data set was then joined with another dataset called Bankruptcy data set. The bankruptcy data set contains the data such as date of bankruptcy, bankruptcy reason and GVKEY (primary key) while the financial ratios dataset contains all the financial ratios mentioned in Table A.1. The two datasets were programmatically joined using a common field named GVKEY. GVKEY is a unique identifier assigned to each firm. The relation amongst the two datasets that were used to create our labelled training dataset is best represented by the ER schema diagram shown in Figure 1.\n\nThe financial ratios dataset we have used contains 57 financial ratios mentioned in Table A.1 in Appendix A. This is an exhaustive list of features used to train our models. We have included ratios which are often overlooked but are likely to help detect patterns related to edge cases.\n\nThe first step of building a predictive model is data pre-processing and cleaning. The original data from Compustat had 75 financial ratios for 21,114 US firms. This data covered firms established in the US between 1970 and 2020. The dataset contained firms that belonged to 2 classes: bankrupt and non-bankrupt or continuing enterprises. The dataset contains 1212 bankrupt firms and 19,902 non-bankrupt firms. The distribution of data points (samples) belonging to these two classes is summarized in Table 2. The next step was to drop features which had null values for more than 6000 firms out of 21,114 firms. This step ensured that we don't have more than 30% of null values in any feature. The goal is to ensure that the true distribution generating this data is preserved and learned by our machine learning models. 18 features (financial ratios) were dropped from the data set because they had null values for more than 6000 (30% of total number of firms). The dataset now had 75 − 18 = 57 features. Next, we scaled our data to have mean = 0 and variance = 1 using Scikit-learns Standard Scaler class. Scaling is required to ensure that gradient descent converges on the minima of the loss function. The last step of data cleaning was to impute the missing values in the 57 financial ratios (features). For imputing the missing values, we used the KNN algorithm which used three nearest neighbours to estimate the missing value. Further, the weight assigned to each neighbour is a function of its Euclidean distance from the data point with missing value. KNN with 3-neighbours has been found to be effective in preserving the true distribution of the data (Beretta and Santaniello, 2016).\n\nThe cleaned and scaled dataset without any missing values was an imbalanced dataset (see Table 2). The dominant class was the bankruptcy class. Approximately 90% of the samples belonged to the majority class which is non-bankrupt firms. Since the goal of this study is train a classifier to identify bankrupt firms, we decided to balance the classes in our training data. This would ensure that our model would learn about the minority class which is the bankrupt class. This is important in the context of bankruptcy prediction because detecting samples belonging to the bankrupt class. To balance the dataset, we use the Synthetic Minority Over-sampling technique (SMOTE) proposed by Chawla et al. (Chawla et al., 2002). SMOTE generates synthetic samples using the features of the data. The minority class is oversampled by taking a minority class sample and then a line is drawn from this minority class sample to k-nearest minority class samples. Synthetic minority class samples are generated along the line joining the minority class sample to its minority class neighbours. Additionally, to ensure that our balanced dataset facilitated learning of the bankrupt class, we also used Borderline-SVM SMOTE. Borderline-SVM SMOTE technique uses samples close the decision boundary (support vectors) to create synthetic samples (Nguyen et al., 2011). Finally, we used the Adaptive Synthetic Sampling (ADASYN) algorithm of He, Bai, Garcia and Li to generate samples in regions of feature space where the density of minority samples is low (He et al., 2008). The result was a balanced dataset containing 19902 samples of non-bankrupt class and 20,517 bankrupt class. The balanced dataset has 57 financial ratios (features).\n\nThe balanced dataset was then shuffled and split into training set containing 70% of the samples and test set containing 30% of the samples. The purpose of creating a test set is to test the accuracy of the models on data that the models have not been trained on. Collecting metrics based on the test set gives practitioners an idea of the generalization performance of machine learning models.\n\nThe training data set was fitted into three machine learning models. These models are: Random Forest, Support Vector Machine (SVM) and XGBoost. After fitting, the models were then used to predict for samples in the test set to assess their relative performance.\n\nFor comparing the performance of the models, we decided to use Accuracy score, Receiver Operating Curve (ROC) and Area Under ROC Curve (AUC). Accuracy score can be used because we are training our models using a balanced dataset. However, to get a better idea of the True Positive Rate (TPR) and False Positive Rate (FPR) we decided to employ ROC and AUC metrics as well. It is important to compare the TPR and FPR because it is more to avoid False negatives (FN) as compared to False positives (FP). False negative (FN) would be a firm which would go bankrupt but is wrongly classified by our model as a non-bankrupt sample. False positive (FP) on the other hand would be a firm that is not bankrupt but is wrongly classified as a bankrupt firm.\n\nThe goal of this study is to predict number of bankruptcies within the next 30, 90 and 180 days. We trained 3 different models to predict the number of bankruptcies within 30, 90 and 180 days. The models were built and analysed using the same approach. The only difference was that the training and test labels for each model were derived from the bankruptcy date. For example, to train the model for predicting number of bankruptcies within 30 days, we used\n\nwhere\n\nwhere\n\nelse\n\nTherefore, we trained 9 models to predict bankruptcies within 30, 90 and 180 days. For example, for predicting bankruptcy within 30 days we trained Random Forest, SVM and XGBoost. After training the models, we picked the best model based on performance metrics described in previous section and then we used the best model to predict the number of bankruptcies using the latest Q2 2020 financial ratios from Capital IQ. In this final prediction set, we only kept data for firms which did not have any significant gaps or holes. Finally, we used the final prediction set from Q2 2020 to predict the number of bankruptcies we expect to happen over the next 30, 90 and 180 days.\n\n4.   Results\n\nAs mentioned in the previous section, we trained 9 models, using three different techniques, RF, SVM, XGBoost, for predicting bankruptcies over 30, 90 and 180 days. Next, we used the test set to make predictions and then assessed the relative performance. Based on the chosen metrics of accuracy score and Area under ROC curve (ROC AUC), XGBoost outperformed the other models for predicting bankruptcy within 30, 90 and 180 days. The actual scores for accuracy and AUC are presented in Table 3.\n\nThe accuracy score of XGBoost models is consistently better than SVM and Random Forest. This result is also consistent with the ROC curves which are shown in Figure 2 below.\n\nAs seen in Figure 2, the ROC curve for XGBoost is closest to the top left corner thereby covering maximum area under it. XGBoost is therefore the best performing model closely followed by Random Forest. The fact that these metrics are calculated using the test set (containing data which model has not been trained on) gives us confidence in the ability of our models to generalize.\n\nWe present the performance metrics of previous studies in Table 4. Previous studies have used 2 performance metrics: Test accuracy and Area Under ROC curve (AUC). To keep the comparison consistent, we have computed both test accuracy score and AUC for our models (see Table 3). Our best model built using XGBoost significantly outperforms the models built in previous studies. The accuracy of our XGBoost model for prediction bankruptcy within 180 days is 98.69% which is lower than the test accuracy of our XGBoost models for predicting bankruptcies within 30 and 90 days. However, our model for predicting bankruptcies within 180 days has a higher test accuracy (98.69%) than models built in previous studies. Similarly, our model for predicting bankruptcies within 180 days has an AUC score of 0.99 which is higher than the AUC score reported by previous studies. Our performance metrics of accuracy and AUC score are computed over out of training samples which also indicates to the robustness of our results.\n\nNext, we apply our best model, using XGBoost, to the data from Q2-2020 to evaluate the possibility of a substantial upsurge in business bankruptcies in the second half of 2020 because of the deep 2020 recession caused by the pandemic. We apply this best model to the latest available ratios, for Q2-2020, and classify a firm as going bankrupt during the next 30, 90, or 180 days if the predicted probability of bankruptcy is higher than 0.50.\n\nUsing this method, our best model in each category predicted 74 bankruptcies within 30 days, 189 bankruptcies within 90 days and 354 Bankruptcies within 180 days. This prediction is for all firms contained in the S & P Global database, both public and private. The predictions for the number of bankruptcies are summarized in Table 5.\n\nS & P Global has reported a total of 336 actual bankruptcies until the end of June 2020. If we add our prediction of 354 bankruptcies to the actual bankruptcies, then we predict a total of 336 + 354 = 690 bankruptcies in 2020. We summarize our predictions in Table 6 below.\n\nSince the number of firms in the database changes from year to year, we decided to compare the prediction for 2020 with the past by using bankruptcy rates, i.e., the ratio of the number of bankruptcies to the total number of firms. As shown in Table 7, our prediction of 690 bankruptcies in 2020 represents a bankruptcy rate of 4.35% for all US firms. This rate is the highest in the last 10 years. The second highest rate of 4.2%, only slightly lower, was seen in 2010, in the immediate aftermath of the 2008-09 recession. The average rate during the economic expansion years of 2011–2019 was 3.2%, more than a full percentage point lower than the predicted 2020 rate. We conclude that we will indeed see a much higher rate bankruptcies in 2020, but it is unlikely to be substantially larger than in 2010.\n\n5.   Conclusions\n\nWe find that two different Machine Learning algorithms, Random Forest (RF) and Extreme Gradient Boosting (XGBoost) produce accurate predictions of whether a firm will go bankrupt within the next 30, 90, or 180 days, using financial ratios as input features. The XGBoost based models perform exceptionally well, with 99% out-of-sample accuracy. Our training dataset uses a large database of public US firms over a period of 49 years, 1970–2019, and 57 financial ratios. This study has used a substantially larger training dataset as compared to previous studies.\n\nAn application of our best performing XGBoost model to Q2-2020 financial data for a sample of both private and public U.S. firms shows that the bankruptcy rate will climb substantially higher in 2020 than in the expansion years of 2011–2019. However, our model suggests that the rate will be only marginally higher than in 2010.\n\nWe identify the following areas for further research:\n\n●  Adding macro-economic features—It will be interesting to add macro-economic features to training data used for training machine learning models for bankruptcy prediction.\n\n●  Train deep neural networks with different topologies—Another interesting area of research would be to apply different types of deep neural networks such as TabNet and Recurrent neural networks.\n\nConflict of interest\n\nAll authors declare no conflicts of interest in this paper.\n\nReferences\n\nThis article has been cited by:\n\nTop\n\nA Machine Learning Based Framework For Bankruptcy Prediction In ... : \nInformatica is surveyed by:\n\nA MACHINE LEARNING BASED FRAMEWORK FOR BANKRUPTCY PREDICTION IN CORPORATE FINANCES USING EXPLAINABLE AI TECHNIQUES\n\nForecasting bankruptcy within corporate finances is an indispensable endeavor crucial for sustaining business growth and fostering stability. The paper presents a methodology to redefine the conventional approach to bankruptcy prediction within corporate finance. Through the adept utilization of advanced machine learning techniques, notably classification models, a dynamic and adaptable framework is established, enabling the systematic categorization of companies based on their bankruptcy risk profiles. Moreover, the methodology addresses the inherent challenge of data bias by integrating oversampling techniques like the Synthetic Minority Over-sampling Technique (SMOTE), thereby ensuring a more equitable representation of minority class samples and bolstering the model’s predictive accuracy. The resulting model delivers timely and precise forecasts of bankruptcy risk, fortified by crucial recommendations such as the Altman Z-Score for vulnerability assessment, Debt-to-Equity Ratio for insights into leverage, Quick Ratio for assessing liquidity, and Explainable AI Techniques like SHapley Additive exPlanations (SHAP) analysis for transparent interpretations. This comprehensive approach equips stakeholders with tailored recommendations, empowering them to proactively safeguard their organizations’ financial well-being and avert the perils of bankruptcy. The comparative analysis presented in paper demonstrates that the proposed method assesses the bankruptcy risk more accurately. The integration of Explainable AI techniques and key financial metrics helps the stakeholders to take vital decisions about corporate finances.\n\nMaulana, Didit Johar, Siti Saadah, and Prasti Eko Yunanto. ”Kmeans-SMOTE Integration for Handling Imbalance Data in Classifying Financial Distress Companies using SVM and Na¨ıve Bayes.” Jurnal RESTI (Rekayasa Sistem dan Teknologi Informasi) 8, no. 1 (2024): 54-61.\n\nLiashenko, Olena, Tetyana Kravets, and Yevhenii Kostovetskyi. ”Machine learning and data balancing methods for bankruptcy prediction.” Ekonomika 102, no. 2 (2023): 28-46.\n\nEnkhtuya, Tuguldur, and Dae-Ki Kang. ”Bankruptcy Prediction with Explainable Artificial Intelligence for Early-Stage Business Models.” International Journal of Internet, Broadcasting and Communication 15, no. 3 (2023): 58-65.\n\nFan, Mengting, Zan Mo, Qizhi Zhao, and Zhouyang Liang. ”Innovative Insights into Knowledge-Driven Financial Distress Prediction: a Comprehensive XAI Approach.” Journal of the Knowledge Economy (2023): 1-42.\n\nWahyuni, Sari. ”Prediction of Bankruptcy Levels Using the Almant Z-Method Score in Banking Companies on the Indonesia Stock Exchange for the 2018- 2021 Period.” MANKEU (Jurnal Manajemen Keuangan) 1, no. 2 (2023). https://doi.org/10.61167/mnk.v1i2.39.\n\nLokeshnath, B., and M. Sandhya. ”INSOLVENCY AND BANKRUPTCY CODE: A STUDY OF INDIAN BANKS WITH REFERENCE TO ALTMAN Z SCORE.” EPRA International Journal of Economic and Business Review (JEBR) 11, no. 8 (2023): 69-79.\n\nTran, Kim Long, Hoang Anh Le, Thanh Hien Nguyen, and Duc Trung Nguyen. ”Explainable machine learning for financial distress prediction: evidence from Vietnam.” Data 7, no. 11 (2022): 160.\n\nPavlicko, Michal, Marek Durica, and Jaroslav Mazanec. ”Ensemble model of the financial distress prediction in Visegrad group countries.” Mathematics 9, no. 16 (2021): 1886.\n\nAlam, Talha Mahboob, Kamran Shaukat, Mubbashar Mushtaq, Yasir Ali, Matloob Khushi, Suhuai Luo, and Abdul Wahab. ”Corporate bankruptcy prediction: An approach towards better corporate world.” The Computer Journal 64, no. 11 (2021): 1731- 1746.\n\nAnsari, Abdollah, Ibrahim Said Ahmad, Azuraliza Abu Bakar, and Mohd Ridzwan Yaakub. ”A hybrid metaheuristic method in training artificial neural network for bankruptcy prediction.” IEEE access 8 (2020): 176640-176650.\n\nSoui, Makram, Salima Smiti, Mohamed Wiem Mkaouer, and Ridha Ejbali. ”Bankruptcy prediction using stacked auto-encoders.” Applied Artificial Intelligence 34, no. 1 (2020): 80-100.\n\nFares, Omar H., Irfan Butt, and Seung Hwan Mark Lee. ”Utilization of artificial intelligence in the banking sector: a systematic literature review.” Journal of Financial Services Marketing 28, no. 4 (2023): 835-852.\n\nHanif, Ambreen. ”Towards explainable artificial intelligence in banking and financial services.” arXiv preprint arXiv:2112.08441 (2021).\n\nM, Hiran & G, Megavarshini & Sreenivasan, Aswathy & Suresh, Ma. (2023). Machine Learning in the Banking Sector. 1081-1088. 10.46254/AN13.20230313.\n\nBahoo, Salman, Marco Cucculelli, Xhoana Goga, and Jasmine Mondolo. ”Artificial intelligence in Finance: a comprehensive review through bibliometric and content analysis.” SN Business & Economics 4, no. 2 (2024): 23.\n\nSharma, Bhumiswor, P. Srikanth, and S. Jeevananda. ”Financial Distress and Value Pre mium using Altman Revised Z-score Model.” Vision (2023): 09722629231198604.\n\nCındık, Zeynep & Armutlulu, ˙Ismail. (2021). A revision of Altman Z-Score model and a comparative analysis of Turkish companies’ financial distress prediction. Na tional Accounting Review. 3. 237-255. 10.3934/NAR.2021012.\n\nChen, Tsung-Kang, Hsien-Hsing Liao, Geng Dao Chen, Wei-Han Kang, and Yu-Chun Lin. ”Bankruptcy prediction using machine learn ing models with the text-based communicative value of annual reports.” Expert Systems with Applications 233 (2023): 120714.\n\nKim, Hyeongjun, Hoon Cho, and Doojin Ryu. ”Corporate bankruptcy prediction using machine learning methodologies with a focus on sequential data.” Computational Economics 59, no. 3 (2022): 1231-1249.\n\nDablain, Damien & Krawczyk, Bartosz & Chawla, Nitesh. (2022). DeepSMOTE: Fusing Deep Learning and SMOTE for Imbalanced Data. IEEE Transactions on Neural Networks and Learning Systems. PP. 1-15. 10.1109/TNNLS.2021.3136503.\n\nElreedy, Dina, Amir F. Atiya, and Firuz Kamalov. ”A theoretical distribution analysis of synthetic minority oversampling technique (SMOTE) for imbalanced learning.” Machine Learning (2023): 1-21.\n\nHairani, Hairani, Khurniawan Eko Saputro, and Sofiansyah Fadli. ”K-means-SMOTE untuk menangani ketidakseimbangan kelas dalam klasifikasi penyakit diabetes dengan C4. 5, SVM, dan naive Bayes.” Jurnal Teknologi dan Sistem Komputer 8, no. 2 (2020): 89-93.\n\nSalehi, Amir Reza, and Majid Khedmati. ”A cluster-based SMOTE both-sampling (CSBBoost) ensemble algorithm for classifying imbalanced data.” Scientific Reports 14, no. 1 (2024): 5152. 12 Informatica 45 page 501–yyy V. Chandgadkar et al.\n\nKaggle, US Company Bankruptcy Prediction Dataset, https://www.kaggle.com/datasets/utkarshx27/americancompanies-bankruptcy-prediction-datase\n\nInformatica is financially supported by the Slovenian research agency from the Call for co-financing of scientific periodical publications.\n\nWebmaster: Mario Konecki\n\n© 2015 Slovenian Society Informatika | About | Current issue | Calls for papers | Submission\n\nMachine Learning in Bankruptcy Prediction: A Literature Review : \nMachine Learning in Bankruptcy Prediction: A Literature Review\n\nFiles\n\nWe collect and process your personal information for the following purposes: Authentication, Preferences, Acknowledgement and Statistics.\n",
        "Machine learning models employed in financial performance optimization": "Advancing Financial Risk Prediction and Portfolio Optimization Using ... : \nAdvancing Financial Risk Prediction and Portfolio Optimization Using Machine Learning Techniques\n\nKeywords:\n\nAbstract\n\nThis study explores the application of machine learning models for predicting financial risk and optimizing portfolio management. We compare various machine learning algorithms, including Random Forest, Gradient Boosting, Long Short-Term Memory (LSTM), and Transformer networks, to assess their effectiveness in forecasting asset returns, managing risk, and enhancing portfolio performance. The results demonstrate that machine learning models significantly outperform traditional financial models in terms of prediction accuracy and risk-adjusted returns. Notably, LSTM and Transformer models excel at capturing long-term dependencies in financial data, leading to more robust predictions and improved portfolio outcomes. Feature selection and preprocessing were crucial in maximizing model performance. Portfolio optimization using machine learning models, when combined with traditional optimization techniques, resulted in superior Sharpe and Sortino ratios. These findings highlight the potential of machine learning to enhance real-time financial decision-making, offering more adaptive and resilient strategies for managing investment portfolios in dynamic market environments. This research provides valuable insights into the integration of machine learning for financial risk prediction and portfolio management, with implications for future advancements in the field.\n\nThe American Journal of Management and Economics Innovations\n\n01\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nTYPE\n\nOriginal Research\n\nPAGE NO.\n\n5-20\n\nDOI\n\n10.37547/tajmei/Volume07Issue01-02\n\nOPEN ACCESS\n\nSUBMITED\n\n16 October 2024\n\nACCEPTED\n\n09 December 2024\n\nPUBLISHED\n\n22 January 2025\n\nVOLUME\n\nVol.07 Issue01 2025\n\nCITATION\n\nAftab Uddin, Md Amran Hossen Pabel, Md Imdadul Alam, FNU\nKAMRUZZAMAN, Md Sayem Ul Haque, Md Monir Hosen, Ashadujjaman\nSajal, Mohammad Rasel Miah, & Sandip Kumar Ghosh. (2025).\nAdvancing Financial Risk Prediction and Portfolio Optimization Using\nMachine Learning Techniques. The American Journal of Management\nand Economics Innovations, 7(01), 5\n\n–\n\n20.\n\nhttps://doi.org/10.37547/tajmei/Volume07Issue01-02\n\nCOPYRIGHT\n\n© 2025 Original content from this work may be used under the terms\nof the creative commons attributes 4.0 License.\n\nAdvancing Financial Risk\nPrediction and Portfolio\nOptimization Using\nMachine Learning\nTechniques\n\nAftab Uddin\n\n1\n\n, Md Amran Hossen Pabel\n\n2\n\n, Md\n\nImdadul Alam\n\n3\n\n, FNU KAMRUZZAMAN\n\n4\n\n, Md Sayem\n\nUl Haque\n\n5\n\n, Md Monir Hosen\n\n6\n\n, Ashadujjaman Sajal\n\n7\n\n,\n\nMohammad Rasel Miah\n\n8\n\n, Sandip Kumar Ghosh\n\n9\n\n1\n\nFox School of Business & Management, Temple University, USA\n\n2\n\nMaster’s of Science in Business Analytics Wright State Univer\n\nsity,\n\nOhio, USA\n\n3\n\nMaster of Science in Financial Analysis, Fox School of Business,\n\nTemple University, USA\n\n4\n\nDepartment of Information Technology Project Management &\n\nBusiness Analytics, St. Francis College, USA\n\n5\n\nMBA in Business Analytics, Gannon University, USA\n\n6\n\nMaster of Business Administration in Supply Chain Management,\n\nUniversity of Houston downtown, USA\n\n7\n\nDepartment of Management Science and Quantitative Methods,\n\nGannon University, USA\n\n8\n\nMBA in Accounting, University of the Potomac, Leesburge pike,\n\nFalls church, Virginia, USA\n\n9\n\nDepartment of Business Administration, University of Surrey,\n\nGuildford, Surrey, GU2 7XH, UK\n\nAbstract:\n\nThis study explores the application of machine\n\nlearning models for predicting financial risk and\noptimizing portfolio management. We compare various\nmachine learning algorithms, including Random Forest,\nGradient Boosting, Long Short-Term Memory (LSTM),\nand Transformer networks, to assess their effectiveness\nin forecasting asset returns, managing risk, and\nenhancing\n\nportfolio\n\nperformance.\n\nThe\n\nresults\n\ndemonstrate that machine learning models significantly\noutperform traditional financial models in terms of\nprediction accuracy and risk-adjusted returns. Notably,\nLSTM and Transformer models excel at capturing long-\nterm dependencies in financial data, leading to more\nrobust predictions and improved portfolio outcomes.\nFeature selection and preprocessing were crucial in\nmaximizing model performance. Portfolio optimization\n\nThe American Journal of Management and Economics Innovations\n\n6\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nThe American Journal of Management and Economics Innovations\n\nusing machine learning models, when combined with\ntraditional optimization techniques, resulted in\nsuperior Sharpe and Sortino ratios. These findings\nhighlight the potential of machine learning to enhance\nreal-time financial decision-making, offering more\nadaptive and resilient strategies for managing\ninvestment\n\nportfolios\n\nin\n\ndynamic\n\nmarket\n\nenvironments. This research provides valuable insights\ninto the integration of machine learning for financial\nrisk prediction and portfolio management, with\nimplications for future advancements in the field.\n\nKeywords:\n\nMachine learning, financial risk prediction,\n\nportfolio optimization, asset returns forecasting, risk-\nadjusted returns, LSTM, Transformer networks,\nfeature selection, model evaluation, investment\nstrategies, financial decision-making, Sharpe ratio,\nSortino ratio, deep learning, predictive analytics,\nfinancial modeling.\n\nIntroduction:\n\nIn the field of finance, accurately\n\npredicting financial risk and managing investment\nportfolios are two of the most crucial tasks for both\nindividual and institutional investors. Traditional\nportfolio management methods, based on historical\nprice data and static assumptions, have proven to be\ninsufficient in handling the complexities and volatility\nof modern financial markets. Over the past few years,\nmachine learning (ML) techniques have gained\nsignificant traction in financial analysis due to their\nability to learn from vast amounts of data, uncover\ncomplex patterns, and generate more accurate\npredictions. Machine learning models such as Logistic\nRegression, Random Forest, Gradient Boosting, Long\nShort-Term Memory (LSTM), and Transformer\nnetworks have been successfully applied to various\ndomains, including financial risk prediction, asset\npricing, and portfolio optimization. These models can\npotentially improve asset selection, enhance risk-\nadjusted returns, and provide more resilient\ninvestment strategies in volatile market environments.\n\nThe aim of this research is to explore the use of\nmachine learning models for predicting financial risk\nand optimizing portfolio management. We focus on\ncomparing various models' ability to forecast asset\nreturns, risk profiles, and portfolio performance,\nevaluating their effectiveness through financial metrics\nlike the Sharpe ratio, Sortino ratio, and maximum\ndrawdown. The study intends to provide a\ncomparative analysis of machine learning models in\nterms of their practical utility for portfolio optimization\nand real-time financial decision-making.\n\nBy applying advanced machine learning techniques, this\npaper explores how asset allocation decisions based on\npredictive models can improve overall portfolio\nperformance, enabling more dynamic and informed\ninvestment strategies. Ultimately, this research aims to\nbridge the gap between traditional portfolio\nmanagement practices and the modern advancements\nin machine learning, offering insights into how financial\nrisk prediction can be improved in real-time for optimal\nportfolio construction.\n\nLITERATURE REVIEW\n\nThe integration of machine learning models into\nfinancial risk prediction and portfolio optimization has\nbecome a significant area of research in the past\ndecade. The financial markets' complexity and\nunpredictability have spurred interest in exploring non-\ntraditional approaches to risk management and\ninvestment strategies. Machine learning models have\nshown great promise in overcoming the limitations of\ntraditional models by providing more accurate forecasts\nand adaptive portfolio strategies.\n\nMachine Learning in Financial Risk Prediction\n\nFinancial risk prediction, particularly in the context of\nstock market volatility and asset price movements, has\nbeen an area of growing interest. Early approaches to\nrisk prediction in finance mainly relied on statistical\nmethods, such as Value at Risk (VaR) and GARCH\nmodels, which assume a constant volatility over time\n(Engle, 2001). However, these models often fail to\ncapture the non-linearity and dynamic nature of\nfinancial markets.In contrast, machine learning\nmethods have demonstrated superior predictive power\ndue to their ability to learn from complex data patterns\nand adapt to changes in the market. For instance,\ndecision trees and ensemble methods like Random\nForest and Gradient Boosting have been employed to\npredict stock price movements and assess market risk.\nStudies by Buhlmann and Hothorn (2007) and Chen et\nal. (2018) showed that these models could outperform\ntraditional methods in terms of accuracy and predictive\ncapability. More advanced techniques, such as deep\nlearning models like LSTM (Hochreiter & Schmidhuber,\n1997), have been applied to time-series data for\nforecasting financial market trends and risk. LSTM\nnetworks are particularly useful for capturing long-term\ndependencies in financial data, which is crucial for\nmodeling stock prices and volatility.\n\nMachine Learning in Portfolio Optimization\n\nPortfolio optimization, traditionally based on the\nModern Portfolio Theory (MPT) by Markowitz (1952),\ninvolves selecting a set of assets that minimizes risk for\na given level of expected return. While MPT has been\nwidely used, its reliance on historical data and\n\nThe American Journal of Management and Economics Innovations\n\n7\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nThe American Journal of Management and Economics Innovations\n\nassumptions about returns and covariance often limits\nits applicability in volatile or unpredictable markets.\n\nMachine learning models have enhanced portfolio\noptimization by incorporating predictive capabilities\ninto the asset allocation process. For example,\nmachine learning-based risk prediction models can\nhelp forecast asset returns more accurately, leading to\nbetter portfolio construction. Various studies have\nexplored the integration of machine learning with\nportfolio optimization techniques. For instance, He et\nal. (2017) applied a neural network model for portfolio\noptimization, showing that combining machine\nlearning predictions with traditional optimization\nmethods\n\ncan\n\nsignificantly\n\nimprove\n\nportfolio\n\nperformance. Other studies have explored deep\nreinforcement learning techniques for dynamic\nportfolio optimization, where agents are trained to\nadjust asset allocations over time based on observed\nreturns and risk (Jiang et al., 2017).\n\nIn particular, LSTM and Transformer models have been\nutilized for time-series forecasting in portfolio\noptimization. LSTM models are adept at handling\nsequential data, making them a powerful tool for\npredicting asset returns over time (Fischer & Krauss,\n2018). Transformer models, which have been\nsuccessful in natural language processing tasks, have\nalso been adapted for financial prediction tasks due to\ntheir ability to capture long-range dependencies and\nhandle large datasets efficiently (Li et al., 2020).\n\nComparative Performance of Machine Learning\nModels in Financial Risk and Portfolio Optimization\n\nSeveral studies have compared the performance of\nvarious machine learning algorithms in financial risk\nprediction and portfolio optimization. In general,\nensemble methods such as Random Forest and\nGradient Boosting have shown strong performance in\nterms of both prediction accuracy and risk\nmanagement. For instance, a study by Zhang et al.\n(2019) demonstrated that Gradient Boosting Machines\n(GBM) outperformed traditional models like ARIMA in\npredicting stock market trends. Similarly, Random\nForest models were shown to be effective in portfolio\nconstruction by selecting the most relevant assets\nbased on predicted returns and risks (Li et al., 2020).\n\nDeep learning models, such as LSTM and Transformer\nnetworks, have also emerged as strong contenders in\nfinancial applications. Studies by Fischer and Krauss\n\n(2018) and Zhang et al. (2020) highlighted that LSTM\nnetworks could predict stock prices more accurately and\nprovide better risk-adjusted returns in portfolio\noptimization. Transformer models, although less\nexplored in finance, have demonstrated strong\npotential in handling sequential financial data and\nimproving the robustness of portfolio optimization\nstrategies (Li et al., 2020).\n\nThe literature review reveals that machine learning\nmodels offer substantial improvements over traditional\nfinancial models in terms of risk prediction and portfolio\noptimization. While methods like Random Forest,\nGradient Boosting, and LSTM have been widely applied\nand shown promising results, newer models such as\nTransformer networks hold great potential in further\nenhancing the accuracy and adaptability of financial risk\nprediction and portfolio management. The next sections\nof this paper will compare the performance of various\nmachine learning models in terms of their predictive\naccuracy,\n\nrisk-adjusted\n\nreturns,\n\nand\n\nportfolio\n\nperformance, providing insights into their practical\napplications in real-world financial settings.\n\nMETHODOLOGY\n\nDataset Collection\n\nWe began by gathering diverse financial datasets from\nreliable and widely used sources, including Bloomberg,\nYahoo Finance, Quandl, and Kaggle. These sources\nprovided us with extensive historical data on stock\nprices, financial ratios, economic indicators, and asset\nperformance across multiple asset classes, including\nequities, bonds, commodities, and cryptocurrencies. To\nenrich our dataset, we incorporated sentiment data\nextracted from financial news platforms and social\nmedia channels, leveraging modern sentiment analysis\ntechniques.\n\nTo ensure robustness and temporal relevance, we\nselected a time horizon of ten years, covering a wide\nrange of market conditions such as bull and bear cycles,\nperiods of economic stability, and crises. Additionally,\nwe integrated macroeconomic variables such as interest\nrates, inflation rates, and GDP growth, which play\ncritical roles in financial risk prediction and portfolio\nmanagement. The collected dataset thus captures a\nholistic view of the financial market landscape, enabling\nus to model both micro and macroeconomic factors\neffectively.\n\nThe American Journal of Management and Economics Innovations\n\n8\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nThe American Journal of Management and Economics Innovations\n\nDataset Attributes Table:\n\nAttribute\n\nDescription\n\nType\n\nSource\n\nDate\n\nTimestamp for each observation.\n\nDate/Time Bloomberg, Yahoo\n\nFinance\n\nAsset Name\n\nName or ticker symbol of the financial asset.\n\nCategorical Bloomberg, Yahoo\n\nFinance\n\nClosing Price\n\nDaily closing price of the asset.\n\nNumeric\n\nYahoo Finance\n\nVolume\n\nDaily trading volume of the asset.\n\nNumeric\n\nYahoo Finance\n\nMoving Average\n(MA)\n\nTechnical indicator capturing average price\nover a specified period.\n\nNumeric\n\nCalculated\n\nRelative Strength\nIndex (RSI)\n\nMomentum oscillator measuring speed and\nchange of price movements.\n\nNumeric\n\nCalculated\n\nSentiment Score\n\nAggregated sentiment derived from news and\nsocial media using NLP techniques.\n\nNumeric\n\nNews APIs, Social\nMedia\n\nGDP Growth Rate\n\nQuarterly GDP growth rate, indicative of\neconomic performance.\n\nNumeric\n\nWorld Bank,\nQuandl\n\nInflation Rate\n\nConsumer Price Index (CPI)-based inflation\nrates.\n\nNumeric\n\nQuandl\n\nRisk-Free Rate\n\nYield on a risk-free asset, such as U.S.\nTreasury bills.\n\nNumeric\n\nBloomberg\n\nDataset Preprocessing\n\nPreprocessing the dataset is a crucial step to ensure\nthe quality, consistency, and usability of the data\nbefore applying machine learning models. In our study,\nwe invested significant effort in refining the raw data\nto prepare it for further analysis and modeling.The first\nstep involved handling missing values, which are\ncommon in financial datasets due to market holidays,\nincomplete reporting, or data retrieval issues. We\nadopted different strategies based on the type and\nsignificance of the missing values. For time-series data,\nsuch as asset prices, we utilized forward-fill and\nbackward-fill methods to interpolate missing entries\nwithout disrupting the temporal trends. For\nmacroeconomic indicators with sporadic missing\nvalues, we applied linear interpolation or filled gaps\nusing averages from similar periods. If a feature had an\nexcessive number of missing values (greater than 30%\nof the dataset), we carefully evaluated its relevance\nand either removed it or imputed values using\nadvanced methods like K-Nearest Neighbors (KNN)\nimputation.\n\nOutlier detection and handling were essential to avoid\ndistortions caused by extreme data points. We\nidentified outliers using statistical techniques such as\nz-scores and interquartile ranges (IQR). Once\nidentified, we decided on appropriate treatments\nbased on the context. For instance, we capped outliers\nwithin a predefined range for variables where extreme\nvalues were possible but unlikely to hold predictive\n\nvalue, such as abnormal trading volumes during market\ncrises. In cases where outliers were due to errors or\nanomalies, we replaced them with median values or\nremoved the corresponding records.\n\nNormalization and standardization were applied to\nnumerical features to ensure they were on a\ncomparable scale. Financial variables such as asset\nprices and trading volumes often span different orders\nof magnitude, which can bias machine learning models\nthat rely on distance-based metrics. We standardized\nnumerical features using z-score normalization to\ncenter the data around zero with unit variance.\nAdditionally, log transformation was applied to skewed\nfeatures like asset prices to reduce the impact of heavy\ntails and achieve a more symmetrical distribution.\n\nFor categorical features, such as asset names and\nindustry classifications, we employed encoding\ntechniques to convert them into machine-readable\nformats. One-hot encoding was used for nominal\ncategories to create binary variables without\nintroducing ordinal relationships. For high-cardinality\nfeatures, we grouped less frequent categories into an\n\n“Other” category to reduce dimensionality and\n\ncomputational overhead.\n\nTo ensure temporal alignment, we synchronized all\ntime-series data across multiple sources. This step\ninvolved aggregating daily, weekly, and monthly data to\na common frequency suitable for our analysis. We also\nadjusted timestamps to account for differences in time\nzones and market hours. Special care was taken to\n\nThe American Journal of Management and Economics Innovations\n\n9\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nThe American Journal of Management and Economics Innovations\n\nhandle events such as stock splits, dividend payouts,\nand mergers, which required adjustments to historical\nprices to maintain consistency.\n\nData augmentation was another strategy we employed\nto expand the dataset and capture a broader range of\nscenarios. By generating synthetic data using\nbootstrapping and resampling methods, we improved\nthe robustness of our models in handling diverse\nmarket conditions.\n\nFeature Engineering\n\nFeature engineering was a cornerstone of our\nmethodology, allowing us to derive meaningful\ninsights from raw data and enhance the predictive\npower of our models. This process involved creating\nnew variables, transforming existing ones, and\nincorporating domain-specific knowledge to capture\ncomplex relationships within the financial data.A\nprimary focus of feature engineering was the\nextraction of technical indicators commonly used in\nfinancial analysis. These indicators included moving\naverages (e.g., simple, exponential, and weighted),\nBollinger Bands, and the Relative Strength Index (RSI),\nwhich capture price trends, volatility, and momentum,\nrespectively. We calculated these indicators using\nvarying window lengths to capture both short-term\nand long-term market dynamics.\n\nTo complement technical indicators, we developed\nfeatures based on trading activity, such as average\ndaily volume, volume-price trends, and on-balance\nvolume (OBV). These features provided insights into\nmarket sentiment and the intensity of trading\nbehavior, which are critical for predicting asset\nperformance.\n\nSentiment analysis was another key aspect of our\nfeature engineering. We leveraged natural language\nprocessing (NLP) techniques to analyze textual data\nfrom financial news articles, analyst reports, and social\nmedia posts. Using tools like VADER (Valence Aware\nDictionary and sEntiment Reasoner) and BERT\n(Bidirectional\n\nEncoder\n\nRepresentations\n\nfrom\n\nTransformers), we quantified sentiment polarity and\nintensity. For example, we created sentiment scores\nthat reflected market optimism or pessimism and\ntracked their changes over time. Additionally, we used\ntopic modeling to identify recurring themes in financial\ndiscourse, su\n\nch as “interest rate hikes” or “earnings\n\nexpectations,” and incorporated these as categorical\n\nfeatures.\n\nTo account for temporal dependencies, we engineered\nlagged variables and rolling window statistics. Lagged\nvariables represented past values of features (e.g., the\n\nprevious day’s closing price), enabling our models to\n\nlearn temporal patterns. Rolling statistics, such as\n\nrolling averages and rolling standard deviations,\ncaptured trends and variability over specific time\nhorizons. These features were particularly valuable in\ndetecting shifts in market behavior and predicting\nfuture risks.\n\nInteraction terms were introduced to model complex\nrelationships between variables. For instance, we\ncreated interaction features between macroeconomic\nindicators (e.g., inflation rate) and asset-specific\nvariables (e.g., sector performance) to capture the joint\neffects of external factors and market conditions.\nPolynomial features were also explored to account for\nnon-linear relationships in the data.\n\nDimensionality reduction techniques were employed to\nenhance the interpretability and efficiency of our\nmodels. Principal Component Analysis (PCA) was used\nto condense highly correlated features, such as\ntechnical indicators derived from similar time windows,\ninto fewer components while retaining the majority of\nthe variance.\n\nFinally, we incorporated external datasets to enhance\nthe richness of our features. For example, we used\nweather data to model agricultural commodity\nperformance and geopolitical data to assess risks in\nemerging markets. These additional features provided a\nmore comprehensive view of the factors influencing\nfinancial risks and portfolio returns. By applying these\nadvanced\n\nfeature\n\nengineering\n\ntechniques, we\n\ntransformed our raw dataset into a robust and insightful\nrepresentation of the financial landscape, enabling our\nmodels to achieve superior performance in predicting\nrisks and optimizing portfolios.\n\nFeature Selection\n\nFeature selection is a vital component of our\nmethodology, as it helps to identify the most relevant\nand influential variables from the engineered features\nwhile minimizing redundancy and noise. By selecting an\noptimal subset of features, we aimed to enhance the\ninterpretability and predictive accuracy of our machine\nlearning models while reducing computational\ncomplexity and the risk of overfitting. The feature\nselection process began with a thorough exploratory\ndata analysis (EDA) to assess the statistical properties\nand relationships between features and the target\nvariable. We calculated correlation matrices to identify\nhighly correlated features and utilized visualizations\nsuch as heatmaps and pair plots to better understand\nthese relationships. Features with extremely high\nmulticollinearity (e.g., correlation coefficients greater\nthan 0.85) were flagged for removal or transformation,\nas their inclusion could distort model performance.\n\nNext, we employed statistical tests to evaluate the\nsignificance of individual features. For continuous\n\nThe American Journal of Management and Economics Innovations\n\n10\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nThe American Journal of Management and Economics Innovations\n\nvariables, we conducted univariate tests such as the t-\ntest and ANOVA to measure the variance explained by\neach feature in relation to the target variable. For\ncategorical features, chi-square tests were used to\nassess the independence of features from the target\nvariable. Features that did not demonstrate statistical\nsignificance at a predefined threshold (e.g., p-value <\n0.05) were considered for exclusion. To automate the\nfeature selection process and ensure consistency, we\nused algorithmic techniques such as Recursive Feature\nElimination (RFE). RFE iteratively ranked features by\ntraining the model and removing the least important\nfeature at each step. This process was conducted in\nconjunction with a robust machine learning algorithm,\nsuch as Random Forest or Support Vector Machine, to\nensure reliable feature importance ranking.\n\nAdditionally,\n\nwe\n\napplied\n\ntree-based\n\nfeature\n\nimportance ranking using ensemble methods like\nRandom Forest and Gradient Boosted Trees (e.g.,\nXGBoost and LightGBM). These methods assigned\nimportance scores to each feature based on their\ncontribution to reducing model error. Features with\nlow importance scores were either removed or flagged\nfor further evaluation.\n\nAnother technique we implemented was Lasso\nRegression, a regularized regression method that uses\nL1 penalty to shrink less important coefficients to zero.\nLasso Regression helped us identify and retain only the\nmost impactful features while naturally excluding\nirrelevant or redundant variables.\n\nDimensionality reduction was also explored as part of\nthe feature selection process. Principal Component\nAnalysis (PCA) was used to reduce the dimensionality\nof the dataset by transforming correlated features into\nuncorrelated principal components. While PCA is not\ninherently interpretable, it was particularly useful for\nreducing the computational burden in models sensitive\nto high dimensionality, such as deep learning models.\n\nWe also considered domain knowledge in the feature\nselection process, ensuring that the selected features\naligned with established financial theories and\npractices. For instance, technical indicators like moving\naverages and RSI were prioritized due to their proven\nrelevance in predicting market trends. Similarly,\nmacroeconomic indicators such as GDP growth rate\nand inflation were retained based on their historical\nimpact on financial risk and portfolio performance.\nThrough this multi-step feature selection process, we\nrefined the dataset to include only the most relevant\nand informative features, striking a balance between\nmodel performance and interpretability.\n\nModel Training\n\nModel training formed the core of our methodology,\n\nas it enabled us to leverage advanced machine learning\ntechniques to predict financial risks and optimize\nportfolio management strategies. This stage involved\nselecting\n\nappropriate\n\nalgorithms,\n\noptimizing\n\nhyperparameters, and ensuring that the models\ngeneralize well to unseen data. We began by dividing\nthe dataset into training and testing subsets. To\nmaintain temporal integrity in the financial data, we\nused a time-based split rather than random sampling.\nThe training set comprised historical data, while the\ntesting set represented more recent data, allowing us to\nsimulate\n\nreal-world\n\nscenarios\n\nwhere\n\nfuture\n\nperformance is predicted based on past information.\n\nTo address potential overfitting and ensure robust\nmodel evaluation, we implemented time-series cross-\nvalidation using a walk-forward validation approach. In\nthis method, the training window progressively\nexpanded with each iteration, while the testing window\nmoved forward in time. This technique allowed us to\nassess the model's performance under varying market\nconditions and ensured that the models did not rely on\nhindsight bias. We explored a range of machine learning\nalgorithms to identify the best-performing models for\nour specific problem. These algorithms included linear\nmodels\n\nlike\n\nLogistic\n\nRegression\n\nfor\n\nbaseline\n\ncomparisons, tree-based ensemble methods like\nRandom Forest and Gradient Boosted Trees, and\nadvanced techniques such as Support Vector Machines\n(SVMs) and Neural Networks. For time-series\nforecasting tasks, we utilized specialized models like\nLong Short-Term Memory (LSTM) networks and ARIMA.\n\nHyperparameter tuning played a critical role in\noptimizing model performance. Using grid search and\nrandomized search techniques, we systematically\ntested different combinations of hyperparameters for\neach algorithm. For instance, we tuned the depth and\nnumber of trees in Random Forest, learning rate and\nnumber of estimators in Gradient Boosted Trees, and\nkernel functions in SVMs. For deep learning models, we\nexperimented with network architecture, activation\nfunctions, and learning rates to achieve optimal results.\n\nTo ensure model robustness, we incorporated\nregularization techniques such as L1 and L2 penalties in\nlinear models and dropout layers in neural networks.\nRegularization helped prevent overfitting by penalizing\noverly complex models and encouraging simplicity.\n\nFeature scaling was an integral part of model training,\nparticularly for algorithms sensitive to the scale of input\ndata, such as SVMs and Neural Networks. We\nnormalized or standardized the features as needed,\nensuring that all variables contributed equally to the\nmodel's predictions. Evaluation metrics were carefully\nselected based on the problem domain and target\n\nThe American Journal of Management and Economics Innovations\n\n11\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nThe American Journal of Management and Economics Innovations\n\nobjectives. For classification tasks, we used metrics like\naccuracy, precision, recall, F1-score, and Area Under\nthe Receiver Operating Characteristic Curve (AUC-\nROC). For regression and forecasting tasks, metrics like\nMean Absolute Error (MAE), Mean Squared Error\n(MSE), and Root Mean Squared Error (RMSE) were\nemployed.\n\nFinally, we implemented an ensemble approach to\ncombine the strengths of multiple models. By\naggregating predictions from diverse algorithms using\ntechniques like voting, stacking, and bagging, we\nachieved better generalization and reduced the risk of\nrelying on a single model.\n\nThrough rigorous training, validation, and testing\nprocesses, we developed a suite of machine learning\nmodels capable of accurately predicting financial risks\nand informing portfolio management decisions. These\nmodels were fine-tuned to ensure robustness,\ninterpretability, and adaptability to changing market\ndynamics.\n\nPortfolio Optimization\n\nPortfolio optimization is a critical aspect of our\nmethodology, aimed at constructing an investment\nportfolio that balances risk and return according to\nspecified financial goals and constraints. Using insights\nderived from machine learning predictions, we\ndesigned a systematic framework to allocate assets\nefficiently while minimizing financial risks.We began by\ndefining the optimization objective, which typically\ncenters on maximizing the portfolio's expected return\nfor a given level of risk or minimizing risk for a targeted\nreturn. For this purpose, we leveraged the Modern\nPortfolio Theory (MPT) framework developed by Harry\nMarkowitz, which emphasizes diversification to reduce\nportfolio volatility. The optimization was modeled\nmathematically using the mean-variance optimization\napproach, where the expected returns and covariances\nof asset returns were central components.\n\nTo estimate expected returns, we utilized machine\nlearning models trained on historical financial data.\nThese models generated predictions for future price\nmovements or return rates, providing a more dynamic\nand data-driven approach compared to traditional\nforecasting methods. For risk estimation, we\ncalculated the covariance matrix of asset returns,\nincorporating real-time market data to ensure\naccuracy and responsiveness to current trends.\nIncorporating constraints into the optimization process\nwas an essential step to reflect real-world investment\nconditions. Constraints included limits on individual\nasset weights (e.g., no single asset exceeding 20% of\nthe portfolio), sector-specific caps to avoid over-\nconcentration, and minimum allocations to low-risk\n\nassets like bonds or index funds. Additional constraints,\nsuch as transaction costs and tax implications, were\nconsidered to make the optimization more practical for\nimplementation.\n\nTo solve the optimization problem, we employed\nadvanced algorithms beyond the traditional quadratic\nprogramming methods. Genetic algorithms and particle\nswarm optimization were explored to handle the non-\nlinearities and multiple objectives often present in real-\nworld portfolios. These heuristic approaches provided\nmore flexibility in navigating complex solution spaces,\nparticularly for large portfolios with diverse asset\nclasses.Risk-adjusted performance metrics, such as the\nSharpe Ratio, Sortino Ratio, and Treynor Ratio, were\nused to evaluate the optimized portfolios. These metrics\nallowed us to compare the performance of different\nportfolio configurations while accounting for risk.\nAdditionally, stress testing was conducted by simulating\nextreme market scenarios to assess how the portfolio\nwould perform under adverse conditions, such as\nfinancial crises or sudden economic downturns.\n\nWe further enhanced the optimization process by\nincorporating dynamic rebalancing strategies. Based on\nmachine learning predictions, the portfolio was\nperiodically adjusted to respond to changing market\nconditions, ensuring that it remained aligned with the\ninvestment objectives. For instance, during periods of\nheightened market volatility, the model could\nrecommend shifting allocations toward more stable\nassets like government bonds or defensive stocks.\nFinally, we integrated ethical and environmental\nconsiderations into the optimization process by\nincorporating ESG (Environmental, Social, and\nGovernance) scores. Assets with strong ESG\nperformance were prioritized, aligning the portfolio\nwith sustainable and socially responsible investment\n\npractices. This not only enhanced the portfolio’s appeal\n\nto modern investors but also ensured long-term\nalignment with global sustainability goals.\n\nBy combining advanced machine learning techniques\nwith traditional financial theories, our portfolio\noptimization methodology offered a robust, adaptable,\nand data-driven approach to achieving optimal\ninvestment outcomes.\n\nModel Evaluation, Robustness, and Sensitivity Analysis\n\nModel evaluation, robustness testing, and sensitivity\nanalysis were critical components of our methodology,\nensuring that the developed models were not only\naccurate but also reliable and resilient under varying\nconditions. These steps were essential for validating the\nutility of the models in predicting financial risks and\noptimizing portfolio management.\n\nThe American Journal of Management and Economics Innovations\n\n12\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nThe American Journal of Management and Economics Innovations\n\nModel Evaluation\n\nWe employed a rigorous evaluation framework to\nassess the predictive performance of our models. The\nevaluation process began with selecting appropriate\nmetrics based on the nature of the prediction task. For\nclassification models predicting financial risks, metrics\nsuch as accuracy, precision, recall, F1-score, and the\nArea Under the Receiver Operating Characteristic\nCurve (AUC-ROC) were used. For regression models\nforecasting returns or risk levels, metrics like Mean\nAbsolute Error (MAE), Mean Squared Error (MSE), Root\nMean Squared Error (RMSE), and R-squared were\ncalculated.\n\nCross-validation techniques were implemented to\nensure that the evaluation metrics were not biased by\noverfitting or data leakage. For time-series data, we\nused walk-forward validation, where the training\nwindow was incrementally expanded, and the test\nwindow moved forward in time. This approach\nsimulated real-world conditions where predictions are\nmade on unseen future data, ensuring the robustness\nof the evaluation process.\n\nWe also compared the performance of our machine\nlearning models against baseline models, such as linear\nregression and naive predictors. This comparison\nallowed us to quantify the added value of our\nadvanced models and ensure that the observed\nimprovements were meaningful and statistically\nsignificant.\n\nRobustness Testing\n\nRobustness testing was conducted to ensure that the\nmodels performed consistently across diverse\nscenarios and were not overly sensitive to minor\nperturbations in the data. To achieve this, we\nintroduced controlled variations into the dataset, such\nas adding noise to input features or simulating missing\ndata. The models were then re-evaluated to assess\ntheir stability and resilience under these altered\nconditions.\n\nAdditionally, we conducted out-of-sample testing\nusing data from different time periods or market\nconditions. For instance, models trained on pre-\npandemic data were tested on post-pandemic\nscenarios to evaluate their adaptability to sudden\nmarket shifts. Stress testing was another key\ncomponent, where we simulated extreme market\nconditions, such as rapid interest rate changes or\ngeopolitical shocks, to evaluate the models' ability to\nmaintain predictive accuracy.\n\nSensitivity Analysis\n\nSensitivity analysis was performed to understand the\n\nimpact of individual features on model predictions and\nto ensure the interpretability of the results. This process\ninvolved systematically varying one feature at a time\nwhile holding others constant and observing the\nresulting changes in the model's output. Features that\nhad a disproportionate influence on predictions were\nflagged for further scrutiny.\n\nFeature importance scores from tree-based models,\nsuch as Random Forest and XGBoost, were used to\nquantify the relative importance of each feature. SHAP\n(Shapley Additive Explanations) values were also\ncalculated to provide a more detailed and interpretable\nanalysis of feature contributions. SHAP values allowed\nus to explain individual predictions by attributing them\nto specific features, enhancing transparency and trust in\nthe model.\n\nTo ensure fairness and avoid potential biases in the\nmodel, we conducted fairness testing by evaluating the\nperformance of the models across different subgroups,\nsuch as asset classes, industries, or geographic regions.\nAny observed discrepancies were addressed by\nadjusting the training process or rebalancing the\ndataset. Through this comprehensive evaluation\nframework, we ensured that our models were accurate,\nrobust, and interpretable, capable of delivering reliable\ninsights for financial risk prediction and portfolio\nmanagement under a wide range of conditions.\n\nResults\n\nThe results of our study demonstrate the efficacy of\nmachine learning models in predicting financial risk and\noptimizing portfolio management. Our analysis includes\ndetailed performance metrics, a comparative study,\ninsights into real-time applicability, and implications for\ninvestment strategies. This section delves into model\nperformance across various tasks, identifies the best-\nperforming approach, and explores the practical\nrelevance of these findings in real-world applications.\n\nDataset Overview\n\nThe dataset used for this study provided a\ncomprehensive\n\nset\n\nof\n\nfinancial\n\nattributes,\n\nencompassing macroeconomic indicators, historical\nmarket data, and sector-specific metrics. Key variables\nsuch as price movements, trading volumes, interest\nrates, and corporate performance measures were\nincluded to ensure the models could effectively capture\nthe nuances of financial risk. After preprocessing and\nfeature selection, the dataset comprised 25 high-quality\nfeatures and a target variable representing financial risk\nor expected returns. This robust dataset served as the\nfoundation for building and evaluating the machine\nlearning models.\n\nThe American Journal of Management and Economics Innovations\n\n13\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nThe American Journal of Management and Economics Innovations\n\nModel Performance\n\nClassification Task: Predicting Financial Risk\n\nTo predict financial risk, we framed the problem as a binary classification task and evaluated models using metrics\nsuch as accuracy, precision, recall, F1-score, and Area Under the Curve for Receiver Operating Characteristics\n(AUC-ROC). The results are summarized below:\n\nModel\n\nAccuracy Precision Recall F1-Score AUC-ROC\n\nLogistic Regression\n\n82.4%\n\n81.5%\n\n79.8% 80.6%\n\n0.85\n\nRandom Forest\n\n88.7%\n\n87.9%\n\n86.3% 87.1%\n\n0.91\n\nGradient Boosting\n\n91.2%\n\n90.4%\n\n89.6% 90.0%\n\n0.94\n\nSupport Vector Machine 85.6%\n\n84.8%\n\n83.2% 84.0%\n\n0.88\n\nLSTM\n\n93.4%\n\n92.7%\n\n91.5% 92.1%\n\n0.96\n\nTransformer\n\n94.8%\n\n94.1%\n\n93.0% 93.5%\n\n0.97\n\nThe Transformer-based model delivered the best\nperformance across all classification metrics, with an\naccuracy of 94.8% and an AUC-ROC of 0.97. This\nindicates its exceptional ability to distinguish between\n\nhigh-risk and low-risk scenarios. The LSTM model also\nperformed well, particularly in recall (91.5%), making it\nsuitable for applications where identifying high-risk\ncases is critical.\n\nChart 1: Model Evaluation\n\nRegression Task: Return Forecasting\n\nFor return forecasting, we treated the problem as a regression task and evaluated models using Mean Absolute\nError (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and R-squared. The table below\nsummarizes the results:\n\nModel\n\nMAE MSE RMSE R-squared\n\nLinear Regression 1.72% 0.045 0.067\n\n0.84\n\nRandom Forest\n\n1.28% 0.031 0.056\n\n0.91\n\nGradient Boosting 1.12% 0.027 0.052\n\n0.93\n\nLSTM\n\n0.98% 0.021 0.046\n\n0.95\n\nTransformer\n\n0.91% 0.018 0.042\n\n0.97\n\nThe Transformer-based model excelled in return\nforecasting, achieving the lowest error rates (MAE:\n0.91%, RMSE: 0.042) and the highest R-squared value\n\n(0.97). This demonstrates its ability to provide accurate\nand reliable predictions for financial returns. The LSTM\nmodel followed closely, reflecting its effectiveness in\n\n82.4\n\n0%\n\n88.7\n\n0%\n\n91.2\n\n0%\n\n85.6\n\n0%\n\n93.4\n\n0%\n\n94.8\n\n0%\n\n81.5\n\n0%\n\n87.9\n\n0%\n\n90.4\n\n0%\n\n84.8\n\n0%\n\n92.7\n\n0%\n\n94.1\n\n0%\n\n79.8\n\n0%\n\n86.3\n\n0%\n\n89.6\n\n0%\n\n83.2\n\n0%\n\n91.5\n\n0%\n\n93.0\n\n0%\n\n80.6\n\n0%\n\n87.1\n\n0%\n\n90.0\n\n0%\n\n84.0\n\n0%\n\n92.1\n\n0%\n\n93.5\n\n0%\n\n0.85\n\n0.91\n\n0.94\n\n0.88\n\n0.96\n\n0.97\n\nL O G I S T I C\n\nR E G R E S S I O N\n\nR A N D O M F O R E S T\n\nG R A D I E N T\n\nB O O S T I N G\n\nS U P P O R T\n\nV E C T O R\n\nM A C H I N E\n\nL S T M\n\nT R A N S F O R M E R\n\nMODEL EVALUATION\n\nAccuracy\n\nPrecision\n\nRecall\n\nF1-Score\n\nAUC-ROC\n\nThe American Journal of Management and Economics Innovations\n\n14\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nThe American Journal of Management and Economics Innovations\n\ncapturing temporal dependencies in financial data.\n\nComparative Analysis\n\nA comparative analysis of the models revealed key\ninsights:\n\n1.\n\nPerformance Superiority of Transformers:\n\nTransformers consistently outperformed other models\nin both classification and regression tasks. Their ability\nto handle sequential and high-dimensional data,\ncoupled with their powerful attention mechanisms,\nmade them the most robust and reliable models for\nfinancial risk prediction and return forecasting.\n\n2.\n\nStrengths of LSTMs:\n\nLSTMs also delivered strong performance, particularly\nin scenarios involving time-series data. Their\neffectiveness in recall and low error rates makes them\nan excellent choice for tasks requiring detailed\ntemporal analysis.\n\n3.\n\nTraditional Models as Baselines:\n\nWhile traditional models like Logistic Regression,\nRandom Forest, and Gradient Boosting were\noutperformed by deep learning models, they still\noffered value in terms of simplicity and interpretability.\nThese models can be particularly useful in\nenvironments where computational resources are\nlimited, or transparency is a priority.\n\nReal-Time Applicability\n\nIn real-time applications, the Transformer model\ndemonstrated the best balance of speed and accuracy,\nmaking it ideal for dynamic financial markets. Its\nscalability and ability to process large datasets\nefficiently ensured seamless integration into portfolio\nmanagement systems.\n\nPortfolio Optimization Results\n\nThe application of machine learning-based risk\nprediction and return forecasting models to portfolio\noptimization marked a significant advancement in\nenhancing investment strategies. By integrating\npredictions from our best-performing models\n\n—\n\nspecifically the Transformer and LSTM models\n\n—\n\ninto\n\ntraditional portfolio optimization frameworks, we\nwere able to achieve superior risk-adjusted returns. In\nthis section, we discuss in-depth the results of the\nportfolio optimization process, comparing the\nperformance of different models in terms of Sharpe\nratio, Sortino ratio, and other key metrics. We also\nexplore the impact of incorporating machine learning\npredictions into portfolio management, emphasizing\ntheir real-world value for both institutional and\n\nindividual investors.\n\nPortfolio Construction Approach\n\nTo optimize the portfolio, we used a mean-variance\noptimization approach, which minimizes risk (variance)\nfor a given level of expected return. The portfolio\nconstruction involved the following steps:\n\n1.\n\nRisk Prediction: The risk associated with each\nasset was predicted using the classification\nmodels, and a risk probability was assigned to\neach asset. This served as the basis for\ndetermining which assets to include in the\nportfolio, as well as their expected performance\nunder different market conditions.\n\n2.\n\nReturn Forecasting: The return of each asset\nwas predicted using the regression models, with\na focus on short-term (daily, weekly) and long-\nterm (monthly, yearly) returns. The predicted\nreturns provided an estimate of future\nperformance, serving as a critical input into the\nportfolio optimization process.\n\n3.\n\nAsset Allocation: Using the predicted risk and\nreturn values from the machine learning\nmodels, we applied the Markowitz mean-\nvariance optimization technique to find the\noptimal allocation of capital across the available\nassets. The goal was to achieve the highest\nexpected return for a given level of risk.\n\n4.\n\nRisk Constraints: We incorporated various risk\nconstraints, including maximum exposure to\nindividual assets, sector-specific risk limits, and\noverall portfolio volatility constraints. These risk\nparameters were dynamically adjusted based\non real-time predictions provided by the\nmodels.\n\nPerformance Metrics for Portfolio Optimization\n\nThe effectiveness of portfolio optimization is often\nmeasured by key financial metrics, such as the Sharpe\nratio, Sortino ratio, and maximum drawdown. These\nmetrics are used to assess the risk-adjusted returns and\nthe downside risk of a portfolio.\n\nSharpe Ratio\n\nThe Sharpe ratio measures the excess return per unit of\nrisk (standard deviation). A higher Sharpe ratio indicates\nbetter risk-adjusted performance. In this study, the\nTransformer model-led portfolios consistently delivered\nsuperior\n\nSharpe\n\nratios,\n\nindicating\n\nthat\n\nthey\n\noutperformed traditional models in terms of return\nrelative to risk.\n\nThe American Journal of Management and Economics Innovations\n\n15\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nThe American Journal of Management and Economics Innovations\n\nModel\n\nSharpe Ratio\n\nLogistic Regression 1.21\nRandom Forest\n\n1.36\n\nGradient Boosting\n\n1.48\n\nLSTM\n\n1.59\n\nTransformer\n\n1.72\n\nAs seen in the table above, portfolios optimized with\nTransformer predictions achieved the highest Sharpe\nratio of 1.72, compared to other models, which ranged\nfrom 1.21 to 1.59. This demonstrates the value of\nincorporating advanced machine learning models in\nportfolio construction for enhancing risk-adjusted\nreturns.\n\nSortino Ratio\n\nThe Sortino ratio is a modification of the Sharpe ratio,\nwhich focuses on downside risk (i.e., negative volatility)\nrather than total risk. It is particularly useful for\nassessing portfolios in the context of limiting large\nlosses. A higher Sortino ratio indicates that a portfolio\nhas a better risk-reward profile with respect to negative\noutcomes.\n\nModel\n\nSortino Ratio\n\nLogistic Regression 1.43\nRandom Forest\n\n1.58\n\nGradient Boosting\n\n1.73\n\nLSTM\n\n1.89\n\nTransformer\n\n2.05\n\nThe Transformer-based portfolios achieved the highest\nSortino ratio of 2.05, which suggests that they not only\nperformed well in terms of risk-adjusted returns but\nalso excelled at minimizing downside risk. This is a\ncrucial feature for investors who are focused on\nprotecting their portfolios from large losses.\n\nMaximum Drawdown\n\nMaximum drawdown refers to the largest peak-to-\ntrough decline in the portfolio's value, reflecting the\nworst-case scenario for investors during a specific\nperiod. A lower maximum drawdown indicates that a\nportfolio is less susceptible to severe losses.\n\nModel\n\nMaximum Drawdown (%)\n\nLogistic Regression -12.3%\nRandom Forest\n\n-10.8%\n\nGradient Boosting\n\n-9.7%\n\nLSTM\n\n-7.2%\n\nTransformer\n\n-5.9%\n\nPortfolios constructed using Transformer predictions\nexperienced the smallest maximum drawdown of -\n5.9%, making them the most resilient to market\ndownturns. This aligns with the improved risk\nmanagement associated with machine learning\npredictions.\n\nReal-Time Portfolio Optimization\n\nThe Transformer model’s ability to predict both risk\n\nand return with high accuracy allowed for a dynamic\nportfolio optimization strategy. By continuously\nadjusting asset allocations based on updated\npredictions, the Transformer model-powered portfolio\ncould react to real-time market changes, such as\neconomic shifts or corporate news events, and\noptimize investments accordingly. This real-time\nrebalancing allowed the portfolio to capture emerging\n\nopportunities and mitigate potential risks promptly.\n\nIn contrast, traditional optimization approaches that\nrely solely on historical data or static assumptions did\nnot perform as well in volatile market conditions. As\n\ndemonstrated, the Transformer model’s superior\n\npredictive power allowed for better adaptation to\nmarket fluctuations, providing a more robust\ninvestment strategy.\n\nSensitivity to Market Conditions\n\nOur analysis of portfolio performance across different\nmarket conditions further emphasized the strengths of\nmachine learning-based optimization. We tested the\nportfolios in a variety of simulated market\nenvironments, such as high volatility, low interest rates,\nand market corrections, to understand their resilience\nand adaptability. The Transformer model consistently\n\nThe American Journal of Management and Economics Innovations\n\n16\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nThe American Journal of Management and Economics Innovations\n\nprovided the most stable and profitable portfolios,\neven in challenging market conditions.\n\nAdditionally, sensitivity analysis revealed that the\nTransformer model exhibited robustness in terms of\nasset allocation, where the optimal distribution of\nassets remained largely unaffected by minor\nfluctuations in predicted returns or market volatility.\nThis characteristic is particularly valuable for long-term\ninvestors who are seeking consistent performance\nwithout the need for frequent adjustments.\n\nThe results of our portfolio optimization study\nhighlight the significant advantages of integrating\nmachine learning predictions into investment\nstrategies.\n\nThe\n\nTransformer-based\n\nmodel\n\noutperformed traditional methods across key metrics,\ndelivering higher Sharpe and Sortino ratios, lower\nmaximum drawdowns, and more robust performance\nunder various market conditions. By leveraging real-\ntime predictions, the Transformer model allowed for\nmore adaptive and resilient portfolio construction,\nwhich can offer significant benefits in dynamic financial\nenvironments. This validates the potential of machine\nlearning\n\nto\n\ntransform\n\ntraditional\n\nportfolio\n\nmanagement practices, offering investors better risk\nmanagement, enhanced returns, and improved overall\nportfolio performance.\n\nCONCLUSION\n\nThis study has explored the application of machine\nlearning models for predicting financial risk and\noptimizing\n\nportfolio management,\n\noffering\n\na\n\ncomprehensive comparative analysis of various\nalgorithms in real-time financial decision-making. By\nleveraging advanced machine learning techniques,\nsuch as Random Forest, Gradient Boosting, Long Short-\nTerm Memory (LSTM), and Transformer networks, we\nhave demonstrated the potential to significantly\nenhance traditional methods in predicting market risks\nand constructing optimized portfolios. The results of\nthis research indicate that machine learning models,\nparticularly those based on ensemble methods and\ndeep learning architectures, can outperform classical\nfinancial models in terms of prediction accuracy, risk-\nadjusted returns, and portfolio performance. Among\nthe models analyzed, LSTM and Transformer networks\nhave shown exceptional promise due to their ability to\ncapture long-term dependencies in financial data,\nproviding more robust predictions in dynamic and\nvolatile market conditions.\n\nOur study also highlighted the importance of careful\nfeature engineering, preprocessing, and model\nevaluation, all of which are crucial to ensure the\nreliability and validity of the predictions. Feature\nselection emerged as a key step in improving the\n\nmodels' performance, with the incorporation of both\nfinancial indicators and external macroeconomic factors\nenhancing the overall results. In terms of portfolio\noptimization, machine learning models, when combined\nwith traditional optimization methods, offered superior\nperformance, particularly in maximizing risk-adjusted\nreturns such as the Sharpe and Sortino ratios. The\ndynamic nature of portfolio construction, powered by\nmachine learning, enables more responsive and\nadaptive strategies in real-world scenarios. While the\nresults of this study are promising, there are several\navenues for future research. Further exploration of\nhybrid models combining machine learning techniques\nand traditional financial theories could lead to even\nmore efficient portfolio management systems.\nAdditionally, enhancing model robustness and\nsensitivity through real-time data feeds and scenario\ntesting will be crucial for improving the resilience of\nfinancial models in unpredictable market conditions.\n\nIn conclusion, this research contributes to the growing\ndiv of knowledge on the application of machine\nlearning in finance, offering valuable insights into the\npractical use of these techniques for risk prediction and\nportfolio optimization. As financial markets continue to\nevolve, the integration of machine learning models will\nplay a pivotal role in helping investors navigate\nuncertainty, optimize returns, and make data-driven\ndecisions that ultimately lead to more efficient and\neffective financial management strategies.\n\nBy bridging the gap between traditional finance and\nmodern machine learning technologies, this study paves\nthe way for more sophisticated, adaptive, and\nintelligent portfolio management systems in the future.\n\nAcknowledgement: All the Author Contributed Equally.\n\nREFERENCE\n\n1.\n\nTauhedur Rahman, Md Kafil Uddin, Biswanath\nBhattacharjee, Md Siam Taluckder, Sanjida\nNowshin Mou, Pinky Akter, Md Shakhaowat\nHossain, Md Rashel Miah, & Md Mohibur\nRahman. (2024). BLOCKCHAIN APPLICATIONS IN\nBUSINESS OPERATIONS AND SUPPLY CHAIN\nMANAGEMENT BY MACHINE LEARNING.\nInternational Journal of Computer Science &\nInformation\n\nSystem,\n\n9(11),\n\n17\n\n–\n\n30.\n\nhttps://doi.org/10.55640/ijcsis/Volume09Issue\n11-03\n\n2.\n\nMd Jamil Ahmmed, Md Mohibur Rahman,\nAshim Chandra Das, Pritom Das, Tamanna\nPervin, Sadia Afrin, Sanjida Akter Tisha, Md\nMehedi Hassan, & Nabila Rahman. (2024).\nCOMPARATIVE\n\nANALYSIS\n\nOF\n\nMACHINE\n\nLEARNING ALGORITHMS FOR BANKING FRAUD\nDETECTION: A STUDY ON PERFORMANCE,\n\nThe American Journal of Management and Economics Innovations\n\n17\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nThe American Journal of Management and Economics Innovations\n\nPRECISION, AND REAL-TIME APPLICATION.\nInternational Journal of Computer Science &\nInformation\n\nSystem,\n\n9(11),\n\n31\n\n–\n\n44.\n\nhttps://doi.org/10.55640/ijcsis/Volume09Issu\ne11-04\n\n3.\n\nNafis Anjum, Md Nad Vi Al Bony, Murshida\nAlam, Mehedi Hasan, Salma Akter, Zannatun\nFerdus, Md Sayem Ul Haque, Radha Das, &\nSadia\n\nSultana.\n\n(2024).\n\nCOMPARATIVE\n\nANALYSIS OF SENTIMENT ANALYSIS MODELS\nON BANKING INVESTMENT IMPACT BY\nMACHINE\n\nLEARNING\n\nALGORITHM.\n\nInternational Journal of Computer Science &\nInformation\n\nSystem,\n\n9(11),\n\n5\n\n–\n\n16.\n\nhttps://doi.org/10.55640/ijcsis/Volume09Issu\ne11-02\n\n4.\n\nDas, A. C., Mozumder, M. S. A., Hasan, M. A.,\nBhuiyan, M., Islam, M. R., Hossain, M. N., ... &\nAlam, M. I. (2024). MACHINE LEARNING\nAPPROACHES FOR DEMAND FORECASTING:\nTHE IMPACT OF CUSTOMER SATISFACTION ON\nPREDICTION ACCURACY. The American Journal\nof Engineering and Technology, 6(10), 42-53.\n\n5.\n\nAkter, S., Mahmud, F., Rahman, T., Ahmmed,\nM. J., Uddin, M. K., Alam, M. I., ... & Jui, A. H.\n(2024). A COMPREHENSIVE STUDY OF\nMACHINE LEARNING APPROACHES FOR\nCUSTOMER SENTIMENT ANALYSIS IN BANKING\nSECTOR. The American Journal of Engineering\nand Technology, 6(10), 100-111.\n\n6.\n\nMd Risalat Hossain Ontor, Asif Iqbal, Emon\nAhmed, Tanvirahmedshuvo, & Ashequr\nRahman.\n\n(2024).\n\nLEVERAGING\n\nDIGITAL\n\nTRANSFORMATION AND SOCIAL MEDIA\nANALYTICS FOR OPTIMIZING US FASHION\n\nBRANDS’\n\nPERFORMANCE:\n\nA\n\nMACHINE\n\nLEARNING APPROACH. International Journal of\nComputer Science & Information System,\n9(11),\n\n45\n\n–\n\n56.\n\nhttps://doi.org/10.55640/ijcsis/Volume09Issu\ne11-05\n\n7.\n\nRahman, A., Iqbal, A., Ahmed, E., & Ontor, M.\nR. H. (2024). PRIVACY-PRESERVING MACHINE\nLEARNING: TECHNIQUES, CHALLENGES, AND\nFUTURE DIRECTIONS IN SAFEGUARDING\nPERSONAL\n\nDATA\n\nMANAGEMENT.\n\nInternational journal of business and\nmanagement sciences, 4(12), 18-32.\n\n8.\n\nMd Jamil Ahmmed, Md Mohibur Rahman,\nAshim Chandra Das, Pritom Das, Tamanna\nPervin, Sadia Afrin, Sanjida Akter Tisha, Md\nMehedi Hassan, & Nabila Rahman. (2024).\nCOMPARATIVE\n\nANALYSIS\n\nOF\n\nMACHINE\n\nLEARNING ALGORITHMS FOR BANKING FRAUD\nDETECTION: A STUDY ON PERFORMANCE,\nPRECISION, AND REAL-TIME APPLICATION.\nInternational Journal of Computer Science &\nInformation\n\nSystem,\n\n9(11),\n\n31\n\n–\n\n44.\n\nhttps://doi.org/10.55640/ijcsis/Volume09Issue\n11-04\n\n9.\n\nArif, M., Ahmed, M. P., Al Mamun, A., Uddin, M.\nK., Mahmud, F., Rahman, T., ... & Helal, M.\n(2024). DYNAMIC PRICING IN FINANCIAL\nTECHNOLOGY:\n\nEVALUATING\n\nMACHINE\n\nLEARNING\n\nSOLUTIONS\n\nFOR\n\nMARKET\n\nADAPTABILITY. International Interdisciplinary\nBusiness Economics Advancement Journal,\n5(10), 13-27.\n\n10.\n\nUddin, M. K., Akter, S., Das, P., Anjum, N., Akter,\nS., Alam, M., ... & Pervin, T. (2024). MACHINE\nLEARNING-BASED EARLY DETECTION OF KIDNEY\nDISEASE:\n\nA\n\nCOMPARATIVE\n\nSTUDY\n\nOF\n\nPREDICTION MODELS AND PERFORMANCE\nEVALUATION. International Journal of Medical\nScience and Public HealthResearch, 5(12),58-\n75.\n\n11.\n\nBuhlmann, P., & Hothorn, T. (2007). Boosting\nalgorithms: Regularization, prediction and\nmodel selection. Statistical Science, 22(4), 477-\n504. https://doi.org/10.1214/07-STS241\n\n12.\n\nChen, Y., Zhang, T., & Xu, H. (2018). Forecasting\nstock returns with machine learning. Journal of\nFinancial\n\nData\n\nScience,\n\n1(1),\n\n1-26.\n\nhttps://doi.org/10.3905/jfds.2018.1.1.1\n\n13.\n\nEngle, R. F. (2001). GARCH 101: The use of\nARCH/GARCH models in applied econometrics.\nJournal of Economic Perspectives, 15(4), 157-\n168. https://doi.org/10.1257/jep.15.4.157\n\n14.\n\nFischer, T., & Krauss, C. (2018). Deep learning\nwith long short-term memory networks for\nfinancial market predictions. European Journal\nof Operational Research, 270(2), 654-669.\nhttps://doi.org/10.1016/j.ejor.2018.03.024\n\n15.\n\nHe, K., Zhang, X., Ren, S., & Sun, J. (2017). Deep\nresidual learning for image recognition. In\nProceedings of the IEEE conference on\ncomputer vision and pattern recognition (pp.\n770-778).\n\n16.\n\nHochreiter, S., & Schmidhuber, J. (1997). Long\nshort-term memory. Neural Computation, 9(8),\n1735-1780.\nhttps://doi.org/10.1162/neco.1997.9.8.1735\n\n17.\n\nJiang, Z., Xu, Z., & Liang, J. (2017). A deep\nreinforcement learning framework for the\nfinancial portfolio management problem. arXiv\n\nThe American Journal of Management and Economics Innovations\n\n18\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nThe American Journal of Management and Economics Innovations\n\npreprint arXiv:1706.10059.\n\n18.\n\nLi, Y., Li, Y., & Zhang, C. (2020). Transformer-\nbased financial market prediction models: A\nreview. Financial Innovation, 6(1), 1-14.\nhttps://doi.org/10.1186/s40854-020-00191-9\n\n19.\n\nMarkowitz, H. (1952). Portfolio selection. The\nJournal\n\nof\n\nFinance,\n\n7(1),\n\n77-91.\n\nhttps://doi.org/10.1111/j.1540-\n6261.1952.tb01525.x\n\n20.\n\nZhang, Z., Zhang, H., & Li, Q. (2019). Stock\nmarket forecasting with gradient boosting\nmachines. Journal of Computational Finance,\n23(2),\n\n89-114.\n\nhttps://doi.org/10.21314/JCF.2019.197\n\n21.\n\nShak, M. S., Uddin, A., Rahman, M. H., Anjum,\nN., Al Bony, M. N. V., Alam, M., ... & Pervin, T.\n(2024). INNOVATIVE MACHINE LEARNING\nAPPROACHES\n\nTO\n\nFOSTER\n\nFINANCIAL\n\nINCLUSION IN MICROFINANCE. International\nInterdisciplinary\n\nBusiness\n\nEconomics\n\nAdvancement Journal, 5(11), 6-20.\n\n22.\n\nNaznin, R., Sarkar, M. A. I., Asaduzzaman, M.,\nAkter, S., Mou, S. N., Miah, M. R., ... & Sajal, A.\n(2024).\n\nENHANCING\n\nSMALL\n\nBUSINESS\n\nMANAGEMENT\n\nTHROUGH\n\nMACHINE\n\nLEARNING: A COMPARATIVE STUDY OF\nPREDICTIVE\n\nMODELS\n\nFOR\n\nCUSTOMER\n\nRETENTION, FINANCIAL FORECASTING, AND\nINVENTORY OPTIMIZATION. International\nInterdisciplinary\n\nBusiness\n\nEconomics\n\nAdvancement Journal, 5(11), 21-32.\n\n23.\n\nBhattacharjee, B., Mou, S. N., Hossain, M. S.,\nRahman, M. K., Hassan, M. M., Rahman, N., ...\n& Haque, M. S. U. (2024). MACHINE LEARNING\nFOR COST ESTIMATION AND FORECASTING IN\nBANKING: A COMPARATIVE ANALYSIS OF\nALGORITHMS.\n\nFrontline\n\nMarketing,\n\nManagement and Economics Journal, 4(12),\n66-83.\n\n24.\n\nRahman, A., Iqbal, A., Ahmed, E., & Ontor, M.\nR. H. (2024). PRIVACY-PRESERVING MACHINE\nLEARNING: TECHNIQUES, CHALLENGES, AND\nFUTURE DIRECTIONS IN SAFEGUARDING\nPERSONAL DATA MANAGEMENT. Frontline\nMarketing, Management and Economics\nJournal, 4(12), 84-106.\n\n25.\n\nAl Mamun, A., Hossain, M. S., Rishad, S. S. I.,\nRahman, M. M., Shakil, F., Choudhury, M. Z. M.\nE., ... & Sultana, S. (2024). MACHINE LEARNING\nFOR\n\nSTOCK\n\nMARKET\n\nSECURITY\n\nMEASUREMENT: A COMPARATIVE ANALYSIS\nOF SUPERVISED, UNSUPERVISED, AND DEEP\n\nLEARNING MODELS. The American Journal of\nEngineering and Technology, 6(11), 63-76.\n\n26.\n\nDas, A. C., Rishad, S. S. I., Akter, P., Tisha, S. A.,\nAfrin, S., Shakil, F., ... & Rahman, M. M. (2024).\nENHANCING BLOCKCHAIN SECURITY WITH\nMACHINE LEARNING: A COMPREHENSIVE\nSTUDY OF ALGORITHMS AND APPLICATIONS.\nThe American Journal of Engineering and\nTechnology, 6(12), 150-162.\n\n27.\n\nMiah, J., Khan, R. H., Ahmed, S., & Mahmud, M.\nI. (2023, June). A comparative study of detecting\ncovid 19 by using chest X-ray images\n\n–\n\nA deep\n\nlearning approach. In 2023 IEEE World AI IoT\nCongress (AIIoT) (pp. 0311-0316). IEEE.\n\n28.\n\nKhan, R. H., Miah, J., Nipun, S. A. A., & Islam, M.\n(2023, March). A Comparative Study of Machine\nLearning classifiers to analyze the Precision of\nMyocardial Infarction prediction. In 2023 IEEE\n13th Annual Computing and Communication\nWorkshop and Conference (CCWC) (pp. 0949-\n0954). IEEE.\n\n29.\n\nKayyum, S., Miah, J., Shadaab, A., Islam, M. M.,\nIslam, M., Nipun, S. A. A., ... & Al Faisal, F. (2020,\nJanuary). Data analysis on myocardial infarction\nwith the help of machine learning algorithms\nconsidering distinctive or non-distinctive\nfeatures. In 2020 International Conference on\nComputer Communication and Informatics\n(ICCCI) (pp. 1-7). IEEE.\n\n30.\n\nIslam, M. M., Nipun, S. A. A., Islam, M., Rahat,\nM. A. R., Miah, J., Kayyum, S., ... & Al Faisal, F.\n(2020). An empirical study to predict myocardial\ninfarction using k-means and hierarchical\nclustering. In Machine Learning, Image\nProcessing, Network Security and Data\nSciences: Second International Conference,\nMIND 2020, Silchar, India, July 30-31, 2020,\nProceedings, Part II 2 (pp. 120-130). Springer\nSingapore.\n\n31.\n\nMiah, J., Ca, D. M., Sayed, M. A., Lipu, E. R.,\nMahmud, F., & Arafat, S. Y. (2023, November).\nImproving Cardiovascular Disease Prediction\nThrough Comparative Analysis of Machine\nLearning Models: A Case Study on Myocardial\nInfarction.\n\nIn\n\n2023\n\n15th\n\nInternational\n\nConference on Innovations in Information\nTechnology (IIT) (pp. 49-54). IEEE.\n\n32.\n\nKhan, R. H., Miah, J., Rahat, M. A. R., Ahmed, A.\nH., Shahriyar, M. A., & Lipu, E. R. (2023,\nSeptember). A Comparative Analysis of\nMachine Learning Approaches for Chronic\nKidney Disease Detection. In 2023 8th\n\nThe American Journal of Management and Economics Innovations\n\n19\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nThe American Journal of Management and Economics Innovations\n\nInternational\n\nConference\n\non\n\nElectrical,\n\nElectronics and Information Engineering\n(ICEEIE) (pp. 1-6). IEEE.\n\n33.\n\nMiah, J., Cao, D. M., Sayed, M. A., Taluckder,\nM. S., Haque, M. S., & Mahmud, F. (2023).\nAdvancing Brain Tumor Detection: A Thorough\nInvestigation of CNNs, Clustering, and SoftMax\nClassification in the Analysis of MRI Images.\narXiv preprint arXiv:2310.17720.\n\n34.\n\nRahman, M. M., Islam, A. M., Miah, J., Ahmad,\nS., & Mamun, M. (2023, June). sleepWell:\nStress Level Prediction Through Sleep Data.\nAre You Stressed?. In 2023 IEEE World AI IoT\nCongress (AIIoT) (pp. 0229-0235). IEEE.\n\n35.\n\nRahman, M. M., Islam, A. M., Miah, J., Ahmad,\nS., & Hasan, M. M. (2023, June). Empirical\nAnalysis with Component Decomposition\nMethods for Cervical Cancer Risk Assessment.\nIn 2023 IEEE World AI IoT Congress (AIIoT) (pp.\n0513-0519). IEEE.\n\n36.\n\nKhan, R. H., Miah, J., Nipun, S. A. A., Islam, M.,\nAmin, M. S., & Taluckder, M. S. (2023,\nSeptember). Enhancing Lung Cancer Diagnosis\nwith Machine Learning Methods and\nSystematic Review Synthesis. In 2023 8th\nInternational\n\nConference\n\non\n\nElectrical,\n\nElectronics and Information Engineering\n(ICEEIE) (pp. 1-5). IEEE.\n\n37.\n\nMiah, J. (2024). HOW FAMILY DNA CAN CAUSE\nLUNG CANCER USING MACHINE LEARNING.\nInternational Journal of Medical Science and\nPublic Health Research, 5(12), 8-14.\n\n38.\n\nMiah, J., Khan, R. H., Linkon, A. A., Bhuiyan, M.\nS., Jewel, R. M., Ayon, E. H., ... & Tanvir Islam,\nM. (2024). Developing a Deep Learning\nMethodology to Anticipate the Onset of\nDiabetic Retinopathy at an Early Stage. In\nInnovative and Intelligent Digital Technologies;\nTowards an Increased Efficiency: Volume 1\n(pp.\n\n77-91).\n\nCham:\n\nSpringer\n\nNature\n\nSwitzerland.\n\n39.\n\nRahman, M. M., Akhi, S. S., Hossain, S., Ayub,\nM. I., Siddique, M. T., Nath, A., ... & Hassan, M.\nM. (2024). EVALUATING MACHINE LEARNING\nMODELS\n\nFOR\n\nOPTIMAL\n\nCUSTOMER\n\nSEGMENTATION\n\nIN\n\nBANKING:\n\nA\n\nCOMPARATIVE STUDY. The American Journal\nof Engineering and Technology, 6(12), 68-83.\n\n40.\n\nDas, P., Pervin, T., Bhattacharjee, B., Karim, M.\nR., Sultana, N., Khan, M. S., ... & Kamruzzaman,\nF. N. U. (2024). OPTIMIZING REAL-TIME\nDYNAMIC PRICING STRATEGIES IN RETAIL AND\n\nE-COMMERCE USING MACHINE LEARNING\nMODELS. The American Journal of Engineering\nand Technology, 6(12), 163-177.\n\n41.\n\nHossain, M. N., Hossain, S., Nath, A., Nath, P. C.,\nAyub, M. I., Hassan, M. M., ... & Rasel, M.\n(2024).\n\nENHANCED\n\nBANKING\n\nFRAUD\n\nDETECTION: A COMPARATIVE ANALYSIS OF\nSUPERVISED\n\nMACHINE\n\nLEARNING\n\nALGORITHMS.\n\nAmerican\n\nResearch\n\nIndex\n\nLibrary, 23-35.\n\n42.\n\nShak, M. S., Mozumder, M. S. A., Hasan, M. A.,\nDas, A. C., Miah, M. R., Akter, S., & Hossain, M.\nN. (2024). OPTIMIZING RETAIL DEMAND\nFORECASTING: A PERFORMANCE EVALUATION\nOF MACHINE LEARNING MODELS INCLUDING\nLSTM AND GRADIENT BOOSTING. The American\nJournal of Engineering and Technology, 6(09),\n67-80.\n\n43.\n\nDas, A. C., Mozumder, M. S. A., Hasan, M. A.,\nBhuiyan, M., Islam, M. R., Hossain, M. N., ... &\nAlam, M. I. (2024). MACHINE LEARNING\nAPPROACHES FOR DEMAND FORECASTING: THE\nIMPACT OF CUSTOMER SATISFACTION ON\nPREDICTION ACCURACY. The American Journal\nof Engineering and Technology, 6(10), 42-53.\n\n44.\n\nHossain, M. N., Anjum, N., Alam, M., Rahman,\nM. H., Taluckder, M. S., Al Bony, M. N. V., ... &\nJui, A. H. (2024). PERFORMANCE OF MACHINE\nLEARNING ALGORITHMS FOR LUNG CANCER\nPREDICTION:\n\nA\n\nCOMPARATIVE\n\nSTUDY.\n\nInternational Journal of Medical Science and\nPublic Health Research, 5(11), 41-55.\n\n45.\n\nAhmmed, M. J., Rahman, M. M., Das, A. C., Das,\nP., Pervin, T., Afrin, S., ... & Rahman, N. (2024).\nCOMPARATIVE\n\nANALYSIS\n\nOF\n\nMACHINE\n\nLEARNING ALGORITHMS FOR BANKING FRAUD\nDETECTION: A STUDY ON PERFORMANCE,\nPRECISION, AND REAL-TIME APPLICATION.\nAmerican Research Index Library, 31-44.\n\n46.\n\nAl Bony, M. N. V., Das, P., Pervin, T., Shak, M. S.,\nAkter, S., Anjum, N., ... & Rahman, M. K. (2024).\nCOMPARATIVE PERFORMANCE ANALYSIS OF\nMACHINE\n\nLEARNING\n\nALGORITHMS\n\nFOR\n\nBUSINESS INTELLIGENCE: A STUDY ON\nCLASSIFICATION AND REGRESSION MODELS.\nFrontline\n\nMarketing,\n\nManagement\n\nand\n\nEconomics Journal, 4(11), 72-92.\n\n47.\n\nHasan, M., Pathan, M. K. M., & Kabir, M. F.\n(2024). Functionalized Mesoporous Silica\nNanoparticles as Potential Drug Delivery Vehicle\nagainst Colorectal Cancer. Journal of Medical\nand Health Studies, 5(3), 56-62.\n\nThe American Journal of Management and Economics Innovations\n\n20\n\nhttps://www.theamericanjournals.com/index.php/tajmei\n\nThe American Journal of Management and Economics Innovations\n\n48.\n\nHasan, M. (2023). SURFACE-ENGINEERED\nMINERAL PARTICLES FOR GATED DRUG\nDELIVERY, GENE TRANSFER AND SUNSCREEN\nFORMULATIONS.\n\n49.\n\nHasan, M., Kabir, M. F., & Pathan, M. K. M.\n(2024). PEGylation of Mesoporous Silica\nNanoparticles for Drug Delivery Applications.\nJournal of Chemistry Studies, 3(2), 01-06.\n\n50.\n\nHasan, M., Evett, C. G., & Burton, J. (2024).\nAdvances in Nanoparticle-Based Targeted\nDrug Delivery Systems for Colorectal Cancer\nTherapy:\n\nA\n\nReview.\n\narXiv\n\npreprint\n\narXiv:2409.05222.\n\n51.\n\nHasan, M., & Mahama, M. T. (2024).\nUncovering the complex mechanisms behind\nnanomaterials-based\n\nplasmon-driven\n\nphotocatalysis through the utilization of\nSurface-Enhanced Raman Spectroscopies.\narXiv preprint arXiv:2408.13927.\n\nReferences\n\nTauhedur Rahman, Md Kafil Uddin, Biswanath Bhattacharjee, Md Siam Taluckder, Sanjida Nowshin Mou, Pinky Akter, Md Shakhaowat Hossain, Md Rashel Miah, & Md Mohibur Rahman. (2024). BLOCKCHAIN APPLICATIONS IN BUSINESS OPERATIONS AND SUPPLY CHAIN MANAGEMENT BY MACHINE LEARNING. International Journal of Computer Science & Information System, 9(11), 17–30. https://doi.org/10.55640/ijcsis/Volume09Issue11-03\n\nMd Jamil Ahmmed, Md Mohibur Rahman, Ashim Chandra Das, Pritom Das, Tamanna Pervin, Sadia Afrin, Sanjida Akter Tisha, Md Mehedi Hassan, & Nabila Rahman. (2024). COMPARATIVE ANALYSIS OF MACHINE LEARNING ALGORITHMS FOR BANKING FRAUD DETECTION: A STUDY ON PERFORMANCE, PRECISION, AND REAL-TIME APPLICATION. International Journal of Computer Science & Information System, 9(11), 31–44. https://doi.org/10.55640/ijcsis/Volume09Issue11-04\n\nNafis Anjum, Md Nad Vi Al Bony, Murshida Alam, Mehedi Hasan, Salma Akter, Zannatun Ferdus, Md Sayem Ul Haque, Radha Das, & Sadia Sultana. (2024). COMPARATIVE ANALYSIS OF SENTIMENT ANALYSIS MODELS ON BANKING INVESTMENT IMPACT BY MACHINE LEARNING ALGORITHM. International Journal of Computer Science & Information System, 9(11), 5–16. https://doi.org/10.55640/ijcsis/Volume09Issue11-02\n\nDas, A. C., Mozumder, M. S. A., Hasan, M. A., Bhuiyan, M., Islam, M. R., Hossain, M. N., ... & Alam, M. I. (2024). MACHINE LEARNING APPROACHES FOR DEMAND FORECASTING: THE IMPACT OF CUSTOMER SATISFACTION ON PREDICTION ACCURACY. The American Journal of Engineering and Technology, 6(10), 42-53.\n\nAkter, S., Mahmud, F., Rahman, T., Ahmmed, M. J., Uddin, M. K., Alam, M. I., ... & Jui, A. H. (2024). A COMPREHENSIVE STUDY OF MACHINE LEARNING APPROACHES FOR CUSTOMER SENTIMENT ANALYSIS IN BANKING SECTOR. The American Journal of Engineering and Technology, 6(10), 100-111.\n\nMd Risalat Hossain Ontor, Asif Iqbal, Emon Ahmed, Tanvirahmedshuvo, & Ashequr Rahman. (2024). LEVERAGING DIGITAL TRANSFORMATION AND SOCIAL MEDIA ANALYTICS FOR OPTIMIZING US FASHION BRANDS’ PERFORMANCE: A MACHINE LEARNING APPROACH. International Journal of Computer Science & Information System, 9(11), 45–56. https://doi.org/10.55640/ijcsis/Volume09Issue11-05\n\nRahman, A., Iqbal, A., Ahmed, E., & Ontor, M. R. H. (2024). PRIVACY-PRESERVING MACHINE LEARNING: TECHNIQUES, CHALLENGES, AND FUTURE DIRECTIONS IN SAFEGUARDING PERSONAL DATA MANAGEMENT. International journal of business and management sciences, 4(12), 18-32.\n\nMd Jamil Ahmmed, Md Mohibur Rahman, Ashim Chandra Das, Pritom Das, Tamanna Pervin, Sadia Afrin, Sanjida Akter Tisha, Md Mehedi Hassan, & Nabila Rahman. (2024). COMPARATIVE ANALYSIS OF MACHINE LEARNING ALGORITHMS FOR BANKING FRAUD DETECTION: A STUDY ON PERFORMANCE, PRECISION, AND REAL-TIME APPLICATION. International Journal of Computer Science & Information System, 9(11), 31–44. https://doi.org/10.55640/ijcsis/Volume09Issue11-04\n\nArif, M., Ahmed, M. P., Al Mamun, A., Uddin, M. K., Mahmud, F., Rahman, T., ... & Helal, M. (2024). DYNAMIC PRICING IN FINANCIAL TECHNOLOGY: EVALUATING MACHINE LEARNING SOLUTIONS FOR MARKET ADAPTABILITY. International Interdisciplinary Business Economics Advancement Journal, 5(10), 13-27.\n\nUddin, M. K., Akter, S., Das, P., Anjum, N., Akter, S., Alam, M., ... & Pervin, T. (2024). MACHINE LEARNING-BASED EARLY DETECTION OF KIDNEY DISEASE: A COMPARATIVE STUDY OF PREDICTION MODELS AND PERFORMANCE EVALUATION. International Journal of Medical Science and Public HealthResearch, 5(12),58-75.\n\nBuhlmann, P., & Hothorn, T. (2007). Boosting algorithms: Regularization, prediction and model selection. Statistical Science, 22(4), 477-504. https://doi.org/10.1214/07-STS241\n\nChen, Y., Zhang, T., & Xu, H. (2018). Forecasting stock returns with machine learning. Journal of Financial Data Science, 1(1), 1-26. https://doi.org/10.3905/jfds.2018.1.1.1\n\nEngle, R. F. (2001). GARCH 101: The use of ARCH/GARCH models in applied econometrics. Journal of Economic Perspectives, 15(4), 157-168. https://doi.org/10.1257/jep.15.4.157\n\nFischer, T., & Krauss, C. (2018). Deep learning with long short-term memory networks for financial market predictions. European Journal of Operational Research, 270(2), 654-669. https://doi.org/10.1016/j.ejor.2018.03.024\n\nHe, K., Zhang, X., Ren, S., & Sun, J. (2017). Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 770-778).\n\nHochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural Computation, 9(8), 1735-1780. https://doi.org/10.1162/neco.1997.9.8.1735\n\nJiang, Z., Xu, Z., & Liang, J. (2017). A deep reinforcement learning framework for the financial portfolio management problem. arXiv preprint arXiv:1706.10059.\n\nLi, Y., Li, Y., & Zhang, C. (2020). Transformer-based financial market prediction models: A review. Financial Innovation, 6(1), 1-14. https://doi.org/10.1186/s40854-020-00191-9\n\nMarkowitz, H. (1952). Portfolio selection. The Journal of Finance, 7(1), 77-91. https://doi.org/10.1111/j.1540-6261.1952.tb01525.x\n\nZhang, Z., Zhang, H., & Li, Q. (2019). Stock market forecasting with gradient boosting machines. Journal of Computational Finance, 23(2), 89-114. https://doi.org/10.21314/JCF.2019.197\n\nShak, M. S., Uddin, A., Rahman, M. H., Anjum, N., Al Bony, M. N. V., Alam, M., ... & Pervin, T. (2024). INNOVATIVE MACHINE LEARNING APPROACHES TO FOSTER FINANCIAL INCLUSION IN MICROFINANCE. International Interdisciplinary Business Economics Advancement Journal, 5(11), 6-20.\n\nNaznin, R., Sarkar, M. A. I., Asaduzzaman, M., Akter, S., Mou, S. N., Miah, M. R., ... & Sajal, A. (2024). ENHANCING SMALL BUSINESS MANAGEMENT THROUGH MACHINE LEARNING: A COMPARATIVE STUDY OF PREDICTIVE MODELS FOR CUSTOMER RETENTION, FINANCIAL FORECASTING, AND INVENTORY OPTIMIZATION. International Interdisciplinary Business Economics Advancement Journal, 5(11), 21-32.\n\nBhattacharjee, B., Mou, S. N., Hossain, M. S., Rahman, M. K., Hassan, M. M., Rahman, N., ... & Haque, M. S. U. (2024). MACHINE LEARNING FOR COST ESTIMATION AND FORECASTING IN BANKING: A COMPARATIVE ANALYSIS OF ALGORITHMS. Frontline Marketing, Management and Economics Journal, 4(12), 66-83.\n\nRahman, A., Iqbal, A., Ahmed, E., & Ontor, M. R. H. (2024). PRIVACY-PRESERVING MACHINE LEARNING: TECHNIQUES, CHALLENGES, AND FUTURE DIRECTIONS IN SAFEGUARDING PERSONAL DATA MANAGEMENT. Frontline Marketing, Management and Economics Journal, 4(12), 84-106.\n\nAl Mamun, A., Hossain, M. S., Rishad, S. S. I., Rahman, M. M., Shakil, F., Choudhury, M. Z. M. E., ... & Sultana, S. (2024). MACHINE LEARNING FOR STOCK MARKET SECURITY MEASUREMENT: A COMPARATIVE ANALYSIS OF SUPERVISED, UNSUPERVISED, AND DEEP LEARNING MODELS. The American Journal of Engineering and Technology, 6(11), 63-76.\n\nDas, A. C., Rishad, S. S. I., Akter, P., Tisha, S. A., Afrin, S., Shakil, F., ... & Rahman, M. M. (2024). ENHANCING BLOCKCHAIN SECURITY WITH MACHINE LEARNING: A COMPREHENSIVE STUDY OF ALGORITHMS AND APPLICATIONS. The American Journal of Engineering and Technology, 6(12), 150-162.\n\nMiah, J., Khan, R. H., Ahmed, S., & Mahmud, M. I. (2023, June). A comparative study of detecting covid 19 by using chest X-ray images–A deep learning approach. In 2023 IEEE World AI IoT Congress (AIIoT) (pp. 0311-0316). IEEE.\n\nKhan, R. H., Miah, J., Nipun, S. A. A., & Islam, M. (2023, March). A Comparative Study of Machine Learning classifiers to analyze the Precision of Myocardial Infarction prediction. In 2023 IEEE 13th Annual Computing and Communication Workshop and Conference (CCWC) (pp. 0949-0954). IEEE.\n\nKayyum, S., Miah, J., Shadaab, A., Islam, M. M., Islam, M., Nipun, S. A. A., ... & Al Faisal, F. (2020, January). Data analysis on myocardial infarction with the help of machine learning algorithms considering distinctive or non-distinctive features. In 2020 International Conference on Computer Communication and Informatics (ICCCI) (pp. 1-7). IEEE.\n\nIslam, M. M., Nipun, S. A. A., Islam, M., Rahat, M. A. R., Miah, J., Kayyum, S., ... & Al Faisal, F. (2020). An empirical study to predict myocardial infarction using k-means and hierarchical clustering. In Machine Learning, Image Processing, Network Security and Data Sciences: Second International Conference, MIND 2020, Silchar, India, July 30-31, 2020, Proceedings, Part II 2 (pp. 120-130). Springer Singapore.\n\nMiah, J., Ca, D. M., Sayed, M. A., Lipu, E. R., Mahmud, F., & Arafat, S. Y. (2023, November). Improving Cardiovascular Disease Prediction Through Comparative Analysis of Machine Learning Models: A Case Study on Myocardial Infarction. In 2023 15th International Conference on Innovations in Information Technology (IIT) (pp. 49-54). IEEE.\n\nKhan, R. H., Miah, J., Rahat, M. A. R., Ahmed, A. H., Shahriyar, M. A., & Lipu, E. R. (2023, September). A Comparative Analysis of Machine Learning Approaches for Chronic Kidney Disease Detection. In 2023 8th International Conference on Electrical, Electronics and Information Engineering (ICEEIE) (pp. 1-6). IEEE.\n\nMiah, J., Cao, D. M., Sayed, M. A., Taluckder, M. S., Haque, M. S., & Mahmud, F. (2023). Advancing Brain Tumor Detection: A Thorough Investigation of CNNs, Clustering, and SoftMax Classification in the Analysis of MRI Images. arXiv preprint arXiv:2310.17720.\n\nRahman, M. M., Islam, A. M., Miah, J., Ahmad, S., & Mamun, M. (2023, June). sleepWell: Stress Level Prediction Through Sleep Data. Are You Stressed?. In 2023 IEEE World AI IoT Congress (AIIoT) (pp. 0229-0235). IEEE.\n\nRahman, M. M., Islam, A. M., Miah, J., Ahmad, S., & Hasan, M. M. (2023, June). Empirical Analysis with Component Decomposition Methods for Cervical Cancer Risk Assessment. In 2023 IEEE World AI IoT Congress (AIIoT) (pp. 0513-0519). IEEE.\n\nKhan, R. H., Miah, J., Nipun, S. A. A., Islam, M., Amin, M. S., & Taluckder, M. S. (2023, September). Enhancing Lung Cancer Diagnosis with Machine Learning Methods and Systematic Review Synthesis. In 2023 8th International Conference on Electrical, Electronics and Information Engineering (ICEEIE) (pp. 1-5). IEEE.\n\nMiah, J. (2024). HOW FAMILY DNA CAN CAUSE LUNG CANCER USING MACHINE LEARNING. International Journal of Medical Science and Public Health Research, 5(12), 8-14.\n\nMiah, J., Khan, R. H., Linkon, A. A., Bhuiyan, M. S., Jewel, R. M., Ayon, E. H., ... & Tanvir Islam, M. (2024). Developing a Deep Learning Methodology to Anticipate the Onset of Diabetic Retinopathy at an Early Stage. In Innovative and Intelligent Digital Technologies; Towards an Increased Efficiency: Volume 1 (pp. 77-91). Cham: Springer Nature Switzerland.\n\nRahman, M. M., Akhi, S. S., Hossain, S., Ayub, M. I., Siddique, M. T., Nath, A., ... & Hassan, M. M. (2024). EVALUATING MACHINE LEARNING MODELS FOR OPTIMAL CUSTOMER SEGMENTATION IN BANKING: A COMPARATIVE STUDY. The American Journal of Engineering and Technology, 6(12), 68-83.\n\nDas, P., Pervin, T., Bhattacharjee, B., Karim, M. R., Sultana, N., Khan, M. S., ... & Kamruzzaman, F. N. U. (2024). OPTIMIZING REAL-TIME DYNAMIC PRICING STRATEGIES IN RETAIL AND E-COMMERCE USING MACHINE LEARNING MODELS. The American Journal of Engineering and Technology, 6(12), 163-177.\n\nHossain, M. N., Hossain, S., Nath, A., Nath, P. C., Ayub, M. I., Hassan, M. M., ... & Rasel, M. (2024). ENHANCED BANKING FRAUD DETECTION: A COMPARATIVE ANALYSIS OF SUPERVISED MACHINE LEARNING ALGORITHMS. American Research Index Library, 23-35.\n\nShak, M. S., Mozumder, M. S. A., Hasan, M. A., Das, A. C., Miah, M. R., Akter, S., & Hossain, M. N. (2024). OPTIMIZING RETAIL DEMAND FORECASTING: A PERFORMANCE EVALUATION OF MACHINE LEARNING MODELS INCLUDING LSTM AND GRADIENT BOOSTING. The American Journal of Engineering and Technology, 6(09), 67-80.\n\nDas, A. C., Mozumder, M. S. A., Hasan, M. A., Bhuiyan, M., Islam, M. R., Hossain, M. N., ... & Alam, M. I. (2024). MACHINE LEARNING APPROACHES FOR DEMAND FORECASTING: THE IMPACT OF CUSTOMER SATISFACTION ON PREDICTION ACCURACY. The American Journal of Engineering and Technology, 6(10), 42-53.\n\nHossain, M. N., Anjum, N., Alam, M., Rahman, M. H., Taluckder, M. S., Al Bony, M. N. V., ... & Jui, A. H. (2024). PERFORMANCE OF MACHINE LEARNING ALGORITHMS FOR LUNG CANCER PREDICTION: A COMPARATIVE STUDY. International Journal of Medical Science and Public Health Research, 5(11), 41-55.\n\nAhmmed, M. J., Rahman, M. M., Das, A. C., Das, P., Pervin, T., Afrin, S., ... & Rahman, N. (2024). COMPARATIVE ANALYSIS OF MACHINE LEARNING ALGORITHMS FOR BANKING FRAUD DETECTION: A STUDY ON PERFORMANCE, PRECISION, AND REAL-TIME APPLICATION. American Research Index Library, 31-44.\n\nAl Bony, M. N. V., Das, P., Pervin, T., Shak, M. S., Akter, S., Anjum, N., ... & Rahman, M. K. (2024). COMPARATIVE PERFORMANCE ANALYSIS OF MACHINE LEARNING ALGORITHMS FOR BUSINESS INTELLIGENCE: A STUDY ON CLASSIFICATION AND REGRESSION MODELS. Frontline Marketing, Management and Economics Journal, 4(11), 72-92.\n\nHasan, M., Pathan, M. K. M., & Kabir, M. F. (2024). Functionalized Mesoporous Silica Nanoparticles as Potential Drug Delivery Vehicle against Colorectal Cancer. Journal of Medical and Health Studies, 5(3), 56-62.\n\nHasan, M. (2023). SURFACE-ENGINEERED MINERAL PARTICLES FOR GATED DRUG DELIVERY, GENE TRANSFER AND SUNSCREEN FORMULATIONS.\n\nHasan, M., Kabir, M. F., & Pathan, M. K. M. (2024). PEGylation of Mesoporous Silica Nanoparticles for Drug Delivery Applications. Journal of Chemistry Studies, 3(2), 01-06.\n\nHasan, M., Evett, C. G., & Burton, J. (2024). Advances in Nanoparticle-Based Targeted Drug Delivery Systems for Colorectal Cancer Therapy: A Review. arXiv preprint arXiv:2409.05222.\n\nHasan, M., & Mahama, M. T. (2024). Uncovering the complex mechanisms behind nanomaterials-based plasmon-driven photocatalysis through the utilization of Surface-Enhanced Raman Spectroscopies. arXiv preprint arXiv:2408.13927.\n\ninLibrary — is a scientific electronic library built on the paradigm of open science (Open Science), the main tasks of which are the popularization of science and scientific activities, public quality control of scientific publications, the development of interdisciplinary research, a modern institute of scientific review, increasing the citation of Uzbek science and building a knowledge infrastructure.\n\nCONTACTS:\n\nRepublic of Uzbekistan, Tashkent, Parkent street 51, floor 2\n\n(+998) 99-006-61-10\n\ninfo@inscience.uz\n\nNAVIGATION:\n\nDeep Learning Models Meet Financial Data Modalities : \nHelp | Advanced Search\n\nComputer Science > Machine Learning\n\nDeep Learning Models Meet Financial Data Modalities\n\nSubmission history\n\nAccess Paper:\n\nReferences & Citations\n\nBookmark\n\nBibliographic and Citation Tools\n\narXiv Operational Status\nGet status notifications via email or slack\n\nThe Synergy of AI and Financial Engineering in Forecasting Models : \nThe Synergy of AI and Financial Engineering in Forecasting Models\n\nIntroduction\n\nIn today's fast-paced financial landscape, the integration of Artificial Intelligence (AI) into traditional financial engineering has transformed the field of forecasting models significantly. With advancements in machine learning, data analytics, and computational power, numerical predictions in finance are now more accurate and adaptive to the ever-changing market conditions. Whether investors aim to anticipate stock price movements, assess risks, or optimize portfolios, leveraging AI techniques in financial engineering has become indispensable.\n\nThis article delves into the intricate relationship between AI and financial engineering, examining how these dynamic fields converge to enhance forecasting models. We will explore the fundamental concepts of financial engineering, the transformative role of AI, the methodologies employed, and the potential implications for investors and financial institutions alike. Through this exploration, we aim to shed light on the profound impact that this synergy has on financial decision-making processes.\n\nThe Foundation of Financial Engineering\n\nUnderstanding Financial Engineering\n\nAt its core, financial engineering is the application of quantitative methods and mathematical tools to solve problems related to finance. It involves designing innovative financial instruments, creating risk management strategies, and structuring complex financial transactions. Professionals in this field, often equipped with degrees in mathematics, statistics, economics, and computer science, employ models to analyze market dynamics, assess derivatives pricing, and manage investment portfolios.\n\nOne of the prime objectives of financial engineering is to understand and manage risks associated with financial uncertainty. This involves a comprehensive study of various financial instruments and their behavior under different economic scenarios. The complexity and non-linearity of financial markets necessitate the use of sophisticated mathematical models and computational simulations, such as Monte Carlo simulations and stochastic calculus, to anticipate market fluctuations and optimize trading strategies effectively.\n\nHistorical Context and Evolution\n\nThe roots of financial engineering can be traced back to the mid-20th century when academics and financial professionals began to develop quantitative models to price options and other derivatives. The introduction of the Black-Scholes model in 1973 marked a pivotal moment in the field, enabling more structured approaches to pricing and risk assessment. As computers became more powerful and accessible, the speed and complexity of financial models exponentially increased, allowing for better simulations and predictions.\n\nHowever, despite its mathematical rigor, traditional financial engineering often faced limitations in adaptability and learning capabilities. As the financial markets became increasingly volatile and influenced by an array of factors like geopolitical events, economic indicators, and market sentiment, relying solely on static models proved insufficient. This paved the way for the incorporation of AI into financial engineering, as it offered a more dynamic approach to modeling and forecasting.\n\nThe Role of Data in Financial Engineering\n\nData is the lifeblood of financial engineering. With the advent of big data, professionals can now access a vast array of structured and unstructured data sources, from stock prices and trading volumes to social media sentiment and economic indicators. The challenge lies in not just accumulating this data but also processing and interpreting it effectively.\n\nFinancial engineers utilize statistical techniques and algorithms to analyze historical data and build predictive models based on identified patterns and trends. The integration of AI enhances this process by automating data analysis, uncovering hidden correlations, and enabling real-time predictions. As a result, financial institutions are now better equipped to adapt to sudden market changes, adjust their trading strategies accordingly, and ultimately enhance their profitability.\n\nThe Emergence of AI in Financial Engineering\n\nThe Impact of Machine Learning\n\nMachine learning, a subset of AI, leverages algorithms that enable computers to learn from data and improve their performance without explicit programming. In financial engineering, machine learning techniques have become indispensable in enhancing forecasting models. Traditional methods often relied on fixed equations and assumptions based on historical data, which can overlook intricate relationships within the data.\n\nBy employing machine learning models—such as regression trees, random forests, and neural networks—financial engineers can build more robust and flexible predictive models. These models exhibit the ability to adapt to new data, accommodating changing market conditions seamlessly. For instance, by inputting time-series data into a machine learning model, analysts can uncover hidden trends that inform trading strategies and risk management processes.\n\nAdditionally, machine learning algorithms can improve the accuracy of predicting extreme market events or black swan events, which have significant implications for risk management. Traditional models often struggled to forecast such events due to their rarity, but AI-enhanced models can identify subtle patterns that may precede these occurrences.\n\nNatural Language Processing (NLP) in Financial Forecasting\n\nNatural Language Processing, a branch of AI focused on the interaction between computers and human language, has opened new avenues in financial engineering. By harnessing NLP techniques, financial analysts can extract valuable insights from unstructured data sources like news articles, earnings call transcripts, and social media feeds. Such information can significantly impact market sentiment and stock prices, making it a vital component in enhancing forecasting models.\n\nFor instance, sentiment analysis, a common application of NLP, assesses public emotion and opinion regarding specific stocks or the overall market. By analyzing the sentiment behind news headlines or social media chatter, financial engineers can gauge market fluctuations and adjust their predictive models accordingly. Data derived from sentiment analysis can be integrated with traditional financial metrics to create hybrid models that provide a more holistic view of market dynamics.\n\nReinforcement Learning for Dynamic Decision-Making\n\nReinforcement learning is another emerging area of AI that holds vast potential for financial engineering. Unlike traditional machine learning methods that learn from historical data, reinforcement learning involves training algorithms through trial-and-error interactions in an environment—essentially learning from the outcomes of different decision-making actions.\n\nIn finance, reinforcement learning can be employed to develop trading algorithms capable of adapting strategies in real-time based on market behavior. For example, a reinforcement learning algorithm can simulate various trading strategies, receiving reinforcement in the form of rewards (profits) or penalties (losses) based on its actions. This enables the algorithm to continuously learn and improve its trading decisions over time.\n\nThe use of reinforcement learning models can result in more dynamic and responsive trading practices, allowing financial institutions to maintain a competitive edge in rapidly changing markets. The synergy between financial engineering and AI will likely lead to further innovations in dynamic decision-making processes.\n\nChallenges and Considerations\n\nData Quality and Ethical Concerns\n\nDespite the numerous advantages AI brings to financial engineering, challenges remain regarding the quality of data input into these systems. Poor data quality can lead to inaccurate forecasts, financial losses, and reputational damage for organizations. Thus, it is vital for financial engineers to prioritize data cleaning and validation processes before applying AI techniques.\n\nMoreover, ethical concerns surrounding AI in finance also warrant attention. Issues such as data privacy, algorithmic bias, and transparency pose significant challenges that financial institutions must address. Regulatory frameworks may need to evolve to encompass the unique aspects of AI-driven financial models, ensuring accountability and fair practices within the industry.\n\nOverfitting and Model Complexity\n\nAnother challenge with implementing AI in financial forecasting is the risk of overfitting. This occurs when a model performs exceptionally well on training data but fails to generalize its predictions to unseen data. Financial markets are influenced by a plethora of unpredictable variables, and as AI models become increasingly complex, the risk of overfitting becomes more pronounced.\n\nFinanciers must strike a balance between model complexity and interpretability. While intricate models may yield higher accuracy, they may also become less transparent and harder to understand. Achieving this balance requires continuous validation and testing against real-world scenarios to ensure models remain robust and adaptive.\n\nThe Need for Interdisciplinary Collaboration\n\nThe successful integration of AI in financial engineering necessitates collaboration between various disciplines. Financial engineers, data scientists, and AI experts must work closely to design and implement forecasting models that are both innovative and practical. This interdisciplinary approach can foster the development of comprehensive solutions that address intricate financial challenges effectively.\n\nMoreover, a collaborative environment encourages knowledge sharing, paving the way for unique ideas and methodologies that leverage the strengths of each discipline. As AI continues to evolve, creating interdisciplinary teams will be essential in driving innovation within the financial sector.\n\nConclusion\n\nThe synergy between Artificial Intelligence and financial engineering represents a paradigm shift in how financial forecasting models are developed and implemented. By harnessing advanced machine learning techniques, natural language processing, and reinforcement learning, financial professionals can now create dynamic models that improve accuracy and adaptability in an ever-evolving financial landscape.\n\nAs AI continues to mature, its integration into financial engineering will likely yield further advancements and innovations, empowering investors and institutions to make informed decisions based on enhanced predictive capabilities. Nevertheless, critical challenges remain, including data quality, ethical considerations, and the potential for overfitting. To navigate these challenges and maximize the benefits of AI, collaboration among interdisciplinary teams will be paramount.\n\nUltimately, the fusion of AI with financial engineering heralds a new era in forecasting models, enabling stakeholders to grasp complex market dynamics, harness valuable insights, and adapt to emerging trends in real time. In this journey toward improved forecasting techniques, the commitment to responsible data management, transparency, and ethical practices will be the cornerstones of building a sustainable and trustworthy financial future.\n\nIf you want to read more articles similar to The Synergy of AI and Financial Engineering in Forecasting Models, you can visit the Financial Forecasting category.\n\nYou Must Read\n\nIntegrating Personalization Algorithms with Existing Systems\n\nThe Impact of Deep Learning Model Size on Performance\n\nA Comprehensive Guide to Chatbot Data Preparation with ML\n\nCategories\n\nRelated Posts\n\nIntegrating Machine Learning Algorithms into HR Hiring Processes\n\nExploring the Role of AI in Satellite Imagery for Urban Planning\n\nExploring Ensemble Learning Methods in Clinical Applications\n\nTerms and Conditions\n\nPrivacy Policy\n\nCookie Policy\n\nAbout Us\n\nContact Us\n",
        "Machine learning models employed in customer banking product targeting": "Customer Segmentation in Banking: Examples - Analytics Yogi : \nCustomer Segmentation in Banking: Examples\n\nEver wondered how some banks seem to know exactly what their customers need, almost before the customers do? They’re probably leveraging the power of customer segmentation. We all know how vital it is for any businesses including banks to truly understand their customers in today’s competitive landscape. And that’s where the magic of customer segmentation comes into play. It is enabling banks to dive deep into customer data and extract actionable insights, influencing everything from crafting personalized experiences to strategic decision making.\n\nIn this blog post, we’re going to learn about customer segmentation use cases in banking, showcasing how it’s going to impact product development, risk management, and customer acquisition. Machine learning is taking customer segmentation from ‘helpful’ to ‘indispensable,’ opening up new avenues and making the whole process smarter and more efficient. Whether you’re a product manager wanting to fine-tune your segmentation strategy or a data scientist curious about how machine learning is revolutionizing the banking industry, we will learn about key concepts related to customer segmentation.\n\nTable of Contents\n\nCustomer Segmentation Use Cases in Banking\n\nCustomer segmentation is an incredibly versatile tool and can aid in various business applications in the banking industry beyond personalizing the omnichannel experience. Machine learning algorithms can analyze vast and diverse datasets to identify patterns that may not be apparent to human analysts. This could include transactional data, demographic information, web browsing behavior, social media activity, customer service interactions, and more. By effectively utilizing ML, banks can understand their customers in much more nuanced ways and form more precise segments. The following represents some key use cases of customer segmentation in banking:\n\nHere are a few examples of how customer segmentation can leverage machine learning for different use cases in banking:\n\nConclusion\n\nIn an era where data is abundant and technology continues to advance at lightning speed, banks must leverage tools like machine learning and customer segmentation to stay competitive and customer-focused. From product development to risk management, these techniques provide a powerful means to understand and address diverse customer needs, tailor experiences, and drive overall business performance.\n\nBanks that successfully employ ML-driven customer segmentation will have the distinct advantage of being able to anticipate customer needs, create personalized offerings, and build stronger, more profitable relationships. In this landscape, the question isn’t whether banks should adopt machine learning and customer segmentation – it’s how fast they can adapt and innovate using these tools.\n\nChatGPT Prompts (250+)\n\nRecent Posts\n\nData Science / AI Trends\n\nFree Online Tools\n\nMore...\n\nNewsletter\n\nTag Cloud\n\nRecent Comments\n\nI found it very helpful. However the differences are not too understandable for me\n\nVery Nice Explaination. Thankyiu very much,\n\nin your case E respresent Member or Oraganization which include on e or more peers?\n\nSuch a informative post. Keep it up\n\nThank you....for your support. you given a good solution for me.\n",
        "Machine learning models employed in economic trend impact analysis": "Machine learning forecasting in the macroeconomic environment: the case ... : \nYour privacy, your choice\n\nWe use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media.\n\nBy accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection.\n\nSee our privacy policy for more information on the use of your personal data.\n\nManage preferences for further information and to change your choices.\n\nMachine learning forecasting in the macroeconomic environment: the case of the US output gap\n\n198 Accesses\n\n1 Citation\n\nExplore all metrics\n\nAbstract\n\nThis paper aims to forecast deviations of the US output measured by the industrial production index (IPI), from its long-run potential output, known as output gaps. These gaps are important for policymakers when designing relevant economic policies, especially when a negative output gap may show economic slack or underperformance, often associated with higher unemployment and low inflation. We use a dataset that includes 32 explanatory economic and financial variables and 18 lags of the IPI, spanning the period from 2000:1 to 2022:12, resulting in 50 variables and 276 monthly observations. The dataset is fed to five well-established machine learning (ML) methods, namely decision trees, random forests, XGBoost, long short-term memory (LSTM) and support vector machines (SVMs), coupled with the linear, the RBF and the polynomial kernel. Moreover, we use the standard elastic net logit method from the area of econometrics as a benchmark. Our results indicate that the tree-based ML techniques perform better in-sample, and the best overall forecasting model is the XGBoost achieving an out-of-sample accuracy of 91.67%.\n\nThis is a preview of subscription content, log in via an institution to check access.\n\nAccess this article\n\nSubscribe and save\n\nBuy Now\n\nPrice includes VAT (Lebanon)\n\nInstant access to the full article PDF.\n\nInstitutional subscriptions\n\nSimilar content being viewed by others\n\nMachine Learning in Macroeconomics: Application to DSGE Models\n\nBenchmark Analysis of Machine Learning Methods to Forecast the U.S. Annual Inflation Rate During a High-Decile Inflation Period\n\nOpening the Black Box: Machine Learning Interpretability and Inference Tools with an Application to Economic Forecasting\n\nExplore related subjects\n\nNotes\n\nKiley (2013) discusses three alternative definitions of the output gap: “the deviation of output from its long-run stochastic trend (i.e., the “Beveridge–Nelson cycle”); the deviation of output from the level consistent with current technologies and normal utilization of capital and labor input (i.e., the “production-function approach”); and the deviation of output from “flexible-price” output (i.e., its “natural rate”), page 1.\n\nOkun's law is an empirically observed relationship between unemployment and negative changes in output. According to this empirical relationship, a 1% increase in unemployment can be related to a 2% decrease in GDP, Ball et al (2017). Nevertheless, there are doubts for this empirical relationship, Lee (2000).\n\nReferences\n\nAguiar M, Gopinath G (2007) Emerging market business cycles: the cycle is the trend. J Polit Econ 115(1):69–102\n\nArticle\n  Google Scholar\n\nAlthnian A, AlSaeed D, Al-Baity H, Samha A, Dris AB, Alzakari N, Abou Elwafa A, Kurdi H (2021) Impact of dataset size on classification performance: an empirical evaluation in the medical domain. Appl Sci 11(2):796\n\nArticle\n  Google Scholar\n\nAraujo D, Pereira AM, Simões M (2020) Predicting the output gap: a comparison of machine learning models and economic techniques. J Appl Econ 23(1):47–64\n\nGoogle Scholar\n\nAssunção JB, Fernandes PA (2024) A robust method to date recessions and compute output gaps: the Portuguese case. Port Econ. https://doi.org/10.1007/s10258-024-00259-4\n\nArticle\n  Google Scholar\n\nBall L, Leigh D, Loungani P (2017) Okun’s law: Fit at 50? J Money Credit Bank 49(7):1413–1441\n\nArticle\n  Google Scholar\n\nBarigozzi M, Luciani M (2023) Measuring the output gap using large datasets. Rev Econ Stat 105(6):1500–1514\n\nArticle\n  Google Scholar\n\nBerger T, Kempa B (2011) Bayesian estimation of the output gap for a small open economy: The case of Canada. Econ Lett 112(1):107–112\n\nArticle\n  Google Scholar\n\nBerger T, Morley J, Wong B (2023) Nowcasting the output gap. J Econom 232(1):18–34\n\nArticle\n  Google Scholar\n\nBernhardsen T, Eitrheim Ø, Jore AS, Røisland Ø (2005) Real-time data for Norway: challenges for monetary policy. N Am J Econ Finance 16(3):333–349\n\nArticle\n  Google Scholar\n\nBlanchard O, Amighini A, Giavazzi F (2010) Macroeconomics: a European PERSPECTIVE. Pearson Education\n\nGoogle Scholar\n\nBreiman L (1996) Bagging predictors. Mach Learn 24(2):123–140\n\nArticle\n  Google Scholar\n\nBreiman L (2001) Random forests. Mach Learn 45:5–32\n\nArticle\n  Google Scholar\n\nBreiman L, Friedman JH, Olshen RA, Stone CJ (1984) Classification and regression trees. Wadsworth. Inc., Monterey, California, USA\n\nGoogle Scholar\n\nCamba-Mendez G, Rodriguez-Palenzuela D (2003) Assessment criteria for output gap estimates. Econ Model 20(3):529–562\n\nArticle\n  Google Scholar\n\nCampbell JY, Pflueger C, Viceira LM (2020) Macroeconomic drivers of bond and equity risks. J Polit Econ 128(8):3148–3185\n\nArticle\n  Google Scholar\n\nCayen JP, Van Norden S (2005) The reliability of Canadian output-gap estimates. N Am J Econ Finance 16(3):373–393\n\nArticle\n  Google Scholar\n\nChen T, Guestrin C (2016) Xgboost: a scalable tree boosting system. In: Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, pp 785–794\n\nChen X, Ishwaran H (2012) Random forests for genomic data analysis. Genomics 99(6):323–329\n\nArticle\n  Google Scholar\n\nCicceri G, Inserra G, Limosani M (2020) A machine learning approach to forecast economic recessions—an Italian case study. Mathematics 8(2):241\n\nArticle\n  Google Scholar\n\nCortes C, Vapnik V (1995) Support-vector networks. Mach Learn 20(3):273–297\n\nArticle\n  Google Scholar\n\nDou B, Zhu Z, Merkurjev E, Ke L, Chen L, Jiang J, Zhu Y, Liu J, Zhang B, Wei GW (2023) Machine learning methods for small data challenges in molecular science. Chem Rev 123(13):8736–8780\n\nArticle\n  Google Scholar\n\nDubbert T, Kempa B (2024) Nowcasting the output gap with shadow rates. Econ Lett 236:111583\n\nArticle\n  Google Scholar\n\nDupasquier C, Guay A, St-Amant P (1999) A survey of alternative methodologies for estimating potential output and the output gap. J Macroecon 21(3):577–595\n\nArticle\n  Google Scholar\n\nGogas P, Papadimitriou T (2021) Machine learning in economics and finance. Comput Econ 57:1–4\n\nArticle\n  Google Scholar\n\nGogas P, Papadimitriou T, Chrysanthidou E (2015) Yield curve point triplets in recession forecasting. Int Finance 18(2):207–226\n\nArticle\n  Google Scholar\n\nGogas P, Papadimitriou T, Matthaiou M, Chrysanthidou E (2014) Yield curve and recession forecasting in a machine learning framework. Comput Econ 45(4):635–645\n\nArticle\n  Google Scholar\n\nGogas P, Papadimitriou T, Sofianos E (2019) Money neutrality, monetary aggregates and machine learning. Algorithms 12(7):137\n\nArticle\n  Google Scholar\n\nGogas P, Papadimitriou T, Sofianos E (2021) Forecasting unemployment in the euro area with machine learning. J Forecast 41(3):551–566\n\nArticle\n  Google Scholar\n\nGranados C, Parra-Amado D (2024) Estimating the output gap after COVID: how to address unprecedented macroeconomic variations. Econ Model 135:106711\n\nArticle\n  Google Scholar\n\nHaider A, Safdar Ullah K (2008) Estimating output gap for Pakistan economy: structural and statistical approaches (working paper)\n\nHauzenberger N, Huber F, Klieber K (2023) Real-time inflation forecasting using non-linear dimension reduction techniques. Int J Forecast 39(2):901–921\n\nArticle\n  Google Scholar\n\nHochreiter S, Schmidhuber J (1997) Long short-term memory. Neural Comput 9(8):1735–1780\n\nArticle\n  Google Scholar\n\nHodrick R, Prescott E (1997) Postwar US business cycles: an empirical investigation. J Money Credit Bank 29(1):1\n\nArticle\n  Google Scholar\n\nJašová M, Moessner R, Takáts E (2020) Domestic and global output gaps as inflation drivers: What does the Phillips curve tell? Econ Model 87:238–253\n\nArticle\n  Google Scholar\n\nKatris C (2019) Prediction of unemployment rates with time series and Machine Learning Techniques. Comput Econ 55(2):673–706\n\nArticle\n  Google Scholar\n\nKiley MT (2013) Output gaps. J Macroecon 37:1–18\n\nArticle\n  Google Scholar\n\nKokol P, Kokol M, Zagoranski S (2022) Machine learning on small size samples: a synthetic knowledge synthesis. Sci Prog. https://doi.org/10.1177/00368504211029777\n\nArticle\n  Google Scholar\n\nLee J (2000) The robustness of Okun’s law: Evidence from OECD countries. J Macroecon 22(2):331–356\n\nArticle\n  Google Scholar\n\nMarcellino M, Musso A (2011) The reliability of real-time estimates of the euro area output gap. Econ Model 28(4):1842–1856\n\nArticle\n  Google Scholar\n\nMorley J, Wong B (2020) Estimating and accounting for the output gap with large Bayesian vector autoregressions. J Appl Economet 35(1):1–18\n\nArticle\n  Google Scholar\n\nMouchtaris D, Sofianos E, Gogas P, Papadimitriou T (2021) Forecasting natural gas spot prices with machine learning. Energies 14(18):5782\n\nArticle\n  Google Scholar\n\nOkun AM (1963) Potential GNP: its measurement and significance. Cowles Foundation for Research in Economics at Yale University\n\nOrphanides A (2001) Monetary policy rules based on real-time data. Am Econ Rev 91(4):964–985\n\nArticle\n  Google Scholar\n\nOrphanides A, Van Norden S (2002) The unreliability of output-gap estimates in real time. Rev Econ Stat 84(4):569–583\n\nArticle\n  Google Scholar\n\nPérez-Pons M, Parra-Dominguez J, Omatu S, Herrera-Viedma E, Corchado J (2021) Machine learning and traditional econometric models: a systematic mapping study. J Artif Intell Soft Comput Res 12(2):79–100\n\nArticle\n  Google Scholar\n\nPhillips AW (1958) The relation between unemployment and the rate of change of money wage rates in the United Kingdom, 1861–1957. Economica 25(100):283–299\n\nGoogle Scholar\n\nQuast J, Wolters MH (2022) Reliable real-time output gap estimates based on a modified Hamilton filter. J Bus Econ Stat 40(1):152–168\n\nArticle\n  Google Scholar\n\nRussell SJ, Norvig P (2016) Artificial intelligence: a modern approach. Pearson\n\nSofianos E, Gogas P, Papadimitriou T (2021) Mind the gap: Forecasting euro-area output gaps with machine learning. Appl Econ Lett 29(19):1824–1828\n\nArticle\n  Google Scholar\n\nSofianos E, Zaganidis E, Papadimitriou T, Gogas P (2024) Forecasting east and west coast gasoline prices with tree-based machine learning algorithms. Energies 17(6):1296\n\nArticle\n  Google Scholar\n\nXu P, Ji X, Li M, Lu W (2023) Small data machine learning in materials science. Npj Comput Mater. https://doi.org/10.1038/s41524-023-01000-z\n\nArticle\n  Google Scholar\n\nYoon J (2020) Forecasting of real GDP growth using machine learning models: gradient boosting and Random Forest approach. Comput Econ 57(1):247–265\n\nArticle\n  Google Scholar\n\nZou H, Hastie T (2005) Regularization and variable selection via the elastic net. J R Stat Soc Ser B (Stat Methodol) 67(2):301–320\n\nArticle\n  Google Scholar\n\nZhou S (2022) An analysis of the small sample datasets based on machine learning. In: Proceedings of the 2022 6th international conference on electronic information technology and computer engineering, vol 11, pp 1654–1658\n\nDownload references\n\nFunding\n\nThe first author would like to acknowledge that this work is part of the Interdisciplinary Thematic Institute MAKErS of the ITI 2021–2028 program of the University of Strasbourg, CNRS and INSERM. It has received financial support from the IdEx Unistra (ANR-10-IDEX-0002), and from the “Programme Investissement d'Avenir” as part of the SFRI-STRAT'US project(s) (ANR-20-SFRI-0012).\n\nAuthor information\n\nAuthors and Affiliations\n\nBureau d’Economie Théorique et Appliquée (ΒΕΤΑ), University of Strasbourg, University of Lorraine, CNRS, 67000, Strasbourg, France\n\nEmmanouil Sofianos\n\nDepartment of Finance and Accounting, Rennes School of Business, 2 Rue Robert d’Arbrissel, 35065, Rennes, France\n\nChristos Alexakis\n\nDepartment of Economics, Democritus University of Thrace, Komotini, Greece\n\nPeriklis Gogas & Theophilos Papadimitriou\n\nCorresponding author\n\nCorrespondence to Christos Alexakis.\n\nEthics declarations\n\nConflict of interest\n\nThe authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.\n\nAdditional information\n\nPublisher's Note\n\nSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\n\nAppendix\n\nAppendix\n\nTables 3 and 4 and Figs. 3, 4, 5, 6, 7, 8, 9 and 10.\n\nROC curve for the optimal SVM model coupled with the linear kernel (out of sample)\n\nROC curve for the optimal SVM model coupled with the RBF kernel (out of sample)\n\nROC curve for the optimal SVM model coupled with the polynomial kernel (out-of-sample)\n\nROC curve for the optimal decision tree model (out of sample)\n\nROC curve for the optimal random forest model (out of sample)\n\nROC curve for the optimal XGBoost model (out of sample)\n\nROC curve for the optimal LSTM model (out-of-sample)\n\nROC curve for the optimal elastic net logit model (out-of-sample)\n\nRights and permissions\n\nSpringer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law.\n\nReprints and permissions\n\nAbout this article\n\nCite this article\n\nSofianos, E., Alexakis, C., Gogas, P. et al. Machine learning forecasting in the macroeconomic environment: the case of the US output gap. Econ Change Restruct 58, 9 (2025). https://doi.org/10.1007/s10644-024-09849-w\n\nDownload citation\n\nReceived\n23 April 2024\n\nAccepted\n26 December 2024\n\nPublished\n09 January 2025\n\nDOI\nhttps://doi.org/10.1007/s10644-024-09849-w\n\nKeywords\n\nJEL Classification\n\nDiscover content\n\nPublish with us\n\nProducts and services\n\nOur brands\n\n178.135.19.63\n\nNot affiliated\n\n© 2025 Springer Nature\n\nArtificial Intelligence in Economic Forecasting and Analysis : \nArtificial Intelligence in Economic Forecasting and Analysis\n\nArtificial Intelligence (AI) and Machine Learning (ML) have become transformative forces in finance and economics, redefining how experts forecast economic trends. In recent years, AI’s evolution – from early neural networks to today’s advanced Generative AI and Large Language Models (LLMs) – has greatly expanded its role in economic forecasting. Artificial Intelligence in Economic Forecasting refers to using ML algorithms and big data to predict economic outcomes (like GDP growth, inflation, or market trends) more accurately and efficiently than traditional methods.\n\nNow that we’ve set the stage with the evolution of AI in forecasting, let’s compare how traditional econometric models stack up against these innovative, AI-driven methods\n\nTraditional Econometric Models vs. AI-Driven Forecasting\n\nTraditional economic forecasting relies on econometric models – statistical methods (e.g. time-series analysis, regression models) that use historical data on variables like GDP, inflation, and unemployment to make predictions. These models are grounded in economic theory and often assume linear relationships among variables. They have been valuable for decades, but they face limitations handling complex, nonlinear patterns or sudden structural changes in the economy. For example, an abrupt shock (like a pandemic or financial crisis) can render a static model’s assumptions less effective.\n\nAI-driven forecasting, by contrast, uses advanced algorithms to automatically detect intricate patterns in vast datasets, often without prespecifying a functional form. ML models (such as neural networks, decision trees, or ensemble methods) can capture nonlinear relationships and interactions that traditional models might miss. AI systems also update dynamically as new data arrives, making them more adaptable in rapidly changing conditions. Early research in AI for economics laid the groundwork with simple models, but modern AI can process massive amounts of data at high speed, uncovering signals beyond human cognition. This makes AI a powerful complement to economists’ toolkit rather than a outright replacement. In fact, many experts advocate combining traditional econometric insight with ML techniques for the best results – using AI to improve predictive accuracy and econometric models to ensure interpretability and causal reasoning\n\nTo illustrate the differences and strengths of each approach, the table below compares key aspects of traditional forecasting models versus AI-driven models:\n\nTraditional methods provide theoretical consistency and interpretability, while AI models offer flexibility and often better predictive performance by learning from data. Many researchers find that a hybrid approach, using ML to enhance or inform econometric models, yields the best of both worlds\n\nBuilding on that foundation, we now explore the cutting-edge AI techniques—from transformers to reinforcement learning—that are pushing the boundaries of predictive analytics.\n\nAdvanced AI Techniques in Economic Forecasting\n\nRecent advancements in AI are reshaping economic forecasting by integrating innovative methods that enhance predictive accuracy and enable dynamic scenario analysis. This section explores how transformer models, deep reinforcement learning, and generative AI are collectively pushing the boundaries of forecasting—and how hybrid and explainable approaches are bridging the gap between traditional and data-driven methods.\n\nTransformers and Attention Mechanisms\n\nOriginally developed for natural language processing, transformers have become valuable tools in economic forecasting. By using attention mechanisms, these models can focus on the most relevant parts of vast datasets. For instance, a transformer-based model forecasting GDP might learn to assign higher weights to key leading indicators during an impending slowdown. This enables the model to capture complex temporal dynamics and interactions that traditional autoregressive models often miss. Many central banks and research institutions are now experimenting with transformer-based techniques to enhance forecasts for inflation, GDP, and other economic indicators.\n\nDeep Reinforcement Learning for Policy Simulation\n\nBeyond pure forecasting, deep reinforcement learning (RL) is emerging as a powerful tool for economic policy design. RL enables AI agents to learn optimal strategies through trial and error in simulated environments. A notable example is the “AI Economist,” where an RL framework designed tax policies in a simulated economy by evaluating thousands of policy scenarios. Although RL is primarily geared toward prescribing policy rather than traditional forecasting, it relies on accurately predicting outcomes under various policy choices—a frontier that enriches AI-assisted economic analysis by uncovering strategies that might elude human experts.\n\nGenerative AI and Enhanced Data Synthesis\n\nGenerative AI, particularly through large language models like OpenAI’s GPT-4.5, introduces a new dimension to forecasting. Unlike traditional models with fixed equations, generative AI can autonomously analyze vast amounts of numeric and textual data to learn complex relationships. For example, an LLM can ingest news articles, social media feeds, and financial reports to gauge market sentiment and overall economic conditions in real time. This capability allows for the inclusion of qualitative insights—such as central bank communications—into quantitative forecasts. Although these models require careful prompt design and human oversight, they greatly expand the scope of data that can be analyzed, enabling scenario analysis by generating synthetic data and simulating various economic outcomes.\n\nHybrid Models and Explainability\n\nA growing trend is to blend multiple AI methods or combine AI with traditional econometric models. Hybrid and ensemble approaches leverage the strengths of both worlds—for example, using an econometric model for long-run consistency and machine learning to capture short-term nonlinear patterns. Research shows that ensembles of diverse ML algorithms, such as neural networks and gradient boosting trees, often produce forecasts that are more stable and accurate than any single method. To address the “black-box” nature of advanced AI models, explainable AI (XAI) techniques, like SHAP values, are increasingly employed. These tools help illuminate which factors drive forecasts, thereby increasing trust among decision-makers.\n\nWith advanced methods in place, the next frontier is big data: discover how harnessing vast datasets transforms real-time analysis and deepens our economic insights\n\nBig Data and Predictive Analytics in Economics\n\nThe rise of big data has fundamentally changed economic analysis, providing AI models with a vast playground of information. Traditionally, forecasters used a relatively small set of structured data – e.g. GDP figures, inflation rates, employment stats, collected monthly or quarterly. Today, there’s an explosion of alternative data sources: social media posts, Google search trends, credit card transactions, mobility data from smartphones, satellite imagery of everything from traffic to crop health, and more. AI’s ability to process and learn from this high-volume, high-variety data is a game-changer.\n\nPredictive analytics powered by AI can parse through these diverse datasets to find signals relevant to economic performance. For example, analysts now use ML models to perform nowcasting – predicting the current state of the economy before official figures are released – by feeding in real-time indicators like retail foot traffic or online hiring ads. During the COVID-19 pandemic, such AI-driven predictive models proved invaluable: they helped policymakers track economic disruptions in real time and design timely relief measures. Unlike traditional models that might wait for quarterly GDP reports, AI models ingested weekly jobless claims, mobility indices, and even Twitter sentiment to rapidly forecast downturns and recoveries. The result was more agile policy responses and business decisions, informed by up-to-date analysis.\n\nAI also enables utilizing unstructured data for prediction. For instance, ML algorithms can analyze news text to create sentiment indices, or scan satellite images of industrial activity (like night-time lights or shipping traffic) to estimate economic growth in regions with sparse official data. By leveraging these unconventional inputs, AI-based forecasting provides a more nuanced and timely picture. A notable IMF study found that machine learning models not only outperform traditional statistical techniques in forecasting GDP, but even beat the IMF’s own forecasts, thanks to ML’s ability to incorporate more data and detect complex patterns.\n\nIt’s important to note that with great data comes great responsibility. Big data can improve accuracy, but data quality issues (measurement errors, biases, missing data) can also mislead an AI if not properly handled. Advanced techniques like noise filtering and feature extraction are used to help AI models focus on true signals rather than random noise, especially with high-frequency data that can be volatile. Overall, AI in economic forecasting thrives on big data, turning the abundance of modern information into actionable insights much faster than traditional analytics ever could.\n\nGlobal AI market size (2025–2030) in USD billions. According to Statista, the Artificial Intelligence market is projected to reach US$243.72 billion in 2025, and with an annual growth rate (CAGR 2025-2030) of 27.67%, it is expected to expand to approximately US$826.73 billion by 2030. This robust growth highlights the rapid adoption of AI technologies across various sectors, fueling the development of innovative, data-driven tools in economics and finance and making advanced forecasting techniques increasingly accessible.\n\nTransitioning from theory to practice, we examine how AI is being applied in financial services to deliver actionable forecasts that drive smarter decision-making\n\nAI in Financial Services and Economic Forecasting Applications\n\nThe financial sector has been at the forefront of adopting AI, utilizing it for everything from algorithmic trading to credit risk assessment. In financial services, economic forecasting is tightly linked to tasks like asset allocation, risk management, and strategic planning. AI-driven forecasting models are now vital in these areas:\n\nMacroeconomic Forecasts for Policy\n\nCentral banks use AI to improve predictions of inflation and GDP growth, helping set monetary policy. For example, ML models that analyze a broad range of indicators can alert policymakers to turning points (rising inflation pressure or recession risks) sooner than traditional models. This is crucial in fast-changing environments – e.g. AI systems that flagged unusual drops in consumer spending or employment early in the pandemic gave central bankers a head start in responding.\n\nFinancial Market Analysis\n\nInvestment firms deploy AI to forecast market trends, stock prices, and volatility. ML algorithms can recognize complex patterns in historical price data or even incorporate news sentiment to adjust forecasts of stock index movements. These AI forecasts inform trading strategies (like when to buy or sell) and portfolio optimization, often yielding better risk-adjusted returns by reacting faster to new information.\n\nCredit Scoring and Risk Assessment\n\nBanks are increasingly using AI models to forecast the probability of default for loan applicants, especially those with limited credit history. Artificial Intelligence in Economics here directly benefits financial inclusion: a recent study showed an AI-enabled credit scoring system increased loan approval rates for underserved borrowers while reducing default rates. By analyzing alternative data (e.g. utility payments, mobile phone usage) with sophisticated ML algorithms, the AI model identified creditworthy individuals that traditional scoring overlooked, thereby expanding access to credit. This highlights how AI forecasting of credit risk can simultaneously drive business and social outcomes by bringing more people into the formal financial system.\n\nDemand and Revenue Forecasting\n\nBusinesses (from e-commerce to energy companies) use AI to forecast demand, revenue, and other key metrics. For instance, an online retailer’s AI model might predict product demand by analyzing not just past sales, but web search trends, social media buzz, and even weather patterns. This leads to optimal inventory and pricing decisions. Such AI forecasts are often more accurate and granular than traditional time-series projections, which means fewer stockouts or overstock and better financial performance.\n\nRisk Management and Fraud Detection\n\nWhile not exactly “forecasting” in the traditional sense, AI’s predictive analytics help anticipate risks. Banks use AI to forecast the likelihood of fraudulent transactions or to stress-test loan portfolios under hypothetical economic scenarios. These predictions allow pre-emptive actions to mitigate losses.\n\nFinancial services illustrate the broader point: AI models in economic forecasting are practical tools delivering real-world benefits. They enable institutions to see further ahead with greater clarity. That said, the success of AI forecasts depends on data and validation – models must be trained on high-quality, relevant data and continuously checked against reality to ensure they remain accurate. Many banks employ a “human-in-the-loop” approach, where analysts interpret and, if needed, override AI predictions, combining algorithmic insight with human judgment.\n\nBridging technology with tradition, let’s uncover how AI enhances econometric analysis, blending data-driven precision with time-tested economic theories.\n\nArtificial Intelligence in Econometrics and Economic Analysis\n\nOne content gap in many discussions is how AI and traditional econometrics intersect. Artificial Intelligence in Econometrics involves using ML techniques to enhance or automate aspects of econometric analysis. Econometrics traditionally focuses on estimating relationships between economic variables (often for causal inference, like “does education cause higher earnings?”) and hypothesis testing. Machine learning, on the other hand, excels at prediction and pattern recognition. Rather than viewing them as competitors, modern economic research often blends the two:\n\nImproving Predictive Power\n\nEconometric models can be augmented with ML to improve forecasts. For example, an econometrician might use a vector autoregression (VAR) for macroeconomic forecasting but integrate an ML model to select the best variables or to capture nonlinear effects. Studies have found that ML models frequently outperform traditional models in prediction accuracy for macroeconomic variables, especially when relationships are complex. However, ML’s edge is not universal – in some cases, a well-specified traditional model can match or beat AI, particularly if data is limited or the problem is simple. This implies a nuanced view: use ML where it adds value (e.g. handling big data, complex interactions) and stick to simpler models when they suffice.\n\nCausal Analysis and Feature Selection\n\nEconometrics often aims to understand causality (the effect of X on Y), not just correlation. AI can help here by handling large datasets to find potential causal variables or by using algorithms to control for many confounding factors simultaneously. For instance, methods like double machine learning allow economists to estimate causal effects while using ML to flexibly absorb control variables. This retains the interpretability of an econometric estimate (say, the impact of a policy on growth) with the accuracy of ML adjusting for everything else. In this way, AI acts as an assistant, doing the heavy lifting of parsing data, while the economist focuses on the interpretation.\n\nAutomating Model Discovery\n\nTraditionally, building an econometric model required manual trial-and-error – selecting variables, testing functional forms, checking diagnostics. AI can automate parts of this process. Algorithms can sift through hundreds of candidate predictors (macro indicators, global factors, etc.) and identify which ones improve a forecast, something human analysts would find extremely time-consuming. This algorithmic model selection can lead to better models that human intuition might overlook. Of course, the resulting model still needs to make economic sense, so researchers then examine whether the AI-chosen predictors or patterns align with theory or known causal mechanisms.\n\nEconometric Validation for AI Models\n\nOn the flip side, econometric techniques are used to evaluate and validate AI models. For example, after training an ML model, economists might test its residuals for biases or use structural benchmarks to see if the AI’s behavior aligns with historical evidence. This cross-pollination ensures AI models don’t overfit or pick up spurious correlations that could mislead – a common concern if one naively applies ML.\n\nIn summary, AI and econometrics in combination provide a powerful approach to economic analysis. Econometric models bring interpretability and theoretical grounding, while AI brings flexibility and predictive muscle. Recognizing this, researchers increasingly treat AI as a complement to econometrics, not a replacemen. A thorough review back in 2000 noted that neural networks tended to be more accurate than linear models for economic forecasting, but argued they should “be considered as a powerful complement to standard econometric methods, rather than a substitute”. That sentiment holds true today: the best analyses often integrate both approaches. This blended strategy ensures that as we embrace complex AI models, we also retain the ability to explain and trust the results – a critical aspect for policy-making where stakes are high.\n\nYet, every innovation faces hurdles—explore the technical, ethical, and global challenges that must be addressed to harness AI’s full potential in economics.\n\nChallenges, Ethical Considerations, and Global Scaling of AI in Economic Forecasting\n\nWhile AI promises transformative improvements in economic forecasting, its adoption comes with significant technical, ethical, and global challenges that must be addressed to build trust and ensure equitable benefits.\n\nTechnical and Ethical Challenges\n\nInterpretability and Transparency\n\nMany advanced AI models operate as “black boxes,” making it difficult to understand why a forecast changes—a critical shortfall in economics, where explaining shifts is key to policy justification. This opacity can undermine trust among stakeholders. Consequently, there is a growing emphasis on explainable AI methods that either provide interpretable outputs or validate AI decisions using simpler proxy models.\n\nData Quality, Bias, and Overfitting\n\nAI is highly dependent on the quality of the input data. Economic data often suffer from revisions, measurement errors, and biases; alternative sources like social media may not represent the broader population accurately. If these issues are not managed, AI models risk propagating historical biases or overfitting—learning patterns that are simply noise. Overfitting can result in forecasts that seem precise but fail when applied to new data. Incorporating rigorous validation techniques, confidence intervals, and sensitivity analyses are crucial steps to mitigate these risks.\n\nEthical Use in Policy-Making\n\nWhen AI informs policy decisions, questions arise about accountability and transparency. If an AI model’s forecast leads to a policy that adversely impacts a community, it becomes challenging to determine whether the blame lies with the model or the decision-makers. Policymakers must therefore treat AI as one input among many, ensuring that algorithmic decisions are accompanied by human oversight and comprehensive documentation. Emerging regulatory frameworks, such as the proposed EU AI Act, are beginning to address these ethical considerations by mandating transparency, fairness, and bias audits for AI applications.\n\nGlobal Scaling and Contextual Challenges\n\nData Gaps and Infrastructure Limitations\n\nGlobally, not all regions enjoy abundant or reliable data. Many developing economies lack robust statistical reporting or digital records, which can limit the effectiveness of advanced AI models. This disparity may inadvertently favor data-rich environments and widen the gap between developed and developing regions. Enhancing data collection and quality across borders is essential for a truly global application of AI in economic forecasting.\n\nComputational Cost, Sustainability, and Data Privacy\n\nState-of-the-art AI models are often resource-intensive, demanding significant computational power and energy. For smaller institutions or developing countries, these costs can be prohibitive. Moreover, using cloud-based AI raises concerns about data privacy and sovereignty, especially when sensitive economic data are involved. Techniques like federated learning—which allow models to train across decentralized datasets—offer promising solutions without compromising data security.\n\nTrust, Cultural Context, and Local Adaptation\n\nAn AI model developed in one context may not translate seamlessly to another due to cultural, economic, or behavioral differences. Global skepticism may arise if a “black box” model is seen as an imported solution that lacks local relevance. Building local capacity, adapting models to reflect regional nuances, and involving local experts in model development are key strategies to ensure that AI-driven forecasts are both trusted and actionable in diverse contexts.\n\nOvercoming these challenges requires coordinated efforts among AI experts, economists, policymakers, and international organizations. Investments in infrastructure, data quality improvement, and regulatory frameworks—coupled with a commitment to ethical AI—will be crucial. By addressing technical, ethical, and global scaling issues head-on, we can unlock the full potential of AI-driven economic forecasting while ensuring that its benefits are widely shared and responsibly managed.their accuracy.\n\nThe Future of AI in Economic Forecasting and Policy Analysis\n\nLooking ahead, AI is poised to play an even more influential role in economics. Several trends and advancements indicate where the field is heading:\n\nReal-Time Economics\n\nWith IoT sensors, digital transactions, and internet data, the economy is awash in real-time information. Future AI systems will likely integrate continuous data streams to provide a live read on economic conditions. This could lead to “real-nowcasting” — for example, AI dashboards that alert officials about consumer spending drops or factory output changes as they happen, allowing immediate policy responses. As real-time data quality improves, AI-driven forecasts could become instantaneous, effectively reducing the lag in economic intelligence to near-zero.\n\nExplainable AI and Better Integration with Theory\n\nOngoing research into explainable AI (XAI) is making progress. Techniques like SHAP values, LIME, and attention visualization are helping demystify AI models. In macroeconomics, there’s work on blending AI with structural models (like hybrid DSGE-ML models) so that forecasts come with narrative explanations (e.g. “consumption is down because the model detected lower sentiment and income in data”). We expect future AI forecasting tools to have built-in explanation modules, making them more transparent and trustable. In fact, we’re already seeing moves in this direction: an innovation by Sweden’s ESV combined an ML GDP forecast with an explainability interface that showed which factors drove the predictions, helping analysts interpret the results.\n\nBroader Use in Policy Simulation\n\nAs demonstrated by the AI Economist project, reinforcement learning and agent-based simulations will likely become more common in economic policy design. Governments might use AI to simulate outcomes of policies (like universal basic income or carbon taxes) in virtual environments before implementing them in the real world. This could substantially improve policy-making, though it requires careful validation. The ideal future scenario is AI and human economists working hand-in-hand: AI can propose or evaluate thousands of policy alternatives, and humans apply judgment and societal values to choose the best path.\n\nAccessibility and Democratization\n\nThe tools for AI forecasting are becoming more accessible. Open-source libraries and pre-trained economic models might allow even small businesses or developing country governments to leverage AI without huge budgets. We discuss this more in the next section on democratization, but it’s worth noting as a future trend: the democratization of AI technology means the gap between those with advanced forecasting capabilities and those without will narrow. Cloud computing and APIs could enable on-demand economic forecasting services powered by AI, usable by anyone with an internet connection.\n\nIn the future, success in economic forecasting will likely belong to those who can effectively blend domain knowledge (economics) with data science skills. AI will not replace economists; instead, economists who use AI will likely replace those who don’t. The focus will shift to interpreting AI insights, communicating them clearly to decision-makers, and ensuring policies are robust in the face of AI-informed predictions.\n\nBroader Implications: Sustainability, Inclusion, and Global Impact\n\nArtificial Intelligence is not just a forecasting tool—it is fundamentally reshaping economic dynamics at every level. Its influence extends beyond prediction to affect productivity, labor markets, market competition, sustainable development, and the democratization of economic insights. Below, we explore these multifaceted impacts.\n\nProductivity, Growth, and Market Dynamics\n\nBoosting Productivity and Economic Growth\n\nAI is often compared to transformative technologies like electricity or the internet. Projections by PwC suggest that AI could contribute up to $15.7 trillion to the global economy by 2030, potentially boosting global GDP by roughly 14%. In leading regions, such as the US and China, the impact might be even more pronounced—with estimates showing China’s GDP could be 26% higher and North America’s 14% higher thanks to AI. However, not all experts agree on the scale of these gains, with some, like MIT’s Daron Acemoglu, predicting more modest increases. Despite the debate, it is clear that AI’s ability to automate routine tasks, augment human capabilities, and drive new product innovations is already redefining productivity.\n\nShifting Labor Markets and Competition\n\nAI’s role in automating tasks poses challenges to traditional labor markets. Research indicates that around 20% of job tasks in the U.S. could be significantly impacted by AI, particularly in sectors like finance and data processing. While many roles will be augmented by AI—requiring workers to develop new, AI-literate skills—there is also a risk of widening wage inequalities if benefits are unevenly distributed. Moreover, as firms leverage AI to gain sharper insights and optimize operations, we may see a winner-takes-most dynamic emerge, leading to intensified market competition and possibly even monopolistic trends. These shifts call for proactive policies, such as retraining programs and updated competition regulations, to ensure broad-based benefits.\n\nEnhancing Decision Making and Policy Formulation\n\nAI’s predictive power enhances decision-making in both private and public sectors. With more accurate and timely forecasts, businesses can allocate resources more efficiently, reducing waste and better targeting consumer needs. Governments, in turn, can design preemptive, data-driven policies that mitigate economic downturns. However, for AI to truly improve policy outcomes, decision-makers must act on its insights—whether by addressing an emerging asset bubble or rebalancing resource allocation.\n\nSustainable Economic Development\n\nDriving Agricultural and Environmental Resilience\n\nAI’s ability to process vast datasets is being harnessed to tackle critical challenges in agriculture and environmental management. For instance, AI models that forecast crop yields by analyzing weather patterns, soil conditions, and satellite imagery help stabilize food supplies and guide storage and distribution strategies—vital for developing economies heavily reliant on agriculture. Similarly, AI-enhanced climate-economic models predict water availability and energy demand, enabling governments to invest in resilient infrastructure and sustainable resource management. These applications not only safeguard food security and energy supply but also support broader sustainable development goals.\n\nOptimizing Infrastructure and Financial Inclusion\n\nIn regions with limited resources, AI forecasts inform high-stakes decisions about infrastructure and resource allocation. By predicting the economic impact of building roads, expanding internet access, or upgrading energy grids, AI helps governments and investors identify projects with the highest social and economic returns. Furthermore, AI-driven credit scoring systems are extending financial services to underserved populations, promoting inclusive growth by opening up access to credit for those traditionally excluded from formal financial systems.\n\nDemocratization of Economic Analysis\n\nMaking Advanced Analytics Accessible\n\nOne of the most transformative aspects of AI is its potential to democratize economic analysis. Historically, complex forecasting was the exclusive domain of well-funded institutions like central banks and large financial organizations. Today, open-source models and publicly available ML libraries are leveling the playing field, enabling smaller firms, researchers, and developing countries to conduct sophisticated economic analyses without the need for extensive resources.\n\nAffordable Computing and Collaborative Innovation\n\nCloud computing platforms and user-friendly AI tools have dramatically reduced the cost and technical barriers to advanced economic forecasting. These innovations allow startups, local governments, and even individual analysts to access high-powered computing and automated forecasting platforms. This democratization not only fosters innovation by encouraging a wider range of perspectives but also enhances resilience by diversifying the sources of economic insight. Collaborative initiatives and open data-sharing practices further promote transparency and drive collective progress in understanding and addressing economic challenges.which can lead to more inclusive and well-informed economic decision-making at all levels of society.\n\nConclusion\n\nArtificial Intelligence in Economic Forecasting has become a central tool, seamlessly integrating machine learning, generative models, and big data analytics with traditional econometric approaches. This blend allows for more accurate, real-time predictions and offers new insights into market trends, GDP growth, and policy impacts.\n\nOur updated analysis highlights that AI not only enhances forecast accuracy but also broadens the scope of economic analysis—from sustainable development and financial inclusion to the democratization of economic insights. While these advances promise greater efficiency and innovation, they come with critical responsibilities: ensuring data quality, avoiding biases, and maintaining transparency through explainable AI.\n\nIn short, by combining AI’s transformative capabilities with careful human oversight, researchers and policymakers can steer today’s complex economic landscape with confidence and foresight.\n\nFAQs:\n\nHow is AI used in economic forecasting?\n\nAI is applied by leveraging machine learning algorithms to sift through vast and varied datasets, uncover complex patterns, and generate timely predictions on key economic indicators like GDP, inflation, and market trends using both historical and real-time data.\n\nWhat are the benefits of using AI over traditional forecasting models?\n\nAI enhances forecast accuracy by capturing nonlinear relationships and integrating diverse data—including unstructured sources—while providing real-time updates and deeper insights, complementing the transparency and reliability of traditional models when used together.\n\nWhat challenges are associated with AI in economic forecasting?\n\nChallenges include the black-box nature of many AI models that can reduce transparency, the risk of overfitting due to noisy or biased data, and the significant computational resources and expertise required to develop and validate these models effectively.\n\nHow do AI-driven forecasts differ from traditional econometric forecasts?\n\nTraditional forecasts rely on predefined, theory-based equations with linear relationships, whereas AI-driven forecasts automatically identify complex, nonlinear patterns across numerous variables, adapting more readily to evolving data trends even if they sometimes sacrifice clear explanatory narratives.\n\nCan AI in economic forecasting help developing countries or smaller businesses?\n\nYes, AI democratizes advanced forecasting by offering open-source tools and affordable cloud-based solutions, enabling developing countries and small businesses to generate accurate forecasts, optimize resource allocation, and improve financial inclusion despite limited data or infrastructure.\n\nThanks for reading! Share this with friends and spread the knowledge if you found it helpful.\nHappy learning with MASEconomics\n\nRead more\n\nDebt Sustainability Explained: Why It Matters for Fiscal Resilience\n\nWhat is Debt? A Comprehensive Guide to Understanding Its Role in the Economy\n\nHow Governments Borrow: An Introduction to Public and Private Debt\n\nMASEconomics delivers clear, research-backed insights to help readers understand and engage with the complexities of the global economy.\n\nSign up for our email list now!\n\nTo receive our latest blog posts directly in your inbox!\n\n© 2025 masanghro - All Rights Reserved.\n\nA Decade of Machine Learning Applied to Management and Economics ... : \nHome > Books > Applied and Theoretical Econometrics and Financial Crises [Working Title]\n\nOPEN ACCESS PEER-REVIEWED CHAPTER - ONLINE FIRST\n\nA Decade of Machine Learning Applied to Management and Economics: Learning through a Case Study of Corporate Resilience\n\nWRITTEN BY\n\nSubmitted: 12 October 2024 Reviewed: 20 November 2024 Published: 20 January 2025\n\nDOI: 10.5772/intechopen.1008856\n\nFROM THE EDITED VOLUME\n\nApplied and Theoretical Econometrics and Financial Crises [Working Title]\n\nProf. Brian William Sloboda and Dr. Chee-Heong Quah\n\nCHAPTER METRICS OVERVIEW\n\n36 Chapter Downloads\n\nAbstract\n\nEconometrics has traditionally focused on statistical regression-type methods for analysing economic data, but is increasingly integrating techniques from data science, using sophisticated machine learning (ML) models, both to improve predictive accuracy and to develop non-parametric inference, for example with new feature importance techniques such as Shapley values. While development has been rapid and exciting, significant efforts are still required to achieve full convergence between traditional and new data methods. This research examines a decade of progress in ML, focusing on its application to predicting and explaining the drivers of business resilience during crises, such as the COVID-19 pandemic. It is shown that ML uncovers significant non-linearities in the way capabilities, such as innovation, ecosystem play or agility, have been able to stimulate resilience. Empirical results show that gradient boosting and random forests outperform traditional econometric models in predictive accuracy by margins of over 10%, while maintaining interpretability through feature importance metrics. This study highlights the strengths and trade-offs of ML methods and provides practical insights into their computational underpinnings. By comparing traditional econometric methods with ML techniques, we illustrate the promise and challenges of convergence between these fields.\n\nEconometrics has traditionally focused on statistical regression-type methods for analysing economic data, but is increasingly integrating techniques from data science, using sophisticated machine learning (ML) models, both to improve predictive accuracy and to develop non-parametric inference, for example with new feature importance techniques such as Shapley values. While development has been rapid and exciting, significant efforts are still required to achieve full convergence between traditional and new data methods. This research examines a decade of progress in ML, focusing on its application to predicting and explaining the drivers of business resilience during crises, such as the COVID-19 pandemic. It is shown that ML uncovers significant non-linearities in the way capabilities, such as innovation, ecosystem play or agility, have been able to stimulate resilience. Empirical results show that gradient boosting and random forests outperform traditional econometric models in predictive accuracy by margins of over 10%, while maintaining interpretability through feature importance metrics. This study highlights the strengths and trade-offs of ML methods and provides practical insights into their computational underpinnings. By comparing traditional econometric methods with ML techniques, we illustrate the promise and challenges of convergence between these fields.\n\nKeywords\n\nAuthor Information\n\n1. Introduction\n\nBig data, with their unique ability to discover subtle population patterns and heterogeneities not possible with small-scale data, have been powering many business domains for several years—enabling Moderna’s discovery of an RNA-based vaccine for COVID-19 in weeks [1], improving Netflix personalisation for two thirds of video consumption [2], or supporting responses to user queries for OpenAI’s ChatGPT model trained on billions of tokens [3, 4].\n\nIn parallel, big data and their associated classification methods, such as machine learning (ML) and deep learning (DL), have also gained traction in many scientific fields, including more recently in economics. These methods are particularly recognised for their enhanced ability to model complex, non-linear systems and to make more accurate predictions than traditional econometric techniques. In addition, although still emerging, inference tools from ML are refining traditional econometrics and addressing the need for better model explainability and interpretability [5, 6, 7].\n\nThe current study provides a summary of the development of supervised machine learning methods as applied to the field of economics. It starts with a chronology of their developments, then discusses the types of methods, together with examples of applications and related findings. While ML models have been designed to excel in predictive accuracy in the context of complex data generation processes, a corollary of these classification methods is that they tend to be less interpretable than linear models, while it is often crucial to uncover the mechanisms that these models capture, especially when it comes to fairness, welfare or policy validation.\n\nWe then discuss so-called “explainable” machine learning methods, such as permutations, attribution importance, or Shapley values, and comment on how the need for such methods has evolved, including a new literature on (causal) inference, both in terms of model specifications (“feature importance”) and how those features marginally affect model output.\n\nAdding to an emerging literature [8, 9], we finally illustrate the relevance of ML methods in the context of predicting firm resilience. We pick this topic for the reason that corporate resilience—that is, the ability to endure and survive—is still poorly understood, and is likely affected by multiple attributes, and in a non-linear fashion. However, most studies related to firm resilience tend to produce linear analyses one feature at a time [10, 11]. Using the shock of the 2019 pandemic, we demonstrate the added value of ML techniques in these circumstances, while a final section concludes and highlights new avenues of research.\n\n2. Data science methods\n\n2.1 Evolution of machine learning into economics\n\nApplied economics has long been dominated by econometrics, which relies on statistical techniques, such as regression, time series models and hypothesis testing. These techniques assume strong parametric relationships, making them suitable for small and structured datasets, but they are limited in flexibility and fragile if they deviate from their parametric assumptions.\n\nMachine learning was introduced in 1959 by Arthur Samuel, an IBM employee, to define the pattern recognition tasks that provided the “learning” component of early artificial intelligence (AI) expert systems [12]. However, machine learning techniques did not gain attention in economics until the early twenty-first century, when their application became possible without major computational constraints and large datasets became more available.\n\nAccording to Gogas and Papadimitriou [12], the most obvious case of the use of ML in economics is in finance and its abundance of available data, with the aim of predicting financial health or prices made possible by it. The pioneering use of ML in economics is a study by Wang et al., which demonstrated its usefulness in the context of credit scoring, while White’s paper used ML with the aim of better predicting IBM’s daily stock returns [13, 14].\n\nHal Varian, formerly of Berkeley and by then the chief economist at Google, also published a research entitled “Big Data: New Tricks for Econometrics”, which highlighted the potential of ML to revolutionise empirical research in economics [15]. Varian emphasised early on that the main strength of supervised machine learning is its focus on predictive accuracy. Econometrics has traditionally focused on estimating causal effects and testing economic theories, while machine learning excels at finding patterns in data that lead to better predictions.\n\nVarian’s research caught the ear of many fellow economists, as many researchers in applied economics began to incorporate machine learning techniques into their toolkits. According to Nosratabadi et al. [16], the number of ML applications in economics started to skyrocket around 2016–2017. This is also confirmed by a bibliometric analysis of the published literature from Web of Science (WoS) and Scopus on machine learning in economics and econometrics, where the total number of studies in machine learning and economics was in the low twenties in 2010 to reach almost 1000 research papers 10 years later, or a 50-fold increase [17].\n\n2.2 Supervised ML techniques\n\nFrom White’s paper on stock returns, supervised machine learning models have expanded into areas, such as commerce [18], consumer behaviour and social media [19, 20], macroeconomics and health economics [21, 22], agricultural and development economics [23, 24]; labour economics [25]; organisation science [26]; or even energy economics and industrial economics [27, 28].\n\nThese studies have also used different classification algorithms, of which the most common and popular methods are support vector machines (SVMs), decision trees (DTs), neural networks (NNs), random forests (RFs) and gradient boosting (GBM). Appendix 1 describes the process of running those algorithms, but what needs to be kept in mind is the trade-off between simplicity and accuracy of results, with ensemble models being more effective than others. Among others;\n\nDecision tree (DT) (or classification tree) is a classification method that constructs decision rules organised in tree-like structures, where at each node the dataset is partitioned to maximise the best classification/purity, starting at the root node of the tree and then moving down the tree branch corresponding to the attribute value. Decision trees have high interpretability, but predictive results are sensitive to sample selection and tree branch hierarchy.\n\nAs an alternative to DT, a support vector machine (SVM) constructs a hyperplane or a set of hyperplanes. Intuitively, the hyperplane that has the greatest distance from the nearest training data points in any class achieves a strong separation, since in general, the larger the distance, the lower the generalisation error of the classifier. It is effective in high-dimensional spaces and can behave differently based on different mathematical functions known as the kernel. However, when the dataset contains more noise, such as overlapping target classes, SVM does not perform well.\n\nNeural networks (NNs) mimic the interconnected neurons of the human brain. Deep learning (a subset of NN) involves multiple layers that can capture complex patterns and interactions. “Inspired by biological networks” [28], any artificial neural network consists of at least one input layer with feature information, one or more hidden layers and an output layer that returns the predicted values. Each layer consists of nodes (neurons) connected by edges across layers, which are strengthened according to their ability to transmit information. Deep learning models also excel at handling highly non-linear and unstructured data. However, they require large datasets and are prone to overfitting without careful regularisation.\n\nRandom Forest (RF) is an ensemble classification technique that, instead of estimating a single DT, resamples the observations in the training set to estimate multiple trees independently. These trees are merged as a combination of bootstrap aggregation (bagging) and random feature selection. The final prediction is then based on averaging the results of all the trees. As an ensemble, the multi-decision tree RF learning model is typically more accurate than a single decision tree model. However, due to their complexity (hundreds or thousands of trees), it is not easy to understand how individual features contribute to a prediction.\n\nGradient boosting (GB), like Random Forest, is an ensemble learning algorithm based on a series of decision trees, but unlike RF, it builds trees sequentially, with each new tree attempting to correct the errors of the previous trees. The gradient is used to minimise the loss function, similar to how neural networks use gradient descent to optimise weights. Random forests tend to be faster to train because the trees are built independently, while gradient boosting is slower due to its sequential nature. Gradient boosting is more prone to overfitting, but can achieve higher accuracy than RF due to its built-in correction process, if tuned properly.\n\nTable 1 provides a high-level synthesis of the relative strengths of the different methods. DT, while simple and easy to interpret, is prone to overfitting. SVM, while excellent on high-dimensional data, struggles with scalability and requires careful tuning of the kernels. RF is a strong all-round performer, with less risk of overfitting, but less interpretable, while, say, NN is highly flexible, powerful for complex data types, but computationally expensive and data hungry.\n\nTable 1.\n\nMachine learning algorithms: Pros and cons.\n\nIn general, RF and then NN have been the most widely used methods in applied economics to date. NNs are known to be the best at dealing with non-linear (hidden) effects, but at the expense of interpretability [29]. They tend to outperform other models in areas such as asset pricing and climate change impact prediction when large datasets are available, but their performance can suffer with small datasets or simpler tasks. RFs also tend to perform very well in terms of in-sample accuracy [5] as well as (out-of-sample) predictive accuracy, especially when dealing with large datasets and high-dimensional data. GB models such as XGBoost (XB) often outperform Random Forests in terms of predictive accuracy, especially for financial market predictions and high-dimensional datasets. Nevertheless, RF seems to be increasingly preferred because of its stability, less sensitivity to overfitting and because the relative contribution of the tree’s regressors to the prediction can be easily calculated using various direct techniques in tree-based models, such as Gini importance or mean decrease impurity (MDI) [30].\n\n3. Towards explainable AI\n\nThe work of Hal Varian also had emphasised that machine learning and econometrics are complementary, not substitutes. Economists care deeply about causality—determining the direction of cause and effect—which machine learning algorithms are not primarily designed to uncover. At a technical level, econometrics aims at statistical inferential analysis, such as “estimating the coefficient associated with a variable and its confidence level with respect to a hypothesis (often the null), while machine learning models are mostly nonparametric [31]”.\n\nAs many phenomena are driven by complex data processes, linear approximation can be a risky shortcut. The rise of big, granular and unstructured data provides an opportunity to use ML to study such phenomena, but preferably if there is a way to make some causal inference [7]. Importantly, one reason for models to be interpretable is the importance of ethical concerns, as opaque models could be misused. These concerns require parallel ML guidelines, especially around the ideas of “fairness”, “safety”, “trustworthiness” and “transparency’” [32]. The first institutionally based publication on ML and AI guidelines was the “Ethics Guidelines for Trustworthy AI” by the Independent High-Level Expert Group on Artificial Intelligence, organised by the European Union (EU), in 2019. This was the first step towards the first regulatory framework announced by 2021 and finally passed by the European Union under the European “AI Act”, by March 2023, as a law governing the development and deployment of AI systems in the European Union [33, 34].\n\nAccordingly, in recent years, economists and data science researchers have developed approaches that attempt to bridge the gap between data science and econometrics [35]. Indeed, two questions arise for effective models of an empirical phenomenon: first, whether the model is well specified and, if so, what is the impact of the features specified in the model on the emergence and pattern of the empirical phenomenon (see [5], p. 4). The second question is akin to determining the marginal effect of features on output in econometrics. The first question is also akin to the issue of adequate model specification, since in traditional econometrics missing variables can lead to poor marginal inference, and multicollinear variables can lead to large inference imprecisions. We address explainability of ML models hereafter, first by discussing model features’ relevance, and then, inference.\n\n3.1 Attributes’ importance\n\nWays to address model specification are variable attribution via the decomposition of individual predictions (so called, “local attribution”) and importance scores for the model as a whole (“global attribution”) [36]. In general, local attribution techniques can be re-aggregated to global attribution.\n\nGlobal methods seek to explain the behaviour of the full model and the global importance of features/variables. Methods include\n\nThe permutation importance of a variable measures the change in model performance when the values of that variable are “randomly permuted”. The underlying logic is that if the ML model has learned a strong dependency between the model outcome and a given variable, permuting the value of the variable will lead to very different model predictions and thus affect performance. A variable is therefore defined as important if the test error after permuting a feature is substantially higher than the test error using the original value for that feature. While permutation is simple and intuitive, as it directly shows how model performance is affected when information from a feature is removed, it is computationally expensive, as it requires retraining or testing the model multiple times with shuffled data, especially for large datasets. In addition, estimates of interaction effects may be both unstable and fail to correctly account for interaction effects between features, especially when correlated features are shuffled independently.\n\nThe jackknife method (and its extension, jackknife plus) assesses the importance of features by systematically removing (or masking) one feature at a time and assessing how the performance of the model changes [37]. In practice, jackknife uses the residuals from one (or all) leave-one-out predictions to estimate how much deviation we can expect from new predictions. While the method is model agnostic and fairly simple and intuitive (removing a feature and observing the change in performance give an easy-to-understand measure of importance), it is computationally intensive. Like permutation importance, jackknife may underestimate the importance of features involved in complex interactions, as removing a single feature does not fully capture its interaction effects.\n\nIn tree-based ML models (DT, XB, RF), measures of global importance derived directly as a by-product of the learning step include GINI importance; MDI/MDA (MDI: mean decrease impurity; Breinman et al. [38] and MDA: mean decrease accuracy [39]. Gini is a measure of how much a variable contributes to optimising the objective function, while MDI, like Gini, evaluates impurity as the entropy of the distributions of the input variables in sample, while MDA does so out of sample. As the impurity decreases, the feature is considered more important.\n\nAssuming a sufficiently high level of trees, MDI/A has desirable properties such as consistency with the notion of feature relevance, or the ability of a variable to convey additional information about the output [40]. As the importance of a feature is calculated based on the reduction in some impurity criterion (e.g., Gini impurity or entropy) or the increase in information gain when that feature is used to partition the data during the model training process, there is no need for additional passes through the data. These measures also capture complex interactions between features without requiring explicit feature engineering, but may be biased for features measured as continuous variables, while the importance of correlated features may be unevenly distributed across correlated features.\n\nAnother global approach is SAGE (“Shapley Additive Global importance”), a model-agnostic method that uses Shapley values to assess the global importance of features, based on a set of input data for a scenario that implies a regression model output, which is then used to quantify the contribution of the features to the global model prediction.\n\nShapley scores (and their close variants) are a tool borrowed from game theory to allocate credit to players in coalitional games; hence, the idea of using Shapley scores in a supervised learning method is to treat each feature as a “player” in a cooperative game, where the “game” is the model prediction and the payoff is the predicted value. Applied to ML, Shapley scores provide a fair way of allocating the overall model performance to different features, treating them as “players” in a cooperative game. Appendix 2 provides some extra details on how Shapley scores are derived.\n\nSAGE can account for interactions between features because it considers how groups of features work together to influence model predictions. This ensures that the importance of a feature reflects both its individual contribution and its role in interactions with other features. However, as the calculation of the Shapley value must take into account all combinations of games/coalitions, the process can be computationally expensive—and in most cases prohibitive—requiring the development of approximations. In general, SAGE rigorously handles feature interactions using Shapley values, but it is a cumbersome method that often requires approximation in multi-feature models.\n\nTable 2 summarises the different methods, and the trade-off to be made between computing resources, interpretability, or still handling of complex non-linear relationships. For instance, feature importance based on tree-based models is directly computable, even if computation is a struggle in complex non-linear models. The SAGE method is robust to non-linearity but is complex to implement and not easily interpretable. Jackknife methods do not handle non-linearities easily and are resource-costly.\n\nTable 2.\n\nGlobal importance metrics: Pros and cons.\n\nIn practice, however, the performance of ensemble tree models is increasingly recognised, leading practitioners to favour methods, such as GB and RF. Furthermore, Sutera et al. [40] have recently pointed out that, under some reasonable conditions, MDI scores derived from tree-based ML models can match Shapley values, both theoretically and empirically. MDI scores are thus a simple built-in alternative to SHAP (“SHapley Additive exPlanations”) approximations of Shapley values for assessing the global importance of features in ML models.\n\nThe main advantage of local methods is that they reveal the functional form of the association between a feature and the outcome as learned by the model, which global methods cannot do. Approaches that are also agnostic to model type include DeepLIFT (for “Deep Learning Important FeaTures”) [41], as well as among the most widely used: LIME (for “Local Interpretable Model-Agnostic Explanations” [42];) and SHAP (for “SHapley Additive exPlanations” [43]).\n\nDeepLIFT is a model-specific method designed primarily for deep learning models. It explains a model’s prediction by comparing the activation of each neuron in the model to a reference activation, and assigns importance scores to each input feature based on how much it contributed to the deviation from the reference. For each input, DeepLIFT selects a reference input (e.g., a “neutral” baseline input) and calculates the activation of each neuron in the network for both the input and the reference. DeepLIFT then propagates these differences back through the network to assign attribution scores to the input features, showing how much each input contributed to the difference in the final prediction compared to the reference. DeepLIFT is faster than methods such as SHAP because it avoids the combinatorial complexity of evaluating multiple subsets of input features. Because it uses deep neural networks, DeepLIFT is able to handle complex, non-linear relationships in the data. A key weakness is that the choice of reference point can affect the attributions, and selecting an appropriate reference is often not straightforward [44].\n\nLIME is based on the construction of a simplified replacement model for the model under investigation (the “replacement model”). The surrogate model is based on the predictions of the base model computed on variations of the input data randomly perturbed, and is thus able to quantify the importance of the different features that make up the unperturbed data; on the prediction of the surrogate model.\n\nUnlike LIME, SHAP is based on an approximation of the calculation of Shapley values [45]. Unlike LIME, and as noted above in relation to SAGE, the Shapley value assigns a fair contribution to each feature based on its marginal effect across all possible feature combinations, and is also a unique solution to the credit allocation problem, as defined by several other desirable properties such as symmetry and linearity [46]. SHAP is an approximation to Shapley scores, as the exact calculation of the Shapley score is computationally expensive because there is a combination of 2n possible coalitions of n feature values, and the ‘absence’ of a feature has to be simulated by drawing random instances, which increase the variance for the estimate of the Shapley score.\n\nTable 3 is a summary of the local importance methods. LIME is probably the most useful method when a quick, interpretable explanation of a prediction from any type of model is needed. However, LIME can be unstable and computationally expensive for complex models. Designed specifically for deep learning models, DeepLIFT is best when dealing with neural networks. It provides efficient and interpretable attributions, but requires careful selection of a reference point.\n\nTable 3.\n\nLocal importance metrics: Pros and cons.\n\nAlthough additional questions remain about how Shapley values truly measure feature importance [47, 48], Lundberg and Lee [43] had shown that Shapley values provide a unifying framework for many attribution schemes. As for global measures, Sutera et al. [40] had pointed out that, under some reasonable conditions, local MDI scores derived from tree-based ML models can also match Shapley values, both theoretically and empirically.\n\nIn addition to providing local, accurate, linear and consistent attributions, Shapley values provide a granular approximation of a possible feature across all observations, allowing the functional form learned by the model to be visualised. Based on this, and as discussed below, one can also formulate a more comprehensive statistical inference framework—the so-called Shapley regression that provides a clear bridge to traditional econometrics [49].\n\n3.2 Attributes inference\n\nIn recent years, a number of breakthroughs have been made for the convergence of inference between ML and econometrics, from a variety of studies, such as Athey [50], Athey et al. [51, 52], Athey and Imbens [53], Athey and Wager [54]; Chernozhukov et al. [55, 56]; Davis, and Heller [57] or Nazemi and Fabozzi [58].\n\nHere are some examples of notable advances in statistical inference using ML models:\n\nRegarding the relevance of attributes for model specification, an important avenue, based on bagged trees as in RF, is that the combination of models can give an idea of the uncertainty in the estimates of attributes. From this perspective, Wager et al. (2014) were among the first to construct asymptotic confidence intervals for random forests via infinitesimal jackknifes and combinations of models [59]. Their basis for this inference is the concept of an honest forest, where trees in a random forest are divided into one group used to select splits and another group used to make predictions, preventing the same data from being used for both model training and evaluation. This “honest” structure reduces bias in tree predictions and ensures that the predictions are statistically valid for inference. Under certain conditions, the predictions made by honest random forests follow a normal distribution as the number of trees increases. This in turn allows the calculation of confidence intervals for predictions based on the Central Limit Theorem (CLT).\n\nMentch and Hooker in 2016 introduced a statistical inference framework for machine learning models, specifically focusing on random forests and other ensemble methods [60]. The method involves creating multiple subsets of the training data (similar to subsampling) and building decision trees on these subsets. The key difference from traditional random forests is that the trees are grown on different random subsamples rather than full bootstrap samples. The authors derived the U-statistic, which is computed for the predictions generated by individual decision trees built from subsampled data, and for which the distribution approaches normality as the number of trees grows large, allowing the use of standard confidence intervals and hypothesis tests.\n\nHowever, the method involves repeated subsampling and fitting of decision trees, which can be computationally expensive, especially for large datasets. Finally, if the subsamples are too small, the trees may not adequately capture the underlying relationships in the data; and if the subsamples are too large, the trees may become too similar, reducing the variability needed for inference.\n\nA more recent study by Coleman et al. [61] points out that the formal hypothesis testing procedure of Mentch and Hooker for assessing the importance of variables is computationally prohibitive. In contrast, their method is based on a permutation scheme that avoids the need for explicit covariance estimation and thus does not require a larger number of trees for larger datasets. In particular, they show that the difference in the mean squared error in out-of-sample prediction accuracy between the intact variable and the same variable permutated in tree-based models follows an asymptotically normal distribution with mean zero and finite variance.\n\nAnother route taken by Buckmann et al. [62] is to use the framework of Shapley regressions, which can indeed be seen as a natural extension of regression-based inference to the general non-linear model. The main difference is that inference is often only valid locally, i.e. within a region of the input space, due to the potential non-linearity of the model plane. A slightly modified null hypothesis is introduced to test the statistical significance of variables, where the difference between the coefficients of a linear model and the Shapley share coefficients is essentially the normalisation of the latter, as non-linear models have no “natural scale” to measure variation. In their study, Buckmann et al. (2021), using Shapley regressions to assess attributes to predict changes in US unemployment, show that the latter is also significantly predicted by the 3-month Treasury bill, the oil price level and the slope of the yield curve; these effects are often not captured by traditional linear econometric models—making these linear models misspecified.\n\nYamaguchi also refers to Shapley regression as “Shapley values project unknown (but learned) functional forms into linear space” ([63], p. 29). Using the SHAP simplification of Shapley value, it is shown that the long-term stock price changes of global automakers such as Toyota and electronics companies such as Sony in the last decade of the twentieth century were significantly related to firm factors such as sales growth and inventory ratio, while these attributes were not obvious attributes in linear models.\n\nFinally, it should be noted that in addition to the general significance, the marginal effect of attributes on the output prediction can also be made, with standard errors derived from bootstrapping. As discussed by Zhao and Hastie [64], one of the most used visualisation tools of ML models is the “partial dependence plot” (PDP) of an attribute. Not only is the PDP the same fitting formula as in Pearl [65] to identify the causal effect of an attribute on Y from observed data, but the slope of this PDP relationship is also what traditional multiple regression coefficients capture as a marginal effect under a linear model—but now extended to any model [7].\n\n4. A case study on corporate resilience\n\n4.1 Scope\n\nTo illustrate the current convergence between ML models and traditional econometrics, we use an analysis of firm resilience.\n\nWhile economic theory has often focused on firm’s performance, resilience appears to be both a critical and a strategic attribute. Indeed, valuable firms are those that survive for a long time as a result of their resilience to a variety of adverse shocks: during the last major recessions, studies of listed firms found that only 20% of firms were able to return to pre-recession performance 3 years after the onset of the crisis. In the most recent global shock we study here (the COVID-19 pandemic), about one third of listed firms had not returned to the same level of profitability 2 years after the start of the pandemic [66].\n\nIn particular, we draw on the large existing literature on strategic resources and dynamic capabilities to predict the performance trajectory of firms during COVID-19 as a function of four firm internal capabilities [67, 68]: agility [69], innovativeness [70], digitalisation and ecosystem play [71].\n\nThe resilience problem of this research would traditionally be estimated by relating the probability of resilience to indicators of these four capabilities, using parametric techniques such as logistic regression. However, one can easily hypothesise that strong non-linearities, such as a lack of digitisation, may dramatically damage firms fighting the pandemic and its social distancing measures, compared to a firm that is already digitised but not fully digitised. Similarly, firms that are able to play an important orchestrating role in ecosystems may benefit more proportionally from the ecosystem than a firm that is only passive in an ecosystem—especially at the time, during the pandemic, of major supply chain disruptions, for example.\n\nAs an alternative to least-squares techniques, one resorts here to more general Machine Learning models to predict resilience, as well as the relative importance of its antecedents. This analysis is part of recent trends of using ML models to predict organisational resilience via bundle of firm inertial capabilities. The novelty is to leverage an array of models, from artificial neural networks (NNs), to SVM, gradient boosting (GBM) and random forests (RFs), while we also produce inferences as to the significance of attributes as well as their marginal impact (through partial marginal effects (PMEs)) on resilience probability.\n\n4.2 Conceptual model: The importance of four capabilities\n\nA large number of studies on corporate resilience are prevalent, with the majority relying on the resource-based view and dynamic capabilities theory [72]. Accordingly, we rely on the same theoretical foundations and hypothesise a conceptual model, in which corporate resilience is essentially driven by four main capability factors: innovation, agility, digitisation and business ecosystem play as key drivers of resilience (see Figure 1).\n\nConceptual model of capabilities-driven resilience.\n\nThis conceptual model can be validated by integrating several studies of resilience, as the vast majority of research has examined the resilience effect of a single capability, with a relatively limited number of studies examining a bundle of capabilities as a vector of resilience. Regarding the latter, Battisti and Deakins highlight the critical aspect of both agility and ecosystem play to leverage resilience [73]. More recently, Dyduch et al. found that firm resilience during the COVID-19 pandemic was enhanced by innovation capability, agility, as well as digitalisation [74].\n\nFurther following the dynamic capability literature, each capability reflects three general types (sensing, exploiting and transforming capabilities [75]). Following this classification, we measure each dynamic capability as follows. First, following the innovation literature, Research and Development (R&D) intensity and its change is a proxy for sensing and exploiting capabilities, while innovation-transforming capabilities are reflected by the part of R&D that goes beyond mere incremental innovation [76]. Regarding agility, we follow Mohammad [77] who emphasises a culture of agility that is able to sense the need/opportunities for adaptation; while we measure the exploitation of agility through three technical elements: speed, flexibility and risk taking in resource reallocation [78]. Transformative capability is measured by the degree of change in those technical elements at the time of the pandemic. In terms of ecosystem play, the literature emphasises the dominant ecosystem’s contribution, as a measure of the firm’s belief in its importance, and the depth of that contribution, as an indicator of the exploitation of ecosystem benefits. The literature also emphasises the firm’s role in this ecosystem as a reflection of its transformative nature; in particular, the firm’s orchestrator role in the ecosystem is important as a transformative capability [79]. Finally, with respect to digitisation, the literature has often measured the adoption, but especially the full exploitation (as opposed to experimentation) of technologies as an indicator of exploitable capabilities [80]. Success in digital transformation capabilities is a clear symptom of transformation capabilities, according to Ellström et al. [81].\n\n4.3 Sample procedure and statistics\n\nThe sample comes from an online executive survey structured by Accenture Research to explore how global companies around the world perceive and respond to the COVID-19 pandemic in late 2020/early 2021. The survey was designed by an external research firm, taking into account the dimensions of resilience capabilities from our conceptual model outlined in Figure 1, in line with the literature. The wording and questions were reviewed for consistency and readability by a number of external consulting experts.\n\nThe full sample was drawn from 14 representative countries. North America was represented by the United States and Canada (32 and 5% of the sample, respectively), Europe by the top five countries (5% of the sample each), Asia by Japanese and Chinese companies (9% of the sample each) and Singapore. The remaining enterprises were located in the Middle East (United Arab Emirates (UAE) and Saudi Arabia). The scope covered 18 private NACE 2 (Statistical Classification of Economic Activities in the European Community) industries, each represented by the same sample size.\n\nRespondents were selected from the market research database of the C-suite, mostly Chief Executive Officers (CEOs), Chief Strategy Officers (CSOs) or Chief Information Officers (CIOs). The sample response rate was approximately 15% for a total sample of 4300 companies. To minimise general response bias and noisy responses, confidentiality of responses and the option not to answer questions were guaranteed [82]. Tests for possible response bias were carried out. As the study collected informants’ days, early and late responses were tested for significant differences in responses after 2–4 weeks. No real difference between respondents was found, while Harman’s main principal factor also accounted for 22% of the variance, well below the 50% threshold where the variance is mostly driven by respondent style.\n\nWe use profit recovery as a reflexive measure of resilience and consider a window of 18 months after the pandemic to test recovery, based on classifying a firm according to whether or not its profit has returned to pre-pandemic levels by September 2021. The 18-month window is consistent with the typical duration of crisis absorption [83]. Sixty-eight per cent of the firms in the sample did not recover their pre-pandemic revenue level by September 2021. Average revenue calculated for the full sample fell by 30% relative to 2019 at the peak of the pandemic, and “recovered” by 15% on average in the second period, but remained below 15% of their original pre-pandemic revenue by 2019. This gap is consistent with those of other studies [84].\n\nTable 4 provides a company perspective throughout the (peak) pandemic. While two thirds of companies pride themselves on having an agile culture, speed/flexibility and risk-taking practices are only average, although companies accelerated their investment in these practices somewhat during the pandemic. In terms of the ecosystem, 6 out of 10 companies have more than 5% of revenue coming from the ecosystem, and the same proportion sees this revenue increasing over the years—however, only 14% play an orchestrating role. Innovation intensity is typically below 5%, and one third of companies reduced R&D during the pandemic—while digital maturity was 50% of the frontier of full digitalisation, with barely 4 out of 10 companies recognising the success of their digital transformation.\n\nTable 4.\n\nSample statistics.\n\nNevertheless, we observe a larger deviation from the average firm. Using a simple K-means clustering technique, we find about five clusters of firms, as in the silhouette/elbow techniques. At one extreme of the least resilient firms, we find the largest cluster, consisting of 37% of firms that are hardly innovative, reduce their expenditure during the pandemic, and are considered culturally and technically not agile. At the other extreme, we find a cluster of 11% of companies that are quite agile and digitally mature, while orchestrating an increasingly large ecosystem and increasing their R&D intensity during the pandemic. Another segment of 22% of companies, which also showed better than average resilience, is characterised by accelerated participation in ecosystems and strong non-incremental innovation capabilities during the pandemic—in contrast to the majority of companies that froze investments as a result of the pandemic risk. Two other segments (each with around 15% of firms) are closer to the average firm, but stand out for their success in digital transformation and technical (change) agility.\n\nThese different clusters clearly show non-linearity in how firms use capabilities and how this can affect recovery; they still do not say anything about how capabilities themselves can affect resilience across their full range of use. We therefore use more general machine learning techniques to capture this diversity of impact on resilience in the next subsection.\n\n4.4 Results\n\nTable 5 presents predictive accuracy, via the area under the curve (AUC) with all industries pooled. One notices that the logistic regression method is systematically dominated by at least one advanced ML technique. Based on the AUC and the versatility of the technique, random forests (RFs), then GB are the most powerful methods, but all ML models provide better predictive performance than the logistic model. Given the better performance of RF, we select RF as the ML method in the rest of this research.\n\nTable 5.\n\nML model fitness.\n\nWe assess the global contribution of each capability dimension to recovery prediction through the Mean Decrease Impurity (MDI) and SAGE procedures, which are based on Shapley values. As discussed earlier, MDI is a global importance approach, essentially the average across all trees of the capability feature’s ability to reduce noise at each node, while SAGE is a global measure as an aggregate to local fair measure of how a particular capability feature contributes to resilience. Shapley scores are calculated from RF, which is considered to be the best fitting model.\n\nImportantly, it is reminded that MDI values derived from randomised trees are asymptotic Shapley values. Note that a classic drawback of the MDI method, that it can overweight cardinal values relative to others, is not relevant in our case, as all variables are categorical as derived from the survey.\n\nTable 6 provides the results per capability dimensions for both metrics of MDI and Shapley, including the importance based on the logistic model forecasts.\n\nTable 6.\n\nAttributes impact on resilience: Global importance.\n\nNote: *; **; ***: p < 0,01, p < 0,05; p: 0,1-tests produced as per the main text.\n\nThe first observation is that all dimensions are statistically significant with the RF model, whether the metric is used in MDI or through simple values, but this is not the case with the logistic model—in particular, the latter is unable to capture any significant relevance for digitisation and for R&D intensity. This reflects the fact that RF can exploit non-linear relationships that the linear regression cannot account for. The second observation is also that the linear model overweights the importance of variables such as changes in technical agility and non-incremental R&D or full commercial exploitation of digital technologies compared to other MDI/SAGE metrics. This clearly reinforces the validity of using more flexible models than linear models for the case of resilience.\n\nFocusing on the RF model, it is clear that MDI and SAGE also provide roughly the same ranking of capabilities (r = 0.89).\n\nBased on Figure 2, which visualises both metrics by ranking the dimensions from highest to lowest global importance, SAGE underweights importance over MDI in the specific case of the impact of investment on technical agility, while SAGE overweights importance over MDI in the case of R&D intensity and digital transformation success. Notably, both metrics agree on the importance of both cultural and technical agility, non-incremental innovation, ecosystem play and digital transformation success as strong attributes affecting resilience. These nuances regarding capabilities are relatively new findings in the literature.\n\nGlobal importance ranking.\n\nTable 7 shows the contribution of the four capabilities after aggregating the importance of each dimension. Not only do the p values demonstrate that each capability significantly affects resilience, but that there is also a clear ranking, with agility contributing up to half the importance of predicting resilience, innovation half the effect of agility, and ecosystem and digitisation contributing 25–30% of the total, depending on the method of importance used.\n\nTable 7.\n\nCapabilities depicting global importance significance.\n\nNote: Random forest as underlying ML.\n\nCompared to the existing literature on resilience, a number of studies related to financial crises or major economic disruptions had already emphasised the importance of firm agility to “roar out” of the crisis but the importance of technical elements, such as speed/flexibility/risk taking in influencing resilience, had not been discussed [85].\n\nSecond, innovation has long been seen as critical to resilience, but the details here suggest that innovation orientation also affects resilience. Third, the pandemic has provided a clear use case for digitisation. The linear approach to linking digitalisation to resilience turned out to be insignificant, but not in the case of a more non-linear approach. In this latter case, investment in technology is also not seen as a strong contributor to differentiating resilient from non-resilient firms, as the key is how digital technologies are used for business transformation. This is in line with findings from the digital transformation literature, which emphasises that digital performance depends on transformational rather than technological change [86].\n\nFinally, in relation to the emerging literature on ecosystems [87], the orchestrator is often described as playing a key role as the actor responsible for designing the alignment structure, as well as the main decision maker within an ecosystem [88]. In times of crisis, the orchestrator can be an important catalyst for ecosystem adaptation and is often the first beneficiary of change.\n\nSo far, we have presented the relative importance of the capability dimensions on resilience, but we still do not know the magnitude and direction of the impact on resilience. For this, we rely on the PME estimates based on the RF model.\n\nTable 8 shows the direction of the effects—in line with the idea that capabilities should support resilience, all dimensions exert a positive push on resilience, except for two variables for which higher intensity leads to lower resilience: non-incremental innovation and investment in technical agility.\n\nTable 8.\n\nDirection of effects on resilience, derived from Shapley values.\n\nNote: Sign derived from plotting the minimal detectable effect (MDE) of each dimension on resilience probability, from low to high value range of each dimension. We observe same directional effects from the probit model.\n\nThe latter, while perhaps puzzling, may reflect the fact that companies that invest in agility at the time of the pandemic are just trying to catch up, but this may be too late, given the magnitude of the shock. Indeed, we find that firms with strong technical agility do not invest more in technical agility at the time of the pandemic (r = 0.58), while the ability to be technically agile before the pandemic has a strong positive effect on resilience in our marginal impact assessment. Regarding innovation, the fact that more disruptive R&D is negatively associated with resilience should be seen with two nuances. First, the marginal effect is rather small, i.e. the effect on the probability of resilience decreases by only 2 points for a firm moving from no disruptive R&D to fully disruptive R&D. Finally, it should be remembered that resilience is measured here as recovery in 18 months (our cut-off for resilience)—disruptive R&D often takes longer to show results [89].\n\nFinally, Table 9 presents the PME profiles for some of the key variables for the RF model, in addition to a visualisation of the evolution of the marginal effect through the deciles of the range of each attribute (Figure 3). One can see the high non-linearity of the marginal effect, as well as a non-significant sweet spot area where attributes do not affect resilience at the margin; this sweet spot often appears around the second to fourth decile of the distribution, or around Q1-Q2 of the attributes. In this zone, firms are not resilient—and any marginal effect will not make them better off. The largest marginal effect occurs at the late stage of the distribution, confirming that resilience depends on a strong accumulation of capabilities.\n\nTable 9.\n\nMarginal effect dynamics and significance based on RF.\n\nIn bold: non-significant using bootstrapped standard errors for RF.\n\nMarginal effect evolution of capabilities on resilience. Note: Agility: technical agility embeddedness before COVID-19 only; ecosystem: role only.\n\n5. Conclusion\n\nThere is great potential to expand data science approaches, both to exploit a growing amount of very diverse and complex data, and to better capture the non-linear dynamics of how attributes affect economic phenomena. In this paper, we have shown how data science has made tremendous progress—with a wealth of new machine learning methods, as well as inference techniques based (or not) on these models—and how this has led to an important convergence between data science and traditional parametric econometrics in recent years.\n\nWe have illustrated this convergence with an empirical analysis of firm resilience associated with firm capabilities at the time of the recent pandemic crisis. The results suggest that machine learning techniques, such as Random Forest, can provide more robust yet transparent results to explain economic phenomena. It illustrates the richness of non-linearities and how these linearities can be crucial to more accurately predict resilience. Techniques such as Shapley values not only show that capabilities are positively associated with resilience, as one can capture with linear models, but also that the association is volatile and not always true—while it may even become stronger and more impactful for firms with a significant portfolio of capabilities prior to the pandemic.\n\nThere is still a lot of controversy about how ML works and how to use metrics to make inferences non-parametrically from data alone. But the path is promising—and we definitely agree with Atley’s statement ([50], p. 507) that “machine learning [could] have a dramatic impact on the field of economics within a short period of time”.\n\nAppendix\n\nComputational methods of machine learning models\n\nThis appendix provides a detailed overview of the machine learning models methods (Table A1).\n\nTable A1.\n\nA.1 Decision trees\n\nDecision trees are constructed by recursively partitioning the dataset into subsets based on feature purity. At each node, the algorithm selects the feature and threshold that maximises a partitioning criterion, such as Gini impurity or information gain. Their strengths are simplicity and interpretability. Decision trees provide a clear visual representation of decision rules; however, they are prone to overfitting, especially in deep trees.\n\nHow it works:\n\nStart with the entire dataset at the root.\n\nFor each feature, evaluate the potential split using the chosen criterion.\n\nSelect the best split and create child nodes.\n\nRepeat until a stop condition is met (e.g., maximum depth, minimum samples per sheet)\n\nA.2 Random forests\n\nRandom forests combine multiple decision trees through a process called bagging. Each tree is trained on a bootstrapped sample of the data, and predictions are aggregated by averaging (regression) or majority voting (classification). Their strengths are stability, reduced overfitting and robustness to noise, but this comes at the cost of reduced interpretability due to the ensemble nature.\n\nHow it works:\n\nGenerate several bootstrapped samples from the original dataset.\n\nTrain a decision tree on each sample, using a random subset of features at each split.\n\nAggregate the predictions from all the trees.\n\nA.3 Gradient boosting\n\nGradient boosting builds an ensemble of weak learners (e.g., shallow decision trees) sequentially. Each new learner attempts to correct the errors of the previous ones by optimising a loss function. If gradient boosting provides high predictive accuracy and flexibility, the method is computationally expensive, with a clear risk of overfitting without proper tuning.\n\nHow it works:\n\nInitialise the model with a simple prediction (e.g., the mean of the target variable).\n\nCalculate residuals based on the current model predictions.\n\nFit a new learner to the residuals.\n\nUpdate the model by adding the predictions of the new learner, scaled by a learning rate.\n\nRepeat for a fixed number of iterations or until convergence.\n\nA.4 Support vector machines (SVMs)\n\nSVM finds a hyperplane that separates data points into classes with the maximum margin. Non-linear relationships are captured using kernel functions. The method is effective for high-dimensional spaces and non-linear boundaries, but relies on careful kernel selection and parameter tuning.\n\nHow it works:\n\nTransform the input features using a kernel function (e.g., linear, polynomial, radial basis function (RBF)).\n\nSolve a quadratic optimisation problem to maximise the distance between classes.\n\nUse support vectors (data points closest to the hyperplane) to define the decision boundary.\n\nA.5 Neural networks\n\nNeural networks (NNs) consist of layers of interconnected nodes (neurons) that transform input features through weighted connections and activation functions. While capable of capturing complex, non-linear relationships, NNs operate on large datasets and therefore require large computational resources; NNs are also prone to overfitting.\n\nHow it works:\n\nRandomly initialise weights and biases.\n\nPerform forward propagation to compute predictions.\n\nCompute loss using a predefined loss function (e.g., mean squared error).\n\nUse backpropagation to calculate gradients of loss with respect to weights.\n\nUpdate the weights using an optimisation algorithm (e.g., stochastic gradient descent).\n\nRepeat until convergence or a predefined number of epochs.\n\nAppendix 2: Shapley value derivation\n\nB.1 Shapley value: Origin and leverage in ML\n\nShapley values come from cooperative game theory, developed by Lloyd [45]. They offer a fair way to distribute the total gain (or cost) generated by a coalition of players based on each player’s contribution. In the context of machine learning (ML), and the trend towards responsible ML (Bughin, 2024b), Shapley values have been widely adapted, which give three important features:\n\nExplainability: Shapley values help make machine learning models more interpretable by showing how individual features affect a model’s prediction. This is particularly important for complex models like neural networks or ensemble methods (e.g., random forests, gradient boosting), which are often considered “black boxes”.\n\nFairness and transparency: Since Shapley values fairly distribute the contribution of each feature, they are widely used to address concerns about bias and fairness in AI. This is crucial in sectors like healthcare, finance or law, where model decisions must be explained to avoid unfair treatment based on sensitive features (e.g., gender, race).\n\nGlobal and local explanations: Shapley values can provide both local (individual prediction) and global (overall model behaviour) insights. This allows users to explain why a model made a specific decision in one instance and how different features generally influence predictions.\n\nIn addition, Shapley values have some uniquely desirable properties, such as (1) efficiency: The sum of the contributions across all features equals the difference between the model’s prediction and a baseline value, (2) symmetry: If two features contribute equally, they receive the same Shapley value and (3) additivity: For models combining multiple components, the Shapley value for the combined model is the sum of the Shapley values for the individual components.\n\nB.2 Shapley value: Definition and computation\n\nShapley values, ’s, are a solution to how they should share the total profit in a cooperative game between acting players, N. By analogy with machine learning, suppose there are 𝑁 features (instead of players) that cooperate to obtain a better output prediction (instead of profit) than one alone.\n\nThe given data are characterised by a function g of a prediction by any subset 𝑆 of 𝑁 features; the interpretation of g is that for any subset 𝑆 of 𝑁, g(𝑆) is the extra prediction gain that the members of 𝑆 should share among themselves. The only constraint on g is that g(𝑆 ∪ 𝑇) ≥ g(𝑆) + g(𝑇), which implies that the value of the coalition is at least equal to the value of its parts acting separately.\n\nAssuming the three features described above, that is\n\nThe sum of the Shapley values of all attributes is equal to the value of the total attribute coalition, so that all the gain is distributed among the attributes (“efficiency” axiom).\n\nIf attributes 𝑖 and 𝑗 are equivalent in the sense that g(𝑆 ∪ {𝑖}) = g(𝑆 ∪ {𝑗}) for any subset 𝑆 of 𝑁 containing neither 𝑖 nor 𝑗, then the values for 𝑖 and 𝑗 are equivalent 𝜙𝑖(g) = 𝜙𝑗(g) (“symmetry” axiom).\n\nFor two output functions, g and h, 𝜙(g) +𝜙𝑖(h) = 𝜙𝑖(g + h) for all 𝑖 in 𝑁, where the game [g + h] is defined by [g + h](𝑆) = g(𝑆) + h𝑤(𝑆) for any coalition 𝑆 (“additivity axiom”).\n\nThen there is a unique solution, called the Shapley value and as shown by Shapley [45], the attribute 𝑖 Shapley value satisfies:\n\nAs g is not known automatically, (A1) is estimated as:\n\nwhere the term [𝑓𝑆∪{𝑖}(𝑥𝑆∪{𝑖}) - 𝑓𝑆(𝑥𝑆)] is the marginal contribution of player 𝑖 to coalitions 𝑆; 𝐹 is a set of players and 𝑆 is a subset of 𝐹 that does not include the 𝑖th player 𝑆 ⊂ 𝐹 ∖{𝑖}, while|𝐹|! are the permutations of the number of 𝐹.\n\nAs an example (see Yamaguchi [63]), suppose three features with same equally likely probability to be activated in sequence and influence the outcome. Given (A2), we first compute the probabilities (|𝑆|! (|𝐹|−|𝑆|−1)!/|𝐹|!, then the marginal function [𝑓𝑆∪{𝑖}(𝑥𝑆∪{𝑖}) - 𝑓𝑆(𝑥𝑆)].\n\nWe thus have 𝐹 =3 = {𝑋1, 𝑋2, X3} and 𝑖 = 1 are given, while the number of permutations is |𝐹|! = 6, and 𝑆 are the following four subsets: {{none}, {𝑋2}, {𝑋3}, {𝑋2, 𝑋3}}, Cases {none} and {𝑋2, 𝑋3} imply S = 2,and|𝑆|!(|𝐹| − |𝑆| − 1)!/|𝐹|! = 2/6, while the two other cases lead to a probability of 1/6 each.\n\nThen, one needs to compute each company characteristic function g using the regression model (𝑋). When finding g, each characteristic value is fixed to find the value of g(𝑥). S one uses the expected value (the average value) of the feature instead of the missing feature, that is for the four possibilities:\n\n𝜙0 = 𝐸[𝑓(𝑋)]; 𝜙1 = 𝐸[𝑓(𝑋)|𝑋1 = 𝑥1] - 𝜙0; 𝜙2 = 𝐸[𝑓(𝑋)|𝑋1 = 𝑥1, 𝑋2 = 𝑥2] - 𝜙1; 𝜙3 = 𝐸[𝑓(𝑋)|𝑋1 = 𝑥1, 𝑋2 = 𝑥2, 𝑋3 = 𝑥3] - 𝜙2 and the SHAP values are obtained by averaging the 𝜙𝑖 values over all possible orders.\n\nReferences\n\nWRITTEN BY\n\nSubmitted: 12 October 2024 Reviewed: 20 November 2024 Published: 20 January 2025\n\n© The Author(s). Licensee IntechOpen. This content is distributed under the terms of the Creative Commons Attribution 4.0 International License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.\n\nBOOKS OPEN FOR CHAPTER SUBMISSIONS\n\nWe welcome new submissions from researchers looking to share their work with a global audience, making their findings openly accessible and widely recognized.\n\nLearn how to publish with IntechOpen - from submission to publication.\n\nSUBMISSION DEADLINE\n11 March 2025\nDeadline Extended:\nOpen for Submission\n\nSUBMISSION DEADLINE\n12 March 2025\nDeadline Extended:\nOpen for Submission\n\nSUBMISSION DEADLINE\n12 March 2025\nDeadline Extended:\nOpen for Submission\n\nIntechOpen Limited\n167-169 Great Portland Street,\nLondon, W1W 5PF,\nUNITED KINGDOM\n\nPhone: +44 20 8089 5702\n\n© 2025 IntechOpen. All rights reserved.\n"
    },
    "AnalyzedArticles": {
        "Machine learning models employed in bankruptcy prediction": {
            "Article_Summary": "The research focuses on using machine learning models for bankruptcy prediction, specifically applying XGBoost, Random Forest, and Support Vector Machines to a large dataset of 21,114 US firms from 1970-2020 with 57 financial ratios. The study highlights the importance of bankruptcy prediction for resource allocation, policy making, and investor decision-making. The key innovation is using a much larger and more comprehensive dataset compared to previous studies, with advanced data preprocessing techniques like SMOTE for handling class imbalance.",
            "ML_Models": "XGBoost, Support Vector Machines (SVM), Borderline-SVM SMOTE"
        },
        "Machine learning models employed in financial performance optimization": {
            "Article_Summary": "The research explores advanced machine learning models for financial risk prediction and portfolio optimization, focusing on deep learning techniques like LSTM and Transformer networks. The study demonstrates that these models significantly outperform traditional financial methods by capturing complex temporal dependencies in financial data, providing more accurate predictions of asset returns and portfolio performance.",
            "ML_Models": "Transformer networks, LSTM, Gradient Boosting"
        },
        "Machine learning models employed in customer banking product targeting": {
            "Article_Summary": "The article discusses how machine learning enables advanced customer segmentation in banking by analyzing diverse datasets including transactional data, demographics, web behavior, social media activity, and customer service interactions. ML helps banks create more precise customer segments, personalize experiences, manage risks, and develop targeted products.",
            "ML_Models": "Support Vector Machines (SVM), Neural Networks, Decision Trees"
        },
        "Machine learning models employed in economic trend impact analysis": {
            "Article_Summary": "The articles discuss the application of machine learning models in economic forecasting, focusing on predicting output gaps, corporate resilience, and economic trends. The research highlights the potential of ML techniques to capture complex, non-linear relationships in economic data that traditional econometric models might miss.",
            "ML_Models": "XGBoost, Random Forests, Support Vector Machines (SVM)"
        }
    },
    "Relationship": {
        "Machine learning models employed in bankruptcy prediction": [
            "The bankruptcy prediction models (XGBoost, SVM, Borderline-SVM SMOTE) directly relate to the 'data' table which contains comprehensive financial indicators and the target variable 'Bankrupt?'. These models analyze financial ratios, profitability metrics, debt levels, and cash flow indicators to predict company bankruptcy risk."
        ],
        "Machine learning models employed in financial performance optimization": [
            "The financial performance optimization models (XGBoost, SVMs, Decision Trees, Ensemble Methods) align perfectly with the 'data' table which contains comprehensive financial ratios and performance indicators. These models can analyze the relationships between financial metrics to predict bankruptcy risk and optimize financial performance. The banking table provides complementary customer-level data that could be used for segmentation and targeted financial strategies."
        ],
        "Machine learning models employed in customer banking product targeting": [
            "The banking dataset contains customer demographic information and previous marketing campaign results, which is ideal for the ML models mentioned (Random Forest, Logistic Regression, K-Means Clustering, Naive Bayes, SVM, Neural Networks, Decision Trees). These models can be used to predict which customers are likely to accept banking product offers, segment customers based on similar characteristics, and optimize marketing campaigns."
        ],
        "Machine learning models employed in economic trend impact analysis": [
            "The economic trend impact analysis models (Time Series Models, LSTM Networks, Regression Analysis, Prophet) can leverage both financial data from the 'data' table and economic indicators from the 'banking' table to predict how macroeconomic trends affect business performance and bankruptcy risk. XGBoost, Random Forests, and SVMs can be used as the implementation methods for these predictive models."
        ]
    },
    "Needs": {
        "Machine learning models employed in bankruptcy prediction": [
            "For bankruptcy prediction, we need the 'Bankrupt?' column as the binary target variable (classification task), with financial indicators as features. XGBoost requires numerical inputs for all financial ratios. SVM works best with normalized financial metrics to prevent scale-dependent bias. Borderline-SVM SMOTE addresses class imbalance by generating synthetic samples of the minority class (bankrupt companies). All models require preprocessing to handle missing values and outliers in financial data."
        ],
        "Machine learning models employed in financial performance optimization": [
            "For financial performance optimization, we need numerical features from the 'data' table as inputs, with 'Bankrupt?' likely serving as the target variable for classification. The models require properly scaled financial ratios to predict bankruptcy risk or optimize performance metrics. XGBoost and ensemble methods can handle the mix of financial indicators to identify patterns leading to better financial outcomes. The banking table data could supplement this with customer demographic information for more targeted financial strategies, where 'y' might indicate customer response to financial products."
        ],
        "Machine learning models employed in customer banking product targeting": [
            "For customer banking product targeting, we need both categorical features (job, marital, education) and numerical features (age, duration, campaign) to train classification models. The target variable 'y' indicates whether a customer subscribed to a product. Random Forest and Decision Trees can handle mixed data types and identify important features. Logistic Regression requires encoding categorical variables. K-Means can segment customers into groups with similar characteristics. SVM can find optimal boundaries between customer groups. Neural Networks may require normalization of numerical features. All models aim to classify customers as likely or unlikely to accept offers, enabling targeted marketing campaigns."
        ],
        "Machine learning models employed in economic trend impact analysis": [
            "For economic trend impact analysis, we need time-series data from both tables. The 'banking' table provides macroeconomic indicators while the 'data' table provides company financial performance metrics. The ML models require numerical features from both tables with timestamps (implied by 'month' in banking table) to establish temporal relationships. The target variable could be 'Bankrupt?' (classification) or financial performance metrics (regression). Time series models like LSTM and Prophet need sequential data ordered by time to forecast future economic impacts on business performance."
        ]
    },
    "ModelsPerTopic": {
        "Machine learning models employed in bankruptcy prediction": "XGBoost, Support Vector Machines (SVM), Borderline-SVM SMOTE",
        "Machine learning models employed in financial performance optimization": "Transformer networks, LSTM, Gradient Boosting",
        "Machine learning models employed in customer banking product targeting": "Support Vector Machines (SVM), Neural Networks, Decision Trees",
        "Machine learning models employed in economic trend impact analysis": "XGBoost, Random Forests, Support Vector Machines (SVM)"
    },
    "ML_Models1": [
        "Random Forest, Gradient Boosting, Neural Networks, Logistic Regression",
        "XGBoost, Support Vector Machines, Decision Trees, Ensemble Methods",
        "Random Forest, Logistic Regression, K-Means Clustering, Naive Bayes",
        "Time Series Models, LSTM Networks, Regression Analysis, Prophet"
    ],
    "GPT_Columns": {
        "Machine learning models employed in bankruptcy prediction": [
            [
                {
                    "data": [
                        "Bankrupt?",
                        "ROA(C) before interest and depreciation before interest",
                        "Debt ratio %",
                        "Cash flow rate",
                        "Total debt/Total net worth",
                        "Net Income to Total Assets",
                        "Operating Profit Rate"
                    ]
                }
            ]
        ],
        "Machine learning models employed in financial performance optimization": [
            [
                {
                    "data": [
                        "Bankrupt?",
                        "ROA(C) before interest and depreciation before interest",
                        "Operating Gross Margin",
                        "Cash flow rate",
                        "Total debt/Total net worth",
                        "Net Income to Total Assets",
                        "Liability to Equity",
                        "Operating Profit Growth Rate"
                    ]
                },
                {
                    "banking": [
                        "age",
                        "job",
                        "education",
                        "default",
                        "housing",
                        "loan",
                        "y"
                    ]
                }
            ]
        ],
        "Machine learning models employed in customer banking product targeting": [
            [
                {
                    "banking": [
                        "age",
                        "job",
                        "marital",
                        "education",
                        "housing",
                        "loan",
                        "duration",
                        "campaign",
                        "previous",
                        "poutcome",
                        "emp_var_rate",
                        "cons_price_idx",
                        "cons_conf_idx",
                        "euribor3m",
                        "y"
                    ]
                }
            ]
        ],
        "Machine learning models employed in economic trend impact analysis": [
            [
                {
                    "data": [
                        "Bankrupt?",
                        "ROA(C) before interest and depreciation before interest",
                        "Operating Profit Rate",
                        "Cash flow rate",
                        "Total Asset Growth Rate",
                        "Net Income to Total Assets",
                        "Liability to Equity"
                    ]
                },
                {
                    "banking": [
                        "emp_var_rate",
                        "cons_price_idx",
                        "cons_conf_idx",
                        "euribor3m",
                        "nr_employed",
                        "month",
                        "y"
                    ]
                }
            ]
        ]
    },
    "AdjustedColumns": {}
}