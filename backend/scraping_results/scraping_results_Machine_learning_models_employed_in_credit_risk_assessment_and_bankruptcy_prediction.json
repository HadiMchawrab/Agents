{
    "content1": "\nNavigation Menu\n\nkoso9/Bankruptcy-ML-Prediction\n\nFolders and files\n\nLatest commit\n\nHistory\n\nRepository files navigation\n\nAI-Driven Credit Risk Assessment for Banking: Predicting Bankruptcy with Machine Learning\n\nOverview\n\nBankruptcy prediction is a critical tool for financial institutions, investors, and risk managers. This project leverages machine learning models to assess corporate financial health, reducing risk exposure and enhancing portfolio decision-making. Using the Polish Companies Bankruptcy Dataset (2000‚Äì2013), this model evaluates key financial indicators to classify firms as financially stable or at risk of bankruptcy. This project achieved 96.28% accuracy using Calibrated XGBoost, demonstrating a scalable approach to modern credit risk evaluation and financial health assessment.\n\nWhy It Matters\n\nKey Features\n\nMachine Learning Models: This project evaluates multiple models to balance accuracy, precision, and recall for bankruptcy prediction:\n\nBaseline Model: Logistic Regression:\n\nAdvanced Model: Random Forest:\n\nAdvanced Model: XGBoost Model:\n\nAdvanced Model: Calibrated XGBoost (Best Model):\n\nWhy Calibrated XGBoost?\nBy applying Isotonic Regression, the calibrated XGBoost model improves probability estimates, making it more effective for financial decision-making where precision and recall must be balanced.\n\nFeature Importance: What Drives Bankruptcy Risk?\n\nThis model identifies the most influential financial ratios in predicting bankruptcy using XGBoost‚Äôs gain-based ranking. What does \"gain\" mean?\n\nTop 10 Features Influencing Bankruptcy Predictions\n\n1Ô∏è‚É£ Return on Assets = Net Profit / Total Assets\n2Ô∏è‚É£ Liabilities Ratio = Total Liabilities / Total Assets\n3Ô∏è‚É£ Cash Ratio\n4Ô∏è‚É£ Net Working Capital Ratio = Working Capital / Total Assets\n5Ô∏è‚É£ Basic Earning Power = EBIT / Total Assets\n6Ô∏è‚É£ Debt Repayment Ratio\n7Ô∏è‚É£ Asset Turnover Ratio = Sales / Total Assets\n8Ô∏è‚É£ Equity Ratio = Equity / Total Assets\n9Ô∏è‚É£ Short-Term Profitability Ratio = Gross Profit / Short-Term Liabilities\nüîü Retained Earnings Ratio = Retained Earnings / Total Assets\n\nData Source\n\nDataset: Polish Companies Bankruptcy Dataset (UCI Repository) https://archive.ics.uci.edu/dataset/365/polish+companies+bankruptcy+data. Please go to the UCI Repository link and download the zip file before running the code\n\nScope: 2000‚Äì2013 financial data covering 5 years of company records\n\nVariables: Profitability, liquidity, leverage, and efficiency ratios\n\nBusiness Use Case & Deployment\n\nThis model has broad applications across banking, investment, and corporate finance, offering predictive insights to mitigate financial risk.\n\nLending & Credit Risk Management\n\nInvestment & Portfolio Risk Analysis\n\nCorporate Finance & Risk Monitoring\n\nModel Deployment & Integration\n\nTechnology Stack\n\nNext Steps & Future Roadmap\n\nWhile this model demonstrates strong predictive performance, particularly with Calibrated XGBoost, there are opportunities to refine its accuracy and applicability further. Enhancing recall for the minority class, incorporating real-time financial data, and improving model interpretability will be key areas of focus moving forward.\n\nFurther Optimization of Calibrated XGBoost:\n\nFeature Engineering & Refinement:\n\nBusiness Application & Deployment:\n\nModel Interpretability:\n\nAlternative Modeling Techniques:\n\nExpanding Dataset Scope:\n\nDeployment & Integration:\n\nFeel free to reach out or contribute to this project for further improvements!\n\nAbout\n\nMachine Learning Model to Predict Bankruptcy\n\nResources\n\nStars\n\nWatchers\n\nForks\n\nReleases\n\nPackages\n\nLanguages\n\nFooter\n\nFooter navigation\n",
    "content2": "\nEnhancing Credit Risk Management with Machine Learning: A Comparative Study of Predictive Models for Credit Default Prediction\n\nKeywords:\n\nAbstract\n\nThis study investigates the application of machine learning algorithms for predictive analytics in credit risk management, aiming to enhance the accuracy of predicting credit defaults. The research compares multiple machine learning models, including logistic regression, decision trees, random forests, gradient boosting, XGBoost, and LightGBM, using a real-world credit risk dataset. The study focuses on evaluating the models' performance based on metrics such as accuracy, precision, recall, and F1-score. The results show that ensemble models, particularly XGBoost and LightGBM, outperform traditional algorithms in terms of predictive accuracy and computational efficiency, demonstrating their ability to effectively handle complex datasets. The comparative analysis highlights the strengths and weaknesses of each model, providing insights into the trade-offs between interpretability and predictive power. XGBoost and LightGBM are found to be highly effective for credit risk prediction, though challenges such as model interpretability and overfitting remain. The findings suggest that machine learning offers a promising approach for improving credit risk management, with implications for the financial industry to make more informed, data-driven lending decisions. The study underscores the importance of addressing interpretability concerns and data quality issues in real-world applications, paving the way for future advancements in machine learning for credit risk prediction.\n\nThe American Journal of Applied Sciences\n\n17\n\nhttps://www.theamericanjournals.com/index.php/tajas\n\nTYPE\n\nOriginal Research\n\nPAGE NO.\n\n21-30\n\nDOI\n\n10.37547/tajas/Volume07Issue01-04\n\nOPEN ACCESS\n\nSUBMITED\n\n25 October 2024\n\nACCEPTED\n\n25 December 2024\n\nPUBLISHED\n\n30 January 2025\n\nVOLUME\n\nVol.07 Issue01 2025\n\nCITATION\n\nQuoc Giang Nguyen, Linh Hoang Nguyen, Md Monir Hosen, Mohammad\nRasel, Jannatul Ferdous Shorna, Md Sakib Mia, & Sajidul Islam Khan.\n(2025). Enhancing Credit Risk Management with Machine Learning: A\nComparative Study of Predictive Models for Credit Default Prediction.\nThe American Journal of Applied Sciences, 7(01), 21\n\n‚Äì\n\n30.\n\nhttps://doi.org/10.37547/tajas/Volume07Issue01-04\n\nCOPYRIGHT\n\n¬© 2025 Original content from this work may be used under the\nterms of the creative commons attributes 4.0 License.\n\nEnhancing Credit Risk\nManagement with\nMachine Learning: A\nComparative Study of\nPredictive Models for\nCredit Default Prediction\n\nQuoc Giang Nguyen\n\n1\n\n, Linh Hoang Nguyen\n\n2\n\n, Md\n\nMonir Hosen\n\n3\n\n, Mohammad Rasel\n\n4\n\n, Jannatul\n\nFerdous Shorna\n\n5\n\n, Md Sakib Mia\n\n6\n\n, Sajidul Islam\n\nKhan\n\n7\n\n1\n\nIEEE Professional Community, IEEE, USA\n\n2\n\nFPT Americas, USA\n\n3\n\nMS in Business Analytics, St.Francis college, USA\n\n4\n\nMasters in Business Analytics, International American University,\n\nLA, California, USA\n\n5\n\nCollege of Engineering and Computer Science, Florida Atlantic\n\nUniversity, Boca Raton, Florida\n\n6\n\nMSc in Business Analytics, Trine University, USA\n\n7\n\nMSc in Business Analytics, Trine University, USA\n\nAbstract:\n\nThis study investigates the application of\n\nmachine learning algorithms for predictive analytics\nin credit risk management, aiming to enhance the\naccuracy of predicting credit defaults. The research\ncompares multiple machine learning models,\nincluding logistic regression, decision trees, random\nforests, gradient boosting, XGBoost, and LightGBM,\nusing a real-world credit risk dataset. The study\nfocuses on evaluating the models' performance\nbased on metrics such as accuracy, precision, recall,\nand F1-score. The results show that ensemble\nmodels, particularly XGBoost and LightGBM,\noutperform traditional algorithms in terms of\npredictive accuracy and computational efficiency,\ndemonstrating their ability to effectively handle\ncomplex datasets. The comparative analysis\nhighlights the strengths and weaknesses of each\nmodel, providing insights into the trade-offs\nbetween interpretability and predictive power.\nXGBoost and LightGBM are found to be highly\neffective for credit risk prediction, though\n\nThe American Journal of Applied Sciences\n\n22\n\nhttps://www.theamericanjournals.com/index.php/tajas\n\nThe American Journal of Applied Sciences\n\nchallenges such as model interpretability and\noverfitting remain. The findings suggest that machine\nlearning offers a promising approach for improving\ncredit risk management, with implications for the\nfinancial industry to make more informed, data-driven\nlending decisions. The study underscores the\nimportance of addressing interpretability concerns and\ndata quality issues in real-world applications, paving\nthe way for future advancements in machine learning\nfor credit risk prediction.\n\nKeywords\n\n: machine learning, credit risk management,\n\npredictive analytics, XGBoost, LightGBM, decision\ntrees, logistic regression, model evaluation, accuracy,\npredictive power, data preprocessing, feature\nselection, overfitting, interpretability.\n\nIntroduction:\n\nIn recent years, credit risk management\n\nhas become an essential aspect of financial institutions\nas they strive to mitigate the risks associated with\nlending. Traditional methods of assessing credit risk\nprimarily rely on expert knowledge and historical\nfinancial data. However, these methods are often\ninsufficient in handling complex and large datasets.\nWith the rapid advancement of machine learning\ntechniques, financial institutions are now leveraging\nthese technologies to improve the accuracy and\nefficiency of credit risk assessments. Predictive\nanalytics, powered by machine learning, can identify\npotential credit defaults more effectively by analyzing\nlarge volumes of structured and unstructured data,\nproviding deeper insights into borrower behavior, and\ndetecting patterns that may not be evident through\nconventional methods.\n\nMachine learning algorithms such as logistic regression,\ndecision trees, random forests, gradient boosting,\nsupport vector machines, XGBoost, and LightGBM have\nshown remarkable success in various domains,\nincluding credit risk modeling. These algorithms can\nlearn from historical data, automatically adapt to new\npatterns, and make data-driven decisions. As a result,\nthey are increasingly used in predictive modeling to\nforecast the likelihood of default, thereby enabling\nfinancial institutions to make informed decisions\nregarding loan approvals and risk management\nstrategies.\n\nThis study aims to explore the application of machine\nlearning algorithms in credit risk prediction and provide\na comparative analysis of their performance. We\nevaluate several popular algorithms based on key\nperformance metrics such as accuracy, precision, recall,\nF1-score, and AUC-ROC. The goal is to determine which\nalgorithm provides the best balance between accuracy\nand interpretability for practical use in credit risk\nmanagement.\n\nLITERATURE REVIEW\n\nThe application of machine learning in credit risk\nmanagement has been a subject of growing interest\nover the past few decades. Early research focused on\nthe traditional statistical methods such as logistic\nregression (Altman, 1968) and discriminant analysis\n(Ohlson, 1980), which laid the foundation for the field\nof credit scoring. These models used a limited set of\nfinancial ratios and historical data to predict the\nlikelihood of default. However, these models often\nstruggled to capture complex relationships between\nvariables and faced challenges in handling large and\nunstructured datasets (Zhao, 2018).\n\nWith the advent of machine learning, the landscape of\ncredit risk management began to shift. Machine\nlearning models, such as decision trees (Breiman, 1986)\nand random forests (Breiman, 2001), provided a more\nflexible and scalable alternative. Decision trees\nmodelled data through a hierarchical structure, where\neach node represents a decision based on a feature,\nand the branches represent possible outcomes.\nRandom forests, an ensemble method, combined\nmultiple decision trees to improve accuracy and reduce\noverfitting. These models quickly gained popularity in\ncredit risk modeling due to their ability to handle large\ndatasets and capture non-linear relationships between\nvariables.\n\nGradient boosting, another ensemble technique, was\nintroduced to further improve predictive performance.\nIt builds a series of weak learners, where each model\ncorrects the errors of the previous one, allowing for\nhigh levels of accuracy and robustness (Friedman,\n2001). This technique, implemented in models like\nXGBoost (Chen & Guestrin, 2016) and LightGBM (Ke et\nal., 2017), has become one of the most effective\napproaches for credit risk prediction. XGBoost, in\nparticular, is known for its speed, scalability, and ability\nto handle missing data and imbalanced classes, making\nit ideal for financial applications.\n\nA number of studies have demonstrated the\neffectiveness of machine learning algorithms in credit\nrisk prediction. For instance, Gangan et al. (2020) used\nXGBoost for predicting credit default risk and found\nthat it outperformed traditional statistical methods in\nterms of accuracy and F1-score. Similarly, Liao et al.\n(2018) employed LightGBM for credit scoring and\nreported superior performance compared to other\nmachine learning algorithms, particularly in terms of\nspeed and accuracy in large datasets.\n\nHowever, while machine learning models have shown\npromise, challenges remain in their adoption in real-\nworld credit risk applications. Interpretability and\ntransparency of machine learning models are crucial in\n\nThe American Journal of Applied Sciences\n\n23\n\nhttps://www.theamericanjournals.com/index.php/tajas\n\nThe American Journal of Applied Sciences\n\nfinancial institutions, as regulators and stakeholders\nrequire explanations for the model's decisions\n(Caruana et al., 2015). Techniques such as SHAP\n(SHapley Additive exPlanations) and LIME (Local\nInterpretable Model-agnostic Explanations) have been\ndeveloped to address this issue and provide\nexplanations for complex models.\n\nDespite these advancements, the integration of\nmachine learning models into credit risk management\nis not without its limitations. One challenge is the\npotential for overfitting, particularly when using highly\ncomplex models such as deep learning (Bengio et al.,\n2013). To mitigate this risk, regularization techniques\nand careful model selection are essential. Additionally,\ndata quality and the handling of missing or incomplete\ninformation remain significant challenges for machine\nlearning models in financial applications.\n\nIn conclusion, while traditional credit risk models have\nprovided a foundation for financial decision-making,\nmachine\n\nlearning\n\nalgorithms\n\noffer\n\nsignificant\n\nadvantages in terms of accuracy, scalability, and the\nability to handle large, complex datasets. Recent\nstudies have shown that algorithms such as XGBoost\nand LightGBM outperform traditional models, making\nthem promising candidates for future credit risk\nmodeling.\n\nHowever,\n\nchallenges\n\nrelated\n\nto\n\ninterpretability, overfitting, and data quality must be\n\naddressed to ensure the successful implementation of\nmachine learning in credit risk management.\n\nMETHODOLOGY\n\nData Collection\n\nThe dataset for this study was carefully curated from\nmultiple reliable sources to ensure the inclusion of\ndiverse attributes relevant to credit risk assessment.\nPrimary data was obtained from publicly available\nfinancial repositories and anonymized datasets shared\nby financial institutions. These datasets included\ndetailed information on customer demographics,\nfinancial behavior, and credit history, which are crucial\nfor predicting credit risk. The data spanned a wide\nrange of loan products, such as personal loans, home\nloans, and credit cards, to provide a comprehensive\nunderstanding of credit risk across different financial\ncontexts.\n\nIn total, the dataset contained 10,000 records with\nboth numerical and categorical variables. Each record\nrepresented\n\na\n\nunique\n\ncustomer\n\nand\n\ntheir\n\ncorresponding financial attributes. The dataset was\nsubjected to an initial exploratory data analysis (EDA)\nto understand its structure and distribution, identifying\npatterns, anomalies, and potential data quality issues.\n\nBelow is the table summarizing the dataset attributes:\n\nAttribute\n\nDescription\n\nType\n\nExample\n\nCustomer_ID\n\nUnique identifier for each customer\n\nCategorical C001, C002\n\nAge\n\nAge of the customer\n\nNumerical\n\n35, 42\n\nGender\n\nGender of the customer\n\nCategorical Male, Female\n\nIncome\n\nAnnual income of the customer\n\nNumerical\n\n45,000, 65,000\n\nCredit_History_Length Duration of credit history (in years)\n\nNumerical\n\n5, 10\n\nCredit_Utilization\n\nPercentage of credit limit used\n\nNumerical\n\n40%, 75%\n\nDebt_to_Income_Ratio Ratio of total debt to annual income\n\nNumerical\n\n0.3, 0.5\n\nRepayment_Status\n\nStatus of repayments (on-time, late, defaulted)\n\nCategorical On-time, Defaulted\n\nLoan_Amount\n\nAmount of the loan or credit issued\n\nNumerical\n\n20,000, 50,000\n\nLoan_Purpose\n\nPurpose of the loan\n\nCategorical Home, Education\n\nDefault_Status\n\nWhether the customer defaulted (Target Variable) Categorical Yes, No\n\nData Processing\n\nThe data processing phase was a crucial step to ensure\nthe quality, consistency, and usability of the dataset for\nbuilding machine learning models. The raw dataset,\nwhile comprehensive, contained several imperfections,\nincluding missing values, outliers, inconsistent formats,\nand class imbalance issues. Each of these challenges\nwas addressed systematically to prepare the data for\nanalysis and modeling.\n\nThe first step involved handling missing values, which\nwere prevalent in both numerical and categorical\nattributes. Missing data can lead to biased outcomes if\nnot managed appropriately. For numerical features,\n\nsuch as Income and Credit_History_Length, the mean\nof the respective column was used for imputation. This\napproach preserved the central tendency of the data\nwithout introducing significant bias. For categorical\nattributes, such as Gender and Repayment_Status, the\nmode of each column was utilized to fill in missing\nvalues, as it represented the most frequent category\nand maintained the categorical distribution.\n\nOutlier detection and treatment formed the next\ncritical stage of data processing. Extreme values,\nparticularly in attributes like Loan_Amount and\nDebt_to_Income_Ratio, were identified using the\ninterquartile range (IQR) method. These values were\nvisualized through box plots to confirm their deviation\n\nThe American Journal of Applied Sciences\n\n24\n\nhttps://www.theamericanjournals.com/index.php/tajas\n\nThe American Journal of Applied Sciences\n\nfrom normal distributions. Rather than discarding\noutliers outright, a capping strategy was employed,\nwhere values beyond the 1st and 99th percentiles were\nadjusted to lie within these limits. This ensured that\nsignificant variations in the data were preserved while\nreducing the impact of extreme values that could\ndistort model performance.\n\nEncoding categorical variables into numerical\nrepresentations was another essential task. The\ndataset contained categorical attributes, such as\nGender, Repayment_Status, and Loan_Purpose, which\nrequired transformation for compatibility with\nmachine learning algorithms. Binary attributes, like\nGender, were encoded into numerical values (e.g., 0 for\nMale and 1 for Female). For multi-class variables, such\nas Loan_Purpose, one-hot encoding was applied to\ncreate separate binary columns for each category,\neffectively capturing the categorical information in a\nnumerical format.\n\nTo ensure uniformity in data representation, numerical\nattributes were scaled to a standard range. This step\naddressed the issue of varying scales among features,\nsuch as Income and Credit_Utilization. Min-Max scaling\nwas used to normalize these attributes, transforming\nthem to a common range between 0 and 1. Scaling\nprevented\n\nlarger\n\nnumerical\n\nranges\n\nfrom\n\ndisproportionately influencing the performance of\ndistance-based algorithms like Support Vector\nMachines and Gradient Boosting.\n\nAnother critical challenge was the class imbalance in\nthe target variable, Default_Status, which is a common\nissue in credit risk datasets. The dataset exhibited a\nskewed distribution, with significantly more instances\nof non-defaults compared to defaults. To address this\nimbalance, the Synthetic Minority Oversampling\nTechnique (SMOTE) was employed. SMOTE generated\nsynthetic samples for the minority class by\ninterpolating between existing samples, effectively\nbalancing the class distribution and enhancing the\nmodel's ability to detect credit defaults.\n\nFinally, the preprocessed dataset was split into training\nand testing subsets. A standard 80:20 split was\nemployed, with the larger portion designated for\ntraining the machine learning models. This ensured\nthat the models could learn from a comprehensive\ndataset while leaving a representative subset for\nunbiased evaluation. Care was taken to apply\nconsistent preprocessing steps to both training and\ntesting datasets, preserving the integrity of the\nevaluation process.\n\nThrough these detailed processing steps, the dataset\nwas transformed into a structured and clean format,\nready for feature selection, engineering, and model\n\ndevelopment. This meticulous approach ensured that\nthe subsequent analyses and predictions were built on\na solid foundation of reliable data.\n\nFeature Selection\n\nFeature selection is a critical step in the machine\nlearning pipeline, as it identifies the most relevant\nattributes from the dataset that contribute significantly\nto the predictive power of the model. By selecting the\nmost impactful features, the process reduces\ndimensionality, mitigates overfitting, and enhances the\nmodel's interpretability. In this study, feature selection\nwas performed using a combination of statistical\nmethods, domain knowledge, and algorithmic\napproaches.\n\nInitially, correlation analysis was conducted to measure\nthe linear relationships between numerical features\nand the target variable, Default_Status. Features with a\nhigh correlation coefficient (either positive or negative)\nwere prioritized for inclusion in the model. Heatmaps\nwere generated to visualize these correlations, helping\nto identify potential redundancies among predictors.\nAttributes\n\nlike\n\nDebt_to_Income_Ratio\n\nand\n\nCredit_Utilization showed strong correlations with\ncredit default likelihood, warranting their inclusion.\n\nFor categorical variables, Chi-square tests were applied\nto assess their statistical dependence on the target\nvariable. Variables with significant p-values were\nconsidered relevant. Additionally, domain knowledge\nwas incorporated to ensure that features with practical\nimportance,\n\nsuch\n\nas\n\nLoan_Purpose\n\nand\n\nRepayment_Status, were not excluded based solely on\nstatistical metrics.\n\nRecursive Feature Elimination (RFE) was employed as\nan advanced feature selection technique. Using\nmachine learning algorithms, such as Random Forest\nand Gradient Boosting, RFE iteratively removed less\nimportant features, retaining only those that\ncontributed the most to model accuracy. This\nautomated method ensured that the feature selection\nprocess was robust, and data driven.\n\nFeature Engineering\n\nFeature engineering further refined the dataset by\ncreating new features and transforming existing ones\nto capture more meaningful patterns and relationships.\nThis process aimed to improve the model's ability to\ndistinguish between defaults and non-defaults by\nenhancing the informativeness of the predictors.\n\nOne of the first steps involved creating interaction\nterms between features that exhibited strong\ncorrelations. For instance, the interaction between\nDebt_to_Income_Ratio and Credit_Utilization was\nexplored, as these attributes together could provide\n\nThe American Journal of Applied Sciences\n\n25\n\nhttps://www.theamericanjournals.com/index.php/tajas\n\nThe American Journal of Applied Sciences\n\ndeeper insights into a customer's financial behavior.\nPolynomial features were also introduced for key\nnumerical\n\nvariables,\n\nsuch\n\nas\n\nIncome\n\nand\n\nCredit_History_Length,\n\nto\n\ncapture\n\nnon-linear\n\nrelationships.\n\nNormalization and scaling techniques were applied to\nthe engineered features to maintain consistency across\nthe dataset. Continuous variables, including newly\ncreated features, were transformed using logarithmic\nscaling to reduce skewness and emphasize relative\ndifferences.\n\nBinning techniques were used to group numerical\nattributes into categorical ranges. For example, Age\nwas divided into brackets (e.g., young, middle-aged,\nsenior) to simplify its relationship with credit risk.\nSimilarly, Loan_Amount was categorized into small,\nmedium, and large loans to highlight patterns specific\nto different loan sizes.\n\nCategorical features were further enriched through\none-hot encoding, while ordinal encoding was applied\nto variables with an inherent order, such as\nCredit_History_Length. Feature engineering also\nincluded deriving composite variables, such as\nCredit_Utilization_to_Income_Ratio,\n\nwhich\n\nencapsulated financial stress in a single metric.\n\nModel Development\n\nThe model development phase involved selecting,\ntraining, and fine-tuning multiple machine learning\nalgorithms to predict credit risk effectively. A range of\nsupervised learning techniques was considered,\nincluding logistic regression, decision trees, random\nforests, gradient boosting (XGBoost, LightGBM), and\nsupport vector machines (SVM). Each model was\nchosen for its unique strengths in handling structured\ndatasets and addressing imbalanced classes.\n\nBefore training, hyperparameter tuning was conducted\nusing grid search and random search methods. For\ninstance, parameters such as the learning rate,\nmaximum tree depth, and number of estimators were\noptimized for boosting algorithms, while regularization\nterms were adjusted for logistic regression. The\noptimization process aimed to strike a balance\nbetween model complexity and generalizability.\n\nCross-validation was employed to evaluate model\nstability and prevent overfitting. A stratified k-fold\napproach was chosen, ensuring that each fold retained\nthe same class proportions as the original dataset. This\ntechnique provided a robust assessment of model\nperformance across different subsets of data.\n\nEnsemble methods, such as stacking, were also\nexplored to combine the predictive power of multiple\nalgorithms. By leveraging the strengths of diverse\n\nmodels, the ensemble approach enhanced accuracy\nand robustness. Each model's predictions were\nweighted according to its performance, and a meta-\nmodel was trained to aggregate these outputs for final\npredictions.\n\nModel Evaluation\n\nModel evaluation focused on assessing the\nperformance of each algorithm using a comprehensive\nset of metrics tailored to the problem of credit risk\nprediction. Since the dataset was imbalanced, accuracy\nalone was insufficient to gauge model effectiveness.\nMetrics such as precision, recall, F1-score, and area\nunder the receiver operating characteristic curve (AUC-\nROC) were prioritized.\n\nThe confusion matrix provided detailed insights into\nthe distribution of true positives, true negatives, false\npositives, and false negatives. This allowed for a\nthorough understanding of how well the model\ndifferentiated between default and non-default cases.\nSpecial emphasis was placed on minimizing false\nnegatives, as failing to identify a defaulter poses a\nsignificant risk to financial institutions.\n\nThe AUC-ROC curve was used to compare the\ndiscriminative power of the models across different\nthresholds. A higher AUC value indicated a model's\nsuperior ability to distinguish between the two classes.\nAdditionally, the precision-recall (PR) curve was\nanalyzed to assess the trade-off between precision and\nrecall, particularly for the minority class.\n\nThe evaluation also included testing the models on\nunseen data to validate their generalizability. This step\nsimulated real-world scenarios, ensuring that the\nselected model could perform consistently in practical\napplications.\n\nAfter rigorous evaluation, the best-performing model\nwas selected based on its balance of precision, recall,\nand overall robustness. This model was then deployed\nfor credit risk prediction, offering a reliable tool for\nidentifying high-risk customers.\n\nResults\n\nThe results of this study are presented in detail,\nincluding an overall performance summary of the\nmachine learning models, a comparative analysis of\ntheir effectiveness, and a discussion of which model\ndemonstrated the best predictive capabilities for credit\nrisk management.\n\nOverall Results\n\nThe performance of each model was evaluated using a\nrange of metrics, including accuracy, precision, recall,\nF1-score, and the Area Under the Receiver Operating\nCharacteristic Curve (AUC-ROC). These metrics\nprovided a comprehensive assessment of the models'\n\nThe American Journal of Applied Sciences\n\n26\n\nhttps://www.theamericanjournals.com/index.php/tajas\n\nThe American Journal of Applied Sciences\n\nability to predict credit defaults accurately while\nminimizing false positives and negatives. Table 1\n\nsummarizes the performance metrics for all the tested\nmodels.\n\nTable 1: Performance Metrics of Machine Learning Models\n\nModel\n\nAccuracy Precision Recall F1-Score AUC-ROC\n\nLogistic Regression\n\n83.2%\n\n78.5%\n\n76.4% 77.4%\n\n0.85\n\nDecision Tree\n\n81.7%\n\n76.2%\n\n74.8% 75.5%\n\n0.82\n\nRandom Forest\n\n89.5%\n\n84.3%\n\n86.7% 85.5%\n\n0.92\n\nGradient Boosting\n\n91.3%\n\n88.5%\n\n87.8% 88.1%\n\n0.94\n\nSupport Vector Machine 84.9%\n\n79.7%\n\n78.4% 79.0%\n\n0.86\n\nXGBoost\n\n92.4%\n\n89.6%\n\n89.0% 89.3%\n\n0.95\n\nLightGBM\n\n93.1%\n\n90.2%\n\n90.1% 90.1%\n\n0.96\n\nChart 1: Model Evaluation of Different machine learning algorithm\n\n83.20%\n\n81.70%\n\n89.50%\n\n91.30%\n\n84.90%\n\n92.40%\n\n93.10%\n\n78.50%\n\n76.20%\n\n84.30%\n\n88.50%\n\n79.70%\n\n89.60%\n\n90.20%\n\n76.40%\n\n74.80%\n\n86.70%\n\n87.80%\n\n78.40%\n\n89.00%\n\n90.10%\n\n77.40%\n\n75.50%\n\n85.50%\n\n88.10%\n\n79.00%\n\n89.30%\n\n90.10%\n\n0.85\n\n0.82\n\n0.92\n\n0.94\n\n0.86\n\n0.95\n\n0.96\n\n0.00%\n\n20.00%\n\n40.00%\n\n60.00%\n\n80.00%\n\n100.00%\n\n120.00%\n\nLogistic Regression\n\nDecision Tree\n\nRandom Forest\n\nGradient Boosting\n\nSupport Vector Machine\n\nXGBoost\n\nLightGBM\n\nModel Evaluation\n\nAUC-ROC\n\nF1-Score\n\nRecall\n\nPrecision\n\nAccuracy\n\nThe American Journal of Applied Sciences\n\n27\n\nhttps://www.theamericanjournals.com/index.php/tajas\n\nThe American Journal of Applied Sciences\n\nComparative Study\n\nIn the chart 1 comparative analysis reveals distinct\nstrengths and weaknesses across the evaluated\nmodels:\n\n1.\n\nLogistic Regression:\n\nLogistic Regression served as a baseline model,\nproviding a foundation for comparing other algorithms.\nIt achieved an accuracy of 83.2% and an AUC-ROC of\n0.85, indicating decent performance for a linear model.\nIts primary advantage lies in simplicity and\ninterpretability, making it suitable for quick\nimplementation. However, its limited capacity to\ncapture non-linear relationships in the dataset\nhindered its predictive power compared to more\nadvanced methods.\n\n2.\n\nDecision Tree:\n\nThe Decision Tree model demonstrated slightly lower\nperformance, with an accuracy of 81.7% and an AUC-\nROC of 0.82. While it offered high interpretability and\nease of implementation, its tendency to overfit the\ntraining data reduced its generalization capabilities.\nPruning techniques and hyperparameter tuning can\nmitigate overfitting, but the model remained less\ncompetitive overall.\n\n3.\n\nRandom Forest:\n\nRandom Forest improved the results significantly,\nachieving an accuracy of 89.5% and an AUC-ROC of\n0.92. By combining multiple decision trees through\nbagging, the model reduced overfitting and enhanced\nrobustness. This ensemble method effectively captured\ncomplex patterns in the data, making it a reliable choice\nfor credit risk prediction.\n\n4.\n\nGradient Boosting:\n\nGradient Boosting outperformed Random Forest with\nan accuracy of 91.3% and an AUC-ROC of 0.94. Its\niterative optimization approach, which builds weak\nlearners sequentially to minimize errors, allowed it to\nmodel intricate relationships in the dataset. While\ncomputationally more intensive, Gradient Boosting\ndemonstrated superior predictive capabilities, making\nit highly suitable for this domain.\n\n5.\n\nSupport Vector Machine (SVM):\n\nThe SVM model performed reasonably well, achieving\nan accuracy of 84.9% and an AUC-ROC of 0.86. Its ability\nto find optimal decision boundaries using kernel\nfunctions contributed to its performance. However, its\nsensitivity to hyperparameter selection and higher\ncomputational cost for large datasets limited its\napplicability in practical scenarios.\n\n6.\n\nXGBoost:\n\nXGBoost emerged as one of the top-performing\nmodels, with an accuracy of 92.4% and an AUC-ROC of\n0.95. Its advanced gradient boosting mechanism,\ncombined with effective handling of missing data and\nregularization techniques, made it highly effective for\ncredit risk prediction. Its capacity to mitigate class\nimbalance further enhanced its performance.\n\n7.\n\nLightGBM:\n\nLightGBM delivered the best overall results, achieving\nthe highest accuracy of 93.1% and an AUC-ROC of 0.96.\nIts speed, efficiency, and ability to handle large datasets\nand categorical features contributed to its exceptional\nperformance. Additionally, its leaf-wise tree growth\nstrategy allowed it to optimize resource allocation and\nmodel complex relationships effectively.\n\nThe comparative analysis clearly indicates that\nensemble methods, particularly LightGBM and\nXGBoost, outperformed traditional models such as\nLogistic Regression and Decision Trees. LightGBM's\nability to handle both categorical and numerical data\nefficiently, combined with its gradient-based learning\napproach, positioned it as the best model for this\napplication.\n\nGradient Boosting and Random Forest also showed\nstrong results, demonstrating the effectiveness of\nensemble techniques in capturing complex patterns.\nOn the other hand, SVM and Logistic Regression, while\nuseful, were less competitive due to their limitations in\nscalability and handling imbalanced data.\n\nOverall, LightGBM proved to be the most effective\nmodel for credit risk prediction in this study, delivering\nthe highest accuracy and AUC-ROC values. Its\nperformance highlights the importance of leveraging\nadvanced ensemble techniques to address the\nchallenges of credit risk management, including class\nimbalance, large feature spaces, and intricate data\npatterns.\n\nThe results underscore the need for financial\ninstitutions to adopt state-of-the-art machine learning\nmodels like LightGBM to improve decision-making,\nminimize risks, and enhance operational efficiency in\ncredit risk assessment. Future work can explore\nintegrating these models with real-time decision\nsystems to provide dynamic and adaptive risk\nevaluations.\n\nCONCLUSION\n\nIn this study, we explored the application of machine\nlearning algorithms for predictive analytics in credit risk\nmanagement. The primary aim was to evaluate and\ncompare the performance of various machine learning\nmodels, including logistic regression, decision trees,\nrandom forests, gradient boosting, XGBoost, and\n\nThe American Journal of Applied Sciences\n\n28\n\nhttps://www.theamericanjournals.com/index.php/tajas\n\nThe American Journal of Applied Sciences\n\nLightGBM, in predicting credit defaults. By utilizing a\nreal-world dataset, we applied a comprehensive\nmethodology\n\nencompassing\n\ndata\n\ncollection,\n\npreprocessing, feature selection, feature engineering,\nmodel development, and evaluation.\n\nThe results demonstrated that machine learning\nalgorithms\n\nsignificantly\n\noutperform\n\ntraditional\n\nmethods in terms of accuracy, precision, recall, and F1-\nscore. Among the models tested, XGBoost and\nLightGBM showed superior performance, providing\nhighly accurate predictions while maintaining\ncomputational efficiency. These models' ability to\nhandle large, complex datasets and capture intricate\npatterns within the data positions them as ideal\ncandidates for deployment in real-world credit risk\nmanagement systems.\n\nDespite their promising results, challenges such as\nmodel interpretability and overfitting must be\naddressed to ensure their practical applicability.\nTechniques such as SHAP and LIME can offer valuable\ninsights into model decisions, increasing transparency\nand trust among stakeholders. Additionally, issues\nrelated to data quality, such as missing values and\noutliers, require careful attention during the data\npreprocessing phase to avoid model degradation.\n\nDISCUSSION\n\nThe findings of this study reinforce the growing\nimportance of machine learning in the field of credit\nrisk management. Traditional credit scoring models,\nsuch as logistic regression, have served as the backbone\nof financial institutions' credit risk assessments for\ndecades. However, these models struggle to adapt to\nthe increasing complexity and volume of data\ngenerated in the modern financial landscape. Machine\nlearning models, on the other hand, offer significant\nadvantages in terms of scalability, adaptability, and\npredictive power.\n\nAmong the machine learning algorithms evaluated,\nXGBoost and LightGBM consistently outperformed the\nothers in terms of accuracy, precision, and recall. This\nis consistent with recent literature, which highlights the\nsuperiority of gradient boosting algorithms in credit\nscoring tasks (Gangan et al., 2020; Liao et al., 2018).\nThese models' ability to reduce bias and variance\nthrough ensemble methods makes them particularly\nwell-suited for handling imbalanced datasets, which is\noften the case in credit risk prediction where defaulters\nrepresent a small proportion of the total population.\n\nThe comparative study also revealed that decision trees\nand random forests, while effective, did not match the\nperformance of XGBoost and LightGBM in terms of\ncomputational efficiency and predictive accuracy.\nThese models, however, remain valuable due to their\n\nsimplicity and interpretability, which are important in\nregulatory environments where financial institutions\nmust justify their decisions. Logistic regression, while\nhistorically popular, was found to be less effective in\ncapturing the complex relationships in the data and\nperformed poorly compared to more advanced\nmachine learning models.\n\nWhile machine learning models offer substantial\nimprovements in predictive accuracy, challenges\nrelated to interpretability and overfitting persist.\nXGBoost and LightGBM, while effective in prediction,\nare considered \"black-box\" models, meaning that\nunderstanding why a model made a particular decision\ncan be difficult. This is a crucial concern in the financial\nindustry, where regulators and stakeholders require\ntransparency and the ability to explain model\noutcomes. Techniques such as SHAP and LIME are\nemerging as valuable tools to provide explanations for\ncomplex machine learning models and offer insights\ninto the key features driving predictions.\n\nOverfitting is another concern, particularly with\ncomplex models like gradient boosting, which can lead\nto overly optimistic results during training but perform\npoorly on unseen data. To address this, regularization\ntechniques, such as early stopping, pruning, and cross-\nvalidation, can help prevent overfitting and improve\ngeneralization.Data quality also plays a significant role\nin the performance of machine learning models.\nMissing data, outliers, and noise can degrade model\nperformance, emphasizing the importance of thorough\ndata preprocessing. Techniques such as imputation,\nnormalization, and outlier detection are critical to\nensure that the data fed into the model is clean and\nrepresentative of real-world scenarios.\n\nIn conclusion, machine learning represents a\ntransformative approach to credit risk management.\nThe ability to analyze large datasets and identify\npatterns that traditional models may overlook enables\nfinancial institutions to make more accurate and\ninformed lending decisions. However, further research\nis needed to improve model interpretability, address\noverfitting,\n\nand\n\noptimize\n\ndata\n\npreprocessing\n\ntechniques to ensure the successful implementation of\nmachine learning in credit risk management. By\novercoming these challenges, machine learning can\nsignificantly enhance the ability of financial institutions\nto predict credit defaults and manage risk effectively,\ncontributing to the overall stability of the financial\nsystem.\n\nFuture Directions\n\nFuture research could explore the integration of deep\nlearning models, such as neural networks, into credit\nrisk prediction. These models have the potential to\n\nThe American Journal of Applied Sciences\n\n29\n\nhttps://www.theamericanjournals.com/index.php/tajas\n\nThe American Journal of Applied Sciences\n\ncapture even more complex relationships in data, but\nthey also come with challenges related to\ninterpretability\n\nand\n\ntraining\n\ntime.\n\nMoreover,\n\ncombining machine learning techniques with domain\nexpertise could help develop hybrid models that offer\nboth predictive accuracy and transparency.\n\nAnother promising direction is the use of alternative\ndata sources, such as social media activity, transaction\nhistory, and customer behavior data, to further\nenhance credit risk prediction. With the increasing\navailability of big data, machine learning models could\nbenefit from incorporating these unstructured data\nsources to gain a more comprehensive understanding\nof borrower behavior and risk.\n\nIn summary, while the use of machine learning in credit\nrisk management has made significant strides, there\nare still opportunities for further refinement and\ninnovation. Continued research and development in\nthis area will be key to unlocking the full potential of\nmachine learning for financial institutions and ensuring\nthat these models are both effective and trustworthy.\n\nAcknowledgement:\n\nAll the Author Contributed Equally.\n\nREFERENCE\n\nAltman, E. I. (1968). Financial ratios, discriminant\nanalysis, and the prediction of corporate bankruptcy.\nThe\n\nJournal\n\nof\n\nFinance,\n\n23(4),\n\n589-609.\n\nhttps://doi.org/10.1111/j.1540-6261.1968.tb00843.x\n\nBengio, Y., Courville, A., & Vincent, P. (2013). Learning\ndeep architectures for AI. Foundations and Trends in\nMachine\n\nLearning,\n\n2(1),\n\n1-127.\n\nhttps://doi.org/10.1561/2200000006\n\nBreiman, L. (1986). Bagging predictors. Machine\nLearning,\n\n24(2),\n\n123-140.\n\nhttps://doi.org/10.1007/BF00116837\n\nBreiman, L. (2001). Random forests. Machine Learning,\n45(1),\n\n5-32.\n\nhttps://doi.org/10.1023/A:1010933404324\n\nCaruana, R., Gehrke, J., Koch, P., & Sturm, M. (2015).\nThe importance of model interpretability in credit\nscoring. Proceedings of the 2015 IEEE International\nConference\n\non\n\nData\n\nMining,\n\n567-576.\n\nhttps://doi.org/10.1109/ICDM.2015.61\n\nChen, T., & Guestrin, C. (2016). XGBoost: A scalable tree\nboosting system. Proceedings of the 22nd ACM SIGKDD\nInternational Conference on Knowledge Discovery and\nData\n\nMining,\n\n785-794.\n\nhttps://doi.org/10.1145/2939672.2939785\n\nFriedman, J. H. (2001). Greedy function approximation:\nA gradient boosting machine. Annals of Statistics, 29(5),\n1189-1232. https://doi.org/10.1214/aos/1013203451\n\nGangan, A., Bhattacharyya, D., & Gupta, P. (2020).\n\nCredit scoring using XGBoost: A comparison of machine\nlearning\n\napproaches.\n\nInternational\n\nJournal of\n\nComputer\n\nApplications,\n\n175(13),\n\n1-6.\n\nhttps://doi.org/10.5120/ijca2020919469\n\nKe, G., Meng, Q., & Finley, T. (2017). LightGBM: A highly\nefficient gradient boosting decision tree. Proceedings\nof the 31st International Conference on Neural\nInformation\n\nProcessing\n\nSystems,\n\n3146-3154.\n\nhttps://doi.org/10.5555/3295222.3295268\n\nLiao, S. H., & Lu, C. C. (2018). Predicting credit scoring\nusing LightGBM: An empirical study. Sustainable\nComputing: Informatics and Systems, 19, 1-7.\nhttps://doi.org/10.1016/j.suscom.2017.11.003\n\nOhlson, J. A. (1980). Financial ratios and the\nprobabilistic prediction of bankruptcy. Journal of\nAccounting\n\nResearch,\n\n18(1),\n\n109-131.\n\nhttps://doi.org/10.2307/2490395\n\nZhao, Z. (2018). An analysis of credit risk prediction\nusing machine learning. Journal of Computer Science\nand\n\nTechnology,\n\n33(5),\n\n987-1003.\n\nhttps://doi.org/10.1007/s11390-018-1825-2\n\nMd Jamil Ahmmed, Md Mohibur Rahman, Ashim\nChandra Das, Pritom Das, Tamanna Pervin, Sadia Afrin,\nSanjida Akter Tisha, Md Mehedi Hassan, & Nabila\nRahman. (2024). COMPARATIVE ANALYSIS OF\nMACHINE LEARNING ALGORITHMS FOR BANKING\nFRAUD DETECTION: A STUDY ON PERFORMANCE,\nPRECISION,\n\nAND\n\nREAL-TIME\n\nAPPLICATION.\n\nInternational Journal of Computer Science &\nInformation\n\nSystem,\n\n9(11),\n\n31\n\n‚Äì\n\n44.\n\nhttps://doi.org/10.55640/ijcsis/Volume09Issue11-04\n\nDas, A. C., Mozumder, M. S. A., Hasan, M. A., Bhuiyan,\nM., Islam, M. R., Hossain, M. N., ... & Alam, M. I. (2024).\nMACHINE LEARNING APPROACHES FOR DEMAND\nFORECASTING:\n\nTHE\n\nIMPACT\n\nOF\n\nCUSTOMER\n\nSATISFACTION ON PREDICTION ACCURACY. The\nAmerican Journal of Engineering and Technology,\n6(10), 42-53.\n\nMd Risalat Hossain Ontor, Asif Iqbal, Emon Ahmed,\nTanvirahmedshuvo, & Ashequr Rahman. (2024).\nLEVERAGING DIGITAL TRANSFORMATION AND SOCIAL\nMEDIA ANALYTICS FOR OPTIMIZING US FASHION\n\nBRANDS‚Äô PERFORMANCE: A MACHINE LEARNING\n\nAPPROACH. International Journal of Computer Science\n&\n\nInformation\n\nSystem,\n\n9(11),\n\n45\n\n‚Äì\n\n56.\n\nhttps://doi.org/10.55640/ijcsis/Volume09Issue11-05\n\nRahman, A., Iqbal, A., Ahmed, E., & Ontor, M. R. H.\n(2024). PRIVACY-PRESERVING MACHINE LEARNING:\nTECHNIQUES, CHALLENGES, AND FUTURE DIRECTIONS\nIN SAFEGUARDING PERSONAL DATA MANAGEMENT.\nInternational journal of business and management\nsciences, 4(12), 18-32.\n\nThe American Journal of Applied Sciences\n\n30\n\nhttps://www.theamericanjournals.com/index.php/tajas\n\nThe American Journal of Applied Sciences\n\nShak, M. S., Uddin, A., Rahman, M. H., Anjum, N., Al\nBony, M. N. V., Alam, M., ... & Pervin, T. (2024).\nINNOVATIVE MACHINE LEARNING APPROACHES TO\nFOSTER FINANCIAL INCLUSION IN MICROFINANCE.\nInternational Interdisciplinary Business Economics\nAdvancement Journal, 5(11), 6-20.\n\nNaznin, R., Sarkar, M. A. I., Asaduzzaman, M., Akter, S.,\nMou, S. N., Miah, M. R., ... & Sajal, A. (2024).\nENHANCING\n\nSMALL\n\nBUSINESS\n\nMANAGEMENT\n\nTHROUGH MACHINE LEARNING: A COMPARATIVE\nSTUDY OF PREDICTIVE MODELS FOR CUSTOMER\nRETENTION,\n\nFINANCIAL\n\nFORECASTING,\n\nAND\n\nINVENTORY\n\nOPTIMIZATION.\n\nInternational\n\nInterdisciplinary Business Economics Advancement\nJournal, 5(11), 21-32.\n\nBhattacharjee, B., Mou, S. N., Hossain, M. S., Rahman,\nM. K., Hassan, M. M., Rahman, N., ... & Haque, M. S. U.\n(2024). MACHINE LEARNING FOR COST ESTIMATION\nAND FORECASTING IN BANKING: A COMPARATIVE\nANALYSIS OF ALGORITHMS. Frontline Marketing,\nManagement and Economics Journal, 4(12), 66-83.\n\nRahman, A., Iqbal, A., Ahmed, E., & Ontor, M. R. H.\n(2024). PRIVACY-PRESERVING MACHINE LEARNING:\nTECHNIQUES, CHALLENGES, AND FUTURE DIRECTIONS\nIN SAFEGUARDING PERSONAL DATA MANAGEMENT.\nFrontline Marketing, Management and Economics\nJournal, 4(12), 84-106.\n\nAl Mamun, A., Hossain, M. S., Rishad, S. S. I., Rahman,\nM. M., Shakil, F., Choudhury, M. Z. M. E., ... & Sultana,\nS. (2024). MACHINE LEARNING FOR STOCK MARKET\nSECURITY MEASUREMENT: A COMPARATIVE ANALYSIS\nOF SUPERVISED, UNSUPERVISED, AND DEEP LEARNING\nMODELS. The American Journal of Engineering and\nTechnology, 6(11), 63-76.\n\nDas, A. C., Rishad, S. S. I., Akter, P., Tisha, S. A., Afrin, S.,\nShakil, F., ... & Rahman, M. M. (2024). ENHANCING\nBLOCKCHAIN SECURITY WITH MACHINE LEARNING: A\nCOMPREHENSIVE STUDY OF ALGORITHMS AND\nAPPLICATIONS. The American Journal of Engineering\nand Technology, 6(12), 150-162.\n\nMiah, J., Khan, R. H., Ahmed, S., & Mahmud, M. I. (2023,\nJune). A comparative study of detecting covid 19 by\nusing chest X-ray images\n\n‚Äì\n\nA deep learning approach. In\n\n2023 IEEE World AI IoT Congress (AIIoT) (pp. 0311-\n0316). IEEE.\n\nMiah, J. (2024). HOW FAMILY DNA CAN CAUSE LUNG\nCANCER USING MACHINE LEARNING. International\nJournal of Medical Science and Public Health Research,\n5(12), 8-14.\n\nRahman, M. M., Akhi, S. S., Hossain, S., Ayub, M. I.,\nSiddique, M. T., Nath, A., ... & Hassan, M. M. (2024).\n\nEVALUATING MACHINE LEARNING MODELS FOR\nOPTIMAL CUSTOMER SEGMENTATION IN BANKING: A\nCOMPARATIVE STUDY. The American Journal of\nEngineering and Technology, 6(12), 68-83.\n\nDas, P., Pervin, T., Bhattacharjee, B., Karim, M. R.,\nSultana, N., Khan, M. S., ... & Kamruzzaman, F. N. U.\n(2024). OPTIMIZING REAL-TIME DYNAMIC PRICING\nSTRATEGIES IN RETAIL AND E-COMMERCE USING\nMACHINE LEARNING MODELS. The American Journal of\nEngineering and Technology, 6(12), 163-177.\n\nHossain, M. N., Hossain, S., Nath, A., Nath, P. C., Ayub,\nM. I., Hassan, M. M., ... & Rasel, M. (2024). ENHANCED\nBANKING FRAUD DETECTION: A COMPARATIVE\nANALYSIS OF SUPERVISED MACHINE LEARNING\nALGORITHMS. American Research Index Library, 23-35.\n\nAhmmed, M. J., Rahman, M. M., Das, A. C., Das, P.,\nPervin, T., Afrin, S., ... & Rahman, N. (2024).\nCOMPARATIVE ANALYSIS OF MACHINE LEARNING\nALGORITHMS FOR BANKING FRAUD DETECTION: A\nSTUDY ON PERFORMANCE, PRECISION, AND REAL-TIME\nAPPLICATION. American Research Index Library, 31-44.\n\nAl Bony, M. N. V., Das, P., Pervin, T., Shak, M. S., Akter,\nS., Anjum, N., ... & Rahman, M. K. (2024).\nCOMPARATIVE PERFORMANCE ANALYSIS OF MACHINE\nLEARNING ALGORITHMS FOR BUSINESS INTELLIGENCE:\nA STUDY ON CLASSIFICATION AND REGRESSION\nMODELS. Frontline Marketing, Management and\nEconomics Journal, 4(11), 72-92.\n\nDas, A. C., Rishad, S. S. I., Akter, P., Tisha, S. A., Afrin, S.,\nShakil, F., ... & Rahman, M. M. (2024). ENHANCING\nBLOCKCHAIN SECURITY WITH MACHINE LEARNING: A\nCOMPREHENSIVE STUDY OF ALGORITHMS AND\nAPPLICATIONS. The American Journal of Engineering\nand Technology, 6(12), 150-162.\n\nAhmed, M. P., Das, A. C., Akter, P., Mou, S. N., Tisha, S.\nA., Shakil, F., ... & Ahmed, A. (2024). HARNESSING\nMACHINE LEARNING MODELS FOR ACCURATE\nCUSTOMER\n\nLIFETIME\n\nVALUE\n\nPREDICTION:\n\nA\n\nCOMPARATIVE STUDY IN MODERN BUSINESS\nANALYTICS. American Research Index Library, 06-22.\n\nAkter, P., Hossain, S., Siddique, M. T., Ayub, M. I., Nath,\nA., Nath, P. C., ... & Hassan, M. M. (2025). Sentiment\nAnalysis of Consumer Feedback and Its Impact on\nBusiness Strategies by Machine Learning. The American\nJournal of Applied sciences, 7(01), 6-16.\n\nHossain, M. S., Khan, A., Das, P., Haque, M. S. U.,\nKamruzzaman, F., Akter, S., ... & Miah, M. R. (2025).\nEnhanced market trend forecasting using machine\nlearning models: a study with external factor\nintegration. International Interdisciplinary Business\nEconomics Advancement Journal, 6(01), 5-12.\n\nReferences\n\nAltman, E. I. (1968). Financial ratios, discriminant analysis, and the prediction of corporate bankruptcy. The Journal of Finance, 23(4), 589-609. https://doi.org/10.1111/j.1540-6261.1968.tb00843.x\n\nBengio, Y., Courville, A., & Vincent, P. (2013). Learning deep architectures for AI. Foundations and Trends in Machine Learning, 2(1), 1-127. https://doi.org/10.1561/2200000006\n\nBreiman, L. (1986). Bagging predictors. Machine Learning, 24(2), 123-140. https://doi.org/10.1007/BF00116837\n\nBreiman, L. (2001). Random forests. Machine Learning, 45(1), 5-32. https://doi.org/10.1023/A:1010933404324\n\nCaruana, R., Gehrke, J., Koch, P., & Sturm, M. (2015). The importance of model interpretability in credit scoring. Proceedings of the 2015 IEEE International Conference on Data Mining, 567-576. https://doi.org/10.1109/ICDM.2015.61\n\nChen, T., & Guestrin, C. (2016). XGBoost: A scalable tree boosting system. Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 785-794. https://doi.org/10.1145/2939672.2939785\n\nFriedman, J. H. (2001). Greedy function approximation: A gradient boosting machine. Annals of Statistics, 29(5), 1189-1232. https://doi.org/10.1214/aos/1013203451\n\nGangan, A., Bhattacharyya, D., & Gupta, P. (2020). Credit scoring using XGBoost: A comparison of machine learning approaches. International Journal of Computer Applications, 175(13), 1-6. https://doi.org/10.5120/ijca2020919469\n\nKe, G., Meng, Q., & Finley, T. (2017). LightGBM: A highly efficient gradient boosting decision tree. Proceedings of the 31st International Conference on Neural Information Processing Systems, 3146-3154. https://doi.org/10.5555/3295222.3295268\n\nLiao, S. H., & Lu, C. C. (2018). Predicting credit scoring using LightGBM: An empirical study. Sustainable Computing: Informatics and Systems, 19, 1-7. https://doi.org/10.1016/j.suscom.2017.11.003\n\nOhlson, J. A. (1980). Financial ratios and the probabilistic prediction of bankruptcy. Journal of Accounting Research, 18(1), 109-131. https://doi.org/10.2307/2490395\n\nZhao, Z. (2018). An analysis of credit risk prediction using machine learning. Journal of Computer Science and Technology, 33(5), 987-1003. https://doi.org/10.1007/s11390-018-1825-2\n\nMd Jamil Ahmmed, Md Mohibur Rahman, Ashim Chandra Das, Pritom Das, Tamanna Pervin, Sadia Afrin, Sanjida Akter Tisha, Md Mehedi Hassan, & Nabila Rahman. (2024). COMPARATIVE ANALYSIS OF MACHINE LEARNING ALGORITHMS FOR BANKING FRAUD DETECTION: A STUDY ON PERFORMANCE, PRECISION, AND REAL-TIME APPLICATION. International Journal of Computer Science & Information System, 9(11), 31‚Äì44. https://doi.org/10.55640/ijcsis/Volume09Issue11-04\n\nDas, A. C., Mozumder, M. S. A., Hasan, M. A., Bhuiyan, M., Islam, M. R., Hossain, M. N., ... & Alam, M. I. (2024). MACHINE LEARNING APPROACHES FOR DEMAND FORECASTING: THE IMPACT OF CUSTOMER SATISFACTION ON PREDICTION ACCURACY. The American Journal of Engineering and Technology, 6(10), 42-53.\n\nMd Risalat Hossain Ontor, Asif Iqbal, Emon Ahmed, Tanvirahmedshuvo, & Ashequr Rahman. (2024). LEVERAGING DIGITAL TRANSFORMATION AND SOCIAL MEDIA ANALYTICS FOR OPTIMIZING US FASHION BRANDS‚Äô PERFORMANCE: A MACHINE LEARNING APPROACH. International Journal of Computer Science & Information System, 9(11), 45‚Äì56. https://doi.org/10.55640/ijcsis/Volume09Issue11-05\n\nRahman, A., Iqbal, A., Ahmed, E., & Ontor, M. R. H. (2024). PRIVACY-PRESERVING MACHINE LEARNING: TECHNIQUES, CHALLENGES, AND FUTURE DIRECTIONS IN SAFEGUARDING PERSONAL DATA MANAGEMENT. International journal of business and management sciences, 4(12), 18-32.\n\nShak, M. S., Uddin, A., Rahman, M. H., Anjum, N., Al Bony, M. N. V., Alam, M., ... & Pervin, T. (2024). INNOVATIVE MACHINE LEARNING APPROACHES TO FOSTER FINANCIAL INCLUSION IN MICROFINANCE. International Interdisciplinary Business Economics Advancement Journal, 5(11), 6-20.\n\nNaznin, R., Sarkar, M. A. I., Asaduzzaman, M., Akter, S., Mou, S. N., Miah, M. R., ... & Sajal, A. (2024). ENHANCING SMALL BUSINESS MANAGEMENT THROUGH MACHINE LEARNING: A COMPARATIVE STUDY OF PREDICTIVE MODELS FOR CUSTOMER RETENTION, FINANCIAL FORECASTING, AND INVENTORY OPTIMIZATION. International Interdisciplinary Business Economics Advancement Journal, 5(11), 21-32.\n\nBhattacharjee, B., Mou, S. N., Hossain, M. S., Rahman, M. K., Hassan, M. M., Rahman, N., ... & Haque, M. S. U. (2024). MACHINE LEARNING FOR COST ESTIMATION AND FORECASTING IN BANKING: A COMPARATIVE ANALYSIS OF ALGORITHMS. Frontline Marketing, Management and Economics Journal, 4(12), 66-83.\n\nRahman, A., Iqbal, A., Ahmed, E., & Ontor, M. R. H. (2024). PRIVACY-PRESERVING MACHINE LEARNING: TECHNIQUES, CHALLENGES, AND FUTURE DIRECTIONS IN SAFEGUARDING PERSONAL DATA MANAGEMENT. Frontline Marketing, Management and Economics Journal, 4(12), 84-106.\n\nAl Mamun, A., Hossain, M. S., Rishad, S. S. I., Rahman, M. M., Shakil, F., Choudhury, M. Z. M. E., ... & Sultana, S. (2024). MACHINE LEARNING FOR STOCK MARKET SECURITY MEASUREMENT: A COMPARATIVE ANALYSIS OF SUPERVISED, UNSUPERVISED, AND DEEP LEARNING MODELS. The American Journal of Engineering and Technology, 6(11), 63-76.\n\nDas, A. C., Rishad, S. S. I., Akter, P., Tisha, S. A., Afrin, S., Shakil, F., ... & Rahman, M. M. (2024). ENHANCING BLOCKCHAIN SECURITY WITH MACHINE LEARNING: A COMPREHENSIVE STUDY OF ALGORITHMS AND APPLICATIONS. The American Journal of Engineering and Technology, 6(12), 150-162.\n\nMiah, J., Khan, R. H., Ahmed, S., & Mahmud, M. I. (2023, June). A comparative study of detecting covid 19 by using chest X-ray images‚ÄìA deep learning approach. In 2023 IEEE World AI IoT Congress (AIIoT) (pp. 0311-0316). IEEE.\n\nMiah, J. (2024). HOW FAMILY DNA CAN CAUSE LUNG CANCER USING MACHINE LEARNING. International Journal of Medical Science and Public Health Research, 5(12), 8-14.\n\nRahman, M. M., Akhi, S. S., Hossain, S., Ayub, M. I., Siddique, M. T., Nath, A., ... & Hassan, M. M. (2024). EVALUATING MACHINE LEARNING MODELS FOR OPTIMAL CUSTOMER SEGMENTATION IN BANKING: A COMPARATIVE STUDY. The American Journal of Engineering and Technology, 6(12), 68-83.\n\nDas, P., Pervin, T., Bhattacharjee, B., Karim, M. R., Sultana, N., Khan, M. S., ... & Kamruzzaman, F. N. U. (2024). OPTIMIZING REAL-TIME DYNAMIC PRICING STRATEGIES IN RETAIL AND E-COMMERCE USING MACHINE LEARNING MODELS. The American Journal of Engineering and Technology, 6(12), 163-177.\n\nHossain, M. N., Hossain, S., Nath, A., Nath, P. C., Ayub, M. I., Hassan, M. M., ... & Rasel, M. (2024). ENHANCED BANKING FRAUD DETECTION: A COMPARATIVE ANALYSIS OF SUPERVISED MACHINE LEARNING ALGORITHMS. American Research Index Library, 23-35.\n\nAhmmed, M. J., Rahman, M. M., Das, A. C., Das, P., Pervin, T., Afrin, S., ... & Rahman, N. (2024). COMPARATIVE ANALYSIS OF MACHINE LEARNING ALGORITHMS FOR BANKING FRAUD DETECTION: A STUDY ON PERFORMANCE, PRECISION, AND REAL-TIME APPLICATION. American Research Index Library, 31-44.\n\nAl Bony, M. N. V., Das, P., Pervin, T., Shak, M. S., Akter, S., Anjum, N., ... & Rahman, M. K. (2024). COMPARATIVE PERFORMANCE ANALYSIS OF MACHINE LEARNING ALGORITHMS FOR BUSINESS INTELLIGENCE: A STUDY ON CLASSIFICATION AND REGRESSION MODELS. Frontline Marketing, Management and Economics Journal, 4(11), 72-92.\n\nDas, A. C., Rishad, S. S. I., Akter, P., Tisha, S. A., Afrin, S., Shakil, F., ... & Rahman, M. M. (2024). ENHANCING BLOCKCHAIN SECURITY WITH MACHINE LEARNING: A COMPREHENSIVE STUDY OF ALGORITHMS AND APPLICATIONS. The American Journal of Engineering and Technology, 6(12), 150-162.\n\nAhmed, M. P., Das, A. C., Akter, P., Mou, S. N., Tisha, S. A., Shakil, F., ... & Ahmed, A. (2024). HARNESSING MACHINE LEARNING MODELS FOR ACCURATE CUSTOMER LIFETIME VALUE PREDICTION: A COMPARATIVE STUDY IN MODERN BUSINESS ANALYTICS. American Research Index Library, 06-22.\n\nAkter, P., Hossain, S., Siddique, M. T., Ayub, M. I., Nath, A., Nath, P. C., ... & Hassan, M. M. (2025). Sentiment Analysis of Consumer Feedback and Its Impact on Business Strategies by Machine Learning. The American Journal of Applied sciences, 7(01), 6-16.\n\nHossain, M. S., Khan, A., Das, P., Haque, M. S. U., Kamruzzaman, F., Akter, S., ... & Miah, M. R. (2025). Enhanced market trend forecasting using machine learning models: a study with external factor integration. International Interdisciplinary Business Economics Advancement Journal, 6(01), 5-12.\n\ninLibrary ‚Äî is a scientific electronic library built on the paradigm of open science (Open Science), the main tasks of which are the popularization of science and scientific activities, public quality control of scientific publications, the development of interdisciplinary research, a modern institute of scientific review, increasing the citation of Uzbek science and building a knowledge infrastructure.\n\nCONTACTS:\n\nRepublic of Uzbekistan, Tashkent, Parkent street 51, floor 2\n\n(+998) 99-006-61-10\n\ninfo@inscience.uz\n\nNAVIGATION:\n",
    "content3": "\nData Science in Finance and Economics\n\nData Science in Finance and Economics\n\nBankruptcy prediction using machine learning and an application to the case of the COVID-19 recession\n\nJEL Codes: O30, E37, E60\n\nAbstract\n\nBankruptcy prediction is an important problem in finance, since successful predictions would allow stakeholders to take early actions to limit their economic losses. In recent years many studies have explored the application of machine learning models to bankruptcy prediction with financial ratios as predictors. This study extends this research by applying machine learning techniques to a quarterly data set covering financial ratios for a large sample of public U.S. firms from 1970‚Äì2019. We find that tree-based ensemble methods, especially XGBoost, can achieve a high degree of accuracy in out-of-sample bankruptcy prediction. We next apply our best model, using XGBoost, to the problem of predicting the overall bankruptcy rate in USA in the second half of 2020, after the COVID-19 pandemic had necessitated a lockdown, leading to a deep recession. Our model supports the prediction, made by leading economists, that the rate of bankruptcies will rise substantially in 2020, but it also suggests that this elevated level will not be much higher than 2010.\n\n1.   Introduction\n\nBankruptcy prediction is the problem of detecting financial distress in businesses which will lead to eventual bankruptcy. Bankruptcy prediction has been studied since at least 1930s. The early models of bankruptcy prediction employed univariate statistical models over financial ratios. The univariate models were followed by multi-variate statistical models such as the famous Altman Z-score model. The recent advances in the field of Machine learning have led to the adoption of Machine learning algorithms for bankruptcy prediction. Machine Learning methods are increasingly being used for bankruptcy prediction using financial ratios. A study by Barboza, Kimura and Altman found that Machine Learning models can outperform classical statistical models like multiple discriminant analysis (MDA) by a significant margin in bankruptcy prediction (Barboza et al., 2017).\n\nBankruptcy prediction is an important for modern economies because early warnings of bankrupt help not only the investor but also public policy makers to take proactive steps to minimize the impact of bankruptcies. The reasons that add to the significance of bankruptcy prediction are as follows:\n\n(1). Better allocation of resources\n\nInstitutional investors, banks, lenders, retail investors are always looking at information that predicts financial distress in publicly traded firms. Early prediction of bankruptcy helps not only the investors and lenders but also the managers of a firm to take corrective action thereby conserving scare economic resources. Efficient allocation of capital is the cornerstone of growth in modern economies.\n\n(2). Input to policy makers\n\nAccurate prediction of bankruptcies of businesses and individuals before they happen gives law makers and policy makers some additional time to alleviate systemic issues that might be causing the bankruptcies. Indeed, with bankruptcies taking center stage in political discourse of many countries, the accurate prediction of bankruptcy is a key input for politicians, bureaucrats and in general for anyone who is making public policy.\n\n(3). Corrective action for business managers\n\nThe early prediction of bankruptcy is likely to highlight business issues thereby giving the company's manager additional time to make decisions that will help avoid bankruptcy. This effect is likely to be more profound in public companies where the management has a fiduciary duty to the shareholders.\n\n(4). Identification of sector wide problems\n\nBankruptcy prediction models that flag firms belonging to a certain sector are likely to be a leading indicator of an upcoming downturn in a certain sector of an economy. With robust models, the business managers and government policy makers would become aware and take corrective action to limit the magnitude and intensity of the downturn in the specific sector. Industry groups in turn has been shown to significantly effect forecasting models (Chava and Jarrow, 2004).\n\n(5). Signal to Investors\n\nInvestors can make better and more informed decisions based on the prediction of bankruptcy models. This not only forces the management of firms to take corrective action but also helps to soften the overall economic fallout that results from the bankruptcies. Empirical studies have shown that investment opportunities are significantly related to likelihood of bankruptcy (Lyandres & Zhdanov, 2007).\n\n(6). Relation to adjacent problems\n\nBankruptcy prediction is often the first step used by ratings agencies to detect financial distress in firms. Based on the predictions of bankruptcy models, ratings agencies investigate and assess credit risk. Getting flagged by bankruptcy prediction models is often the first step that triggers the process of revising credit ratings. A literature survey covering 2000‚Äì2013 demonstrates the close relation between bankruptcy prediction and credit risk (Garc√≠a et al., 2015).\n\nMost past studies in bankruptcy prediction including those using Machine Learning have used a relatively small sample of firms and a small number of financial ratios. This study distinguishes itself by using a much larger dataset having data for 21,114 U.S. firms (samples) and 57 financial ratios (features). Our dataset covers US firms from 1970 to 2020. Bankruptcy prediction models have been researched and built since the 1960s. The models built from 1960 to 1990 were primarily statistical models such as univariate, multiple discriminant analysis and logit and probit models. Starting from 1990s machine learning models started outperforming statistical models. Since this study applies the most popular contemporary machine learning algorithms using a big data set, we will compare our model with the machine learning models built since the 1990s. A full listing outlining the comparison with past machine learning studies and models for bankruptcy prediction is shown in the Table 1.\n\nIn this study we have used three popular machine learning techniques‚ÄîRandom Forest, Support Vector Machines, and XGBoost to construct forecasting models. We find that Machine Learning models perform very well, with XGBoost being the most successful technique that achieves an accuracy score of more than 99% in out of sample testing.\n\nWe also apply our XGBoost model to an important current issue, the task of predicting bankruptcies during the second half of 2020. The depth of the recession caused by the lockdowns that have been imposed to contain the COVID-19 pandemic has raised worries that corporate bankruptcies may rise substantially in the near future. According to a report in the New York Times (2020), Edward Altman, a pioneer of bankruptcy prediction research, and the creator of the famous Z score model, expects a \"tsunami of bankruptcies\" that will exceed the number of bankruptcies that followed the 2008 financial crisis. The result from our Machine Learning model confirms Prof Altman's fears that corporate bankruptcies will rise substantially in late 2020 and equal the highs seen during the 2008-09 recession. However, this study finds that the elevated level of bankruptcies will not be significantly different from 2010.\n\nThe previous studies done for bankruptcy prediction have not taken a systematic view of the data used to build the models. The previous studies have been more focused on the models rather than on the data used to build the models. This study offers a much more balanced view where both the data and the models are given equal importance. To begin with, we have use Compustat are a source database to get an exhaustive list of financial ratios over US firms from 1970 to 2020. Compustat is a high-quality database used by several famous finance related papers such as Fama and French (1993). Most of the previous studies have used relatively small datasets as compared to ours. This study takes a systematic look at as many features as possible to train our machine learning models. Our balanced approach is also consistent with the shift from model centric to data centric approach proposed by Andrew Ng (Gil Press, 2021).\n\nThe rest of the paper is structured as follows:\n\nSection 2‚ÄîDescribes the existing literature for bankruptcy prediction.\n\nSection 3‚ÄîDescribes the data and the method used to clean, process, and fit the data into our machine learning models. This section also covers the process used to predict the number of bankruptcies using Q2-2020 ratios.\n\nSection 4‚ÄîDescribes the results observed from the experiments\n\nSection 5‚ÄîPresents our final comments and discusses the implications of the results.\n\n2.   Literature review\n\nBankruptcy prediction models prior to 1990s were primarily statistical models employing univariate, multivariate and logit & probit techniques. In 1966, Beaver applied univariate analysis in which the predictive ability of 30 financial ratios was tested one at a time to predict bankruptcy (Beaver, 1966). Altman in 1968 performed a multi-variate discriminant analysis (MDA) using 5 ratios to create a linear discriminant function of 5 variables (Altman, 1968). Several variants of MDA were developed in the following years. Edmister used 19 financial ratios to build a linear model for bankruptcy prediction (Edmister, 1972). Deakin found that a linear combination of the 14 ratios could be used to predict bankruptcy five years prior to failure (Deakin, 1972). Ohlson studied the shortcomings of MDA models and built a conditional logit model using maximum likelihood estimation (Ohlson, 1980). The datasets used in all these studies were quite small as compared to modern standards. Ohlson's study for example used a dataset of 2058 firms out of which 105 firms represented the bankrupt class.\n\nThe next phase in the evolution of bankruptcy models started in the 1990s with several machine learning algorithms outperforming the older statistical models. Machine learning models such as Random Forests, Support Vector Machines (SVM) and Gradient Boosted Trees were found to be particularly effective for bankruptcy prediction. Barboza, Kimura and Altman compared statistical models with machine learning (ML) models. They found the Random Forests outperformed Alman's Z-score model by a significant margin (Barboza et al., 2017). These results were corroborated by studies (Joshi et al., 2018; Rustam and Saragih, 2018; Gnip and Drot√°r, 2019). Support Vector Machine (SVM) was also found to be a very effective machine learning algorithm in several studies. Hang et al. (2004) and Chen et al. (2008) achieved superior results for credit rating classification problem by using SVM. Song et al. (2008) used SVM to predict financial distress. Some studies also found boosted trees-based algorithms to outperform SVM. Wang, Ma and Yang proposed a new boosted tree-based algorithm for bankruptcy prediction which they found to be more effective than SVM (Wang et al., 2014). Heo and Yang (2014) used Adaboost algorithm to predict bankruptcy for Korean construction firm. They found Adaboost to have better accuracy than SVM (Heo and Yang, 2014). A more recent study in 2021 has used XGBoost and Random Forest algorithms to predict bankruptcies over 12 months. This study used a medium sized training dataset containing data for 8959 firms registered in Italy (Perboli and Arabnezad, 2021). Another recent study uses a database of Taiwanese firms to predict bankruptcy. This study used data set contain 96 attributes for 6819 firms to train machine learning models (Wang and Liu, 2021). One common attribute shared by all the forementioned studies is the relatively small size of their training data sets. The datasets used by these studies are small as compared to datasets used in the big data era. The largest training dataset in these studies had just 2600 samples which is quite small.\n\nBased on the literature review, the following trends become apparent:\n\n‚óè  Machine Learning Models are now consistently outperforming statistical models\n\n‚óè  The training data sets used to train the existing machine learning models are relatively small as compared to the data sets used for training models in other application areas.\n\n‚óè  Ensemble methods such as Random Forest and Boosted trees have performed better than other models in bankruptcy prediction.\n\n3.   Data and methodology\n\nThis study differentiates itself from previous studies by using a substantially larger dataset as compared to previous studies. We use a very standard and well documented dataset called Compustat to retrieve the financial ratios. Compustat is a standard financial dataset used in financial research. Compustat has been used by some very popular papers in finance such as Fama and French (1993). We have used 57 financial ratios that are listed in Table 2. Financial ratios are inputs used to train Bankruptcy prediction models. While most studies use fewer financial ratios, this study applies a large set of financial ratios of US Firms from 1970‚Äì2020 (50 years) to train Random Forest, SVM and XGBoost Models. This section discusses the overall methodology which includes data cleaning, balancing, model fitting, and analysis of results.\n\nPrevious studies have used small to medium sized data sets for training Machine learning models. This study sets itself apart by using a much larger training dataset. We used financial ratios data set from Compustat. The financial ratios data set was then joined with another dataset called Bankruptcy data set. The bankruptcy data set contains the data such as date of bankruptcy, bankruptcy reason and GVKEY (primary key) while the financial ratios dataset contains all the financial ratios mentioned in Table A.1. The two datasets were programmatically joined using a common field named GVKEY. GVKEY is a unique identifier assigned to each firm. The relation amongst the two datasets that were used to create our labelled training dataset is best represented by the ER schema diagram shown in Figure 1.\n\nThe financial ratios dataset we have used contains 57 financial ratios mentioned in Table A.1 in Appendix A. This is an exhaustive list of features used to train our models. We have included ratios which are often overlooked but are likely to help detect patterns related to edge cases.\n\nThe first step of building a predictive model is data pre-processing and cleaning. The original data from Compustat had 75 financial ratios for 21,114 US firms. This data covered firms established in the US between 1970 and 2020. The dataset contained firms that belonged to 2 classes: bankrupt and non-bankrupt or continuing enterprises. The dataset contains 1212 bankrupt firms and 19,902 non-bankrupt firms. The distribution of data points (samples) belonging to these two classes is summarized in Table 2. The next step was to drop features which had null values for more than 6000 firms out of 21,114 firms. This step ensured that we don't have more than 30% of null values in any feature. The goal is to ensure that the true distribution generating this data is preserved and learned by our machine learning models. 18 features (financial ratios) were dropped from the data set because they had null values for more than 6000 (30% of total number of firms). The dataset now had 75 ‚àí 18 = 57 features. Next, we scaled our data to have mean = 0 and variance = 1 using Scikit-learns Standard Scaler class. Scaling is required to ensure that gradient descent converges on the minima of the loss function. The last step of data cleaning was to impute the missing values in the 57 financial ratios (features). For imputing the missing values, we used the KNN algorithm which used three nearest neighbours to estimate the missing value. Further, the weight assigned to each neighbour is a function of its Euclidean distance from the data point with missing value. KNN with 3-neighbours has been found to be effective in preserving the true distribution of the data (Beretta and Santaniello, 2016).\n\nThe cleaned and scaled dataset without any missing values was an imbalanced dataset (see Table 2). The dominant class was the bankruptcy class. Approximately 90% of the samples belonged to the majority class which is non-bankrupt firms. Since the goal of this study is train a classifier to identify bankrupt firms, we decided to balance the classes in our training data. This would ensure that our model would learn about the minority class which is the bankrupt class. This is important in the context of bankruptcy prediction because detecting samples belonging to the bankrupt class. To balance the dataset, we use the Synthetic Minority Over-sampling technique (SMOTE) proposed by Chawla et al. (Chawla et al., 2002). SMOTE generates synthetic samples using the features of the data. The minority class is oversampled by taking a minority class sample and then a line is drawn from this minority class sample to k-nearest minority class samples. Synthetic minority class samples are generated along the line joining the minority class sample to its minority class neighbours. Additionally, to ensure that our balanced dataset facilitated learning of the bankrupt class, we also used Borderline-SVM SMOTE. Borderline-SVM SMOTE technique uses samples close the decision boundary (support vectors) to create synthetic samples (Nguyen et al., 2011). Finally, we used the Adaptive Synthetic Sampling (ADASYN) algorithm of He, Bai, Garcia and Li to generate samples in regions of feature space where the density of minority samples is low (He et al., 2008). The result was a balanced dataset containing 19902 samples of non-bankrupt class and 20,517 bankrupt class. The balanced dataset has 57 financial ratios (features).\n\nThe balanced dataset was then shuffled and split into training set containing 70% of the samples and test set containing 30% of the samples. The purpose of creating a test set is to test the accuracy of the models on data that the models have not been trained on. Collecting metrics based on the test set gives practitioners an idea of the generalization performance of machine learning models.\n\nThe training data set was fitted into three machine learning models. These models are: Random Forest, Support Vector Machine (SVM) and XGBoost. After fitting, the models were then used to predict for samples in the test set to assess their relative performance.\n\nFor comparing the performance of the models, we decided to use Accuracy score, Receiver Operating Curve (ROC) and Area Under ROC Curve (AUC). Accuracy score can be used because we are training our models using a balanced dataset. However, to get a better idea of the True Positive Rate (TPR) and False Positive Rate (FPR) we decided to employ ROC and AUC metrics as well. It is important to compare the TPR and FPR because it is more to avoid False negatives (FN) as compared to False positives (FP). False negative (FN) would be a firm which would go bankrupt but is wrongly classified by our model as a non-bankrupt sample. False positive (FP) on the other hand would be a firm that is not bankrupt but is wrongly classified as a bankrupt firm.\n\nThe goal of this study is to predict number of bankruptcies within the next 30, 90 and 180 days. We trained 3 different models to predict the number of bankruptcies within 30, 90 and 180 days. The models were built and analysed using the same approach. The only difference was that the training and test labels for each model were derived from the bankruptcy date. For example, to train the model for predicting number of bankruptcies within 30 days, we used\n\nwhere\n\nwhere\n\nelse\n\nTherefore, we trained 9 models to predict bankruptcies within 30, 90 and 180 days. For example, for predicting bankruptcy within 30 days we trained Random Forest, SVM and XGBoost. After training the models, we picked the best model based on performance metrics described in previous section and then we used the best model to predict the number of bankruptcies using the latest Q2 2020 financial ratios from Capital IQ. In this final prediction set, we only kept data for firms which did not have any significant gaps or holes. Finally, we used the final prediction set from Q2 2020 to predict the number of bankruptcies we expect to happen over the next 30, 90 and 180 days.\n\n4.   Results\n\nAs mentioned in the previous section, we trained 9 models, using three different techniques, RF, SVM, XGBoost, for predicting bankruptcies over 30, 90 and 180 days. Next, we used the test set to make predictions and then assessed the relative performance. Based on the chosen metrics of accuracy score and Area under ROC curve (ROC AUC), XGBoost outperformed the other models for predicting bankruptcy within 30, 90 and 180 days. The actual scores for accuracy and AUC are presented in Table 3.\n\nThe accuracy score of XGBoost models is consistently better than SVM and Random Forest. This result is also consistent with the ROC curves which are shown in Figure 2 below.\n\nAs seen in Figure 2, the ROC curve for XGBoost is closest to the top left corner thereby covering maximum area under it. XGBoost is therefore the best performing model closely followed by Random Forest. The fact that these metrics are calculated using the test set (containing data which model has not been trained on) gives us confidence in the ability of our models to generalize.\n\nWe present the performance metrics of previous studies in Table 4. Previous studies have used 2 performance metrics: Test accuracy and Area Under ROC curve (AUC). To keep the comparison consistent, we have computed both test accuracy score and AUC for our models (see Table 3). Our best model built using XGBoost significantly outperforms the models built in previous studies. The accuracy of our XGBoost model for prediction bankruptcy within 180 days is 98.69% which is lower than the test accuracy of our XGBoost models for predicting bankruptcies within 30 and 90 days. However, our model for predicting bankruptcies within 180 days has a higher test accuracy (98.69%) than models built in previous studies. Similarly, our model for predicting bankruptcies within 180 days has an AUC score of 0.99 which is higher than the AUC score reported by previous studies. Our performance metrics of accuracy and AUC score are computed over out of training samples which also indicates to the robustness of our results.\n\nNext, we apply our best model, using XGBoost, to the data from Q2-2020 to evaluate the possibility of a substantial upsurge in business bankruptcies in the second half of 2020 because of the deep 2020 recession caused by the pandemic. We apply this best model to the latest available ratios, for Q2-2020, and classify a firm as going bankrupt during the next 30, 90, or 180 days if the predicted probability of bankruptcy is higher than 0.50.\n\nUsing this method, our best model in each category predicted 74 bankruptcies within 30 days, 189 bankruptcies within 90 days and 354 Bankruptcies within 180 days. This prediction is for all firms contained in the S & P Global database, both public and private. The predictions for the number of bankruptcies are summarized in Table 5.\n\nS & P Global has reported a total of 336 actual bankruptcies until the end of June 2020. If we add our prediction of 354 bankruptcies to the actual bankruptcies, then we predict a total of 336 + 354 = 690 bankruptcies in 2020. We summarize our predictions in Table 6 below.\n\nSince the number of firms in the database changes from year to year, we decided to compare the prediction for 2020 with the past by using bankruptcy rates, i.e., the ratio of the number of bankruptcies to the total number of firms. As shown in Table 7, our prediction of 690 bankruptcies in 2020 represents a bankruptcy rate of 4.35% for all US firms. This rate is the highest in the last 10 years. The second highest rate of 4.2%, only slightly lower, was seen in 2010, in the immediate aftermath of the 2008-09 recession. The average rate during the economic expansion years of 2011‚Äì2019 was 3.2%, more than a full percentage point lower than the predicted 2020 rate. We conclude that we will indeed see a much higher rate bankruptcies in 2020, but it is unlikely to be substantially larger than in 2010.\n\n5.   Conclusions\n\nWe find that two different Machine Learning algorithms, Random Forest (RF) and Extreme Gradient Boosting (XGBoost) produce accurate predictions of whether a firm will go bankrupt within the next 30, 90, or 180 days, using financial ratios as input features. The XGBoost based models perform exceptionally well, with 99% out-of-sample accuracy. Our training dataset uses a large database of public US firms over a period of 49 years, 1970‚Äì2019, and 57 financial ratios. This study has used a substantially larger training dataset as compared to previous studies.\n\nAn application of our best performing XGBoost model to Q2-2020 financial data for a sample of both private and public U.S. firms shows that the bankruptcy rate will climb substantially higher in 2020 than in the expansion years of 2011‚Äì2019. However, our model suggests that the rate will be only marginally higher than in 2010.\n\nWe identify the following areas for further research:\n\n‚óè  Adding macro-economic features‚ÄîIt will be interesting to add macro-economic features to training data used for training machine learning models for bankruptcy prediction.\n\n‚óè  Train deep neural networks with different topologies‚ÄîAnother interesting area of research would be to apply different types of deep neural networks such as TabNet and Recurrent neural networks.\n\nConflict of interest\n\nAll authors declare no conflicts of interest in this paper.\n\nReferences\n\nThis article has been cited by:\n\nTop\n"
}